At the time, Google served an average of 18 million queries/day.
Probability that random surfer visits a page is its PR.
If there are some pages that point to it and have a high PageRank.
Associate the text of a link with the page that the link is on and the page the link points to.
Anchors may exist for documents which cannot be indexed (i.e.
Full raw HTML of pages is available in a repository.
In the past, focused largely on scientific stories, articles, etc.
Document Index � Keep info of each document (docID, fixed width ISAM index)
Current doc status, a pointer into the repository, a doc checksum, and various statistics.
Implemented with a hash table of pointers (word ids) to barrels (that are sorted lists)
Hit Lists � Stores occurrences of a particular word in a particular document.
Types of hits: Plain, Fancy and anchor (2 bytes per hit)
Forward Index � Barrel holds a range of word ids.
Can be sorted by doc id or by ranking of word occurrence.
Crawlers have different states: DNS lookup, connecting to host, send request, receiving response.
Parsing � Parsers need to handle errors very well (typos, formatting, etc.)
Words converted into word id and occurrences into hit lists.
Sorting � Forward barrels are sorted by word id to produce an inverted index.
Ranking system: � Every hit list includes position, font and capitalization info.
Consider each hit to be one of several different type and each of which has its own type-weight.
Seek to the start of the doclist in the short barrel for every word.
Scan through the doclists until there is a document that matches all the search terms.
If we are in the short barrels and at the end of any doclist, seek to the start of the doclist in the full barrel for every word and go to step 4
If we are not at the end of any doclist go to step 4
Sort the documents that have matched by rank and return the top k.
Additional storage used by Google for indexes, temporary storage, lexicon, etc.
To improve efficiency, the Indexer and Crawlers need to be capable of simultaneous execution.
Sorting needs to be done in parallel on several machines.
Disk I/O – Requires most time (seek time, transfer time, network delay, etc.)
Complete architecture for gathering web pages, indexing them, and performing search queries over them.
