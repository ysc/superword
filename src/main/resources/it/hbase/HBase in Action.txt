The publisher offers discounts on this book when ordered in quantity.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the publisher.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in the book, and Manning Publications was aware of a trademark claim, the designations have been printed in initial caps or all caps.
Recognizing the importance of preserving what has been written, it is Manning’s policy to have the books we publish printed on acid-free paper, and we exert our best efforts to that end.
Recognizing also our responsibility to conserve the resources of our planet, Manning books are printed on paper that is at least 15 percent recycled and processed without the use of elemental chlorine.
Its basic operation can be explained on the back of a napkin over a drink (or two)
The distributed HBase application is made up of client and server processes.
HBase uses yet another distributed system, Apache ZooKeeper, to manage its cluster state.
Most deployments throw in MapReduce to assist with bulk loading or running distributed full-table scans.
It can be tough to get all the pieces pulling together in any approximation of harmony.
Setting up the proper environment and configuration for HBase is critical.
HBase is a general data store that can be used in a wide variety of applications.
It ships with defaults that are conservatively targeted at a common use case and a generic hardware profile.
If your HBase data-schema model is out of alignment with how the data store is being queried, no amount of configuration can compensate.
You can achieve huge improvements when the schema agrees with how the data is queried.
If you come from the realm of relational databases, you aren’t used to modeling schema.
Although there is some overlap, making a columnar data store like HBase hum involves a different bag of tricks from those you use to tweak, say, MySQL.
If you need help with any of these dimensions, or with others such as how to add custom functionality to the HBase core or what a well-designed HBase application.
FOREWORDxii should look like, this is the book for you.
In this timely, very practical text, Amandeep and Nick explain in plain language how to use HBase.
It’s the book for those looking to get a leg up in deploying HBase-based applications.
He has been paying the HBase community back ever since by helping others on the project mailing lists.
Nick showed up not long after and has been around the HBase project in one form or another since that time, mostly building stuff on top of it.
These boys have done the HBase community a service by taking the time out to research and codify their experience in a book.
You could probably get by with this text and an HBase download, but then you’d miss out on what’s best about HBase.
A functional, welcoming community of developers has grown up around the HBase project and is all about driving the project forward.
It’s the participating individuals who make HBase what it is.
You could either use one of the free databases, such as MySQL or PostgreSQL, or a pure key/value store like Berkeley DB.
Or you could develop something on your own and open up the playing field—which of course only a few of us were bold enough to attempt, at least in those days.
These solutions might have worked, but one of the major concerns was scalability.
This feature wasn’t well developed and was often an afterthought to the existing systems.
I had to store billions of documents, maintain a search index on them, and allow random updates to the data, while keeping index updates short.
Both had a strong pedigree, and they came out of Google, a Valhalla of the best.
My belief was that if these systems could serve an audience as big as the world, their underlying foundations must be solid.
Thus, I proposed to built my project with HBase (and Lucene, as a side note)
But as we flash forward through the years, the playing field grew, and we saw the advent of many competing, or complementing, solutions.
The term NoSQL was used to group the increasing number of distributed databases under a common umbrella.
The next attempt to frame the various nascent systems was based on how their features compared: strongly consistent versus eventual consistent models, which were built to fulfill specific needs.
People again tried to put HBase and its peers into this perspective: for example, using Eric Brewer’s CAP theorem.
And yet again a heated discussion ensued about what was most important: being strongly consistent or being able to still serve data despite catastrophic, partial system failures.
And as before, to me, it was all about choices—but I learned that you need to fully understand a system before you can use it.
It’s not about slighting other solutions as inferior; today we have a plentiful selection, with overlapping qualities.
You have to become a specialist to distinguish them and make the best choice for the problem at hand.
Without a doubt, its adoption by wellknown, large web companies has raised its profile, proving that it can handle the given use cases.
These companies have an important advantage: they employ very skilled engineers.
On the other hand, a lot of smaller or less fortunate companies struggle to come to terms with HBase and its applications.
We need someone to explain in plain, no-nonsense terms how to build easily understood and reoccurring use cases on top of HBase.
Their wealth of real-world experience at making HBase work in a variety of use cases will help you understand the intricacies of using the right data schema and access pattern to successfully build your next project.
Thank you to all who have treated me as a fellow member; to those who daily help with patches and commits to make HBase even better; to companies that willingly sponsor engineers to work on HBase full time; and to the PMC of HBase, which is the absolutely most sincere group of people I have ever had the opportunity know—you rock.
And finally a big thank-you to Nick and Amandeep for writing this book.
It contributes to the value of HBase, and it opens doors and minds.
We met before you started writing the book, and you had some concerns.
I stand by what I said then: this is the best thing you could have done for HBase and the community.
I, for one, am humbled and proud to be part of it.
It was a young project then, released only in the preceding year.
As early releases go, it was quite capable, although not without its fair share of embarrassing warts.
The term NoSQL hadn’t even been presented yet but would come into common parlance over the next year.
The community was polarized, with people either bashing relational databases for their foolish rigidity or mocking these new technologies for their lack of sophistication.
The people exploring this new idea were mostly in internet companies, and I came to work for such a company—a startup interested in the analysis of social media content.
Facebook still enforced its privacy policies then, and Twitter wasn’t big enough to xv.
I left a company where I’d spent the better part of three years working on a hierarchical database engine.
We made extensive use of Berkeley DB, so I was familiar with data technologies that didn’t have a SQL engine.
I joined a small team tasked with building a new data-management platform.
We had an MS SQL database stuffed to the gills with blog posts and comments.
When our daily analysis jobs breached the 18-hour mark, we knew the current system’s days were numbered.
After cataloging a basic set of requirements, we set out to find a new data technology.
We were a small team and spent months evaluating different options while maintaining current systems.
We studied the CAP theorem and eventual consistency—and the tradeoffs.
Despite its warts, we decided on HBase, and we convinced our manager that the potential benefits outweighed the risks he saw in open source technology.
I’d played a bit with Hadoop at home but had never written a real MapReduce job.
I’d heard of HBase but wasn’t particularly interested in it until I was in this new position.
With the clock ticking, there was nothing to do but jump in.
We scrounged up a couple of spare machines and a bit of rack, and then we were off and running.
It was a .NET shop, and we had no operational help, so we learned to combine bash with rsync and managed the cluster ourselves.
I joined the mailing lists and the IRC channel and started asking questions.
He was working on his master’s thesis, hacking up HBase to run on systems other than Hadoop.
Soon he finished school, joined Amazon, and moved to Seattle.
We were among the very few HBase-ers in this extremely Microsoftcentric city.
The idea of HBase in Action was first proposed to us in the fall of 2010
Why should we, two community members, write a book about HBase? Internally, it’s a complex beast.
The Definitive Guide was still a work in progress, but we both knew its author, a committer, and were well aware of the challenge before him.
We weren’t going to write another internals book, and I wasn’t convinced there was enough going on from the application developer’s perspective to justify an entire book.
We started brainstorming the project, and it quickly became clear that I was wrong.
Not only was there enough material for a user’s guide, but our position as community members made us ideal candidates to write such a book.
We set out to catalogue the useful bits of knowledge we’d each accumulated over the couple of years we’d used the technology.
It’s targeted to those brand new to HBase, and it provides guidance over the stumbling blocks we encountered during our own journeys.
We’ve collected and codified as much as we could of the tribal knowledge floating around the community.
Far more than a simple FAQ, we hope you’ll find this book to be a complete manual to getting off the ground with HBase.
Most of the warts we encountered when we began with the project have been cleaned up, patched, or completely re-architected.
HBase is approaching its 1.0 release, and we’re proud to be part of this community as we approach this milestone.
We’re proud to present this manuscript to the community in hopes that it will encourage and enable the next generation of HBase users.
The single strongest component of HBase is its thriving community—we hope you’ll join us in that community and help it continue to innovate in this new era of data systems.
Let me start by saying thank you for choosing this book as your means to learn about HBase and how to build applications that use HBase as their underlying storage system.
I hope you’ll find the text useful and learn some neat tricks that will help you build better applications and enable you to succeed.
I was pursuing graduate studies in computer science at UC Santa Cruz, specializing in distributed systems, when I started working at Cisco as a part-time researcher.
The team I was working with was trying to build a data-integration framework that could integrate, index, and allow exploration of data residing in hundreds of heterogeneous data stores, including but not limited to large RDBMS systems.
We started looking for systems and solutions that would help us solve the problems at hand.
We evaluated many different systems, from object databases to graph databases, and we considered building a custom distributed data-storage layer backed by Berkeley DB.
It was clear that one of the key requirements was scalability, and we didn’t want to build a fullfledged distributed system.
If you’re in a situation where you think you need to build out a custom distributed database or file system, think again—try to see if an existing solution can solve part of your problem.
Following that principle, we decided that building out a new system wasn’t the best approach and to use an existing technology instead.
That was when I started playing with the Hadoop ecosystem, getting my hands dirty with the different components in the stack and going on to build a proof-of-concept for the data-integration system on top of HBase.
HBase has one of the most welcoming and vibrant open source communities; it was much smaller at the time, but the key principles were the same then as now.
The project used HBase at its core, and I became more involved with the community as I built it out.
I asked questions, and, with time, answered questions others asked, on both the mailing lists and the IRC channel.
This is when I met Nick and got to know what he was working on.
With each day that I worked on this project, my interest and love for the technology and the open source community grew, and I wanted to stay involved.
After finishing grad school, I joined Amazon in Seattle to work on back-end distributed systems projects.
Much of my time was spent with the Elastic MapReduce team, building the first versions of their hosted HBase offering.
Nick also lived in Seattle, and we met often and talked about the projects we were working on.
Toward the end of 2010, the idea of writing HBase in Action for Manning came up.
Do you want to write a book about three API calls?”
We decided that more material on how to effectively use HBase would help users of the system build the applications they need.
It took a while for the idea to materialize; in fall 2011, we finally got started.
Around this time, I moved to San Francisco to join Cloudera and was exposed to many applications that were built on top of HBase and the Hadoop stack.
I brought what I knew, combined it with what I had learned over the last couple of years working with HBase and pursuing my master’s, and distilled that into concepts that became part of the manuscript for the book you’re now reading.
HBase has come a long way in the last couple of years and has seen many big players adopt it as a core part of their stack.
It’s more stable, faster, and easier to operationalize than it has ever been, and the project is fast approaching its 1.0 release.
Our intention in writing this book was to make learning HBase more approachable, easier, and more fun.
As you learn more about the system, we encourage you to get involved with the community and to learn beyond what the book has to offer—to write blog posts, contribute code, and share your experiences to help drive this great open source project forward in every way possible.
Flip open the book, start reading, and welcome to HBaseland!
HBase and Hadoop couldn’t exist if not for those papers published by Google nearly a decade ago.
HBase wouldn’t exist if not for the many individuals who picked up those papers and used them as inspiration to solve their own challenges.
To every HBase and Hadoop contributor, past and present: we thank you.
They continue to devote their time and effort to one of the most state-of-the-art data technologies in existence.
Even more amazing, they give away the fruit of that effort to the wider community.
This book would not have been possible without the entire HBase community.
HBase enjoys one of the largest, most active, and most welcoming user communities in NoSQL.
Our thanks to everyone who asks questions on the mailing list and who answers them in kind.
Your welcome and willingness to answer questions encouraged us to get xix.
Your unabashed readiness to post questions and ask for help is the foundation for much of the material we distill and clarify in this book.
We hope to return the favor by expanding awareness of and the audience for HBase.
ACKNOWLEDGMENTSxx for contributing the foreword to our book and to Lars for penning the letter to the HBase community.
We’d also like to thank our respective employers (Cloudera, Inc., and The Climate Corporation) not just for being supportive but also for providing encouragement, without which finishing the manuscript would not have been possible.
You saw us through from a rocky start to the successful completion of this book.
We hope your other projects aren’t as exciting as ours! Thanks also to our technical editor Mark Henry Ryan and our technical proofreaders Jerry Kuch and Kristine Kuch.
Last but not the least—no project is complete without recognition of family and friends, because such a project can’t be completed without the support of loved ones.
Thank you all for your support and patience throughout this adventure.
You need not be an expert in all these technologies to make effective use of HBase, but it helps to have an understanding of these foundational layers in order to take full advantage of HBase.
They’re open source clones of the technologies described in these publications.
Reading these academic papers isn’t a prerequisite for using HBase or these other technologies; but when you’re learning a technology, it can be helpful to understand the problems that inspired its invention.
This book doesn’t assume you’re familiar with these technologies, nor does it assume you’ve read the associated papers.
HBase in Action is a user’s guide to HBase, nothing more and nothing less.
It doesn’t venture into the bowels of the internal HBase implementation.
HBase in Action maintains a singular focus on using HBase.
It aims to educate you enough that you can build an application on top of HBase and launch that application into production.
Along the way, you’ll learn some of those HBase implementation details.
You’ll learn enough to understand why HBase behaves the way it does, and you’ll be able to ask intelligent questions.
In these six chapters, you’ll go from HBase novice to fluent in writing applications on HBase.
Along the way, you’ll learn about the basics, schema design, and how to use the most advanced features of HBase.
The two chapters in part 3 move beyond sample applications and give you a taste of HBase in real applications.
Part 4 is aimed at taking your HBase application from a development prototype to a full-fledged production system.
Chapter 1 introduces the origins of Hadoop, HBase, and NoSQL in general.
We explain what HBase is and isn’t, contrast HBase with other NoSQL databases, and describe some common use cases.
We’ll help you decide if HBase is the right technology choice for your project and organization.
Chapter 1 concludes with a simple HBase install and gets you started with storing data.
Through this example, we explore the foundations of using HBase.
Creating tables, storing and retrieving data, and the HBase data model are all covered.
We also explore enough HBase internals to understand how data is organized in HBase and how you can take advantage of that knowledge in your own applications.
This chapter explores the relationship between HBase, Hadoop, and ZooKeeper.
You’ll learn about the distributed architecture of HBase and how that translates into a powerful distributed data system.
The use cases for using HBase with Hadoop MapReduce are explored with hands-on examples.
You’ll see how table design decisions affect the application and how to avoid common mistakes.
We’ll map any existing relational database knowledge you have into the HBase world.
You’ll also see how to work around an imperfect schema design using server-side filters.
This chapter also covers the advanced physical configuration options exposed by HBase.
Chapter 5 introduces coprocessors, a mechanism for pushing computation out to your HBase cluster.
You’ll extend the sample application in two different ways, building new application features into the cluster itself.
Chapter 6 is a whirlwind tour of alternative HBase clients.
HBase is written in Java, but that doesn’t mean your application must be.
You’ll interact with the sample application from a variety of languages and over a number of different network protocols.
You’ll learn a bit about the problem domain and the specific challenges the application solves.
Then we dive deep into the implementation and don’t skimp on the technical details.
If ever there was a front-to-back exploration of an application built on HBase, this is it.
Chapter 8 shows you how to map HBase onto a new problem domain.
The focus is on a domain-specific schema design and making maximum use of scans and filters.
No previous GIS experience is expected, but be prepared to use most of what you’ve learned in the previous chapters.
Starting from a blank slate, we show you how to tackle your HBase deployment.
What kind of hardware, how much hardware, and how to allocate that hardware are all fair game in this chapter.
With hardware determined, we show you how to configure your cluster for a basic deployment and how to get everything up and running.
We show you how to keep an eye on your cluster through metrics and monitoring tools.
You’ll see how to further tune your cluster for performance, based on your application workloads.
We show you how to administer the needs of your cluster, keep it healthy, diagnose and fix it when it’s sick, and upgrade it when the time comes.
You’ll learn to use the bundled tools for managing data backups and restoration, and how to configure multi-cluster replication.
Intended audience This book is a hands-on user’s guide to a database.
As such, its primary audience is application developers and technology architects interested in coming up to speed on HBase.
It’s more practical than theoretical and more about consumption than internals.
It’s probably more useful as a developer’s companion than a student’s textbook.
It also covers the basics of deployment and operations, so it will be a useful starting point for operations engineers.
Honestly, though, the book for that crowd, as pertains to HBase, hasn’t been written yet.)
HBase is written in Java and runs on the JVM.
We expect you to be comfortable with the Java programming language and with JVM concepts such as class files and JARs.
We also assume a basic familiarity with some of the tooling around the JVM, particularly Maven, as it pertains to the source code used in the book.
Hadoop and HBase are run on Linux and UNIX systems, so experience with UNIX basics such as the terminal are expected.
The Windows operating systems aren’t supported by HBase and aren’t supported with this book.
Relational databases are ubiquitous, so concepts from those technologies are also assumed.
HBase is a distributed system and participates in distributed, parallel computation.
We expect you to understand basic concepts of concurrent programs, both multithreaded and concurrent processes.
We don’t expect you know how to program a concurrent program, but you should be comfortable with the idea of multiple simultaneous threads of execution.
This book isn’t heavy in algorithmic theory, but anyone working with terabytes or petabytes of data should be familiar with asymptotic computational complexity.
Big-O notation does play a role in the schema design chapter.
Code conventions In line with our aim of producing a practical book, you’ll find that we freely mix text and code.
Sometimes as little as two lines of code are presented between paragraphs.
Those code snippets evolve and grow over the course of a section or chapter.
We always conclude a chapter that contains code with a complete listing that provides the full context.
We occasionally employ pseudo-code in a Python-like style to assist with an explanation.
This is done primarily where the pure Java contains so much boilerplate or other language noise that it confuses the intended point.
Because this is a hands-on book, we also include many commands necessary to demonstrate aspects of the system.
These commands include both what you type into the terminal and the output you can expect from the system.
Software changes over time, so it’s entirely possible that this output has changed since we printed the output of the commands.
Still, it should be enough to orient you to the expected behavior.
In commands and source code, we make extensive use of bold text; and annotations draw your attention to the important aspects of listings.
Some of the command output, particularly when we get into the HBase shell, can be dense; use the bold text and annotations as your guide.
Code terms used in the body of the text appear in a monotype font like this.
Code downloads All of our source code, both small scripts and full applications, is available and open source.
In the spirit of open source, we hope you’ll find our example code useful in your applications.
We encourage you to play with it, modify it, fork it, and share it with others.
If you find bugs, please let us know in the form of issues, or, better still, pull requests.
As they often say in the open source community: patches welcome.
Author Online Purchase of HBase in Action includes free access to a private web forum run by Manning Publications where you can make comments about the book, ask technical questions, and receive help from the authors and from other users.
This page provides information on how to get on the forum once you’re registered, what kind of help is available, and the rules of conduct on the forum.
Manning’s commitment to our readers is to provide a venue where a meaningful dialogue between individual readers and between readers and the authors can take place.
It’s not a commitment to any specific amount of participation on the part of the authors, whose contribution to the book’s forum remains voluntary (and unpaid)
We suggest you try asking the authors some challenging questions, lest their interest stray!
The Author Online forum and the archives of previous discussions will be accessible from the publisher’s website as long as the book is in print.
Since then, he has applied Hadoop and HBase to projects in social media, social gaming, click-stream analysis, climatology, and geographic data.
Nick also helped establish Seattle’s Scalability Meetup and tried his hand at entrepreneurship.
His current passion is distributed, scalable, online access to scientific data.
Amandeep’s background is in large-scale distributed systems and information management.
Hacquet (1739–1815) was an Austrian physician and scientist who spent many years studying the botany, geology, and ethnography of many parts of the Austrian Empire, as well as the Veneto, the Julian Alps, and the western Balkans, inhabited in the past by peoples of many different tribes and nationalities.
Hand-drawn illustrations accompany the many scientific papers and books that Hacquet published.
The rich diversity of the drawings in Hacquet’s publications speaks vividly of the uniqueness and individuality of Alpine and Balkan regions just 200 years ago.
Dress codes have changed since then and the diversity by region, so rich at the time, has faded away.
It is now often hard to tell the inhabitant of one continent from another and the residents of the picturesque towns and villages on the Adriatic coast are not readily distinguishable from people who live in other parts of the world.
We at Manning celebrate the inventiveness, the initiative, and the fun of the computer business with book covers based on costumes from two centuries ago brought back to life by illustrations such as this one.
The first three chapters of HBase in Action introduce the basics of HBase.
In chapter 1, we provide an overview of databases in general and give specific context for HBase.
Chapter 2 teaches the foundations of HBase as you build an example application: TwitBase.
Through this application, you’ll see how to interact with HBase and how to design a schema for HBase, and you’ll get a glimpse of how to make efficient use of HBase in your own applications.
HBase is a distributed system, and we explore that architecture in chapter 3
You’ll see how HBase manages your data across the cluster and how to interact with HBase from MapReduce.
Upon completion of part 1, you’ll have the basic knowledge you need to begin building your own HBase application.
You’ll hear people refer to it as a key value store, a column family-oriented database, and sometimes a database storing versioned maps of maps.
But fundamentally, it’s a platform for storing and retrieving data with random access, meaning you can write data as you like and read it back again as you need it.
HBase stores structured and semistructured data naturally so you can load it with tweets and parsed log files and a catalog of all your products right along with their customer reviews.
It can store unstructured data too, as long as it’s not too large.
It doesn’t care about types and allows for a dynamic and flexible data model that doesn’t constrain the kind of data you store.
HBase isn’t a relational database like the ones to which you’re likely accustomed.
It doesn’t speak SQL or enforce relationships within your data.
It’s often described as a sparse, distributed, persistent, multidimensional sorted map, which is indexed by rowkey, column.
HBase is designed to run on a cluster of computers instead of a single computer.
The cluster can be built using commodity hardware; HBase scales horizontally as you add more machines to the cluster.
Each node in the cluster provides a bit of storage, a bit of cache, and a bit of computation as well.
No node is unique, so if one of those machines breaks down, you simply replace it with another.
This adds up to a powerful, scalable approach to data that, until now, hasn’t been commonly available to mere mortals.
Given that HBase has a different design and different goals as compared to traditional database systems, building applications using HBase involves a different approach as well.
This book is geared toward teaching you how to effectively use the features HBase has to offer in building applications that are required to work with large amounts of data.
Before you set out on the journey of learning how to use HBase, let’s get historical perspective about how HBase came into being and the motivations behind it.
We’ll then touch on use cases people have successfully solved using HBase.
If you’re like us, you’ll want to play with HBase before going much further.
We’ll wrap up by walking through installing HBase on your laptop, tossing in some data, and pulling it out.
Join the community Unfortunately, no official public numbers specify the largest HBase clusters running in production.
This kind of information easily falls under the realm of business confidential and isn’t often shared.
For now, the curious must rely on footnotes in publications, bullets in presentations, and the friendly, unofficial chatter you’ll find at user groups, meet-ups, and conferences.
So participate! It’s good for you, and it’s how we became involved as well.
HBase is an open source project in an extremely specialized space.
It has well-financed competition from some of the largest software companies on the planet.
It’s the community that created HBase and the community that keeps it competitive and innovative.
Relational database systems have been around for a few decades and have been hugely successful in solving data storage, serving, and processing problems over the years.
Several large companies have built their systems using relational database systems, online transactional systems, as well as back-end analytics applications.
Online transaction processing (OLTP) systems are used by applications to record transactional information in real time.
For instance, the cash registers in retail stores record purchases and payments in real time as customers make them.
Banks have large OLTP systems that they use to record transactions between users like transferring of funds and such.
Web companies like LinkedIn also have such applications—for instance, when users connect with other users.
The term transaction in OLTP refers to transactions in the context of databases, not financial transactions.
Online analytical processing (OLAP) systems are used to answer analytical queries about the data stored in them.
In the context of retailers, these would mean systems that generate daily, weekly, and monthly reports of sales and slice and dice the information to allow analysis of it from several different perspectives.
For a company like LinkedIn, where the establishing of connections counts as transactions, analyzing the connectedness of the graph and generating reports on things like the number of average connections per user falls in the category of business intelligence; this kind of processing would likely be done using OLAP systems.
Relational databases, both open source and proprietary, have been successfully used at scale to solve both these kinds of use cases.
This is clearly highlighted by the balance sheets of companies like Oracle, Vertica, Teradata, and others.
Microsoft and IBM have their share of the pie too.
Some scale better than others; some are open source, and others require you to pay steep licensing fees.
The internal design of relational databases is driven by relational math, and these systems require an up-front definition of schemas and types that the data will thereafter adhere to.
Over time, SQL became the standard way of interacting with these systems, and it has been widely used for several years.
But it might not be the best way to express the access patterns in every situation, and that’s where issues like object-relational mismatch arose.
For those who don’t know (or don’t remember), ACID is an acronym standing for atomicity, consistency, isolation, and durability.
These are fundamental principles used to reason about data systems.
Any problem in computer science can be solved with a level of indirection.
Solving problems like object-relational mismatch was no different and led to frameworks being built to alleviate the pain.
Let’s take a closer look at the term Big Data.
To be honest, it’s become something of a loaded term, especially now that enterprise marketing engines have gotten hold of it.
What is Big Data? Several definitions are floating around, and we don’t believe that any of them explains the term clearly.
Some definitions say that Big Data means the data is large enough that you have to think about it in order to gain insights from it.
Others say it’s Big Data when it stops fitting on a single machine.
These definitions are accurate in their own respect but not necessarily complete.
Big Data, in our opinion, is a fundamentally different way of thinking about data and how it’s used to drive business value.
Traditionally, there were transaction recording (OLTP) and analytics (OLAP) on the recorded data.
But not much was done to understand the reasons behind the transactions or what factors contributed to business taking place the way it did, or to come up with insights that could drive the customer’s behavior directly.
In the context of the earlier LinkedIn example, this could translate into finding missing connections based on user attributes, second-degree connections, and browsing behavior, and then prompting users to connect with people they may know.
Effectively pursuing such initiatives typically requires working with a large amount of varied data.
This new approach to data was pioneered by web companies like Google and Amazon, followed by Yahoo! and Facebook.
These companies also wanted to work with different kinds of data, and it was often unstructured or semistructured (such as logs of users’ interactions with the website)
This required the system to process several orders of magnitude more data.
Traditional relational databases were able to scale up to a great extent for some use cases, but doing so often meant expensive licensing and/or complex application logic.
But owing to the data models they provided, they didn’t do a good job of working with evolving datasets that didn’t adhere to the schemas defined up front.
There was a need for systems that could work with different kinds of data formats and sources without requiring strict schema definitions up front, and do it at scale.
The requirements were different enough that going back to the drawing board made sense to some of the internet pioneers, and that’s what they did.
This was the dawn of the world of Big Data systems and NoSQL.
Some might argue that it happened much later, but that’s not the point.
This did mark the beginning of a different way of thinking about data.)
As part of this innovation in data management systems, several new technologies were built.
Each solved different use cases and had a different set of design assumptions and features.
As we now know, many prominent internet companies, most notably Google, Amazon, Yahoo!, and Facebook, were on the forefront of this explosion of data.
Some generated their own data, and others collected what was freely available; but managing these vastly different kinds of datasets became core to doing business.
They all started by building on the technology available at the time, but the limitations of this technology became limitations on the continued growth and success of these businesses.
Although data management technology wasn’t core to the businesses, it became essential for doing business.
The ensuing internal investment in technical research resulted in many new experiments in data technology.
Although many companies kept their research closely guarded, Google chose to talk about its successes.
Shortly thereafter, Google published the Bigtable paper,6 which provided a complement to the storage paradigm provided by its file system.
Other companies built on this momentum, both the ideas and the habit of publishing their successful experiments.
As Google’s publications provided insight into indexing the internet, Amazon published Dynamo,7 demystifying a fundamental component of the company’s shopping cart.
It didn’t take long for all these new ideas to begin condensing into open source implementations.
In the years following, the data management space has come to host all manner of projects.
Some focus on fast key-value stores, whereas others provide native data structures or document-based abstractions.
Equally diverse are the intended access patterns and data volumes these technologies support.
Some forego writing data to disk, sacrificing immediate persistence for performance.
Most of these technologies don’t hold ACID guarantees as sacred.
Although proprietary products do exist, the vast majority of the technologies are open source projects.
Thus, these technologies as a collection have come to be known as NoSQL.
Where does HBase fit in? HBase does qualify as a NoSQL store.
It provides a keyvalue API, although with a twist not common in other key-value stores.
It promises strong consistency so clients can see data immediately after it’s written.
HBase runs on multiple nodes in a cluster instead of on a single machine.
HBase is designed for terabytes to petabytes of data, so it optimizes for this use case.
It’s a part of the Hadoop ecosystem and depends on some.
Now that you have some context for the environment at large, let’s consider specifically the beginnings of HBase.
Pretend that you’re working on an open source project for searching the web by crawling websites and indexing them.
You have an implementation that works on a small cluster of machines but requires a lot of manual steps.
Pretend too that you’re working on this project around the same time Google publishes papers about its datastorage and -processing frameworks.
Clearly, you would jump on these publications and spearhead an open source implementation based on them.
Okay, maybe you wouldn’t, and we surely didn’t; but Doug Cutting and Mike Cafarella did.
From there, Hadoop was extracted out of Nutch and eventually became an Apache top-level project.
With Hadoop well underway and the Bigtable paper published, the groundwork existed to implement an open source Bigtable on top of Hadoop.
In 2007, Cafarella released code for an experimental, open source Bigtable.
The startup Powerset decided to dedicate Jim Kellerman and Michael Stack to work on this Bigtable analog as a way of contributing back to the open source community on which it relied.9
HBase proved to be a powerful tool, especially in places where Hadoop was already in use.
Even in its infancy, it quickly found production deployment and developer support from other companies.
Today, HBase is a top-level Apache project with thriving developer and user communities.
It has become a core infrastructure component and is being run in production at scale worldwide in companies like StumbleUpon, Trend Micro, Facebook, Twitter, Salesforce, and Adobe.
HBase isn’t a cure-all of data management problems, and you might include another technology in your stack at a later point for a different use case.
Let’s look at how HBase is being used today and the types of applications people have built using it.
Through this discussion, you’ll gain a feel for the kinds of data problems HBase can solve and has been used to tackle.
Sometimes the best way to understand a software product is to look at how it’s used.
The kinds of problems it solves and how those solutions fit into a larger application architecture can tell you a lot about a product.
A short historical summary was published by Doug Cutting at http://cutting.wordpress.com/2009/08/10/ joining-cloudera/
HBase use cases and success stories publicized production deployments, we can do just that.
This section elaborates on some of the more common use cases that people have successfully used HBase to solve.
It’s a nascent technology, and innovation in terms of use cases is what drives the development of the system.
If you have a new idea that you think can benefit from the features HBase offers, try it.
The community would love to help you during the process and also learn from your experiences.
HBase is modeled after Google’s Bigtable, so we’ll start our exploration with the canonical Bigtable problem: storing the internet.
Search is the act of locating information you care about: for example, searching for pages in a textbook that contain the topic you want to read about, or for web pages that have the information you’re looking for.
Searching for documents containing particular terms requires looking up indexes that map terms to the documents that contain them.
This is precisely what Google and other search engines do.
Their document corpus is the entire internet; the search terms are whatever you type in the search box.
Bigtable, and by extension HBase, provides storage for this corpus of documents.
Bigtable supports row-level access so crawlers can insert and update documents individually.
The search index can be generated efficiently via MapReduce directly against Bigtable.
Support for all these access patterns was key in influencing the design of Bigtable.
Figure 1.1 illustrates the critical role of Bigtable in the web-search application.
We highly recommend the three papers on Google File System, MapReduce, and Bigtable as required reading for anyone curious about these technologies.
With the canonical HBase example covered, let’s look at other places where HBase has found purchase.
The adoption of HBase has grown rapidly over the last couple of years.
This has been fueled by the system becoming more reliable and performant, due in large part to the engineering effort invested by the various companies backing and using it.
As more commercial vendors provide support, users are increasingly confident in using the system for critical applications.
A technology designed to store a continuously updated copy of the internet turns out to be pretty good at other things internet-related.
HBase has found a home filling a variety of roles in and around social-networking companies.
From storing communications between individuals to communication analytics, HBase has become a critical infrastructure at Facebook, Twitter, and StumbleUpon, to name a few.
HBase has been used in three major types of use cases but it’s not limited to those.
In the interest of keeping this chapter short and sweet, we’ll cover the major use cases here.
Data often trickles in and is added to an existing data store for further usage, such as analytics, processing, and serving.
Many HBase use cases fall in this category—using HBase as the data store that captures incremental data coming in from various data sources.
These data sources can be, for example, web crawls (the canonical Bigtable use case that we talked about), advertisement impression data containing information about which user saw what advertisement and for how long, or time series data generated from recording metrics of various kinds.
Let’s talk about a few successful use cases and the companies that are behind these projects.
Web-based products serving millions of users typically have hundreds or thousands of servers in their back-end infrastructure.
These servers spread across various functions—serving traffic, capturing logs, storing data, processing data, and so on.
To keep the products up and running, it’s critical to monitor the health of the servers as well as the software running on these servers (from the OS right up to the application the user is interacting with)
Monitoring the entire stack at scale requires systems that can collect and store metrics of all kinds from these different sources.
A MapReduce job runs over the entire table, generating search indexes for the web search application.
A MapReduce process scans the table to produce the search index.
Search results are queried from Bigtable to display to the user.
HBase use cases and success stories its own way of achieving this.
Some use proprietary tools to collect and visualize metrics; others use open source frameworks.
StumbleUpon built an open source framework that allows the company to collect metrics of all kinds into a single system.
Metrics being collected over time can be thought of as basically time-series data: that is, data collected and recorded over time.
This framework uses HBase at its core to store and access the collected metrics.
The intention of building this framework was to have an extensible metrics collection system that could store and make metrics be available for access over a long period of time, as well as allow for all sorts of new metrics to be added as more features are added to the product.
StumbleUpon uses OpenTSDB to monitor all of its infrastructure and software, including its HBase clusters.
We cover OpenTSDB in detail in chapter 7 as a sample application built on top of HBase.
There are also metrics about user interaction with a product.
StumbleUpon had its start with MySQL, but as the service became more popular, that technology choice failed it.
The online demand of this increasing user load was too much for the MySQL clusters, and ultimately StumbleUpon chose HBase to replace those clusters.
At the time, HBase didn’t directly support the necessary features.
StumbleUpon implemented atomic increment in HBase and contributed it back to the project.
Facebook uses the counters in HBase to count the number of times people like a particular page.
Content creators and page owners can get near real-time metrics about how many users like their pages.
This allows them to make more informed decisions about what content to generate.
Facebook built a system called Facebook Insights, which needs to be backed by a scalable storage system.
The company looked at various options, including RDBMS, in-memory counters, and Cassandra, before settling on HBase.
This way, Facebook can scale horizontally and provide the service to millions of users as well as use its existing experience in running large-scale HBase clusters.
The system handles tens of billions of events per day and records hundreds of metrics.
HBase has been successfully used to capture and store crash reports that are generated from software crashes on users’ computers.
The Mozilla Foundation is responsible for the Firefox web browser and Thunderbird email client.
These tools are installed on millions of computers worldwide and run on a wide variety of OSs.
When one of these tools crashes, it may send a crash report back to Mozilla in the form of a bug report.
The introduction of HBase enabled basic analysis over far more data than was previously possible.
This analysis was used to direct Mozilla’s developer focus to great effect, resulting in the most bug-free release ever.
Trend Micro provides internet security and threat-management services to corporate clients.
A key aspect of security is awareness, and log collection and analysis are critical for providing that awareness in computer systems.
Trend Micro uses HBase to manage its web reputation database, which requires both row-level updates and support for batch processing with MapReduce.
Much like Mozilla’s Socorro, HBase is also used to collect and analyze log activity, collecting billions of records every day.
The flexible schema in HBase allows data to easily evolve over time, and Trend Micro can add new attributes as analysis processes are refined.
Over the last decade or so, online advertisements have become a major source of revenue for web-based products.
The model has been to provide free services to users but have ads linked to them that are targeted to the user using the service at the time.
This kind of targeting requires detailed capturing and analysis of user-interaction data to understand the user’s profile.
The ad to be displayed is then selected based on that profile.
Fine-grained user-interaction data can lead to building better models, which in turn leads to better ad targeting and hence more revenue.
But this kind of data has two properties: it comes in the form of a continuous stream, and it can be easily partitioned based on the user.
In an ideal world, this data should be available to use as soon as it’s generated, so the user-profile models can be improved continuously without delay—that is, in an online fashion.
For the uninitiated, these terms describe the conditions under which a software system is expected to perform.
In some cases, it’s better for these systems to respond with no answer than to take too long producing the correct answer.
You can think of a system as online if there’s a user at the other end impatiently tapping their foot.
There’s a user waiting for an answer, but that response isn’t expected immediately.
These factors make collecting user-interaction data a perfect fit for HBase, and HBase has been successfully used to capture raw clickstream and user-interaction data incrementally and then process it (clean it, enrich it, use it) using different processing mechanisms (MapReduce being one of them)
If you look for companies that do this, you’ll find plenty of examples.
One of the major use cases of databases traditionally has been that of serving content to users.
Applications that are geared toward serving different types of content are backed by databases of all shapes, sizes, and colors.
These applications have evolved over the years, and so have the databases they’re built on top of.
A vast amount of content of varied kinds is available that users want to consume and interact with.
In addition, accessibility to such applications has grown, owing to this burgeoning thing called the internet and an even more rapidly growing set of devices that can connect to it.
The various kinds of devices lead to another requirement: different devices need the same content in different formats.
In another entirely different use case, users generate content: tweets, Facebook posts, Instagram pictures, and micro blogs are just a few examples.
The bottom line is that users consume and generate a lot of content.
HBase is being used to back applications that allow a large number of users interacting with them to either consume or generate content.
A content management system (CMS) allows for storing and serving content, as well as managing everything from a central location.
More users and more content being generated translates into a requirement for a more scalable CMS solution.
Salesforce provides a hosted CRM product that exposes rich relational database functionality to customers through a web browser interface.
Long before Google was publishing papers about its proto-NoSQL systems, the most reasonable choice to run a large, carefully scrutinized database in production was a commercial RDBMS.
Over the years, Salesforce has scaled that approach to do hundreds of millions of transactions per day, through a combination of database sharding and cutting-edge performance engineering.
Its tight integration with Hadoop MapReduce makes it equally capable of offline access as well.
When looking for ways to expand its database arsenal to include distributed database systems, Salesforce evaluated the full spectrum of NoSQL technologies before deciding to implement HBase.12 The primary factor in the choice was consistency.
Bigtable-style systems are the only architectural approach that combines seamless horizontal scalability with strong record-level consistency.
Additionally, Salesforce already used Hadoop for doing large offline batch processing, so the company was able to take advantage of in-house expertise in running and administering systems on the Hadoop stack.
Su.pr uses HBase as its back end, and that allows it to scale up—shorten URLs and store tons of short URLs and their mapping to the longer versions.
Often, the content being served out of HBase isn’t consumed directly by users, but is instead used to make decisions about what should be served.
It’s metadata that is used to enrich the user’s interaction.
Remember the user profiles we talked about earlier in the context of ad serving? Those profiles (or models) can also be served out of HBase.
Such models can be of various kinds and can be used for several different use cases, from deciding what ad to serve to a particular user, to deciding price offers in real time when users shop on an e-commerce portal, to adding context to user interaction and serving back information the user asked for while searching for something on a search engine.
There are probably many such use cases that aren’t publicly talked about, and mentioning them could get us into trouble.
Runa13 serves user models that are used to make real-time price decisions and make offers to users during their engagement with an e-commerce portal.
The models are fine-tuned continuously with the help of new user data that comes in.
This statement is based on personal conversations with some of the engineers at Salesforce.
One such use case that is often publicly discussed and is probably a big driver of HBase development is Facebook messages.
If you’re on Facebook, you’ve likely sent or received messages from your Facebook friends at some point.
All messages that users write or read are stored in HBase.16 The system supporting Facebook messages needs to deliver high write throughput, extremely large tables, and strong consistency within a datacenter.
In addition to messages, other applications had requirements that influenced the decision to use HBase: read throughput, counter throughput, and automatic sharding are necessary features.
The engineers found HBase to be an ideal solution because it supports all these features, it has an active user community, and Facebook’s operations teams had experience with other Hadoop deployments.
Facebook engineers shared some interesting scale numbers at HBaseCon 2012
Billions of messages are exchanged every day on this platform, translating to about 75 billion operations per day.
At peak time, this can involve up to 1.5 million operations per second on Facebook’s HBase clusters.
These are just a few examples of how HBase is solving interesting problems new and old.
You may have noticed a common thread: using HBase for both online services and offline processing over the same data.
This is a role for which HBase is particularly well suited.
Now that you have an idea how HBase can be used, let’s get started using it.
Like the rest of the Hadoop ecosystem components, it’s written in Java.
The standalone mode is what we’ll work with through the book.
That means you’re running all of HBase in just one Java process.
This is how you’ll interact with HBase for exploration and local development.
You can also run in pseudo-distributed mode, a single machine running many Java processes.
The last deployment configuration is fully distributed across a cluster of machines.
The other modes required dependency packages to be installed and HBase to be configured properly.
This statistic was shared during a keynote at HBaseCon 2012
We don’t have a document to cite, but you can do a search for more info.
If you’re running Windows, the best bet is to get a Linux VM.
To run HBase in the standalone mode, you don’t need to do a lot.
You’ll work with the Apache 0.92.1 release and install it using the tarball.
If you’d like to work with a different distribution than the stock Apache 0.92.1, feel free to install that.
HBase needs the Java Runtime Environment (JRE) to be installed and available on the system.
Oracle’s Java is the recommended package for use in production systems.
Go ahead and install Java on your system before diving into the installation of HBase.
These steps download and untar the HBase tarball from the Apache mirror.
As a convenience, create an environment variable pointing at this location; it’ll make life easier later.
Put it in your environment file so you don’t have to set it every time you open a new shell.
Once that’s done, you can spin up HBase using the provided scripts:
A note about Java HBase is essentially written in Java, barring a couple of components, and the only language that is currently supported as a first-class citizen is Java.
If you aren’t a Java developer, you’ll need to learn some Java skills along with learning about HBase.
The intention of this book is to teach you how to use HBase effectively, and a big part of that is learning how to use the API, which is all Java.
The configurations for HBase primarily go into two files: hbase-env.sh and hbase-site.xml.
By default in standalone mode, HBase writes data into /tmp, which isn’t the most durable place to write to.
You can edit the hbasesite.xml file and put the following configuration into it to change that location to a directory of your choice:
Your HBase install has a management console of sorts running on http:// localhost:60010
Now that you have everything installed and HBase fired up, let’s start playing with it.
From this interface, you can get a general sense of the health of your installation.
It also allows you to explore the distribution of data and perform basic administrative tasks, but most administration isn’t done through this interface.
You use the HBase shell to interact with HBase from the command line.
This works the same way for both local and cluster installations.
You can run it in either interactive or batch mode.
Interactive is for casual inspection of an HBase installation; batch is great for programmatic interaction via shell scripts and or even loading small files.
The shell provides you with tab-completion of your commands and inline access to command documentation:
If you’ve made it this far, you’ve confirmed the installation of both Java and the HBase libraries.
For the final validation, let’s ask for a listing of registered tables.
Doing so makes a full-circle request from this client application to the HBase server infrastructure and back again.
You should see zero results found as a confirmation and again be greeted with a prompt:
With your installation complete and verified, let’s create a table and store some data.
HBase uses the table as the top-level structure for storing data.
To write data into HBase, you need a table to write it into.
To begin, create a table called mytable with a single column family.
JRuby and JVM languages Those of you unfamiliar with Java may be confused by this JRuby concept.
JRuby is an implementation of the Ruby programming language on top of the Java runtime.
In addition to the usual Ruby syntax, JRuby provides support for interacting with Java objects and libraries.
Java and Ruby aren’t the only languages available on the JVM.
Jython is an implementation of Python on the JVM, and there are entirely unique languages like Clojure and Scala as well.
All of these languages can interact with HBase via the Java client API.
With a table created, you can now write some data.
Go ahead and add a couple more values, like so:
You now have three cells in three rows in your table.
Notice that you didn’t define the columns before you used them.
Nor did you specify what type of data you stored in each column.
This is what the NoSQL crowd means when they say HBase is a schema-less database.
But what good is writing data if you can’t read it? No good at all.
HBase gives you two ways to read data: get and scan.
As you undoubtedly astutely noticed, the command you gave HBase to store the cells was put.
Remember when we mentioned HBase having a key-value API but with a twist? scan is that twist.
Chapter 2 will explain how scan works and why it’s important.
The shell shows you all the cells in the row, organized by column, with the value associated at each timestamp.
The default number of versions stored is three, but it’s configurable.
At read time, only the latest version is returned, unless otherwise specified.
If you don’t want multiple versions to be stored, you can configure HBase to store only one version.
Be careful! Unless you specify otherwise, it returns all rows in the table.
Command to create table mytable; column family name is cfListing tables returns.
They’re ordered by the row name; HBase calls this the rowkey.
HBase has a couple other tricks up its sleeve, but everything else is built on the basic concepts you’ve just used.
We covered quite a bit of material for an introductory chapter.
Knowing where a technology comes from is always helpful when you’re learning.
By now you should understand the roots of HBase and have some context for the NoSQL phenomenon.
You also understand the basics of the problem HBase is designed for as well as some of the problems HBase has solved.
Chapter 2 will get you started on the path of building your own application that uses HBase as its back-end data store.
You’ll gain a handle on the logical data model presented by HBase, the various modes of interacting with HBase, and the details of how to use those APIs.
Our other goal is to teach you HBase schema design.
HBase has a different physical data model from the relational data systems you’re likely used to.
We’ll teach you the basics of that physical model so that you can take advantage of it while designing schemas optimized for your applications.
To accomplish all these goals, you’ll build an application from scratch.
Allow us to introduce TwitBase, a simplified clone of the social network Twitter, implemented entirely in HBase.
We won’t cover all the features of Twitter and this isn’t intended to be a production-ready system.
The key difference between this system and the early versions of Getting started.
The goal of the next couple of chapters is to teach you how to use HBase.
First and foremost, you’ll become comfortable with the features HBase provides you as an.
Twitter is that TwitBase is designed with scale in mind and hence is backed by a data store that can help achieve that.
You’ll see how to create HBase tables, populate them with data, and read it back again.
We’ll introduce the basic operations HBase provides for working with data as well as the fundamental components of the data model.
Along the way, you’ll learn a little about how HBase works under the hood.
This knowledge is fundamental to making good decisions in your schema designs.
This chapter is the launch-point for your study of HBase and the rest of this book.
At its core, TwitBase stores three simple data elements: users, twits, and relationships.
They log into the application, maintain a profile, and interact with other users by posting twits.
Twits are short messages written publicly by the users of TwitBase.
A relationship connects one user to another, making it easy to read twits from other users.
You’ll start building TwitBase by laying the foundations for storing its users.
HBase is a database that stores data in tables, so you’ll begin by creating a users table.
To do that, you’ll pick up where you left off, at the HBase shell:
The shell opens a connection to HBase and greets you with a prompt.
With the shell prompt ahead of you, create your first table:
A word about Java The vast majority of code used in this book is written in Java.
We use pseudo-code here and there to help teach concepts, but the working code is Java.
The entire Hadoop stack, including HBase, is implemented in Java.
An HBase deployment requires tuning the JVM for optimal performance.
But there are means for interacting with Hadoop and HBase from non-Java and non-JVM languages.
Presumably 'users' is the name of the table, but what about this 'info' business? Just like tables in a relational database, tables in HBase are organized into rows and columns.
HBase treats columns a little differently than a relational database.
Columns in HBase are organized into groups called column families.
A table in HBase must have at least one column family.
Among other things, column families impact physical characteristics of the data store in HBase.
For this reason, at least one column family must be specified at table creation time.
You can alter column families after the table is created, but doing so is a little tedious.
For now, know that your users table is as simple as it gets—a single column family with default parameters.
If you’re familiar with relational databases, you’ll notice right away that the table creation didn’t involve any columns or types.
Other than the column family name, HBase doesn’t require you to tell it anything about your data ahead of time.
That’s why HBase is often described as a schema-less database.
You can verify that your users table was created by asking HBase for a listing of all registered tables:
The list command proves the table exists, but HBase can also give you extended details about your table.
You can see all those default parameters using the describe command:
The shell describes your table as a map with two properties: the table name and a list of column families.
Each column family has a number of associated configuration details.
For now, don’t worry about these details; we’ll examine them all in due course.
The shell is well and good, but who wants to implement TwitBase in shell commands? Those wise HBase developers thought of this and equipped HBase with a complete Java client library.
A similar API is exposed to other languages too; we’ll cover those in chapter 6
The Java code for opening a connection to the users table looks like this:
The HTable constructor reads the default configuration information to locate HBase, similar to the way the shell did.
It then locates the users table you created earlier and gives you a handle to it.
You can also pass a custom configuration object to the HTable object:
This is equivalent to letting the HTable object create the configuration object on its own.
To customize the configuration, you can define parameters like this:
Creating a table instance is a relatively expensive operation, requiring a bit of network overhead.
Rather than create a new table handle on demand, it’s better to use a.
HBase shell The HBase shell exposes a wealth of features, though it’s primarily used for administrative purposes.
Being implemented in JRuby, it has access to the entire Java client API.
You can further explore the shell’s capabilities using the help command.
HBase client configuration HBase client applications need to have only one configuration piece available to them to access HBase—the ZooKeeper quorum address.
Both ZooKeeper and the exact interaction between client and the HBase cluster are covered in the next chapter where we go into details of HBase as a distributed store.
For now, all you need to know is that the configuration parameters can be picked either by the Java client from the hbase-site.xml file in their classpath or by you setting the configuration explicitly in the connection.
When you leave the configuration completely unspecified, as you do in this sample code, the default configuration is read and localhost is used for the ZooKeeper quorum address.
When working in local mode, as you are here, that’s exactly what you want.
Using an HTablePool is more common in practice than instantiating HTables directly:
Closing the table when you’re finished with it allows the underlying connection resources to be returned to the pool.
What good is a table without data in it? No good at all.
Every row in an HBase table has a unique identifier called its rowkey.
Other coordinates are used to locate a piece of data in an HBase table, but the rowkey is primary.
Just like a primary key in a table in a relational database, rowkey values are distinct across all rows in an HBase table.
Every interaction with data in a table begins with the rowkey.
Every user in TwitBase is unique, so the user’s name makes a convenient rowkey for the users table; that’s what you’ll use.
To store data in a table, you’ll need to create a Put instance.
Creating a Put instance from a rowkey looks like this:
Why can’t you store the user’s name directly? All data in HBase is stored as raw data in the form of a byte array, and that includes the rowkeys.
The Java client library provides a utility class, Bytes, for converting various Java data types to and from byte[] so you don’t have to worry about doing it yourself.
Note that this Put instance has not been inserted into the table yet.
Now that you’ve staged a command for adding data to HBase, you still need to provide data to store.
You can start by storing basic information about Mark, such as his email address and password.
What happens if another person comes along whose name is also Mark Twain? They’ll conflict, and you won’t be able to store data about them in TwitBase.
Instead of using the person’s real name as the rowkey, let’s use a unique username and store their real name in a column.
Remember, HBase uses coordinates to locate a piece of data within a table.
The rowkey is the first coordinate, followed by the column family.
When used as a data coordinate, the column family serves to group columns.
The next coordinate is the column qualifier, often called simply column, or qual, once you’re versed in HBase vernacular.
The column qualifiers in this example are name, email, and password.
Because HBase is schema-less, you never need to predefine the column qualifiers or assign them types.
They’re dynamic; all you need is a name that you give them at write time.
The cell is where HBase stores data as a value.
The previous code stores three values in three cells within a single row.
The last step in writing data to HBase is sending the command to the table.
Changing data in HBase is done the same way you store new data: create a Put object, give it some data at the appropriate coordinates, and send it to the table.
Whether you use Put to record a new row in HBase or to modify an existing row, the internal process is the same.
HBase receives the command and persists the change, or throws an exception if the write fails.
When a write is made, by default, it goes into two places: the write-ahead log (WAL), also referred to as the HLog, and the MemStore (figure 2.1)
The default behavior of HBase recording the write in both places is in order to maintain data durability.
Only after the change is written to and confirmed in both places is the write considered complete.
The MemStore is a write buffer where HBase accumulates data in memory before a permanent write.
Its contents are flushed to disk to form an HFile when the MemStore fills up.
It doesn’t write to an existing HFile but instead forms a new file on every flush.
Data manipulation and a column family can have multiple HFiles.
But a single HFile can’t have data for multiple column families.
Failures are common in large distributed systems, and HBase is no exception.
Imagine that the server hosting a MemStore that has not yet been flushed crashes.
You’ll lose the data that was in memory but not yet persisted.
HBase safeguards against that by writing to the WAL before the write completes.
You’ll learn more about the various configurations in chapter 9
Clients don't interact directly with the underlying HFiles during writes.Client.
MemStore gets flushed to disk to form a new HFile when filled up with writes.
Every write to HBase requires confirmation from both the WAL and the MemStore.
The two steps ensure that every write to HBase happens as fast as possible while maintaining durability.
The MemStore is flushed to a new HFile when it fills up.
HBase cluster keeps a WAL to record changes as they happen.
The WAL is a file on the underlying file system.
A write isn’t considered successful until the new WAL entry is successfully written.
This guarantee makes HBase as durable as the file system backing it.
Most of the time, HBase is backed by the Hadoop Distributed Filesystem (HDFS)
If HBase goes down, the data that was not yet flushed from the MemStore to the HFile can be recovered by replaying the WAL.
It’s all handled under the hood by HBase as a part of the recovery process.
There is a single WAL per HBase server, shared by all tables (and their column families) served from that server.
As you can imagine, skipping the WAL during writes can help improve write performance.
There’s one less thing to do, right? We don’t recommend disabling the WAL unless you’re willing to lose data when things fail.
In case you want to experiment, you can disable the WAL like this:
Disable the WAL, and HBase can’t recover your data in the face of failure.
Any writes that haven’t flushed to disk will be lost.
Reading data back out of HBase is as easy as writing.
Make a Get command instance, tell it what cells you’re interested in, and send it to the table:
The table gives you back a Result instance containing your data.
This instance contains all the columns from all the column families that exist for the row.
You can limit the amount of data returned by placing restrictions on the Get instance.
The same can be done per column family using addFamily(), in which case it’ll return all the columns in the specified column family:
Retrieve the specific value and convert it back from bytes like so:
As a general rule, if you want fast access to data, keep it ordered and keep as much of it as possible in memory.
HBase accomplishes both of these goals, allowing it to serve millisecond reads in most cases.
A read against HBase must be reconciled between the persisted HFiles and the data still in the MemStore.
This cache, also called the BlockCache, sits in the JVM heap alongside the MemStore.
The BlockCache is designed to keep frequently accessed data from the HFiles in memory so as to avoid disk reads.
Understanding the BlockCache is an important part of understanding how to run HBase at optimal performance.
The “Block” in BlockCache is the unit of data that HBase reads from disk in a single pass.
The HFile is physically laid out as a sequence of blocks plus an index over those blocks.
This means reading a block from HBase requires only looking up that block’s location in the index and retrieving it from disk.
The block is the smallest indexed unit of data and is the smallest unit of data that can be read from disk.
The block size is configured per column family, and the default value is 64 KB.
You may want to tweak this value larger or smaller depending on your use case.
If you primarily perform random lookups, you likely want a more granular block index, so a smaller block size is preferred.
Having smaller blocks creates a larger index and thereby consumes more memory.
If you frequently perform sequential scans, reading many blocks at a time, you can afford a larger block size.
This allows you to save on memory because larger blocks mean fewer index entries and thus a smaller index.
Reading a row from HBase requires first checking the MemStore for any pending modifications.
Then the BlockCache is examined to see if the block containing this row has been recently accessed.
There are more things going on under the hood, but this is the overall outline.
Note that HFiles contain a snapshot of the MemStore at the point when it was flushed.
Data for a complete row can be stored across multiple HFiles.
Data is reconciled from the BlockCache, the MemStore, and the HFiles to give the client an up-to-date view of the row(s) it asked for.
You make an instance of the Delete command, constructed with a rowkey:
You can delete only part of a row by specifying additional coordinates:
The method deleteColumns() removes a cell entirely from the row.
This is a distinct method from deleteColumn() (notice the missing s at the end of the method name), which operates on the content of a cell.
That is, a new “tombstone” record is written for that value, marking it as deleted.
The tombstone is used to indicate that the deleted value should no longer be included in Get or Scan results.
Because HFiles are immutable, it’s not until a major compaction runs that these tombstone records are reconciled and space is truly recovered from deleted records.
Both types result in a consolidation of the data persisted in HFiles.
A minor compaction folds HFiles together, creating a larger HFile from multiple smaller HFiles, as shown in figure 2.3
Restricting the number of HFiles is important for read performance, because all of them must be referenced to read a complete row.
During the compaction, HBase reads the content of the existing HFiles, writing records into a new one.
Then, it swaps in the new HFile as the current active one and deletes the old ones that formed the new one.2 HBase decides which HFiles to compact based on their number and relative sizes.
Minor compactions are designed to be minimally detrimental to HBase performance, so there is an upper limit on the number of HFiles involved.
When a compaction operates over all HFiles in a column family in a given region, it’s called a major compaction.
Upon completion of a major compaction, all HFiles in the column family are merged into a single file.
See appendix B for an explanation of the HDFS write path for further details.
Data manipulation for the entire table (or a particular region) manually from the shell.
This is a relatively expensive operation and isn’t done often.
Minor compactions, on the other hand, are relatively lightweight and happen more frequently.
Major compactions are the only chance HBase has to clean up deleted records.
Resolving a delete requires removing both the deleted record and the deletion marker.
There’s no guarantee that both the record and marker are in the same HFile.
A major compaction is the only time when HBase is guaranteed to have access to both of these entries at the same time.
The compaction process is described in greater detail, along with incremental illustrations, in a post on the NGDATA blog.3
In addition to being a schema-less database, HBase is also versioned.
For example, you can look back in time for the original password:
Two or more HFiles get combined to form a single HFile during a compaction.
Records are read from the existing HFiles and combined into a single, merged HFile.
That new HFile is then marked as the new canonical data on disk, and the old HFiles are deleted.
When a compaction is run simultaneously over all HFiles in a column family, it’s called a major compaction.
When a cell exceeds the maximum number of versions, the extra records are dropped during the next major compaction.
Instead of deleting an entire cell, you can operate on a specific version or versions within that cell.
The deleteColumns() method (with the s) described previously operates on all KeyValues with a version less than the provided version.
If no version is provided, the default of now is used.
The deleteColumn() method (without the s) deletes a specific version of a cell.
Be careful which method you call; they have identical calling signatures and only subtly different semantics.
This section covers a lot of ground, both in terms of data model and implementation details.
Let’s pause momentarily to recap what we’ve discussed thus far.
The logical entities in an HBase schema are as follows:
Table names are Strings and composed of characters that are safe for use in a file system path.
Row—Within a table, data is stored according to its row.
Rowkeys don’t have a data type and are always treated as a byte[]
Column family—Data within a row is grouped by column family.
Column families also impact the physical arrangement of data stored in HBase.
For this reason, they must be defined up front and aren’t easily modified.
Every row in a table has the same column families, although a row need not store data in all its families.
Column family names are Strings and composed of characters that are safe for use in a file system path.
Column qualifier—Data within a column family is addressed via its column qualifier, or column.
Like rowkeys, column qualifiers don’t have a data type and are always treated as a byte[]
That is, the current time in milliseconds of the RegionServer that received the operation.
Thus it’s important to keep the clocks on all machines in your HBase cluster in sync.
When a version isn’t specified, the current timestamp is used as the basis for the operation.
The number of cell value versions retained by HBase is configured via the column family.
They’re exposed to the user via the logical view presented by the API.
They’re the building blocks on which the implementation manages data physically on disk.
Keeping these six concepts straight in your mind will take you a long way in understanding HBase.
A unique data value in HBase is accessed by way of its coordinates.
The complete coordinates to a value are rowkey, column family, column qualifier, and version.
These coordinates are covered in more detail in the next section.
In the logical data model, the version number is also part of the coordinates of a piece of data.
You can think of a relational database as storing a piece of data in a table in a 2D coordinate system based first on row and second on column.
By that analogy, HBase stores a piece of data in a table based on a 4D coordinate system.
The coordinates used by HBase, in order, are rowkey, column family, column qualifier, and version.
Considering the full set of coordinates as a unit, you can think of HBase as a keyvalue store.
With this abstraction of the logical data model in mind, you can consider the coordinates as a key and the cell data as the value (see figure 2.5)
The HBase API is built such that you aren’t required to provide the entire coordinate path when requesting data.
If you omit the version in your Get request, HBase.
Each cell has multiple versions, typically represented by the timestamp.
Figure 2.4 The coordinates used to identify data in an HBase table are B rowkey, C column family,
By providing decreasingly specific coordinates in your request, HBase allows you to request more data in a single operation.
In that way, you can think of HBase as a key-value store where the value is a map, or a map of maps.
Figure 2.5 HBase can be considered a key-value store, where the four coordinates to a cell act as a key.
In the API, the complete coordinates to a value, plus the value itself, are packaged together by the KeyValue class.
Drop version and you're left with a map of version to values2
Omit qualifier and you have a map of qualifiers to the previous maps3
Finally, drop the column family and you have a row, a map of maps4
Figure 2.6 Alternate views of HBase as a key-value data store.
Decreasing the precision of your cell coordinates results in larger groups of KeyValues as the resulting values.
We’ll discuss this concept in more detail when we explain the HBase data models, later in this chapter.
Now that you’ve seen how to interact with HBase, let’s assemble what you know into a working example.
To start, define a simple model object for the User instances, as in the next listing.
Let’s wrap all the user-centric HBase interactions in a single class.
Follow that with the public interfaces and a private implementation of the User model, as shown next.
The last piece of this puzzle is a main() method.
Let’s make a UsersTool, shown in the next listing, to simplify interaction with the users table in HBase.
Listing 2.3 UsersTool, a command-line interface to the users table.
With all the code available, you can try the whole thing.
In the root directory of this book’s source code, compile the application jar:
Using UsersTool to add Mark to the users table is easy:
Now that you’ve seen a little of how to interact with HBase, let’s better understand the logical and physical data models present in HBase.
As you’ve seen, the way HBase models data is a little different from the relational systems with which you’re familiar.
These systems require strict rules around tables, columns, and data types—the shape of your data.
Data conforming to these strict requirements is called structured data.
HBase is designed for data without such a strict shape.
Records can have divergent columns, variance in field size, and so on.
This kind of data is said to have a semistructured shape.
The propensity of a data system toward structured or semistructured data at the logical model influences decisions in the physical model.
Relational systems assume all records in a table to be structured and highly regular.
They use this to their advantage in physical implementations, optimizing on-disk formats and in-memory structures accordingly.
Likewise, HBase takes advantage of the semistructured shape of the data it stores.
As systems evolve, these assumptions in the physical model influence the logical.
Because of this tight relationship, a strong understanding of both logical and physical models is required to make optimal use of a data system.
In addition to focusing on semistructured data, HBase has another primary concern: scale.
The loose coupling of data components in a semistructured logical model has the benefit of being easier to physically distribute.
The physical model in HBase is designed with physical distribution in mind and that decision also influences the logical model.
On the other hand, this physical model forces HBase to give up some features provided by relational systems.
In particular, HBase can’t enforce relational constraints or provide multirow transactions.5 These next couple topics are influenced by this relationship.
There are a number of valid descriptions for the logical data model used in HBase.
The next model we’ll consider is a sorted map of maps.
Presumably you’re familiar with a map or dictionary structure from your favorite programming language.
Think of HBase as an unlimited, persisted, nested version of that structure.
For an example, take Mark’s record from the users table (figure 2.7)
Rudimentary support for multirow transactions over data on a single host is provided by a future HBase release.
While thinking of this map of maps, consider those coordinates from the inside out.
You can think of a cell as a map keyed on version with the stored data as the value.
One layer up, a column family is a map keyed on column qualifier with the cell as the value.
At the top, a table is a map keyed on rowkey to the column family.
Notice also we said it’s a sorted map of maps.
The example shows only a single record, but even there the sorting is present.
HBase sorts the version timestamp in descending order so the newest data is always on top.
This physical design decision results in slightly faster access to recent versions.
The current example doesn’t display this behavior, so let’s insert a couple records and see what it looks like:
HBase logically organizes data as a nested map of maps.
Within each map, data is physically sorted by that map’s key.
In this example, "email" comes before "name" and more recent versions come before older ones.
Now you can list the users table again and see:
This sorting business turns out to be a critical consideration when designing HBase table schema in practice.
This is another point where the physical data model influences the logical.
Understanding this detail allows you to design your schema to take advantage of this feature.
Like a relational database, tables in HBase consist of rows and columns.
In HBase, the columns are grouped together in column families.
This grouping is expressed logically as a layer in the map of maps.
Each column family gets its own set of HFiles on disk.
This physical isolation allows the underlying HFiles of one column family to be managed in isolation of the others.
As far as compactions are concerned, the HFiles for each column family are managed independently.
Records in HBase are stored in the HFiles as key-value pairs.
The HFile itself is a binary file and isn’t human-readable.
Mark’s user data stored on disk in an HFile looks something like figure 2.8
Notice that Mark’s row consumes multiple records in the HFile.
HBase doesn’t need to store anything to indicate the absence of data.
Figure 2.8 HFile data for the info column family in the users table.
Data from a single column family for a single row need not be stored in the same HFile.
Mark’s info data could be spread across any number of HFiles.
The only requirement is that within an HFile, data for a row’s column family is stored together.
If the users table had another column family and Mark had data in those columns, Mark’s row would have records in those HFiles as well.
Using separate HFiles for each column family means HBase doesn’t need to read all the data for a row when performing a read.
It need only retrieve data for the requested column families.
Being column-oriented means HBase need not read over placeholder entries when looking for a specific cell.
These two physical details make for efficient storage and fast reads of particularly sparse datasets.
Let’s say you add another column family to the users table for storing activity on the TwitBase site; it will result in more HFiles.
The complete set of tooling that allows HBase to host a single row is illustrated in figure 2.9
For reasons we’ll cover in the next chapter, HBase refers to this machinery as a region.
As you can see in figure 2.9, interacting with data in different column families involves completely separate MemStores and HFiles.
This allows data in the activity column family to grow without adversely affecting performance of the info column family.
You likely noticed the lack of a query command of any kind.
The only way to access records containing a specific value is by using the Scan command to read across some portion of the table, applying a filter to.
All data for a given row in the table is managed together in a region.
As you might imagine, the records returned while scanning are presented in sorted order.
HBase is designed to support this kind of behavior so it’s fast.
To scan the entire contents of a table, use the bare Scan constructor:
Often, however, you’re only interested in a subset of the entire table.
Perhaps you only want users with IDs starting with the letter T.
This is a contrived example, perhaps, but you get the idea.
How about a practical example? You need to store twits.
Further, you know you’ll want to access the most recent twits from a particular user.
Just as you would when designing a relational schema, designing schema for HBase tables requires that you consider the data shape and access patterns.
Twits are a different kind of data with different access patterns than users, so let’s put them in their own table.
For kicks, you’ll create the new table using the Java API instead of the shell.
Table manipulation is performed using an instance of the HBaseAdmin object:
Making an HBaseAdmin instance explicitly requires a Configuration instance, a detail hidden from you by the default HTable and HTablePool constructors.
Now you can define a new table and create it:
The HTableDescriptor object lets you build up the description of the new table, starting with its name: twits.
Likewise, you build up the column family, also named twits, using the HColumnDescriptor.
As with the users table, you only need one column family here.
You don’t need twit versioning, so you’ll limit the retained versions to one.
With a fancy new twits table, you can begin storing twits.
A twit consists of a message and the date and time it was posted.
You’ll need a unique value for the rowkey, so let’s try the username plus the timestamp.
First, notice that the user ID is a variable-length string.
This can cause you some hassle when using a compound rowkey because you need to split on a delimiter of some kind.
An alternative approach is to hash the portion of the rowkey that is of variable length.
Choose a hashing algorithm that produces values of constant size.
MD5 is a good choice because you want twits to be stored in groups by user.
Within the group, appending the postdate orders the twits chronologically.
MD5 is a one-way hash; don’t forget to also store the unencoded user ID in a column if you need it later.
You know that HBase stores rows in sorted order by rowkey in its physical data model.
By including the timestamp of the twit in the rowkey and multiplying it by -1, you have the most recent twits first.
Rowkey design is critical in HBase schema This point we can’t stress enough: HBase rowkeys are the number one most important thing to think about when designing a table.
We cover this in much greater detail in chapter 4
We mention it now so you can keep it in mind as you pursue the examples.
Using the user as the first portion of the twits rowkey turns out to be useful.
It effectively creates buckets of data by user in the natural ordering of rows.
What does the Scan look like? More or less the same as before, just with more complexity in calculating the stop key:
In this case, you create the stop key by incrementing the value of the last byte of the user ID portion of the rowkey.
Scanners return records inclusive of the start key and exclusive of the end key, so this gives you twits for only the matching user.
The only work done in the loop is fixing the timestamp value and converting byte[] values back to their proper data types.
A scan can be configured to retrieve a batch of rows in every RPC call it makes to HBase.
This configuration can be done at a per-scanner level by using the setCaching(int) API on the scan object.
If the caching value is set to n, the scanner will return n rows with every RPC call and they will be cached at the client side while it works through them.
That’s a conservative number, and you can tune it for better performance.
But setting the value too high would mean that the client’s interaction with HBase would have longer pauses, and this could result in timeouts on HBase’s side.
The ResultScanner interface also has a next(int) call that you can use to ask it to return the next n rows from the scan.
This is an API convenience that doesn’t have any relation to the number of RPC calls the client makes to HBase to get those n rows.
Under the hood, ResultScanner makes as many RPC calls as necessary to satisfy the request; the number of rows returned per RPC call is solely dependent on the caching value you configure for the scanner.
It’s not always possible to design a rowkey to perfectly match your access patterns.
Sometimes you’ll have use cases where you need to scan through a set of data in HBase but return only a subset of it to the client.
A filter is a predicate that executes in HBase instead of on the client.
When you specify a Filter in your Scan, HBase uses it to determine whether a record should be returned.
It also keeps the filtering on the server instead of placing that burden on the client.
HBase provides a number of filters, but it’s easy to implement your own.
The ParseFilter object implements a kind of query language used to construct a Filter instance for you.
The same TwitBase filter can be constructed from an expression:
In either case, your regular expression is compiled and applied in the region before data ever reaches the client.
This is a simple example of using a filter in your applications.
Filters in HBase can be applied to rowkeys, column qualifiers, or data values.
You can also compose multiple filters together using the FilterList and WhileMatchFilter objects.
Filters also allow you to page over data, limiting the number of rows returned by the scanner.
We cover the bundled filters in more depth in chapter 4
The last command in the HBase arsenal is the Increment Column Value (ICV)
It’s exposed as both the Increment command object like the others but also as a method on the HTableInterface.
Let’s use the HTableInterface version because it offers slightly more intuitive semantics.
Using it to keep count of the number of twits per user looks like this:
This command allows you to change an integral value stored in an HBase cell without reading it back first.
The data manipulation happens in HBase, not in your client application, which makes it fast.
It also avoids a possible race condition where some other client is interacting with the same cell.
The increment value can be any Java Long value, positive or negative.
We’ll cover atomic operations in more detail in the next section.
Notice also that you’re not storing this data in the twits table but instead in the users table.
You store it there because you don’t want this information as part of a scan.
Keeping it in the twits table would upset the common access pattern of that table.
This implementation is quite a bit longer, but you can do it.
Following the same patterns as before, you can now easily build a TwitsTool.
The model, DAO, and command-line implementations look similar to what you’ve seen for the users table.
An implementation is provided in the source code accompanying this book.
If you’ve worked with database systems, you’ve heard about the ACID semantics that various systems provide.
Using these properties, you can reason the behavior of your application when it comes to interacting with the underlying store.
Keep in mind that ACID is different from CAP, which we briefly touched on earlier:
If the operation fails, it fails in its entirety and the system is left in exactly the same state as it was in before the operation started.
If the operation makes the system inconsistent, it won’t be performed or it will be rolled back.
For instance, no two writes to a single object will happen at the same time.
The writes will happen one after the other, but not at the exact same moment.
It means that once data is written, it’s guaranteed to be read back and not lost in due course of normal operation of the system.
In case you missed something along the way, here is a quick overview of the material covered in this chapter.
HBase is a database designed for semistructured data and horizontal scalability.
Within a table, data is organized over a four-dimensional coordinate system: rowkey, column family, column qualifier, and version.
HBase is schema-less, requiring only that column families be defined ahead of time.
It’s also type-less, storing all data as uninterpreted arrays of bytes.
The data model is logically organized as either a key-value store or as a sorted map of maps.
The physical data model is column-oriented along column families and individual records are stored in a key-value style.
HBase persists data records into HFiles, an immutable file format.
Because records can’t be modified once written, new values are persisted to new HFiles.
Data view is reconciled on the fly at read time and during compactions.
Table connections can be established by constructing an HTable instance directly.
Instantiating an HTable instance is expensive, so the preferred method is via the HTablePool because it manages connection reuse.
Tables are created and manipulated via instances of the HBaseAdmin, HTableDescriptor, and HColumnDescriptor classes.
All five commands are exposed via their respective command objects: Get, Put, Delete, Scan, and Increment.
The results of executing Get, Scan, and Increment commands are returned in instances of Result and ResultScanner objects.
HBase’s ACID semantics are described in the HBase manual: http://hbase.apache.org/acid-semantics.html.
But HBase provides some guarantees that you can use to reason about the behavior of your application’s interaction with the system.
In other words, any Put() on a given row either succeeds in its entirety or fails and leaves the row the way it was before the operation started.
There will never be a case where part of the row is written and some part is left out.
This property is regardless of the number of column families across which the operation is being performed.
There are no guarantees that all operations will complete or fail together in their entirety.
All the individual operations are atomic as listed in the previous point.
A scan across a table is not a scan over a snapshot of the table at any point.
If a row R is mutated after the scan has started but before R is read by the scanner object, the updated version of R is read by the scanner.
But the data read by the scanner is consistent and contains the complete row at the time it’s read.
From the context of building applications with HBase, these are the important points you need to be aware of.
All of these operations are also available on the command line via the HBase shell.
Schema designs in HBase are heavily influenced by anticipated data-access patterns.
Ideally, the tables in your schema are organized according to these patterns.
The rowkey is the only fully indexed coordinate in HBase, so queries are often implemented as rowkey scans.
Compound rowkeys are a common practice in support of these scans.
What may not yet be clear to you is why.
Most important, what benefits do we, as application developers, enjoy from this relationship? HBase depends on Hadoop for two separate concerns.
Hadoop MapReduce provides a distributed computation framework for highthroughput data access.
The Hadoop Distributed File System (HDFS) gives HBase a storage layer providing availability and reliability.
In this chapter, you’ll see how TwitBase is able to take advantage of this data access for bulk processing and how HBase uses HDFS to guarantee availability and reliability.
To begin this chapter, we’ll show you why MapReduce is a valuable alternative access pattern for processing data in HBase.
With this knowledge, we’ll tie it all back into HBase as a distributed system.
We’ll show you how to use HBase from MapReduce jobs and explain some useful tricks you can do with HBase from MapReduce.
Finally, we’ll show you how HBase provides availability, reliability, and durability for your data.
If you’re a seasoned Hadooper and know a bunch about MapReduce and HDFS, you can jump straight to section 3.3 and dive into learning about distributed HBase.
Everything you’ve seen so far about HBase has a focus on online operations.
You expect every Get and Put to return results in milliseconds.
You carefully craft your Scans to transfer as little data as possible over the wire so they’ll complete as quickly as possible.
The twits table’s rowkey is designed to maximize physical data locality and minimize the time spent scanning records.
You likely don’t care if the monthly site traffic summary report is generated in four hours or five hours, as long as it completes before the business owners are ready for it.
Instead of focusing on individual request latency, these concerns often focus on the entire computation in aggregate.
MapReduce is a computing paradigm built for offline (or batch) processing of large amounts of data in an efficient manner.
The concept of this duality between online and offline concerns has come up a couple times now.
This duality exists in traditional relational systems too, with Online Transaction Processing (OLTP) and Online Analytical Processing (OLAP)
To get the best performance for the least cost, you need to use the right tool for the job.
The same system that handles fast real-time queries isn’t necessarily optimized for batch operations on large amounts of data.
Did you go to the store, buy a single item, and return it to your pantry, only to return to the store for the next item? Well sure, you may do this sometimes, but it’s not ideal, right? More likely you made a shopping list, went to the store, filled up your cart, and brought everything home.
The entire trip took longer, but the time you spent away from home was shorter per item than taking an entire trip per item.
In this example, the time in transit dominates the time spent shopping for, purchasing, and unpacking the groceries.
A case for MapReduce buying multiple things at once, the average time spent per item purchased is much lower.
While in the store, you’ll need a bigger cart to accommodate that long shopping list; a small hand basket won’t cut it.
Tools that work for one approach aren’t always sufficient for another.
We think about data access in much the same way.
Online systems focus on minimizing the time it takes to access one piece of data—the round trip of going to the store to buy a single item.
Response latency measured on the 95th percentile is generally the most important metric for online performance.
Offline systems are optimized for access in the aggregate, processing as much as we can all at once in order to maximize throughput.
These systems usually report their performance in number of units processed per second.
Regardless of the unit, it’s about overall processing time of the task, not the time of an individual unit.
You wrapped up the last chapter by using Scan to look at the most recent twits for a user of TwitBase.
Create the start rowkey, create the end rowkey, and execute the scan.
That works for exploring a single user, but what if you want to calculate a statistic over all users? Given your user base, perhaps it would be interesting to know what percentage of twits are about Shakespeare.
Maybe you’d like to know how many users have mentioned Hamlet in their twits.
How can you look at all the twits from all the users in the system to produce these metrics? The Scan object will let you do that:
This block of code asks for all the data in the table and returns it for your client to iterate through.
Does it have a bit of code-smell to you? Even before we explain the inner workings of iterating over the items in the ResultScanner instance, your intuition should flag this as a bad idea.
The code for distributing the work over different threads might look something like this:
What do you do? You can settle for waiting longer for the computation to finish, but that solution won’t last forever as hours quickly turn into days.
Parallelizing the computation worked well last time, so you might as well throw more computers at it.
Now that you have the computing power, you still need to deal with splitting the problem across those machines.
Once you’ve solved that problem, the aggregation step will require a similar solution.
And all this while you’ve assumed everything works as expected.
How does the aggregation keep track of which splits have finished and which haven’t? How do the.
Only because of incidental concerns must they be written in a serial fashion.
Such concerns could be any of programming language design, storage engine implementation, library API, and so on.
The challenge falls to you as an algorithm designer to see these situations for what they are.
Not all problems are easily parallelizable, but you’ll be surprised by how many are once you start to look.
A case for MapReduce results get shipped back for aggregation? Parallelizing the problem was pretty easy, but the rest of this distributed computation is painful bookkeeping.
If you think about it, the bookkeeping would be required for every algorithm you write.
Hadoop gives us two major components that solve this problem.
The Hadoop Distributed File System (HDFS) gives all these computers a common, shared file system where they can all access the data.
This removes a lot of the pain from farming out the data to the workers and aggregating the work results.
Your workers can access the input data from HDFS and write out the processed results to HDFS, and all the others can see them.
Hadoop MapReduce does all the bookkeeping we described, splitting up the workload and making sure it gets done.
This function expects long keys and Text instances as input and writes out pairs of Text to LongWritable.
There are no split calculations, no Futures to track, and no thread pool to clean up after.
Better still, this code can run anywhere on the Hadoop cluster! Hadoop distributes your worker logic around the cluster according to resource availability.
Hadoop makes sure every machine receives a unique slice of the twits table.
Hadoop ensures no work is left behind, even if workers crash.
Your Aggregate Work code is shipped around the cluster in a similar fashion.
In this case, the [String,Long] pairs are written back to the HDFS.
You could have just as easily written them back to HBase.
HBase provides TableMapper and TableReducer classes to help with that.
You’ve just seen when and why you’ll want to use MapReduce instead of programming directly against the HBase client API.
Now let’s take a quick look at the MapReduce framework.
In order to provide you with a general-purpose, reliable, fault-tolerant distributed computation harness, MapReduce constrains how you implement your program.
Hadoop MapReduce enforces these constraints by requiring that programs be implemented with map and reduce functions.
These functions are composed into a Job and run as a unit: first the mappers and then the reducers.
Because there are no runtime dependencies between concurrent tasks, Hadoop can run them in any order as long as the map tasks are run before the reduce tasks.
The decisions of how many tasks to run and which tasks to run are up to Hadoop.
Exceptions to every rule As far as Hadoop MapReduce is concerned, the points outlined previously are more like guidelines than rules.
MapReduce is batch-oriented, meaning most of its design principles are focused on the problem of distributed batch processing of large amounts of data.
A system designed for the distributed, real-time processing of an event stream might take a different approach.
On the other hand, Hadoop MapReduce can be abused for any number of other workloads that fit within these constraints.
The Hadoop MapReduce framework is a reliable, fault-tolerant job execution framework that can be used for both kinds of jobs.
But MapReduce is optimized for I/O intensive jobs and makes several optimizations around minimizing network bottlenecks by reducing the amount of data that needs to be transferred over the wire.
Implementing programs in terms of Map and Reduce Steps requires a change in how you tackle a problem.
This can be quite an adjustment for developers accustomed to other common kinds of programming.
Some people find this change so fundamental that they consider it a change of paradigm.
Don’t worry! This claim may or may not be true.
We’ll make it as easy as possible to think in MapReduce.
MapReduce is all about processing large amounts of data in parallel, so let’s break down a MapReduce problem in terms of the flow of data.
For this example, let’s consider a log file from an application server.
Such a file contains information about how a user spends time using the application.
Let’s calculate the amount of time each user spends using the application.
A basic implementation might be to iterate through the file, summing the values of TimeSpent for each user.
Your program could have a single HashMap (or dict, for you Pythonistas) with UserID as the key and summed TimeSpent as the value.
This looks a lot like the serial example from the previous section, doesn’t it? Like the serial example, its throughput is limited to a single thread on a single machine.
The first thing to do when parallelizing a problem is break it up.
Notice that each line in the input file is processed independently from all the other lines.
The only time when data from different lines is seen together is during the aggregation step.
That means this input file can be parallelized by any number of lines, processed independently, and aggregated to produce exactly the same result.
Let’s split it into four pieces and assign those pieces to four different machines, as per figure 3.1
Hadoop doesn’t know anything about this data other than that it’s line-oriented.
In particular, there’s no effort made to group according to UserID.
How do you rewrite the program to work with this data? As you saw from the map and reduce stubs, MapReduce operates in terms of key-value pairs.
While walking through the MapReduce workflow, we refer in general to this first set of key-value pairs as [k1,v1]
Let’s start by writing the Map Step, again in pseudo-code:
The Map Step is defined in terms of the lines from the file.
For each line in its portion of the file, this Map Step splits the line and produces a new key-value pair of [UserID:TimeSpent]
In this pseudo-code, the function emit handles reporting the produced pairs back to Hadoop.
As you likely guessed, we’ll refer to the second set of key-value pairs as [k2,v2]
Each record in the log file can be processed independently, so you split the input file according to the number of workers available.
The Map Step processes each line and produces pairs of UserID to TimeSpent, [k2,v2]
Before Hadoop can pass the values of [k2,v2] on to the Reduce Step, a little bookkeeping is necessary.
Remember that bit about grouping by UserID? The Reduce Step expects to operate over all TimeSpent by a given UserID.
For this to happen correctly, that grouping work happens now.
MapReduce takes [k2,v2], the output from all four Map Steps on all four servers, and assigns it to reducers.
Each reducer is assigned a set of values of UserID and it copies those [k2,v2] pairs from the mapper nodes.
A reduce task expects to process all values of k2 at the same time, so a sort on key is necessary.
The output of that Sort Step is [k2,<v2>], a list of Times for each UserID.
It serves to prepare the output from the Map Step for aggregation in the Reduce Step.
No values are changed by the process; it serves only to reorganize data.
These sums are collected by Hadoop and written to the output destination.
You can run this application if you’d like; the source is bundled with the TwitBase code.
To do so, compile the application JAR and launch the job like this:
Available servers process the groups of UserID to Times, [k2,<v2>], in this case, summing the values.
Every MapReduce application performs this sequence of steps, or most of them.
If you can follow these basic steps, you’ve successfully grasped this new paradigm.
Building a system for general-purpose, distributed, parallel computation is nontrivial.
That’s precisely why we leave that problem up to Hadoop! All the same, it can be useful to understand how things are implemented, particularly when you’re tracking down a bug.
Let’s walk through them and see what makes MapReduce tick.
A process called the JobTracker acts as an overseer application.
It’s responsible for managing the MapReduce applications that run on your cluster.
Jobs are submitted to the JobTracker for execution and it manages distributing the workload.
It also keeps tabs on all portions of the job, ensuring that failed tasks are retried.
A single Hadoop cluster can run multiple MapReduce applications simultaneously.
It falls to the JobTracker to oversee resource utilization, and job scheduling as well.
The work defined by the Map Step and Reduce Step is executed by another process called the TaskTracker.
Figure 3.5 illustrates the relationship between a JobTracker and its TaskTrackers.
Any TaskTracker can run any task, be it a map or reduce, from any job.
Hadoop is smart and doesn’t randomly spray work across the.
Figure 3.5 The JobTracker and its TaskTrackers are responsible for execution of the MapReduce applications submitted to the cluster.
As we mentioned, Hadoop is optimized for minimal network I/O.
It achieves this by bringing computation as close as possible to the data.
This allows the map and reduce tasks to run on the same physical node where the data is located.
By doing so, Hadoop can avoid transferring the data over the network.
When it isn’t possible to run the tasks on the same physical node, running the task in the same rack is a better choice than running it on a different rack.
When HBase comes into the picture, the same concepts apply, but in general HBase deployments look different from standard Hadoop deployments.
By now you know that HBase is essentially a database built on top of HDFS.
It’s also sometimes referred to as the Hadoop Database, and that’s where it got its name.
Theoretically, HBase can work on top of any distributed file system.
It’s just that it’s tightly integrated with HDFS, and a lot more development effort has gone into making it work well with HDFS as compared to other distributed file systems.
Having said that, from a theoretical standpoint, there is no reason that other file systems can’t support HBase.
One of the key factors that makes HBase scalable (and fault tolerant) is that it persists its data onto a distributed file system that provides it a single namespace.
This is one of the key factors that allows HBase to be a fully consistent data store.
There are other factors at play that you’ll learn about in this section.
Having a good understanding of these is important in order to design your application optimally.
This knowledge will enable you to make smart choices about how you want to access HBase, what your keys should look like, and, to some degree, how HBase should be configured.
Configuration isn’t something you as an application developer should be worried about, but it’s likely that you’ll have some role to play when bringing HBase into your stack initially.
Just as in any other database, tables in HBase comprise rows and columns, albeit with a different kind of schema.
Tables in HBase can scale to billions of rows and millions of columns.
The size of each table can run into terabytes and sometimes even petabytes.
It’s clear at that scale that the entire table can’t be hosted on a single machine.
Instead, tables are split into smaller chunks that are distributed across multiple servers.
RegionServers are typically collocated with HDFS DataNodes (figure 3.7) on the same physical hardware, although that’s not a requirement.
The only requirement is that RegionServers should be able to access HDFS.
The master process does the distribution of regions among RegionServers, and each RegionServer typically hosts multiple regions.
Given that the underlying data is stored in HDFS, which is available to all clients as a single namespace, all RegionServers have access to the same persisted files in the file system and can therefore host any region (figure 3.8)
By physically collocating DataNodes and RegionServers, you can use the data locality property; that is, RegionServers can theoretically read and write to the local DataNode as the primary DataNode.
You may wonder where the TaskTrackers are in this scheme of things.
In some HBase deployments, the MapReduce framework isn’t deployed at all if the workload is primarily random reads and writes.
In other deployments, where the MapReduce processing is also a part of the workloads, TaskTrackers, DataNodes, and HBase RegionServers can run together.
Figure 3.6 A table consists of multiple smaller chunks called regions.
Figure 3.7 HBase RegionServer and HDFS DataNode processes are typically collocated on the same host.
When a region becomes bigger than that size (as you write more data into it), it gets split into two regions.
You’ve learned that tables are split into regions and regions are assigned to RegionServers without any predefined assignment rules.
HBase in distributed mode don’t keep moving around in a running system! Region assignment happens when regions split (as they grow in size), when RegionServers die, or when new RegionServers are added to the deployment.
Two special tables in HBase, -ROOT- and .META., help find where regions for various tables are hosted.
When a client application wants to access a particular row, it goes to the -ROOTtable and asks it where it can find the region responsible for that particular row.
The -ROOT- table is the -ROOT- node of the B+Tree.
Note that the region assignments shown here are arbitrary and don’t represent how they will happen when such a system is deployed.
The entry point for an HBase system is provided by another system called ZooKeeper (http://zookeeper.apache.org/)
As stated on ZooKeeper’s website, ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.
The client interaction with the system happens in steps, where ZooKeeper is the point of entry, as mentioned earlier.
Which region can I find it in, and what RegionServer is serving it?
Figure 3.11 Steps that take place when a client interacts with an HBase system.
The interaction starts with ZooKeeper and goes to the RegionServer serving the region with which the client needs to interact.
The interaction with the RegionServer could be for reads or writes.
This section gave you an overview of the implementation of HBase’s distributed architecture.
You can see all these details for yourself on your own cluster.
We show you exactly how to explore ZooKeeper, -ROOT-, and .META.
Now that you have an understanding of MapReduce and HBase in distributed mode, let’s look at them together.
There are three different ways of interacting with HBase from a MapReduce application.
HBase can be used as a data source at the beginning of a job, as a data sink at the end of a job, or as a shared resource for your tasks.
The third, however, has some interesting use cases we’ll address shortly.
All the code snippets used in this section are examples of using the Hadoop MapReduce API.
There are no HBase client HTable or HTablePool instances involved.
Those are embedded in the special input and output formats you’ll use here.
You will, however, use the Put, Delete, and Scan objects with which you’re already familiar.
Creating and configuring the Hadoop Job and Configuration instances can be messy work.
In the example MapReduce application, you read lines from log files sitting in the HDFS.
Those files, specifically the directory in HDFS containing those files, act as the data source for the MapReduce job.
The TextInputFormat class configured as part of the job defines this schema.
The relevant code from the TimeSpent example looks like this:
TextInputFormat defines the [k1,v1] type for line number and line as the types LongWritable and Text, respectively.
The associated map task definition is typed for consuming these input pairs:
HBase provides similar classes for consuming data out of a table.
When mapping over data in HBase, you use the same Scan class you used before.
Under the hood, the rowrange defined by the Scan is broken into pieces and distributed to all the workers (figure 3.12)
This is identical to the splitting you saw in figure 3.1
Creating a Scan instance for scanning over all rows in a table from MapReduce looks like this:
In this case, you’re asking the scanner to return only the text from the twits table.
Just like consuming text lines, consuming HBase rows requires a schema.
That’s the same scanner result as when you consume the regular HBase API.
The provided TableMapper wraps up these details for you, so you’ll want to use it as the base class for your Map Step implementation:
The next step is to take your Scan instance and wire it into MapReduce.
HBase provides the handy TableMapReduceUtil class to help you initialize the Job instance:
This takes your job-configuration object and sets up the HBase-specific input format (TableInputFormat)
It then configures MapReduce to read from the table using your Scan instance.
It also wires in your Map and Reduce class implementations.
From here, you write and run the MapReduce application as normal.
When you run a MapReduce job as described here, one map task is launched for every region in the HBase table.
In other words, the map tasks are partitioned such that each map task reads from a region independently.
The JobTracker tries to schedule map tasks as close to the regions as possibly and take advantage of data locality.
The tasks take the key range of the region as their input split and scan over it.
Figure 3.12 MapReduce job with mappers taking regions from HBase as their input source.
Writing to an HBase table from MapReduce (figure 3.13) as a data sink is similar to reading from a table in terms of implementation.
Let’s first make an example of sink configuration in a standard MapReduce application.
In the MapReduce application, they’re of the Hadoop serializable types Text and LongWritable, respectively.
Configuring output types is similar to configuring input types, with the exception that the [k3,v3] output types can’t be inferred by the OutputFormat:
When writing to HBase from MapReduce, you’re again using the regular HBase API.
The types of [k3,v3] are assumed to be a rowkey and an object for manipulating HBase.
That means the values of v3 must be either Puts or Deletes.
Because both of these object types include the relevant rowkey, the value of k3 is ignored.
Just as the TableMapper wraps up these details for you, so does the TableReducer:
Reduce tasks don't necessarily write to a region on the same physical host.
They will write to whichever region contains the key range that they are writing into.
This could potentially mean that all reduce tasks talk to all regions on the cluster.
Figure 3.13 HBase as a sink for a MapReduce job.
In this case, the reduce tasks are writing to HBase.
The last step is wiring your reducer into the job configuration.
You need to specify the destination table along with all the appropriate types.
Now your job is completely wired up, and you can proceed as normal.
Unlike the case where map tasks are reading from HBase, tasks don’t necessarily write to a single region.
The writes go to the region that is responsible for the rowkey that is being written by the reduce task.
The default partitioner that assigns the intermediate keys to the reduce tasks doesn’t have knowledge of the regions and the nodes that are hosting them and therefore can’t intelligently assign work to the reducers such that they write to the local regions.
Moreover, depending on the logic you write in the reduce task, which doesn’t have to be the identity reducer, you might end up writing all over the table.
Reading from and writing to HBase using MapReduce is handy.
It gives us a harness for batch processing over data in HBase.
A few predefined MapReduce jobs ship with HBase; you can explore their source for more examples of using HBase from MapReduce.
One common use of HBase is to support a large map-side join.
In this scenario, you’re reading from HBase as an indexed resource accessible from all map tasks.
Joining two tables is a fundamental concept in relational databases.
The idea behind a join is to combine records from the two different sets based on like values in a common attribute.
It produces a dataset containing a UserID and the TotalTime they spent on the TwitBase site:
You also have the user information in the TwitBase table that looks like this:
You’d like to know the ratio of how much time a user spends on the site to their total twit count.
Although this is an easy question to answer, right now the relevant data is split between two different datasets.
You’d like to join this data such that all the information about a user is in a single row.
The result of performing the join and dropping unused fields looks like this:
Joins in the relational world are a lot easier than in MapReduce.
Relational engines enjoy many years of research and tuning around performing joins.
Moreover, the data typically resides on a single physical server.
Joining across multiple relational servers is far more complicated and isn’t common in practice.
A join in MapReduce means joining on data spread across multiple servers.
But the semantics of the MapReduce framework make it easier than trying to do a join across different relational database systems.
There are a couple of different variations of each type, but a join implementation is either map-side or reduce-side.
They’re referred as map- or reduce-side because that’s the task where records from the two sets are linked.
Reduce-side joins are more common because they’re easier to implement.
A reduce-side join takes advantage of the intermediate Shuffle Step to collocate relevant records from the two sets.
The idea is to map over both sets and emit tuples keyed on the join key.
Once together, the reducer can produce all combinations of values.
Given the sample data, the pseudo-code of the map task for consuming the TimeSpent data looks like this:
This map task splits the k1 input line into the UserID and TimeSpent values.
It then constructs a dictionary with type and TimeSpent attributes.
A map task for consuming the Users data is similar.
The only difference is that it drops a couple of unrelated fields:
Producing compound records as v2 is common in MapReduce jobs.
Both map tasks use UserID as the value for k2
This allows Hadoop to group all records for the same user.
The reduce task has everything it needs to complete the join:
The reduce task groups records of identical type and produces all possible combinations of the two types as k3
For this specific example, you know there will be only one record of each type, so you can simplify the logic.
You also can fold in the work of producing the ratio you want to calculate:
This new and improved reduce task produces the new, joined dataset:
There you have it: the reduce-side join in its most basic glory.
One big problem with the reduce-side join is that it requires all [k2,v2] tuples to be shuffled and sorted.
But if the datasets are very, very large, with millions of pairs per value of k2, the overhead of that step can be huge.
Reduce-side joins require shuffling and sorting data between map and reduce tasks.
This incurs I/O costs, specifically network, which happens to be the slowest aspect of any distributed system.
The map-side join is a technique that isn’t as general-purpose as the reduce-side join.
It assumes the map tasks can look up random values from one dataset while they iterate over the other.
If you happen to want to join two datasets where at least one of them.
In these cases, you can skip the Shuffle and Reduce Steps entirely and emit your final output from the Map Step.
Compared to the last version, this looks like cheating! Remember, though, you can only get away with this approach when you can fit one of the datasets entirely into memory.
There are of course implications to doing joins like this.
Now you can join over the massive Users table and massive TimeSpent data set in record time! The map-side join using HBase looks like this:
Think of this as an external hash-table that each map task has access to.
You don’t need to create that hash-table object for every task.
You also avoid all the network I/O involved in the Shuffle Step necessary for a reduce-side join.
There’s a lot more to distributed joins than we’ve covered in this section.
They’re so common that Hadoop ships with a contrib JAR called hadoop-datajoin to make things easier.
You should now have enough context to make good use of it and also take advantage of HBase for other MapReduce optimizations.
The JobTracker distributes work across all the TaskTrackers in the cluster according to optimal resource utilization.
If any of those nodes fails, another machine is staged and ready to pick up the computation and ensure job success.
This section provides a complete example of consuming HBase from a MapReduce application.
Please keep in mind that running MapReduce jobs on an HBase cluster creates a significant burden on the cluster.
You don’t want to run MapReduce jobs on the same cluster that serves your low-latency queries, at least not when you expect to maintain OLTP-style service-level agreements (SLAs)! Your online access will suffer.
Idempotent operations Hadoop MapReduce assumes your map and reduce tasks are idempotent.
This means the map and reduce tasks can be run any number of times with the same input and produce the same output state.
This allows MapReduce to provide fault tolerance in job execution and also take maximum advantage of cluster processing power.
HBase’s Increment command is an example of such a stateful operation.
For example, suppose you implement a row-counting MapReduce job that maps over every key in the table and increments a cell value.
While the job is running, a disk drive fails on one of the TaskTracker nodes.
This causes the map task to fail, and Hadoop assigns that task to another node.
Before failure, 750 of the keys were counted and incremented.
When the new instance takes up that task, it starts again at the beginning of the key range.
Instead of incrementing the counter in the mapper, a better approach is to emit ["count",1] pairs from each mapper.
Sum the pairs in a reducer, and write out a single value from there.
This also avoids an unduly high burden being applied to the single machine hosting the incremented cell.
Another thing to note is a feature called speculative execution.
When certain tasks are running more slowly than others and resources are available on the cluster, Hadoop schedules extra copies of the task and lets them compete.
The moment any one of the copies finishes, it kills the remaining ones.
This feature can be enabled/ disabled through the Hadoop configuration and should be disabled if the MapReduce jobs are designed to interact with HBase.
As food for thought, consider this: don’t even run a JobTracker or TaskTrackers on your HBase cluster.
Unless you absolutely must, leave the resources consumed by those processes for HBase.
HBase is running on top of Hadoop, specifically the HDFS.
Data in HBase is partitioned and replicated like any other data in the HDFS.
That means running a MapReduce program over data stored in HBase has all the same advantages as a regular MapReduce program.
This is why your MapReduce calculation can execute the same HBase scan as the multithreaded example and attain far greater throughput.
In the MapReduce application, the scan is executing simultaneously on multiple nodes.
This removes the bottleneck of all data moving through a single machine.
If you’re running MapReduce on the same cluster that’s running HBase, it’s also taking advantage of any collocation that might be available.
Putting it all together, the Shakespearean counting example looks like the following listing.
CountShakespeare is pretty simple; it packages a Mapper implementation and a main method.
It also takes advantage of the HBase-specific MapReduce helper class TableMapper and the TableMapReduceUtil utility class that we talked about earlier in the chapter.
This example doesn’t need to perform additional computation in the reduce phase.
Would you like to see what it looks like to run a MapReduce job? We thought so.
Now that you have some data, you can run the CountShakespeare application over it:
Counters are fun and all, but what about writing back to HBase? We’ve developed a similar algorithm specifically for detecting references to Hamlet.
You’ll often hear the terms scalable, available, and reliable in the context of distributed systems.
In our opinion, these aren’t absolute, definite qualities of any system, but a set of parameters that can have varied values.
In other words, different systems scale to different sizes and are available and reliable in certain scenarios but not others.
These properties are a function of the architectural choices that the systems make.
Let’s instead jump into understanding what availability and reliability mean in the context of HBase and how it achieves them.
These properties are useful to understand from the point of view of building your application so that you as an application developer can understand what you can expect from HBase as a back-end data store and how that affects your SLAs.
Availability in the context of HBase can be defined as the ability of the system to handle failures.
The most common failures cause one or more nodes in the HBase cluster to fall off the cluster and stop serving requests.
This could be because of hardware on the node failing or the software acting up for some reason.
Any such failure can be considered a network partition between that node and the rest of the cluster.
When a RegionServer becomes unreachable for some reason, the data it was serving needs to instead be served by some other RegionServer.
But if there is a network partition and the HBase masters are separated from the cluster or the ZooKeepers are separated from the cluster, the slaves can’t do much on their own.
This goes back to what we said earlier: availability is best defined by the kind of failures a system can handle and the kind it can’t.
It isn’t a binary property, but instead one with various degrees.
For instance, if you have multiple masters, keep them in different racks.
Reliability is a general term used in the context of a database system and can be thought of as a combination of data durability and performance guarantees in most cases.
For the purpose of this section, let’s examine the data durability aspect of HBase.
Data durability, as you can imagine, is important when you’re building applications atop a database.
HBase, on the other hand, has certain guarantees in terms of data durability by virtue of the system architecture.
HBase assumes two properties of the underlying storage that help it achieve the availability and reliability it offers to its clients.
It assumes all the RegionServers have access to that file system across the entire cluster.
The file system exposes a single namespace to all the RegionServers in the cluster.
The data visible to and written by one RegionServer is available to all other RegionServers.
If a RegionServer goes down, any other RegionServer can read the data from the underlying file system and start serving the regions that the first RegionServer was serving (figure 3.15)
At this point, you may be thinking that you could have a network-attached storage (NAS) that was mounted on all the servers and store the data on that.
That’s theoretically doable, but there are implications to every design and implementation choice.
Having a NAS that all the servers read/write to means your disk I/O will be bottlenecked by the interlink between the cluster and the NAS.
You can have fat interlinks, but they will still limit the amount you can scale to.
Collocating these two processes helps in that RegionServers can read and write to the local DataNode, thereby saving network I/O whenever possible.
There is still network I/O, but this optimization reduces the costs.
You’re currently using a standalone HBase instance for the TwitBase application.
Chapter 9 goes into details of deploying HBase in a fully distributed manner, backed by HDFS.
When you do that, you’ll configure HBase to write to HDFS in a prespecified.
Disaster strikes on the host that was serving region R1
Another host picks up the region and starts serving it from the persisted HFile from HDFS.
The lost copy of the HFile will get replicated to another DataNode.
Figure 3.15 If a RegionServer fails for some reason (such as a Java process dying or the entire physical node catching fire), a different RegionServer picks up the regions the first one was serving and begins serving them.
This is enabled by the fact that HDFS provides a single namespace to all the RegionServers, and any of them can access the persisted files from any other.
HBase assumes that the data it persists on the underlying storage system will be accessible even in the face of failures.
If a server running the RegionServer goes down, other RegionServers should be able to take up the regions that were assigned to that server and begin serving requests.
The assumption is that the server going down won’t cause data loss on the underlying storage.
A distributed file system like HDFS achieves this property by replicating the data and keeping multiple copies of it.
At the same time, the performance of the underlying storage should not be impacted greatly by the loss of a small percentage of its member servers.
Theoretically, HBase could run on top of any file system that provides these properties.
But HBase is tightly coupled with HDFS and has been during the course of its development.
Apart from being able to withstand failures, HDFS provides certain write semantics that HBase uses to provide durability guarantees for every byte you write to it.
We covered quite a bit of ground this chapter, much of if at an elementary level.
There’s a lot more going on in Hadoop than we can cover with a single chapter.
You should now have a basic understanding of Hadoop and how HBase uses it.
In practice, this relationship with Hadoop provides an HBase deployment with many advantages.
It depends on Hadoop for both data access and data reliability.
Whereas HBase is an online system driven by low latency, Hadoop is an offline system optimized for throughput.
These complementary concerns make for a powerful, flexible data platform for building horizontally scalable data applications.
Hadoop MapReduce is a distributed computation framework providing data access.
MapReduce programs are written by composing map and reduce operations into Jobs.
MapReduce takes advantage of the HDFS by assigning tasks to blocks on the file system and distributing the computation to the data.
This allows for highly parallel programs with minimal distribution overhead.
HBase is designed for MapReduce interaction; it provides a TableMapper and a TableReducer to ease implementation of MapReduce applications.
The TableMapper allows your MapReduce application to easily read data directly out of HBase.
The TableReducer makes it easy to write data back to HBase from MapReduce.
It’s also possible to interact with the HBase key-value API from within the Map and Reduce Steps.
This is helpful for situations where all your tasks need random access to the same data.
With the basics covered, part 2 explores more advanced topics.
It continues the example application established in chapter 2 and provides insight into how to model data in HBase for your application.
This chapter will help you understand the trade-offs you’ll make in your schema design choices.
Chapter 5 shows how to build and use coprocessors, an advanced technique for pushing computational logic into your HBase cluster, close to where your data is stored.
Chapter 6 explains how to interact with HBase with alternative client libraries, on and off the JVM.
With this part of the book under your belt, you’ll be ready to make effective use of HBase in your application and also build with HBase in non-Java applications.
As a part of building our TwitBase, you created tables in your HBase instance to store data in.
The table definition was given to you, and you created the tables without going into the details of why you created them the way you did.
In other words, we didn’t talk about how many column families to have, how many columns to have in a column family, what data should go into the column names and what should go into the cells, and so on.
This chapter introduces you to HBase schema design and covers things that you should think about when designing schemas and rowkeys in HBase.
They’re much simpler and provide a few things you can play with.
But the simplicity gives you the ability to tweak it in order to extract optimal performance HBase table design.
In the first three chapters, you learned about interacting with HBase using the Java.
Some schemas may be great for writes, but when reading the same data back, these schemas may not perform as well, or vice versa.
To learn about designing HBase schemas, you’ll continue to build on the TwitBase application and introduce new features into it.
That’s not nearly enough functionality for an application and won’t drive user traffic unless users have the ability to be social and read other users’ twits.
Users want to follow other users, so let’s build tables for that purpose.
You’ll start with a simple schema design and iteratively improve it, and we’ll introduce important concepts along the way.
Some people may argue that a schema is only what you define up front on table creation.
Others may argue that all the points in this list are part of schema design.
NoSQL as a domain is relatively new, and clear definitions of terms are emerging as we speak.
We feel it’s important to encompass all of these points into a broad schema design topic because the schema impacts the structure of your table and how you read or write to it.
Let’s return to the table, which will store data about what users a particular user follows.
In that case, you’d be interested in checking whether TheRealMT exists in the list of users TheFakeMT follows.
A possible solution is to have a row for each user, with the user ID being the rowkey and each column representing a user they follow.
Remember column families? So far, you’ve used only a single column family because you haven’t needed anything more.
But what about this table? All users in the list of users TheFakeMT follows have an equal chance of being checked for existence, and you can’t differentiate between them in terms of access patterns.
You can’t assume that one member of this list is accessed more often than any of the others.
This bit of reasoning allows you to conclude that the entire list of followed users should go into the same column family.
How did we come to that conclusion? All data for a given column family goes into a single store on HDFS.
A store may consist of multiple HFiles, but ideally, on compaction, you achieve a single HFile.
Columns in a column family are all stored together on disk, and that property can be used to isolate columns with different access patterns by putting them in different column families.
In the table you’re building, you don’t need to isolate certain users being followed from others.
To store these relationships, you can create a new table called follows that looks like figure 4.1
You can create this table using the shell or the Java client, as you learned in chapter 2
Let’s look at it in a little more depth and make sure you have the optimal table design.
Keep in mind that once the table is created, changing any of its column families will require that the table be taken offline.
Now you need to validate that this table satisfies your requirements.
Figure 4.1 The follows table, which persists a list of users a particular user follows.
Online migrations HBase 0.92 has an experimental feature to do online schema migrations, which means you don’t need to take tables offline to change column families.
Designing your tables well up front goes a long way.
You aren’t too far along, so let’s do it now.
To define the access patterns, a good first step is to define the questions you want to answer using this table.
Whom does TheFakeMT follow?” can be answered by a simple get() call on the table you just designed.
It gives you the entire row, and you can iterate over the list to find the users TheFakeMT follows.
The entire list returned is the answer to question 1
Answering question 2 means iterating through the entire list and checking for the existence of TheRealMT.
The code is similar to the previous snippet, but instead of creating an array list, you compare at each step:
TheRealMT represents a cell in the column family follows with the column qualifier 1 and the value TheRealMT.
The fake Mark Twain wants to know everything he can about the real one.
He’s following not only the real Mark Twain but also his fans, his wife, and his friends.
Cheeky, huh? The real Mark Twain, on the other hand, keeps it simple and only wants to get twits from his dear friend and his wife.
It doesn’t get simpler than that, does it? Let’s continue building on this and ensure that your table design is the best you can accomplish and is optimal for all expected access patterns.
You now have a table design that can answer two out of the four questions on the earlier list.
You haven’t yet ascertained whether it answers the other two questions.
The questions so far define the read patterns for the table.
From the perspective of TwitBase, you expect data to be written to HBase when the following things happen:
Let’s look at the table and try to find places you can optimize based on these write patterns.
One thing that jumps out is the work the client needs to do when a user follows someone new.
This requires making an addition to the list of users the user is already following.
When TheFakeMT follows one more user, you need to know that the user is number 5 in the list of users TheFakeMT follows.
That information isn’t available to your client code without asking the HBase table.
Also, there is no concept of asking HBase to add a cell to an existing row without specifying the column qualifier.
To solve that problem, you have to maintain a counter somewhere.
The best place to do that is the same row.
In that case, the table now looks like figure 4.3
The count column gives you the ability to quickly display the number of users anyone is following.
This is good progress! Also notice that you haven’t needed to change the table definition so far.
Adding a new user to the list of followed users involves a few steps, as outlined in figure 4.4
Code for adding a new user to the list of followed users looks like this:
As you can see, keeping a count makes the client code complicated.
Every time you have to add a user to the list of users A is following, you have to first read back the count from the HBase table, add the next user, and update the count.
This process smells a lot like a transaction from the relational database systems you’ve likely worked with.
Figure 4.4 Steps required to add a new user to the list of followed users, based on the current table design.
Given that HBase doesn’t have the concept of transactions, this process has a couple of issues you should be aware of.
What if the user decides to follow two different users at the same time, maybe using two different browser windows or different devices? That’s not a common occurrence, but a similar effect can happen when the user clicks the Follow button for two different users quickly, one after the other: the threads processing those requests may read back the same count, and one may overwrite the other’s work.
Second, what if the client thread dies halfway through that process? You’ll have to build logic to roll back or repeat the write operation in your client code.
The only way you can solve this problem without making the client code complicated is to remove the counter.
Again, you can use the schema-less data model to your advantage.
One way to do it is to move the followed user ID into the column qualifier.
Remember, HBase stores only byte[], and you can have an arbitrary number of columns within a column family.
Let’s use those properties to your advantage and change the table to look like figure 4.5
You put the followed user’s username in the column qualifier instead of their position on the list of followed users.
You need something to put there because cells can’t be empty, so you can enter the number 1
This is different from how you would design tables in relational systems.
This is different from relational systems, where column names are fixed and need to be defined up front at the time of table creation.
The simplicity and flexibility of HBase’s schema allows you to make such optimizations without a lot of work but gain significant simplicity in client code or achieve greater performance.
With this new table design, you’re back to not having to keep a count, and the client code can use the followed user ID in the column qualifier.
That value is always unique, so you’ll never run into the problem of overwriting existing information.
The code for adding new users to the followed list becomes much simpler:
Figure 4.5 Cells now have the followed user’s username as the column qualifier and an arbitrary string as the cell value.
The code for reading back the list changes a little.
Instead of reading back the cell values, you now read back the column qualifiers.
With this change in the design, you lose the count that was available earlier.
Don’t worry about it right now; we’ll teach you how to implement that functionality in the next chapter.
Avoid designs that require transactional logic in client code, because it leads to a complex client that you have to maintain.
The implication is that the HBase table you just designed will have variable-length rows.
If you who don't have a computer science background, or if your CS is rusty, this O(n) business is called asymptotic notation.
It's a way to talk about, in this case, the worst-case runtime complexity of an algorithm.
O(n) means the algorithm grows linearly with the size of n.
O(1) means the algorithm runs in constant time, regardless of the size of the input.
We're using this notation to talk about the time it takes to access data stored in HBase, but it can also be used to talk about other characteristics of an algorithm, such as its memory footprint.
Note that we’re looking at this in the context of a single column family.
You begin by defining the time taken to find the relevant HFile block for a given rowkey.
This work happens whether you’re doing a get() on a single row or looking for the starting key for a scan.
First, the client library has to find the correct RegionServer and region.
It takes three fixed operations to get to the right region—lookup ZK, lookup -ROOT-, lookup .META..
In a given region, the row can exist in two places in the read path: in the MemStore if it hasn’t been flushed to disk yet, or in an HFile if it has been flushed.
For the sake of simplicity, we’re assuming there is only one HFile and either the entire row is contained in that file or it hasn’t been flushed yet, in which case it’s in the MemStore.
Consider the schema design shown in figure 4.6 for the follows table.
Until now, you’ve been working with a table that’s designed to be a wide table.
In other words, a single row contains lots of columns.
The same information can be stored in the form of a tall table, which is the new schema in figure 4.6
The KeyValue objects in HFiles store the column family along with it.
Keeping to short column family names makes a difference in reducing both disk and network I/O.2This optimization also applies to.
If the row is in the MemStore, looking it up is O(log e) because the MemStore is implemented as a skip list.2 If the row has been flushed to disk, you have to find the right HFile block.
The block index is ordered, so finding the correct block is a O(log b) operation.
Finding the KeyValue objects that make up the row you’re looking for is a linear scan inside the block.
Once you’ve found the first KeyValue object, it’s a linear scan thereafter to find the rest of them.
The scan is O(e/b), assuming that the number of cells in the row all fit into the same block.
If not, the scan must access data in multiple sequential blocks, so the operation is dominated by the number of rows read, making it O(c)
To sum it up, the cost of getting to a particular row is as follows:
O(log e) to locate the KeyValue in the MemStore if it’s in the MemStore or O(1) for region lookup.
O(log b) to find the correct block in the HFile.
O(max(c,e/b)) to find the dominating component of the scan if it has been flushed to disk.
When accessing data in HBase, the dominating factor is the time taken to scan the HFile block to get to the relevant KeyValue objects.
Having wide rows increases the cost of traversing the entire row during a scan.
All of this assumes that you know the rowkey of the row you’re looking for.
If you don't know the rowkey, you’re scanning an entire range of rows (possibly the entire table) to find the row you care about, and that is O(n)
In this case, you no longer benefit from limiting your scan to a few HFile blocks.
If the data read from the HFile is already loaded into the block cache, this sidebar’s analysis holds true.
If the data needs to be read into the BlockCache from HDFS, the cost of reading the blocks from disk is much greater, and this analysis won’t hold much significance, academically speaking.
The take-away is that accessing wider rows is more expensive than accessing smaller ones, because the rowkey is the dominating component of all these indexes.
Knowing the rowkey is what gives you all the benefits of how HBase indexes under the hood.
A table with some sample data is shown in figure 4.7
There’s only one cell in the column family, so you don’t need multiple KeyValues as in the previous design.
In HBase, accessing a single narrow row resident in the BlockCache is the fastest possible read operation.
From an I/O standpoint, you’re reading the same amount of data from the RegionServer when scanning those rows as compared to doing a Get on a single wide row and iterating over all the cells.
Remember the HFile design? The physical storage for both the table designs mentioned is essentially the same.
The physical indexing is what changed, as we’ll discuss a little later.
The + in the rowkey refers to concatenating the two values.
You can delimit using any character you like: for example, A-B or A,B.
Keeping the column family and column qualifier names short reduces the data transferred over the network back to the client.
Figure 4.6 New schema for the follows table with the follower as well as followed user IDs in the rowkey.
This translates into a single follower-followed relationship per row in the HBase table.
This is a tall table instead of a wide table like the previous ones.
Figure 4.7 The follows table designed as a tall table instead of a wide table.
And Amandeep is the fanboy we’ve been referring to so far.) Putting the user name in the column qualifier saves you from looking up the users table for the name of the user given an ID.
You can simply list names or IDs while looking at relationships just from this table.
The downside is that you need to update the name in all the cells if the user updates their name in their profile.
The code for getting the list of followed users now looks like this:
The code for checking whether a relationship exists between two users looks like this:
To add to the list of followed users, you do a simple put() as follows:
To gain the performance benefits of a tall table, you trade off atomicity for certain operations.
In the earlier design, you could update the followed list for any user with a single Put operation on a row.
In the second design, you give up the ability to do that.
In this case, it’s okay because your application doesn’t require that.
But other use cases may need that atomicity, in which case wide tables make more sense.
A good question to ask here is, why put the user ID in the column qualifier? It isn’t necessary to do that.
Think about TwitBase and what users may be doing that translates into reading this table.
Either they’re asking for a list of all the people they follow or they’re looking at someone’s profile to see if they’re following that user.
That information is stored in the users table at this point.
In order to populate the real name for the end user, you have to fetch it from the user table for each row in the follows table that you’ll return to the user.
Unlike in a relational database system, where you do a join and can accomplish all this in a single SQL query, here you have to explicitly make.
Includes all r where TheFakeMT is first part of ke.
To simplify, you could de-normalize3 and put the username in the column qualifier, or, for that matter, in the cell in this table.
This approach makes maintaining consistency across the users table and the follows table a little challenging.
That’s a trade-off you may or may not choose to make.
The intention of doing it here is to expose you to the idea of de-normalizing in HBase and the reasoning behind it.
If you expect your users to change their names frequently, denormalizing may not be a good idea.
We’re assuming that their names are relatively static content and de-normalizing won’t cost you much.
As of today, HBase doesn’t provide the features that make normalization easy to do.
In the twits table, you used MD5 as the rowkey.
First, your rowkeys are all of consistent length, giving you more predictability in terms of read and write performance.
That’s probably not a huge win if you put a limit on the user ID length.
The other benefit is that you don’t need the delimiter any more; it becomes simpler to calculate start and stop rows for the scans.
Using hashed keys also buys you a more uniform distribution of data across regions.
In the example you’ve been working with so far, distribution isn’t a problem.
It becomes a problem when your access patterns are skewed inherently and you’re at risk of hot-spotting on a few regions rather than spreading the load across the entire cluster.
For instance, if you’re inserting time-series data, and the timestamp is at the beginning of the rowkey, you’re always appending to the bottom of the table because the timestamp for any write is always greater than any timestamp that has already been written.
So, you’ll hot-spot on the last region of the table.
If you MD5 the timestamp and use that as the rowkey, you achieve an even distribution across all regions, but you lose the ordering in the data.
In other words, you can no longer scan a small time range.
If this is the first time you’ve come across the term de-normalization, it will be useful to read up on it before you proceed.
Essentially, you’re increasing the replication of data, paying more in storage and update costs, to reduce the number of accesses required to answer a question and speed overall access times.
Hot-spotting Hot-spotting in the context of HBase means there is a heavy concentration of load on a small subset of regions.
This is undesirable because the load isn’t distributed across the entire cluster.
Overall performance becomes bottlenecked by the few hosts that are serving those regions and thereby doing a majority of the work.
You haven’t lost getting access to records, though, because your clients can MD5 the timestamp before making the request.
By storing MD5s of the user IDs in the rowkey, you can’t get back the user IDs when you read back.
When you want the list of users Mark Twain follows, you get the MD5s of the user IDs instead of the user IDs.
But the name of the user is stored in the column qualifier because you want to store that information as well.
To make the user ID accessible, you can put it into the column qualifier and the name into the cell value.
The table looks like figure 4.9 with data in it.
Hashing and MD54 Hash functions can be defined as functions that map a large value of variable length to a smaller value of fixed length.
There are various types of hashing algorithms, and MD5 is one of them.
It’s a popular hash function that you’re likely to come across in various places; you probably already have.
Covering these algorithms in detail is beyond the scope of this text.
If you want to learn more about the guts of hashing and the MD5 algorithm, we recommend finding an online resource.
Using MD5 for the userIDs gives you fixed lengths instead of variable-length userIDs.
The rowkeys now consist of fixedlength portions, with each user ID being 16 bytes.
At this point, you may wonder what kind of indexing is taking place in HBase.
We’ve talked about it in the last two chapters, but it becomes important when thinking about your table designs.
The tall table versus wide table discussion is fundamentally a discussion of what needs to be indexed and what doesn’t.
Putting more information into the rowkey gives you the ability to answer some questions in constant time.
Remember the read path and block index from chapter 2? That’s what’s at play here, enabling you to get to the right row quickly.
Only the keys (the Key part of the KeyValue object, consisting of the rowkey, column qualifier, and timestamp) are indexed in HBase tables.
Think of it as the primary key in a relational database system, but you can’t change the column that forms the primary key, and the key is a compound of three data elements (rowkey, column qualifier, and timestamp)
The only way to access a particular row is through the rowkey.
Indexing the qualifier and timestamp lets you skip to the right column without scanning all the previous columns in that row.
The KeyValue object that you get back is basically a row from the HFile, as shown in figure 4.10
There are two ways to retrieve data from a table: Get and Scan.
If you want a single row, you use a Get call, in which case you have to provide the rowkey.
If you want to execute a Scan, you can choose to provide the start and stop rowkeys if you know them, and limit the number of rows the scanner object will scan.
We'll look at what it means to Get() row r5 from this table.
Figure 4.10 Logical to physical translation of an HBase table.
The KeyValue object represents a single entry in the HFile.
When you execute a Get, you can skip to the exact block that contains the row you’re looking for.
From there, it scans the block to find the relevant KeyValue objects that form the row.
In the Get object, you can also specify the column family and the column qualifiers if you want.
By specifying the column family, you can limit the client to accessing only the HFiles for the specified column families.
Specifying the column qualifier doesn’t play a role in limiting the HFiles that are read off the disk, but it does limit what’s sent back over the wire.
If multiple HFiles exist for a column family on a given region, all of them are accessed to find the components of the row you specify in the Get call.
This access is regardless of how many HFiles contain data relevant to the request.
Being as specific as possible in your Get is useful, though, so you don’t transfer unnecessary data across the wire to the client.
The only cost is potential disk I/O on the RegionServer.
If you specify timestamps in your Get object, you can avoid reading HFiles that are older than that timestamp.
You can use this information to inform your table design.
Putting data into the cell value occupies the same amount of storage space as putting it into the column qualifier or the rowkey.
But you can possibly achieve better performance by moving it up from the cell to the rowkey.
The downside to putting more in the rowkey is a bigger block index, given that the keys are the only bits that go into the index.
You’ve learned quite a few things so far, and we’ll continue to build on them in the rest of the chapter.
Figure 4.11 Depending on what part of the key you specify, you can limit the amount of data you read off the disk or transfer over the network.
Specifying the rowkey lets you read just the exact row you need.
But the server returns the entire row to the client.
Specifying the column family lets you further specify what part of the row to read, thereby allowing for reading only a subset of the HFiles if the row spans multiple families.
Further specifying the column qualifier and timestamp lets you save on the number of columns returned to the client, thereby saving on network I/O.
Hashing allows for fixed-length keys and better distribution but takes away ordering.
It also affects the disk and network I/O cost when the data is accessed.
The length of the column family name impacts the size of data sent over the wire to the client (in KeyValue objects)
Having worked through an example table design process and learned a bunch of concepts, let’s solidify some of the core ideas and look at how you can use them while designing HBase tables.
One of the key concepts when designing HBase tables is de-normalization.
So far, you’ve looked at maintaining a list of the users an individual user follows.
When a TwitBase user logs in to their account and wants to see twits from the people they follow, your application fetches the list of followed users and their twits, returning that information.
This process can take time as the number of users in the system grows.
Moreover, if a user is being followed by lots of users, their twits are accessed every time a follower logs in.
The region hosting the popular user’s twits is constantly answering requests because you’ve created a read hot spot.
The way to solve that is to maintain a twit stream for every user in the system and add twits to it the moment one of the users they follow writes a twit.
Earlier, you read the list of users they follow and then combined the latest twits for each of them to form the stream.
With this new idea, you’ll have a persisted list of twits that make up a user’s stream.
Normalization and de-normalization Normalization is a technique in the relational database world where every type of repeating information is put into a table of its own.
This has two benefits: you don’t have to worry about the complexity of updating all copies of the given data when an update or delete happens; and you reduce the storage footprint by having a single copy instead of multiple copies.
The data is recombined at query time using JOIN clauses in SQL statements.
This makes querying the data much easier and faster because you no longer need expensive JOIN clauses.
In this case, you can de-normalize by having another table for twit streams.
By doing this, you’ll take away the read-scalability issue and solve it by having multiple copies of the data (in this case, a popular user’s twits) available for all readers (the users following the popular user)
As of now, you have the users table, the twits table, and the follows table.
When a user logs in, you get their twit stream by using the following process:
Combine the twits and order them by timestamp, latest first.
You can add another column family to the users table and maintain a stream there for each user.
Putting the twit stream in the users table isn’t ideal because the rowkey design of that table is such that it isn’t optimal for what you’re trying to do.
The access pattern for the twit stream table consists of two parts:
Reading a list of twits to show to a given user when the user logs in, and displaying it in reverse order of creation timestamp (latest first)
Adding to the list of twits for a user when any of the users they follow writes a twit.
Another thing to think about is the retention policy for the twit stream.
You may want to maintain a stream of the twits from only the last 72 hours, for instance.
We talk about Time To Live (TTL) later, as a part of advanced column family configurations.
Using the concepts that we’ve covered so far, you can see that putting the user ID and the reverse timestamp in the rowkey makes sense.
You can easily scan a set of rows in the table to retrieve the twits that form a user’s twit stream.
You also need the user ID of the person who created each twit.
Normalization optimizes the table for writes; you pay the cost of combining data at read time.
Denormalization optimizes for reads, but you pay the cost of writing multiple copies at write time.
When someone creates a twit, all their followers should get that twit in their respective streams.
This can be accomplished using coprocessors, which we talk about in the next chapter.
When a user creates a twit, a list of all their followers is fetched from the relationships table, and the twit is added to each of the followers’ streams.
To accomplish this, you need to first be able to find the list of users following any given user, which is the inverse of what you’ve solved so far in your relationships table.
With the current table design, this question can be answered by scanning the entire table and looking for rows where the second half of the rowkey is the user you’re interested in.
In a relational database system, this can be solved by adding an index on the second column and making a slight change to the SQL query.
Also keep in mind that the amount of data you would work with is much smaller.
What you’re trying to accomplish here is the ability to perform these kinds of operations with large volumes of data.
HBase schemas are flexible, and you’ll use that flexibility now to avoid doing scans every time you want a list of followers for a given user.
The intent is to expose you to the various ideas involved in designing HBase tables.
The relationships table as you have it now has the rowkey as follows:
You can add the relationship information to this key and make it look like this:
That lets you store both kinds of relationships in the same table: following as well as followed by.
Answering the questions you’ve been working with so far now involves checking for the relationship information from the key.
When you’re accessing all the followers for a particular user or all the users a particular user is following, you’ll do scans over a set of rows.
When you’re looking for a list of users for the first case, you.
Figure 4.12 A table to store twit streams for every user.
Reverse timestamps let you sort the twits with the latest twit first.
That allows for efficient scanning and retrieval of the n latest twits.
Retrieving the latest twits in a user’s stream involves scanning the table.
Rowkey design strategies want to avoid having to read information for the other case.
In other words, when you’re looking for a list of followers for a user, you don’t want a list of users that the user follows in the dataset returned to your client application.
You can accomplish this by specifying the start and end keys for the scan.
Let’s look at another possible key structure: putting the relationship information in the first part of the key.
Think about how the data is distributed across the RegionServers now.
If you’re querying for a list of followers more often than the followed list, the load isn’t well distributed across the various regions.
That is the downside of this key design and the challenge in storing heterogeneous data in the same table.
The way to improve the load distribution in this case is to have separate tables for the two types of relationships you want to store.
You can create a table called followedBy with the same design as the follows table.
By doing that, you avoid putting the relationship type information in the key.
One of the challenges we haven’t addressed yet is keeping the two relationship entries consistent.
When Mark Twain decides to follow his fanboy, two entries need to be made in the tables: one in the follows table and the other in the followedBy table.
Given that HBase doesn’t allow inter-table or inter-row transactions, the client application writing these entries has to ensure that both rows are written.
Failures happen all the time, and it will make the client application complicated if you try to implement transactional logic there.
In an ideal world, the underlying database system should handle this for you; but design decisions are different at scale, and this isn’t a solved problem in the field of distributed systems at this point.
By now, you may have seen a pattern in the design process you went through to come up with the two tables to store relationship information.
You should model keys based on the expected access pattern.
Your rowkeys determine the performance you get while interacting with HBase tables.
Two factors govern this behavior: the fact that regions serve a range of rows based on the rowkeys and are responsible for every row that falls in that range, and the fact that HFiles store the rows sorted on disk.
This sorted nature of HBase tables and their underlying storage format allows you to reason about performance based on how you design your keys and what you put in your column qualifiers.
Unlike relational databases, where you can index on multiple columns, HBase indexes only on the key; the only way to access data is by using the rowkey.
If you don’t know the rowkey for the data you want to access, you’ll end up scanning a chunk of rows, if not the entire table.
There are various techniques to design rowkeys that are optimized for different access patterns, as we’ll explore next.
The sorted nature of HBase tables can turn out to be a great thing for your application—or not.
For instance, when we looked at the twit stream table in the previous section, its sorted nature gave you the ability to quickly scan a small set of rows to find the latest twits that should show up in a user’s stream.
But the same sorted nature can hurt you when you’re trying to write a bunch of time-series data into an HBase table (remember hot-spotting?)
If you choose your rowkey to be the timestamp, you’ll always be writing to a single region, whichever is responsible for the range in which the timestamp falls.
In fact, you’ll always be writing to the end of a table, because timestamps are monotonically increasing in nature.
This not only limits your throughput to what a single region can handle but also puts you at risk of overloading a single machine where other machines in the cluster are sitting idle.
The trick is to design your keys such that they’re optimized for the access pattern you care about.
When you’re writing lots of data into HBase tables, you want to optimize by distributing the load across RegionServers.
This isn’t all that hard to do, but you may have to make trade-offs in optimizing your read patterns: for instance, the time-series data example.
If your data is such that you use the timestamp as the rowkey, you’ll hot-spot on a single region during write time.
In many use cases, you don’t need to access the data based on a single timestamp.
You’ll probably want to run a job that computes aggregates over a time range, and if that’s not latency sensitive, you can afford to do a parallel scan across multiple regions.
HFile for the info column family in the users table.
The question is, how do you distribute that data across multiple regions? There are a few options to consider, and the answer depends on what kind of information you want your rowkeys to contain.
If you’re willing to lose the timestamp information from your rowkey (which may be okay in cases where you need to scan the entire table every time you want to do something, or you know the exact key every time you want to read data), making your rowkey a hash of the original data is a possible solution:
You need to know "TheRealMT" every time you want to access the row that is keyed by the hashed value of this function.
You most likely don’t know the specific timestamp when you access data; you probably have a time range in mind.
But there are cases like the twits table or the relationship tables you created earlier, where you know the user ID and can calculate the hash to find the correct row.
The way you use your hash function is also important.
The relationship tables you built earlier in this chapter use MD5 hashes of the user IDs, but you can easily regenerate those when you’re looking for a particular user’s information.
The reason is that when you want to scan all the relationships for a given user, you pass start and stop rowkeys to your scanner object.
Doing that when the key is a hash of the combination of the two user IDs isn’t possible because you lose the information for the given user ID from that rowkey.
Salting is another trick you can have in your tool belt when thinking about rowkeys.
Suppose you know the time range at read time and don’t want to do full table scans.
Hashing the timestamp and making the hash value the rowkey requires full table scans, which is highly inefficient, especially if you have the ability to limit the scan.
When working with large datasets, be careful to use a hashing algorithm that has lower probability of collision.
You can instead prefix the timestamp with a random number.
For example, you can generate a random salt number by taking the hash code of the timestamp and taking its modulus with some multiple of the number of RegionServers:
This involves taking the salt number and putting it in front of the timestamp to generate your timestamp:
Reads now involve distributing the scans to all the regions and finding the relevant rows.
Because they’re no longer stored together, a short scan won’t cut it.
It’s about trade-offs and choosing the ones you need to make in order to have a successful application.
Optimizing rowkeys for reads was your focus while designing the twit stream table.
The idea was to store the last few twits for a user’s stream together so they could be fetched quickly without having to do disk seeks, which are expensive.
It’s not just the disk seeks but also the fact that if the data is stored together, you have to read a smaller number of HFile blocks into memory to read the dataset you’re looking for; data is stored together, and every HFile block you read gives you more information per read than if the data were distributed all over the place.
In the twit stream table, you used reverse timestamps (Long.MAX_VALUE - timestamp) and appended it to the user ID to form the rowkey.
Now you need to scan from the user ID for the next n rows to find the n latest twits the user must see.
Putting the user ID first allows you to configure your scan so you can easily define your start rowkey.
Effective rowkey design isn’t just about what goes into the rowkey, but also about where elements are positioned in the rowkey.
You’ve already seen two cases of how the structure impacted read performance in the examples you’ve been working on.
First was the relationship table design, where you put the relationship type between the two user IDs.
You had to read (at least from the disk) all the information for both types of relationships for any given user even though you only needed information for one kind of relationship.
Moving the relationship type information to the front of the key solved that problem and allowed you to read only the data you needed.
Second was the twit stream table, where you put the reverse timestamp as the second part of the key and the user ID as the first.
That allowed you to scan based on user IDs and limit the number of rows to fetch.
Changing the order there resulted in losing the information about the user ID, and you had to scan a time range for the twits, but that range contained twits for all users with something in that time range.
For the sake of creating a simple example, consider the reverse timestamps to be in the range 1..10
There are three users in the system: TheRealMT, TheFakeMT, and Olivia.
If the rowkey contains the user ID as the first part, the rowkeys look like the following (in the order that HBase tables store them):
But if you flip the order of the key and put the reverse timestamp as the first part, the rowkey ordering changes:
Getting the last n twits for any user now involves scanning the entire time range because you can no longer specify the user ID as the start key for the scanner.
Now look back at the time-series data example, where you added a salt as a prefix to the timestamp to form the rowkey.
That was done to distribute the load across multiple regions at write time.
You had only a few ranges to scan at read time when you were looking for data from a particular time range.
This is a classic example of using the placement of the information to achieve distribution across the regions.
We have explored several concepts about HBase table design in this chapter thus far.
You may be at a place where you understand everything and are ready to go build your application.
Or you may be trying to look at what you just learned through the lens of what you already know in the form of relational database table modeling.
You’ve likely used relational database systems while building applications and been involved in the schema design.
If that’s not the case and you don’t have a relational database background, skip this section.
Before we go further into this conversation, we need to emphasize the following point: There is no simple way to map your relational database knowledge to HBase.
Mapping from relational to non-relational isn’t a topic that has received much attention so far.
There is a notable master’s thesis5 that explores this subject.
But we can draw some analogies and try to make the learning process a little easier.
In this section, we’ll map relational database modeling concepts to what you’ve learned so far about modeling HBase tables.
Things don’t necessarily map 1:1, and these concepts are evolving and being defined as the adoption of NoSQL systems increases.
The mapping of these concepts to HBase is somewhat convoluted.
That’s probably the most obvious mapping from the relational database world to HBase land.
In both relational databases and HBase, the default container for an entity is a table, and each row in the table should represent one instance of that entity.
This isn’t an iron-clad rule, but it’s a good place to start.
HBase forces you to bend the rules of normalization, so a lot of things that are full tables in a relational database end up being something else in HBase.
To map attributes to HBase, you must distinguish between (at least) two types:
Identifying attribute—This is the attribute that uniquely identifies exactly one instance of an entity (that is, one row)
In relational tables, this attribute forms the table’s primary key.
In HBase, this becomes part of the rowkey, which, as you saw earlier in the chapter, is the most important thing to get right while designing HBase tables.
This maps to the concept of compound keys in relational database systems: for instance, when you define relationships.
In the HBase world, the identifying attributes make up the rowkey, as you saw in the tall version of the follows table.
The rowkey was formed by concatenating the user IDs of the users that formed the relationship.
HBase doesn’t have the concept of compound keys, so both identifying attributes had to be put into the rowkey.
Variable lengths mean you need delimiters and escaping logic in your client code to figure out the composite attributes that form the key.
Fixed length also makes it easier to reason about start and stop keys.
A way to achieve fixed length is to hash the individual attributes as you did in the follows table.
For the users table that you built earlier in the book, non-identifying attributes were things like the password and the email address.
As explained earlier in this chapter, each key/value (for example, the fact that user TheRealMT has a state of Missouri) carries its entire set of coordinates around with it: rowkey, column family name, column qualifier, and timestamp.
If you have a relational database table with wide rows (dozens or hundreds of columns), you probably don’t want to store each of those columns as a column in HBase (particularly if most operations deal with mutating the entire row at a time)
Instead, you can serialize all the values in the row into a single binary blob that you store as the value in a single cell.
This takes a lot less disk space, but it has downsides: the values in the row are now opaque, and you can’t use the structure that HBase tables have to offer.
When the storage footprint (and hence the disk and network I/O) are important and the access patterns always involve reading entire rows, this approach makes sense.
Logical relational models use two main varieties of relationships: one-to-many and many-to-many.
Relational databases model the former directly as foreign keys (whether explicitly enforced by the database as constraints, or implicitly referenced by your application as join columns in queries) and the latter as junction tables (additional tables where each row represents one instance of a relationship between the two main tables)
There is no direct mapping of these in HBase, and often it comes down to denormalizing the data.
The first thing to note is that HBase, not having any built-in joins or constraints, has little use for explicit relationships.
You can just as easily place data that is one-tomany in nature into HBase tables: one table for users and another for their twits.
But this is only a relationship in that some parts of the row in the former table happen to correspond to parts of rowkeys in the latter table.
HBase knows nothing of this relationship, so it’s up to your application to do things with it (if anything)
As mentioned earlier, if the job is to return all the twits for all the users you follow, you can’t rely on a join or subquery to do this, as you can in SQL:
Instead, you need to write code outside of HBase that iterates over each user and then does a separate HBase lookup for that user to find their recent twits (or else, as explained previously, de-normalize copies of the twits for each follower)
As you can see, outside of implicit relationships enforced by some external application, there’s no way to physically connect disparate data records in HBase.
One thing that’s significantly different about HBase is that the columns (also known as column qualifiers) aren’t predefined at design time.
From relational to non-relational then with the followed username as the qualifier)
Note that far from being a flexible schema row, this represents the ability to nest another entity inside the row of a parent or primary entity (figure 4.14)
As an added bonus, in this pattern you do get transactional protection around the parent and child records, because in HBase, the row is the boundary of transactional protection.
So you can do check and put operations and generally be sure that all your modifications are wrapped up and commit or fail together.
You can put in nested entities by using HBase’s flexibility because of the way columns are designed.
HBase doesn’t necessarily have special abilities to store nested entities.
First, this technique only works to one level deep: your nested entities can’t themselves have nested entities.
You can still have multiple different nested child entities in a single parent, and the column qualifier is their identifying attributes.
Second, it’s not as efficient to access an individual value stored as a nested column qualifier inside a row, as compared to accessing a row in another table, as you learned earlier in the chapter.
Still, there are compelling cases where this kind of schema design is appropriate.
If the only way you get at the child entities is via the parent entity, and you’d like to have transactional protection around all children of a parent, this can be the right way to go.
Figure 4.15 HBase tables can contain regular columns along with nested entities.
HBase doesn’t help you with optimized joins or any such thing; but you don’t get off easy by nesting an entity, because each relationship has two parents.
This often translates to de-normalization, as it did in the case of the follows table earlier in the chapter.
You de-normalized the follower relationship, which is a self-referential many-to-many relationship on users.
These are the basic foundations of mapping your relational modeling knowledge to concepts in the HBase world.
So far, you’ve mapped a bunch of concepts from the relational world to HBase.
It turns out there’s no direct analogue in the relational world! Column families exist in HBase as a way for a single row to contain disjoint sets of columns in a way that’s physically efficient but can be processed atomically.
Unless you use a column-oriented database like Vertica, or special analytical features of the commercial relational databases, this isn’t something relational databases do.
An example is user personal information (email address, birthday, and so on) versus user system preferences (background color, font size, and so on)
It’s common to model these as two separate physical tables in a relational database, with the thought that because your SQL statements nearly always hit one or the other, but not both, they may perform more optimally if you separate the tables.
This depends heavily on which database you’re using and a million other factors, but it does happen.)
In HBase, this is a perfect case for using two column families in a single table.
And, likewise, the nested entity relationships mentioned earlier can easily be partitioned into separate column families, on the assumption that you’d likely not access both together.
Generally speaking, using multiple column families in HBase is an advanced feature that you should only jump into if you’re sure you understand the trade-offs.
Another common question when migrating from a relational database to HBase is: what about indexes? In relational databases, the ability to easily declare indexes that are automatically maintained by the database engine is one of the most magical and helpful capabilities the software provides, and it’s nowhere to be found in HBase.
For now, the answer to this question is: tough luck.
You can make some approximation of this feature by de-normalizing data and writing it into multiple tables, but make no mistake: when you move to HBase, you’re explicitly giving up the warm, comfortable world where a simple CREATE INDEX statement solves big performance problems and gets your boss off your back.
Advanced column family configurations you have to work through all those questions up front and design your access patterns into your schema.
There’s one final interesting angle on the relationship between relational databases and non-relational ones: the time dimension.
If, in your relational schema, there are places where you explicitly store timestamps, these can in many cases be subsumed into the timestamp that’s stored in HBase cells.
Beware that this is only a long, so if you need more than UNIX-era timestamps held in a 64-bit long, that’s all you get in HBase timestamps (thus they’re probably not right for storing the granules of time in atomic simulations)
Even better, if your application currently goes out of its way to store historical versions of values in a table (in a pattern often referred to as the history table pattern, where you use the same primary key from the main table coupled with a timestamp, in order to preserve all copies of rows over time): rejoice! You can dump that dumb idea and replace it with a single HBase entity, and set the number of versions to keep appropriately in the column family metadata.
This is an area that’s significantly easier in HBase; the original architects of relational models didn’t want to consider time to be a special dimension outside of the relational model, but let’s face it: it is.
We hope you now have a good sense of what all those years of studying relational database design bought you in the move to HBase.
If you understand the basics of logical modeling and know what schema dimensions are available in HBase, you’ve got a fighting chance of preserving the intent of your designs.
HBase has a few advanced features that you can use when designing your tables.
These aren’t necessarily linked to the schema or the rowkey design but define aspects of the behavior of the tables.
In this section, we’ll cover these various configuration parameters and how you can use them to your advantage.
The HFile block size can be configured at a column family level.
This block is different from HDFS blocks that we talked about earlier.
The block index stores the starting key of each HFile block.
The block size configuration affects the size of the block index size.
The smaller the block size, the larger the index, thereby yielding a bigger memory footprint.
It gives you better random lookup performance because smaller blocks need to be loaded into memory.
If you want good sequential scan performance, it makes sense to load larger chunks of the HFile into the memory at once, which means setting the block size to a larger value.
The index size shrinks and you trade random read performance.
You can set the block size during table instantiation like this:
Often, workloads don’t benefit from putting data into a read cache—for instance, if a certain table or column family in a table is only accessed for sequential scans or isn’t accessed a lot and you don’t care if Gets or Scans take a little longer.
In such cases, you can choose to turn off caching for those column families.
If you’re doing lots of sequential scans, you’re churning your cache a lot and possibly polluting it for data that you can benefit by having in the cache.
By disabling the cache, you not only save that from happening but also make more cache available for other tables and other column families in the same table.
You can disable it at the time of table creation or by altering the table:
You can choose some column families to have a higher priority in the block cache (LRU cache)
This comes in handy if you expect more random reads on one column family compared to another.
Setting it to true isn’t done a lot in practice because no added guarantees are provided except the fact that HBase will try to keep this column family in the block cache more aggressively than the other column families.
The block index provides an effective way to find blocks of the HFiles that should be read in order to access a particular row.
The default size of an HFile block is 64 KB, and this size isn’t tweaked much.
If you have small rows, indexing just the starting rowkey for an entire block doesn’t give you indexing at a fine granularity.
The row you’re looking for may fall in the range of a particular block but doesn’t necessarily have to exist in that block.
There can be cases where the row doesn’t exist in the table or resides in a different HFile or even the MemStore.
In that case, reading the block from disk brings with it I/O overhead and also pollutes the block cache.
This impacts performance, especially when you’re dealing with a large dataset and lots of concurrent clients trying to read it.
Bloom filters allow you to apply a negative test to the data stored in each block.
Advanced column family configurations that row is not in the block.
The bloom filter says conclusively that the row isn’t present, or says that it doesn’t know.
Bloom filters can also be applied to the cells within a row.
The same negative test is made when accessing a specific column qualifier.
Bloom filters grow with the size of the data they index, so a row-level bloom filter takes up less space than a qualifier-level bloom filter.
When space isn’t a concern, they allow you to squeeze that much additional performance out of the system.
You enable bloom filters on the column family, like this:
A row-level bloom filter is enabled with ROW, and a qualifier-level bloom filter is enabled with ROWCOL.
The rowlevel bloom filter checks for the non-existence of the particular rowkey in the block, and the qualifier-level bloom filter checks for the non-existence of the row and column qualifier combination.
The overhead of the ROWCOL bloom filter is higher than that of the ROW bloom filter.
Often, applications have the flexibility or requirement to delete old data from their databases.
Traditionally, a lot of flexibility was built in because scaling databases beyond a certain point was hard.
In TwitBase, for instance, you wouldn’t want to delete any twits generated by users in the course of their use of the application.
This is all human-generated data and may turn out to be useful at a future date when you want to do some advanced analytics.
But it isn’t a requirement to keep all those twits accessible in real time.
Twits older than a certain period can be archived into flat files.
HBase lets you configure a TTL in seconds at the column family level.
Data older than the specified TTL value is deleted as part of the next major compaction.
If you have multiple versions on the same cell, the versions that are older than the configured TTL are deleted.
You can set the TTL while creating the table like this:
This helps by saving on disk I/O and instead paying with a higher CPU utilization for compression and decompression while writing/reading data.
It’s recommended that you enable compression on your tables unless you know for a fact that you won’t benefit from it.
This can be true in cases where either the data can’t be compressed much or your servers are CPU bound for some reason.
Various compression codecs are available to be used with HBase, including LZO, Snappy, and GZIP.
Snappy was released by Google in 2011, and support was added into the Hadoop and HBase projects soon after its release.
The LZO native libraries that need to be used with Hadoop are GPLv2-licensed and aren’t part of any of the HBase or Hadoop distributions; they must be installed separately.
Snappy, on the other hand, is BSD-licensed, which makes it easier to bundle with the Hadoop and HBase distributions.
You can enable compression on a column family when creating tables like this:
It’s kept uncompressed in memory (MemStore or block cache) or while transferring over the network.
It shouldn’t happen often, but if you want to change the compression codec being used for a particular column family, doing so is straightforward.
You need to alter the table definition and put in the new compression scheme.
The HFiles formed as a part of compactions thereafter will all be compressed using the new codec.
There is no need to create new tables and copy data over.
But you have to ensure that the old codec libraries aren’t deleted from the cluster until all the old HFiles are compacted after this change.
If you care about only one version, it’s recommended that you configure your tables to maintain only one.
This way, it doesn’t hold multiple versions for cells you may update.
Versions are also configurable at a column family level and can be specified at the time of table instantiation:
You can specify multiple properties for column families in the same create statement, like this:
You can also specify the minimum versions that should be stored for a column family like this:
This comes in handy in conjunction with setting the TTLs on the family.
When all versions currently stored are older than the TTL, at least the MIN_VERSION number of last versions is kept around.
This ensures that you don’t get empty results if you query and the data is older than the TTL.
You’ve learned so far that HBase has a flexible schema and a simple disk layout, which allows applications to work closer to the disk and network and optimize at that level.
Designing effective schemas is one aspect of it, and by now you have a bunch of concepts that you can apply to do that.
You can design your keys such that data you access together is placed close on the disk so you can save on disk seeks while reading or writing.
Often you have certain criteria, based on which you’re reading data that you can use to further optimize access.
Filters are a powerful feature that can come in handy in such cases.
We haven’t come across many real-life use cases that use filters much; generally the access pattern can be optimized with tweaks to the table designs.
But sometimes you’ve tweaked your table design as much as you can, and optimized it for as many different access patterns as possible.
When you still need to reduce the data returned to clients, that’s when you reach for a filter.
Filters are sometimes called push-down predicates, allowing you to push data-filtering criteria down to the server (see figure 4.16)
That logic is applied during reads and affects the data that is returned to the client.
This saves network I/O by limiting the data transferred over the network.
Figure 4.16 Filtering data can be done at the client side by reading data into the client application from the RegionServers and applying the filter logic there; or it can be done at the server side by pushing the filtering logic down to the RegionServers, thereby reducing the amount of data transferred over the network to the clients.
Filters can essentially save on network I/O costs, and sometimes even on disk I/O.
The network I/O savings can be significant because you’re probably storing a large amount of data in HBase tables, and reading it all into the client application to filter out useful bits is expensive.
HBase provides an API you can use to implement custom filters.
Filtering can be done based on the rowkeys, which happens the earliest in the read process.
Thereafter, filtering can happen based on the KeyValues read off the HFiles.
A filter has to implement the Filter interface that’s part of the HBase JAR or extend one of the abstract classes that implement it.
We recommend extending the FilterBase abstract class so you can avoid having to write boilerplate code.
Extending other classes such as CompareFilter is also an option and works equally well.
The interface has the following methods that are called at various points while reading a row (see figure 4.17 for the order)
This method is the first one to be called and performs filtering based on the rowkey:
Based on the logic in there, it returns true if the row is to be filtered out (not included in the result set returned) or false if it’s to be sent to the client.
If the row isn’t filtered in the previous step, this method is invoked next for every KeyValue object that’s part of the current row:
This method returns a ReturnCode, which is an enum defined as a part of the Filter interface.
The ReturnCode returned determines what happens to that particular KeyValue object.
This method comes after the KeyValues are filtered based on step 2:
This method is passed the list of KeyValue objects that made it after filtering.
Given that this method has access to that list, you can perform any transformations or operations you want to on the elements in the list at this point.
At this point, the framework provides another chance to filter out the row if you choose to do so:
You can build logic in your filter to stop a scan early.
This is the method into which you put that logic:
This is handy in cases where you’re scanning a bunch of rows, looking for something specific in the rowkey, column qualifier, or cell value, and you don’t care about the remaining rows once you’ve found it.
This is the last method to be called in the filtering process.
It resets the filter and is called by the server after it has been applied to the entire row.
In many cases, the requirement for using filters changes if the schema design is changed.
You’ve been building TwitBase, and as the application has matured and gained users, you realize that the password strength policy you have in place for new users doesn’t ensure passwords that are secure enough.
This brings about a new policy, albeit a simple one: TwitBase now requires all users to have a password that’s at least four characters long.
To enforce this policy on old users, you need to go through the entire list of users and check for password length.
In cases where it’s less than four characters, the password needs to be expired and a notification sent across informing the user of the new policy and the action they need to take: resetting their password to something that’s at least six characters long.
You’ll implement this using a custom filter that checks the length of the value in the cell.
This filter can be applied to a scan (or to a MapReduce job), which outputs only the users to whom the password change notification has to be sent.
The output is the user’s name, user ID, and email address.
You’ll implement this using a scan, but you can easily convert it to a MapReduce job.
The filter you need to build is concerned only about the value in the password cell and not about anything else.
Transformation on the KeyValue objects that made it after filtering.
Add to the results to be sent back to client.
This happens for each row in the range that is being scanned by the scanner object.
To install custom filters, you have to compile them into a JAR and put them in the HBase classpath so they get picked up by the RegionServers at startup time.
In a running system, you have to restart your cluster.
To compile the JAR, in the top-level directory of the project, do the following:
Now, edit your hbase-env.sh file in $HBASE_HOME/conf and put the path of the created JAR into the classpath variable.
This filter can be used in a scan as follows:
Listing 4.1 Implementing a custom filter to check password length.
Check length: method sets filterRow boolean variable to true if row to be filtered out, wh happens if password length is greater than min required length.
This usage filters out all rows where the password length is greater than or equal to four characters and returns rows with the names and emails of the users whose passwords don’t match the minimum length requirement.
The password field isn’t returned because its KeyValue object is excluded in the filter.
HBase ships with numerous filters bundled along, so you may not need to implement your own.
To see a comprehensive list, we recommend that you look at the javadocs.
We’ll cover some of the more commonly used ones here.
RowFilter is a comparison filter that comes bundled and allows you to filter data based on rowkeys.
You can do exact matches, substring matches, or regular-expression matches and filter out data that doesn’t match.
To instantiate RowFilter, you have to provide a comparison operator and the value you want to compare.
The comparison operators are defined in CompareOp, which is an enum defined in the CompareFilter abstract class and can have the following values:
Use it to filter based on a prefix value of the rowkey.
This is useful because calculating stopRow correctly can sometimes be tricky when taking byte[] overflow into account.
PrefixFilter isn’t smart enough to skip ahead to the first matching startRow, so be sure to provide it.
It’s smart enough to end the scan once it finds the first rowkey that doesn’t match the prefix.
QualifierFilter is a comparison filter like RowFilter, except it matches the column qualifier name rather than the rowkey.
It uses the same comparison operators and comparator types as RowFilter.
There is a filter to match the column family name as well, but it isn’t as interesting as QualifierFilter.
Besides, you can limit the scan or get operation to a particular column family.
Like a scan, you can apply any filter to a Get object, but not all of them make sense.
For instance, filtering a Get based on the rowkey isn’t useful.
But you can filter out columns being returned in a Get using QualifierFilter.
ValueFilter provides the same functionality as RowFilter or QualifierFilter, but over cell values.
Using this filter allows you to filter out all cells that don’t match the provided criteria:
This filter allows much finer-grained control over the versions that are returned to the client.
You provide a list of timestamps that should be returned, and only cells with a matching timestamp are returned.
The filter, on the other hand, lets you specify a list of timestamps that should be matched:
Suppose you’re looking to get back all rows that match a certain regular expression but are interested in cells that contain a particular word.
In that case, you can combine filters into a FilterList object and pass it to the scanner.
The FilterList class also implements the Filter interface and can be used to create filtering logic that combines multiple individual filters.
As the names suggest, the modes include results in the final list if they pass all filters or if they pass only one filter, respectively:
The filters are applied in the order that the List object gives them back.
So, you can choose to have finer control based on the type of list object you use or by inserting the filters in the list in a particular order.
Filter out columns if cell value doesn’t start with foo.
Instantiate filter list with list of filters and config mode for list.
The Filtering API is powerful and has features that allow you to optimize disk seeks.
This not only saves network I/O but also saves on disk I/O.
We’re glad you made it to the end and hope you learned a few things along the way.
In many ways, HBase provides a new approach to data management.
That’s true both in the capabilities of the system as well as in the best practices around using that system.
With any luck, this chapter has opened your eyes to the considerations that must be addressed when designing HBase tables as well as the feature trade-offs you make when you decide to work with or without a relational system.
When designing for HBase, it’s about efficiently looking up the answer to a question, not purity of the entity model.
You must make this trade-off because distributed transactions bottleneck concurrency and distributed joins are network-bound.
You have to put something on paper and run it through some scenarios to see where it breaks down.
De-normalization is both a powerful friend and a frightful foe.
There’s always a trade-off between the response time of reads and the complexity of writes.
Maximize the number of questions you can answer with a given design, and then tweak it to support two new access patterns.
When building on HBase or any other distributed system, distribution of workload is always a concern.
These tools are designed to handle a huge volume of traffic spread across the cluster.
A build-up of traffic, or hot spot, on any single member of the cluster is catastrophic.
Because of that, you must always keep the even distribution of that load in the back of your mind.
HBase gives you the ability to design that load into your schema.
HBase has multiple indexes over multiple dimensions of the physical data model.
This is as much a challenge as it is empowering.
If you can’t figure out how to answer that last question, step back and see if there’s an index you haven’t taken advantage of yet.
Seeing these opportunities is a big part of why it’s important to understand how HBase works under the hood.
Remember, designing your rowkey is the single most important decision you can make.
Take full advantage of the flexibility of the logical data model.
Scans are your friend, but use them wisely and for the right access patterns.
And remember, when all else fails, you can always fall back on a custom filter.
Now that you’re equipped with the tricks of the trade when it comes to designing HBase tables, the next two chapters are about extending HBase to add interesting functionality that you may want for your application.
Everything you’ve seen of HBase as an online system is centered on data access.
The five HBase commands introduced in chapter 2 are exclusively for reading or writing data.
For the HBase cluster, the most computationally expensive portion of any of those operations occurs when applying server-side filters on Scan results.
Even so, this computation is extremely specific to accessing the data.
You can use custom filters to push application logic onto the cluster, but filters are constrained to the context of a single row.
To perform computation over your data in HBase, you’re forced to rely on Hadoop MapReduce or on custom client code that will read, modify, and write data back to HBase.
HBase coprocessors are an addition to our data-manipulation toolset that were introduced as a feature in HBase in the 0.92.0 release.
With the introduction of coprocessors, we can push arbitrary computation out to the HBase nodes hosting our Extending HBase with coprocessors.
This code is run in parallel across all the RegionServers.
This transforms an HBase cluster from horizontally scalable storage to a highly capable, distributed, data-storage and -processing system.
Think of them as akin to Linux kernel modules or RDBMS stored procedures implemented in C.
Writing an observer coprocessor is tricky to get right, and such a coprocessor can be extremely difficult to debug when running at scale.
Unlike client-side bugs, a buggy coprocessor will take down your cluster.
The HBase community is still working out exactly how to use coprocessors effectively.1 Caution is advised.
In this chapter, we’ll introduce you to the two types of coprocessors and show examples of how to use each one.
We hope this will open your mind to the possibilities so you’ll be able to use coprocessors in your own applications.
You never know: maybe you can be the one to write the blog post describing the canonical coprocessor example! Please make it more interesting than WordCount.
Each serves a different purpose and is implemented according to its own API.
Observers allow the cluster to behave differently during normal client operations.
Endpoints allow you to extend the cluster’s capabilities, exposing new operations to client applications.
To understand observer coprocessors, it helps to understand the lifecycle of a request.
A request starts with the client, creating a request object and invoking the appropriate method on the HTableInterface implementation.
For example, a Put instance is created and the put() method called.
The HBase client resolves the RegionServer that should receive the Put based on the rowkey and makes the RPC call.
The RegionServer receives the Put and delegates it to the appropriate region.
More inspiration from Google As with much of the rest of the Hadoop ecosystem, coprocessors come to the open source community by way of Google.
Coprocessors are cited as crucial for a number of horizontally scalable, low-latency operations.
These operations include machine translation, full-text queries, and scalable metadata management.
Observers sit between the client and HBase, modifying data access as it happens.
You can run an observer after every Get command, modifying the result returned to the client.
Or you can run an observer after a Put command, performing manipulation on the data that a client writes to HBase before it’s persisted.
You can think of observer coprocessors as analogous to triggers from a relational database or to advice from aspect-oriented programming (AOP)
Multiple observers can be registered simultaneously; they’re executed in priority order.
The CoprocessorHost class manages observer registration and execution on behalf of the region.
The region receives the put(), processes it, and constructs a response.
A Put request dispatched from the client results directly in a put() call on the region.
A word of caution Bear in mind that coprocessors are executed in the same process space as the RegionServer.
This means code in a coprocessor has full rights and privileges of the HBase user process on the server.
It also means a buggy coprocessor can potentially crash the process.
As of HBase version 0.92, three kinds of observers are available:
All of the standard data-manipulation commands can be intercepted with both pre- and post-hooks.
It also exposes pre- and post-hooks for internal region operations such as flushing the MemStore and splitting the region.
The RegionObserver runs on the region; thus there can be multiple RegionObservers running on the same RegionServer.
The only available hooks are pre- and post-WAL write events.
Unlike the RegionObserver, WALObservers run in the context of a RegionServer.
CoprocessorHost intercepts the request and invoices prePut() on each RegionObserver registered on the table.
Unless interrupted by a prePut(), the request continues to region and is processed normally.
The result produced by the region is once again intercepted by the CoprocessorHost.
Assuming no postPut() interrupts the response, the final result is returned to 6
Instead of calling put() directly, the region calls prePut() and postPut() on all registered RegionObservers, one after the next.
Each has a chance to modify or interrupt the operation before a response is returned to the client.
MasterObserver—For hooking into DDL events, such as table creation or schema modifications, HBase provides the MasterObserver.
For example, you can use the postDeleteTable() hook to also delete secondary indexes when the primary table is deleted.
When an endpoint is installed on your cluster, it extends the HBase RPC protocol, exposing new methods to client applications.
Just like observers, endpoints execute on the RegionServers, right next to your data.
Endpoint coprocessors are similar to stored procedures in other database engines.
From the client’s perspective, invoking an endpoint coprocessor is similar to invoking any other HBase command, except that the functionality is based on the custom code that defines the coprocessor.
The request object is created, it’s passed to the HTableInterface to execute on the cluster, and the results are collected.
This arbitrary code can do anything for which you can write code in Java.
At their most basic, endpoints can be used to implement scatter-gather algorithms.
HBase ships with an Aggregate example: an endpoint that computes simple aggregates like sum and average.
The regions deploy an implementation of the interface consumed by the client.
An instance of Batch.Call encapsulates method invocation, and the coprocessorExec() method handles distributed invocation.
After each request completes, results are returned to the client and aggregated.
We’ll show you how to implement both kinds of coprocessors and demonstrate activation of these implementations on your HBase installation.
Think back to the follows relationship table you created in the last chapter.
Instead of manually maintaining the secondary index in followedBy, let’s write an observer to maintain that relationship.
To accomplish this goal, you’ll implement a RegionObserver and override its postPut() method.
Inside of postPut(), the only relevant context you’ll have is the Put instance sent by the client.
That means you need to slightly modify the follows and followedBy schema you defined in the previous chapter.
Caveat emptor This example shows how you might maintain a secondary index using coprocessors.
In practice, we don’t recommend this approach when throughput is a consideration.
Updating a secondary index likely requires communication with a region hosted on a different RegionServer.
That communication is additional networking overhead and will impact cluster performance.
That said, if your application doesn’t require maximum throughput, this is a pretty simple way to offload that work.
Under such a scenario, you can reduce client latency by making the postPut operation asynchronous, removing it from the critical path of the write.
Then you can use a MapReduce job to rebuild the index periodically, catching records that fell through the cracks.
Figure 5.4 Schema for follows and followedBy tables as optimized for space and I/O efficiency.
The follows table stores half of a relation entity indexed according to the follower participant.
The followedBy table stores the other half of the same relation entity indexed according to the followed participant.
Because a Put to the follows table now must contain the entire relation entity, you can store the same entity in the followedBy table.
That way both tables have a complete entity stored per row.
With the full context available in the Put, you can go about implementing the observer.
Doing so requires extending BaseRegionObserver and overriding the postPut() method:
Figure 5.5 Schema for the updated follows and followedBy tables.
Now both tables store a full relation entity in each row.
The FollowsObserver keeps track of Puts against the follows table, watching for new follower relationship entries.
When a new entry is found, it constructs the inversion of that relationship and writes it back to the followedBy table.
Check the column family name used in the incoming Put request:
This check is necessary because coprocessors installed via configuration in hbasesite.xml are applied to all tables.
For your purpose, you only want to operate on the follows table.
This check verifies that you’re not operating on some other table.
With the correct condition detected, it’s time to do some work.
Step two is extracting the relevant components from the incoming Put command.
You’ll use these components as parameters to creating the inverted relation.
It returns a list of KeyValues matching the parameters requested.
You know the first KeyValue is the one you’re interested in because the Put contains only a single version for this cell:
The final step is writing the new relation back to HBase.
You can reuse the connection information to operate on the same table as the original.
Remember, the new row is likely hosted on a different RegionServer, so a network operation is often required:
Normally you wouldn’t want to mix client and server code as you’ve done here.
You reuse the RelationsDAO to keep the focus on adding a followed relation rather than constructing that Put.
Exit early and exit often! If this isn’t a Put you’re interested in, be sure to return right away.
The coprocessor is executing as part of the path of data flow.
Time spent here is time the client spends waiting for a response!
Writing back to HBase using the RelationsDAO requires an HTablePool instance.
You can use an instance variable to manage it by hooking into the coprocessor lifecycle.
The start() and stop() methods are provided for this purpose, although their documentation isn’t terribly verbose:
An observer implemented thoughtlessly could result in yet another client Put against the followed table, and so on.
Such code would wreak havoc on a perfectly innocent HBase cluster.
In this case, the base case is verified by checking the direction of the relationship.
Be mindful of these kinds of scenarios when implementing your own observers.
There are two methods of installing an observer coprocessor: a table schema change or through configuration in hbase-site.xml.
Unlike the configuration method, installation via schema change can be done without restarting HBase, but it does require taking the table offline temporarily.
To install FollowsObserver, you need to package it in a JAR.
This allows the process classpath to be updated, a requirement of the installation process.
The coprocessor attribute parameters are delimited by the | character.
The first parameter is the path to the JAR containing your coprocessor implementation.
When you load multiple observers, they’re executed in priority order.
For any given invocation, a previous coprocessor has the opportunity to interrupt the execution chain, preventing later coprocessors from executing.
The final parameter, omitted in this example, is a list of arguments passed to the coprocessor implementation’s constructor.
If all went well, you can describe the follows table and confirm the presence of your new coprocessor:
The next time you add a new record to the follows table, the FollowsObserver coprocessor will kick in, updating the inverted index for you.
In this example, you’ve installed the coprocessor JAR from a path on the local file system.
Picky, picky! When installing coprocessors into a schema, be careful.
HBase won’t notice any errors, such as extra whitespace or an invalid JAR path.
You won’t know the installation failed until the next client operation when your observer doesn’t run.
We suggest you smoke-test your coprocessor deployment before you assume everything is in place.
In practice, the HDFS deployment model is much easier than dealing with copying your application JARs to the individual nodes.
Doing so requires that the observer classes be available in the HBase classpath.
In this case, the observer is registered for all tables, so you must take care in intercepting operations within the intended context.
Configuration is the primary mechanism for registering instances of the MasterObserver coprocessor.
If you want to register two MasterObserver coprocessors, you can do so by adding this property to your hbase-site.xml file:
Tracking these relationships is important for maintaining the connected network of people using TwitBase.
We hope this digital connectivity between people allows for real human relationships to flourish.
Realistically, though, the only reason to keep track of such things is to see if you have more followers than the other guy.
A TwitBase user wants to know exactly how many followers they have right now.
In this case, waiting for a MapReduce job to complete is unacceptable.
Even the overhead of all the data moving over the wire during a standard scan won’t do.
You’ll build this feature into TwitBase using an endpoint coprocessor.
For an individual user, you can implement an on-demand follower count feature using a Scan.
Stealth mode Observers registered via the hbase-site.xml file won’t show up when you describe a table in the shell, as you did previously.
The only method available to validate that the observer is registered is to exercise it, preferably via an automated post-deploy test of some kind.
Why would you want to make this any more complicated? It could be that every millisecond matters.
Every Result returned is taking up bytes over the wire—even if you omit all data, you still have rowkeys to transmit.
By implementing this scan as an endpoint, you keep all that data on the HBase nodes.
To implement followers count as an endpoint, you’ll start with a new interface.
The interface serves as the contract for extending the RPC protocol and must match on both client and server:
This is the building block on which both the client and server code can be written.
Creating a scanner in the region looks a little different from the client API.
Unlike a scan executed via the client API, this scan is reading over data on the machine executing the scan.
InternalScanners are identical in concept to Scanners in the client API.
The difference is that they reside in the RegionServer and interact with the storage and caching layers directly.
InternalScanners are specific to the region where the coprocessor is running.
Access that region via the getRegion() helper method provided by the calling environment.
In this case, you can use local buffers instead of copying bytes over the wire.
It’s much faster, but the interface is a little different.
This is a notable difference from scanners in the client API.
Those scanners return Result instances that represent an entire row.
By carefully limiting the data returned by the scan, you guarantee that a single KeyValue represents a single row in the desired result set.
It also limits the amount of data that must be read off disk.
Putting it all together, the complete RelationCountImpl is shown next.
To make sure you receive all batches of results, use a do-while form as you see here, rather than a standard while loop.
The alternative is to duplicate the logic within your loop: once to read the first page, and again in the normal while form.
This style of iteration is more common in C programs.
With the server portion of your custom endpoint in place, it’s time to build the client.
You’ll put this code in the existing RelationsDAO you built previously.
As is clear by the interface definition, the server portion expects a userId to query.
But the table still needs to know a key range over which the coprocessor will be invoked.
This range is translated into a set of regions to call it against and calculated on the client side.
As it happens, that code is identical to the client-side scanner range calculation:
When the client code executes the coprocessorExec() method, the HBase client sends the invocation to the appropriate RegionServers based on the startKey and endKey.
In this case, it’s splitting the scan range according to region assignments and sending the invocation only to the relevant nodes.
Your client receives a response for each invoked RegionServer and must sum the results.
Loop over the region name to value pairs and sum the results:
For this example, the client-side scan is about as fast as implementing the scan in an endpoint because you’re working with a small amount of data.
But the network I/O consumed by the client-side scan increases linearly with the number of rows scanned.
When the scan is pushed to the endpoint, you save on the network I/O by not having to return the scan results to the client.
The other thing is that the endpoint coprocessor executes in parallel on all regions that contain the relevant rows.
Making it multithreaded and distributed over regions brings in the complexity of managing a distributed application, which we talked about earlier.
In the long run, pushing the scan down into the RegionServers with an endpoint introduces a little deployment complexity but is far faster than a traditional client-side scan.
The client code in its entirety is shown in this listing.
Now that the server portion is ready, let’s deploy it.
Unlike the observer example, endpoints must be deployed via configuration only.
You need to edit two files, both of which are found in the $HBASE_HOME/conf directory.
You also need to ensure that HBase can find your new class.
Rebuild the code, and restart HBase so your new configuration will take effect.
You only need to define it in one direction; your observer is still registered and handles updating the index:
Now verify that the relationships are in place, and hit your endpoint:
It works! Not only is your observer updating the inversion view of the followers relationship, but you can have follower counts in record time.
The coprocessor API provides a powerful extension point for HBase.
Coprocessors are relatively young, and users are still figuring out how to use the feature.
Still, coprocessors are a flexible tool for your toolbox and may be just what the doctor ordered to get you out of a bind.
Java is a core part of the Hadoop stack’s DNA, and you can’t decouple the two easily.
Hadoop is written in Java; HBase is written in Java; the stock HBase client is written in Java.
Now what? HBase provides you with alternate clients (both JVM-based as well as those that don’t require the JVM) that you can use when Java isn’t an option.
In this chapter, you’ll see how to interact with HBase in other ways.
Each section presents a miniature, self-contained application built using the client that is being explained.
Each of these toy applications communicates with HBase using a different type of client.
Each section follows the same structure: introduce the context, Alternative HBase clients.
Each application is independent of the others, so feel free to skip around to what you find useful.
No new theory or HBase internals are covered here, just simple recipes for using HBase from non-Java and non-JVM languages.
First you’ll see how to script HBase externally via UNIX shell scripts.
Next you’ll see how to use the JRuby interface on top of which the HBase shell is implemented.
After that, you’ll explore asynchbase, an alternative Java client library that is designed for asynchronous interaction.
Finally, as promised, you’ll move beyond Java and the JVM and explore both the REST and Thrift gateways to HBase, using Curl and Python, respectively.
The simplest way to program HBase is by scripting the HBase shell.
You’ve had a brief introduction to how to use the shell in the earlier chapters.
Now you’ll take that knowledge and build a useful tool.
Every database installation needs to maintain its schema, and HBase is no different.
In the relational world, management of schema migrations is a prevalent source of headache.
The first is the tight coupling between schema and application.
If you want to add a new attribute to a persisted entity, it usually means adding a new column to a table somewhere.
When you’re working on a young product, especially in a young company, rapid iteration is crucial to your application’s success.
Using a relational database, adding a new column requires a schema change.
Over time, your database schema becomes the sum total of the original design plus each of these incremental changes.
The core relational system isn’t well suited for managing these changes, and thus they become an effort of software engineering.
Some RDBMSs ship powerful tools for managing these kinds of issues, but many don’t.
The changes themselves often take the form of SQL scripts called migrations.
These scripts must be run in order because each builds on the last.
For long-lived, successful data-driven applications, it’s common to find a schema folder containing tens or even hundreds of these files.
Each file name starts with a number indicating its position in the migration sequence.
Slightly more sophisticated versions of migration management exist, but they’re ultimately tools to support the execution of these migration scripts in the proper order.
The application can change incrementally without a change to the HBase schema in such a case.
But introducing a new column family, changing attributes of an existing column family, or adding a new table does require a schema change.
You could create a custom application for each migration, but that would be terrible.
This section will show you how to create these scripts.
The HBase shell comes as part of the default HBase installation.
Depending on how you installed HBase, that script may also be on your $PATH.
Now that you’ve verified your shell installation, you can get down to scripting it.
Way back when learning HBase, you started development on the TwitBase application.
One of the first things you did with TwitBase was to create a users table using the HBase shell.
All management code for those tables accumulated in the InitTables class.
Java isn’t a convenient language for schema management because it’s verbose and requires building a custom application for each migration.
The main body of code for creating a table in InitTables looks mostly the same for each table:
A brush with JRuby If you’re familiar with the Ruby programming language, the create command may look conspicuously like a function invocation.
We’ll look more at this link to JRuby later in this chapter.
Five lines of Java reduced to a single shell command? Not bad.
Now you can take that HBase shell command and wrap it in a UNIX shell script.
Note that the line exec hbase shell may be slightly different for you if the hbase command isn’t on your path.
You handle that scenario in the final script, shown in listing 6.1:
At this point, you’ve moved your table and column family names out of Java.
Overriding them on the command line is now much easier:
If you update your application code to read those same constants from a configuration file, you can move your schema definition completely out of the Java code.
Now you can easily test different versions of TwitBase against different tables on the same HBase cluster.
That flexibility will simplify the process of bringing TwitBase to production.
This was a primer on how you can use the HBase shell to create scripts that make it easy to do janitorial tasks on your HBase deployment.
The HBase shell isn’t something you’ll use as your primary access method to HBase; it’s not meant to have an entire application built on top of it.
It’s an application itself that has been built on top of JRuby, which we study next.
The HBase shell provides a convenient interactive environment and is sufficient for many simple administrative tasks.
As we mentioned in the previous section, the HBase shell is implemented in JRuby.1 Behind the scenes is a nice library exposing the HBase client to JRuby.
You can access that library in your own scripts to create increasingly complex automation over HBase.
In this example, you’ll build a tool for interacting with the TwitBase users table, similar to the UsersTool you wrote in Java.
This will give you a feel for interacting with HBase from JRuby.
Programming HBase via this JRuby interface is one step above the shell in terms of sophistication.
If you find yourself writing complex shell scripts, a JRuby application may be a preferable approach.
If for whatever reason you need to use the C implementation of Ruby instead of JRuby, you’ll want to explore Thrift.
We demonstrate using Thrift from Python later in this chapter; using it from Ruby is similar.
The easiest way to launch your own JRuby applications is through the existing HBase shell.
If you haven’t already done so, locate the shell by following the instructions at the beginning of the previous section.
JRuby is the Ruby programming language implemented on top of the JVM.
Once you’ve found the hbase command, you can use that as the interpreter for your own scripts.
This is particularly useful because it handles importing the necessary libraries and instantiates all the classes you’ll need.
To get started, create a script to list the tables.
They’re part of that JRuby API you’re about to take advantage of.
A great thing about writing code for the shell is that it’s easy to try out.
Scanning over the users table requires a handle to the table and a scanner.
The scanner constructor looks for a few specific keys in that hash, including "STARTROW", "STOPROW", and "COLUMNS"
Scan over all users, returning only their username, name, and email address:
Now you have everything you need to iterate over the keypairs produced by the scanner.
Parse out the data you’re interested in, and accumulate the results:
The regular expression extracts just the qualifier and cell value from the scan result.
Now you have everything you need to complete the example.
Wrap it up in a main(), and ship it! The final TwitBase.jrb script is shown in the following listing.
With your script in order, set it to executable and give it a try:
Programming the JRuby interface is an easy way to explore prototypes on top of HBase or automate common tasks.
It’s all built on the same HBase Java client you’ve used in previous chapters.
For the next sample application, we’ll move off the JVM entirely.
HBase provides a REST interface, and we’ll demonstrate that interface using Curl on the command line.
One of the factors that prevents people from experimenting with HBase is its close relationship with Java.
There are a couple of alternatives for people who are willing to run HBase but want nothing to do with Java for their applications.
Whether you’re exploring HBase or you want to put an HBase cluster directly in the hands of your application developers, the REST interface may be appropriate.
HBase ships with a REST service that you can use to access HBase, no Java required.
The REST service runs as a separate process and communicates with HBase using the same client API we explored earlier.
It can run on any machine configured to communicate with HBase.
That means you can spin up a cluster of REST service.
In practice, the REST service is rarely used for critical application paths.
The next section covers exactly this: communicating with HBase from a Python application over Thrift.
The Scanner API is stateful and requires resource allocation, which happens only on the machine that receives the request.
That means a client using the scanner must always return to the same REST host while performing that scan.
Figure 6.1 loosely illustrates the network topology of a REST gateway deployment.
The REST service also supports a number of response formats, controlled by the Content-Type request header.
Many of the status and administrative endpoints also support plain text.
Running the service as an active process is done using the same hbase base command used to launch the shell:
Launch the REST service, listening on port 9999, like this:
All client activity is funneled through the gateway, greatly reducing client throughput.
Clustering the REST gateway machines can mitigate some of this limitation.
Clustering introduces a new limitation, however, forcing the client to only use the stateless portions of the API.
Verify that your service is up and running by launching a new terminal and issuing a simple curl command.
All the cool kids these days are using JSON, so you will too.
We’ve even taken the liberty of cleaning up the output for your enjoyment:
If you want info about the underlying cluster, you’ll need to ask for that separately:
Notice in the first terminal window that the service is logging the requests it received.
Running the REST service as a daemon is almost as easy.
Depending on your installation, the hbase-daemon.sh script may not be on your PATH.
We’ll continue to gloss over the headers and show beautified output, even though the full command isn’t explicitly shown.
With your service running, it’s time to reach right into HBase.
Want to find out Mark Twain’s password? You just need his rowkey and the column.
Thinking about the logical HBase data model, a map of maps, it’s easy to guess what the RESTful URI will be.
You wanted a single cell from a single row in a single table, and that’s what you received.
Rowkeys, columns, and values are all bytes to HBase, so they’re returned as Base64encoded Strings.
Because you’ve stored the passwords as simple Strings, you can decode them enough to find the value using the base64 utility:
The simplest way to write data is to send raw bytes.
This time, you’ll specify the Content-Type header to indicate how you’re sending the data.
In this case the value you want to write is an ASCII string, so there’s no complication:
It differs from idiomatic JSON in a couple of key ways, because it’s generated using the same library and with the same rules used to generate XML.
The $ field is an example artifact of this implementation detail.
Another is experienced when PUTting new values: attribute order matters.
The classes used to render data from the REST service are well documented3 and clearly describe the schema they expect to produce and consume.
To continue using JSON, you’ll also need to Base64-encode the data before you send it.
Be sure to include the -n option to echo, or you’ll introduce an unintentional newline character at the end of the new password:
Be sure to place the $ last in the Cell object map.
Don’t forget to specify the Content-Type header to indicate you’re sending JSON.
A GET sent to the table will provide a listing of the entire table.
The same endpoint exposes basic filter scanning using an asterisk (*) for prefix matching.
To find all users whose username starts with the letter T, use the following:
For a slightly more granular scan, you can instantiate a scanner on the server and ask it to page through results.
Create a scanner over all users whose username is less than I, paging one cell at a time.
The REST service will return an HTTP 201 Created response code with the URI of your scanner instance.
Use the -v option on curl to see the response code:
Use the location in the response to page through scan results:
Repeated calls to this URI will return consecutive scan results.
Once the row list is exhausted, further calls to the scanner instance will return the HTTP response code 204 No Content.
When it comes to doing anything more than exploring a cluster, you’ll want to use the Thrift gateway instead.
When you live in the world beyond Java, the most common way to interact with HBase is via Thrift.4 Thrift is a language and set of tools for generating code.
Thrift has an Interface Definition Language (IDL) for describing services and objects.
It provides a networking protocol for communication between processes using those object and service definitions.
Thrift uses the IDL you describe to generate code for you in your favorite languages.
Using that code, you can write applications that communicate with each other using the lingua franca provided by Thrift.
HBase ships a Thrift IDL describing a service layer and set of objects.
In this section, you’ll generate the Thrift client library for interacting with HBase.
You’ll use that client library to interact with HBase from Python, completely outside of Java and the JVM.
We chose Python because its syntax is approachable to both novice and seasoned programmers.
The same approach applies for interacting with HBase from your favorite language.
At the time of this writing, Thrift supports 14 different languages.
The beauty of using the Thrift API is that it’s the same for all languages.
Whether you’re using PHP, Perl, or C#, the interface is always the same.
Additional HBase feature support added to the Thrift API is additional feature support available everywhere.
Notably, it suffers the same throughput challenges as the REST gateway.
All client connections are funneled through a single machine that communicates with the cluster on their behalf.
Because the Thrift client opens a connection to a single instance for the duration of its session, clustering Thrift gateways is easier than with REST.
Still, portions of the API are stateful, so a disconnected client will lose access to allocated resources when it opens a new connection.
Figure 6.2 illustrates the network topology of a Thrift gateway deployment.
Originally a project out of Facebook, Thrift is now an Apache project.
Well, you can access them, but you have to modify the Hbase.thrift file for each endpoint you want to expose.
This API is … different In part because of Thrift’s ambitions to support so many languages, its IDL is relatively simple.
It lacks features common in many languages, such as object inheritance.
As a result, the HBase interface via Thrift is slightly different from the Java client API we’ve explored thus far.
An effort5 is under way to bring the Thrift API closer to Java, but it remains a work in progress.
Python is the language for this exercise, so let’s begin by creating a Python project, complete with an HBase client library.
Thrift isn’t packaged yet, so you’ll have to build it from source.
On a Mac, that’s easy because Thrift is available through Homebrew:7
Those running other platforms will need to build Thrift manually.
See the Thrift Requirements8 doc for details specific to your platform.
Once that’s done, verify that your build is alive and well:
You thought you were going to get through this whole book without downloading the HBase source code, didn’t you? Sorry to disappoint you.
If you want a Thrift client, you’ll need to grab the source:
All clients are funneled through the gateway, greatly reducing client throughput.
That’s the IDL file that describes the HBase service API and related objects.
Now you have everything you need to generate the Python client.
Start by creating a project directory for yourself and generating the HBase client bindings:
You’ve created a project called twitbase.py and generated the HBase Python library.
By moving all that up into your project, you can easily import the code into your application.
These are the core components common across all Thrift services used from Python, so you can install them globally:
Alternately, this library is also part of the source you compiled.
You can copy these files into your project as you did with the HBase client.
From within the twitbase.py directory, you do so as follows:
Launch Python, and import both the Thrift and HBase libraries.
Be sure to run these commands from within the twitbase.py directory, or the import statements will fail.
With the client library ready to go, let’s start the server component.
The server component ships with HBase, so it doesn’t involve all the setup required by the client library.
Launch the Thrift service the same way you launch the shell, using the hbase command:
Make sure HBase is up and running, then launch the Thrift service.
With both the client and server ready, it’s time to test them.
Open a terminal window in your twitbase.py project directory, and once again launch Python:
It took you a little while to get here, but it all works! Now you can get down to business.
Before you start writing code, let’s explore at the interpreter a little more to get a feel for the API.
You’re interested in scanning the users table, so let’s start with a scanner.
Examining the Hbase.IFace class in Hbase.py, it looks like scannerOpen() is the simplest method.
It returns a scanner ID you can call on the Thrift server.
Here you’ve asked for an unbounded scanner over the users table, returning only three qualifiers from the info column.
Let’s take the first row and see what you get:
That row has a columns field that is a dictionary from column qualifier to a TCell instance.
Now that you know what you’re working with, let’s build out a class to wrap up all these details.
Call that helper class TwitBaseConn and give it a constructor to hide all these Thrift connection details.
This defines a default constructor that will connect to the Thrift service running locally.
It also adds an extra layer to the networking stack, wrapping the socket in a buffer.
Now add a method to handle scanning rows from the users table:
That takes care of reading rows and cleaning up after the scanner.
Those rows are full of Thrift library details, though, so let’s add another method to pull out the data you want:
This method loops through the TCells and creates a string from their contents.
Update scan_users() to call this method instead of returning the raw rows:
Great! All that’s left is to wrap it up in a main(), and you can give it a spin.
It opens the connection, calls the scan, prints the results, and closes the connection again.
You do need to make the file executable, though, which is a one-liner:
Nicely done! You have everything you need to start building HBase applications in Python.
Next up, we’ll explore an entirely new Java language client, asynchbase.
When your application interacts with HBase through the HTableInterface, every action blocks your application thread while HBase can respond to the request.
Some applications don’t need to wait on the server to respond before continuing with the execution path.
In fact, the synchronous dependency on the server is detrimental to many user-facing applications.
Asynchbase9 is an alternative HBase client, also written in Java.
It’s fully asynchronous, which means it doesn’t block the thread of the calling application.
It makes thread safety a priority, and its client API is designed for use in multithreaded applications.
The author of asynchbase strives for maximal client performance and maintains a set of benchmarks10 comparing asynchbase to the stock HBase client.
Async allows you to build parallel data-processing pipelines by chaining successive actions onto asynchronous computations.
An explanation of the concepts core to these projects is beyond the scope of this section.
We provide you with some of the basics but recommend that you explore these related projects and concepts on your own if you’re serious about using asynchbase.
It’s a different way of thinking, albeit an important one, when considering a user-facing application dealing with large amounts of data at the back end.
The primary notable deployment of asynchbase is OpenTSDB, an application covered in detail in a later chapter.
Both asynchbase and OpenTSDB are written and maintained by the same community of users.
That community is relatively small in comparison to the wider HBase community.
As with any open source project, caution is advised when approaching a project that has not yet achieved critical mass.
That means your client code is entirely decoupled from your cluster deployment.
This can be a huge win when considering client code that can’t be upgraded as frequently as the cluster.
In this example, you’ll build an alternative client to the TwitBase users table using the asynchbase client.
The simplest way to create one is using Maven archetypes.
Maven archetypes are prebuilt project templates that provide basic Maven project scaffolding.
Twisted provides a Deferred object for building chains of nonblocking event handlers.
This versioning scheme is roughly outlined in the Apache Release Management guide: http://mng.bz/6uvM.
After Maven downloads any missing dependencies, it will prompt you to confirm the parameters.
This will create a directory called twitbase-async in the current directory.
The next thing to do is add asynchbase to the project as a dependency.
A file called pom.xml in the top-level project directory manages the Maven project.
This will allow you to create a JAR containing all of the project’s dependencies and simplify launching the AsyncTwitBase application.
Now is a good time to make sure everything works.
Go ahead and build and run your application with the following commands.
Let’s create an application to randomize the passwords of all users in the system.
This kind of thing would be useful if your TwitBase deployment suffered a security breach.
You’d like your application to scan through all users in the users table, retrieve the user’s password, and generate a new password based on the old one.
You also want the application to notify the user of the security breach and inform them as to how they can retrieve their account.
You’ll do all this by chaining successive actions using async’s Deferred and Callback objects.
The workflow as a Callback chain is illustrated in figure 6.3
Wiring a Callback instance onto a Deferred instance chains successive steps together.
This is done using the addCallback family of methods provided by the Deferred class.
Callbacks can also be attached to handle error cases, as you see in step 4b.
Async calls these Errbacks, a term consistent with the terminology used in Twisted Python.
The final result of a Callback chain is retrieved by calling join() on the associated Deferred instance.
If the Deferred is finished processing, calling join(long timeout) returns immediately with a result.
If the Deferred’s Callback chain is still processing, the current thread blocks until either the Deferred completes or the timeout, in milliseconds, expires.
With your newfound understanding of the async data-processing pipeline and a rough idea of the pipeline you want to build, let’s start building it.
Your primary entry point into asynchbase is the HBaseClient class.
Its responsibility is something of a combination of both HTablePool and HTableInterface from the stock client.
Much like an HTableInterface, you need to make sure you close it after you’re finished using it.
This snippet creates an instance of HBaseClient that talks to an HBase managed by localhost.
It then closes that instance and blocks the current thread until the shutdown() method completes.
Waiting on shutdown() to complete is necessary to ensure that all pending RPC requests are completed and the thread pool is properly disposed before the application exits.
Waiting is accomplished by calling one of the join family of methods on the Deferred instance.
Calculate a new password based on the old and send a Put to HBase.
Interpret the Put response as either a success or failure.
Each step takes output from the previous one, processes it, and sends it to the next, until a final result is reached.
Asynchbase: an alternative Java HBase client cleaned when you’re finished.
The asynchbase Scanner is similar to the ResultsScanner with which you’re already familiar.
Create a Scanner against the users table, and limit its results to the info:password column:
Use this Scanner instance to walk the rows in your table by calling nextRows()
Like the other asynchronous operations in this library, nextRows() returns a Deferred instance.
Like the stock scanner, you can request a specific number of results per page by passing a number to nextRows()
To help emphasize the asynchronous nature of the application, let’s limit the scan results to a single row per page.
Each returned row consists of a list of its cells.
These cells are represented by instances of the KeyValue class.
In order to walk the page of returned rows, you loop over a list of lists of KeyValue instances:
Like the call to shutdown(), this code blocks the current thread until all results are available before consuming them.
Scanning rows asynchronously doesn’t make a lot of sense when you’re interested in maintaining row order.
By joining on each Deferred instance, you realize the scan results into the rows variable.
Parsing the results is similar to consuming KeyValue objects in the stock client.
Don’t do this in a real application! Limiting your scanner to a single row per request will significantly hinder your application performance.
The only reason we do so here is to maximize the opportunity for failure scenarios to trigger.
You’ll see what we’re talking about later in the section.
The scanner was limited to returning the info:password column, so you know there will be only a single KeyValue per result row.
You take that KeyValue and pull out the bits relevant to you.
For this example, the old password is used to seed the new password, so pass it into the mkNewPassword() method.
Create a new Put instance, which asynchbase calls a PutRequest, to update the user’s password.
The last step is to construct a Callback chain and attach it to the PutRequest invocation.
Before you start chaining Callbacks, let’s write a couple of methods to help you watch the asynchronous application at work.
Developing and debugging asynchronous applications can be tricky, so you’ll set yourself up for success.
The first thing you want is to print debugging statements with their associated thread.
For this, you’ll use the logging library SLF4J, the same logging library used by asynchbase.
To help explore the asynchronous nature of this code, it’s useful to introduce simulated latency into the system.
The method latency() will occasionally delay processing by forcing the thread to sleep:
You can do the same by introducing occasional failures, slightly less frequently, with the entropy() method:
You’ll call latency() at the beginning and end of each Callback to slow things down a little.
Now it’s time to implement Callbacks for each of the remaining steps.
Step 3 in the data pipeline is to interpret the response generated by the PutRequest sent to HBase.
The implementation receives a Boolean from the HBase response and generates an UpdateResult instance, an object specific to your application.
The UpdateResult class is simple, just a package for data:
Async looks for Exceptions, either thrown by or returned by Deferred and Callback instances, to trigger the error-handling callback chain.
You implement your own exception so you can package a little context along with the exception.
Now you can implement your Callback to handle step 3
It has a constructor to pass in the user ID; that way you know which user you were processing when you received this response.
The meat of the code is in the UpdateResult call(Boolean response) method.
It also takes the response received from HBase and subjects it to entropy()
You can imagine performing an arbitrarily complex operation in your real working code:
InterpretResponse is the most complex Callback in this example, so if you’re still following, you should be in good shape.
This Callback has either performed its transformation or detected an error and bailed.
Either way, the decision of what Callback to invoke next is left up to async.
This is an important concept when thinking about these data-processing pipelines.
Each step in the chain is ignorant of the others.
Those generic types correspond to the signature of the call() method.
For the next step, you’ll implement the successful case first: step 4a from the state diagram.
This step takes the UpdateResult produced in step 3 and converts it into a String message, perhaps to send to the user via email or to update a log somewhere.
Again, you’re calling latency() at the beginning and end of the call() method.
Construction of the message is simple, and it looks like it’s appropriate for the user.
There’s also nothing going on to throw an Exception, so you won’t consider an Errback chain for this step.
The processing work is almost identical, except it retrieves the user ID context from the Exception instead of an UpdateResult:
Both ResultToMessage and FailureToMessage produce a String for their output.
That means they can be chained to the same Callback instance for the final step, 5
Again, you have a little latency() and entropy() to keep things interesting.
Either the message is delivered or an Exception is thrown.
In this case, there is no Errback to chain into the data pipeline, so that error needs to be handled in client code.
With the processing pipeline implemented, let’s return to the code consuming the scanner.
When you last saw your user application, it was reading rows off the scanner and building PutRequest objects to initiate the processing pipeline, essentially step 1 from the state diagram.
The last thing to do is to send those Puts off to HBase and pass the response down the Callback chain, as shown in figure 6.8
Each consecutive call to addCallback() returns the same Deferred instance but with its type updated to correspond to the return type of the attached Callback.
This returns a Deferred<String>, which is typed by the return type of the success case.
The error case in async is always typed by an Exception, so it need not be specified in the Deferred.
Each row in the scan result has a corresponding Deferred<Boolean> whose execution you want to see completed.
The only way to see the results of the full Callback chain for each row is to collect the final Deferred<Boolean> instances and join() on them.
This is the same code as before, just with the extra bookkeeping of collecting the Deferred<Boolean> instances:
Notice that your list of workers preserves the order in which the rows were produced.
You could as easily accumulate state out at this level, for instance, by creating a Map of user ID to Deferred<Boolean> results.
Your machine is executing them all in the background simultaneously.
When you call join(), async gives you back all the results of the processing chains for each worker.
If any component of the chain threw or returned an instance of Exception along the way, it throws that Exception for you to catch here.
Unpack it with a call to getCause() to see the underlying error.
To round it all out, let’s give the command-line application a meaningful name.
You want to do this so you’ll be able to see your log messages, and, in particular, so you can see which thread is doing what work.
Make sure you have HBase running and have populated the users table.
Build your asynchbase client application just like the TwitBase Java project:
It works! You now have a working baseline from which to build a suite of asynchronous applications around HBase.
The decision to deploy HBase ties you to the JVM, at least on the server side.
For managing schema migrations, we recommend becoming comfortable with scripting the HBase shell.
If your migrations are particularly complex, or if you feel like building an ActiveRecord14
If you’re working with Java, we recommend that you give asynchbase serious consideration.
Asynchronous programming can be a challenge, but you’re already stepping up to learn HBase, so we think you can handle it.
Launching the REST gateway against your cluster is simple, and it even scales reasonably well.
Although REST is convenient, Thrift is likely the way to go.
Thrift provides some measure of language-agnostic API definition and has seen more usage in the community than REST.
As always, such decisions are best made on a case-by-case basis.
ActiveRecord is the database abstraction library commonly use in Ruby and famously used in Ruby on Rails.
It defines a schema-migration pattern that is superior to other tools with which we’re familiar.
Part 3 moves past toy example applications and gives you a taste of HBase in real applications.
In chapter 8, you get a glimpse at using HBase for geospatial data.
You’ll learn how to adapt an HBase schema for multidimensional spatial data as you implement multiple spatial queries.
When you finish this part of the book, you’ll be ready to architect your own distributed, fault-tolerant, HBase-backed data systems from the ground up.
In this chapter, we want to give you a sense of what it’s like to build applications against HBase.
What better way is there to learn a technology than to see first-hand how it can be used to solve a familiar problem? Rather than continuing on with our contrived example, we’ll look at an existing application: OpenTSDB.
Our goal is to show you what an application backed by HBase looks like, so we won’t skimp on the gritty details.
By the time we’re through, you’ll have a good idea of what it takes to build an application on HBase by example: OpenTSDB.
Perhaps more important, you’ll have insight into how to think like an HBase application designer.
You’ll gain an understanding of what OpenTSDB is and what challenge it solves.
Then we’ll peel back the layers, exploring the design of both the application and the database schema.
You’ll see the application logic necessary for storing and retrieving data from HBase and how this data is used to build informative charts for the user.
OpenTSDB is a distributed, scalable Time Series Database (TSDB) written on top of HBase.
OpenTSDB was written to address a common need: store, index, and serve metrics collected from computer systems (network gear, operating systems, applications) at a large scale, and make this data easily accessible and graphable.
OpenTSDB is a great project for a practical book because it solves the pervasive problem of infrastructure monitoring.
If you’ve deployed a production system, you know the importance of infrastructure monitoring.
It’s also interesting because the data OpenTSDB stores is time series.
Efficient storage and querying of time-series data is something for which the standard relational model isn’t well suited.
Relational database vendors often look to nonstandard solutions for this problem, such as storing the time-series data as an opaque blob and providing proprietary query extensions for its introspection.
OpenTSDB was built at StumbleUpon, a company highly experienced with HBase.
It’s a great example of how to build an application with HBase as its backing store.
OpenTSDB is open source, so you have complete access to the code.
The entire project is less than 15,000 lines of Java so it can easily be digested in its entirety.
Every data point it stores in HBase must be made available to the user, on demand, in a chart like the one shown in figure 7.1
What is a blob? As you’ll learn later in the chapter, time-series data has distinct characteristics.
These properties can be exploited by customized data structures for more efficient storage and queries.
Relational systems don’t natively support these kinds of specialized storage formats, so these structures are often serialized into a binary representation and stored as an unindexed byte array.
Custom operators are then required to inspect this binary data.
Data stored as a bundle like this is commonly called a blob.
Next we’ll look more closely at the challenge OpenTSDB is designed to solve and the kinds of data it needs to store.
After that, we’ll consider why HBase is a good choice for an application like OpenTSDB.
Let’s look now at infrastructure monitoring so you can understand how the problem domain motivates the schema.1
Infrastructure monitoring is the term we use for keeping tabs on deployed systems.
The vast majority of software projects are deployed as online systems and services communicating over a network.
Odds are, you’ve deployed a system like this, which means odds are you’ve found it your professional responsibility to maintain that system.
The series of events that triggered your midnight alarm represent only a small amount of the total data those tools collect.
Relevant data points include service requests per second, concurrent active user sessions, database reads and writes, average response latency, process memory consumption, and so on.
Each of these is a time-series measurement associated with a specific metric and individually provides only a small snapshot of visibility into overall system operation.
Take these measurements together along a common time window, and you begin to have an actionable view of the running system.
Ultimately it’s about providing insight into the data it stores in graphs like this one.
Generating a graph like the one in figure 7.1 requires that data be accessible by metric as well as time interval.
OpenTSDB must be able to collect a variety of metrics from a huge number of systems and yet support online queries against any of those metrics.
You’ll see in the next section how this requirement becomes a key consideration in the OpenTSDB schema design.
We’ve mentioned time series more than a few times because it also plays a critical role in the design of OpenTSDB’s schema.
Think of time-series data as a collection of data points or tuples.
This set of points ordered by time is the time-series.
For instance, you might use OpenTSDB to collect bytes sent by the MySQL process every 15 seconds.
In this case, you would have a series of points like those in figure 7.2
It’s common for these data points to also carry metadata about the measurement, such as the fully qualified hostname generating the series.
Time-series data is commonly found in economics, finance, natural sciences, and signal processing.
By attaching a timestamp to a measurement, we can understand differences between measurement values as time progresses and also understand patterns over time.
For instance, the current temperature at a particular location can be measured.
Figure 7.2 A time series is a sequence of time-ordered points.
Here, two time series on the same scale are rendered on the same graph.
The timestamp is commonly used as an X-axis value when representing a time series visually.
It’s natural to assume previous points can inform a future point.
You could guess the next hour’s temperature based on the last five hours’ measurements.
All data points in a system may share the same fields, for instance: date/time, location, and measurement.
But two data points with different values for any one of these fields might be completely unrelated.
If one point is the temperature in New York and another in San Francisco, they’re likely not related even with a similar timestamp.
Another notable issue with time series is in recording this data.
Trees are an efficient data structure for random access, but special care must be taken when building them in sorted order.
A time series is naturally ordered by time and is often persisted according to that order.
This can result in the storage structures being built in the worst possible way, as illustrated by (b) in figure 7.3
Just like a tree, this ordering can also cause havoc on a distributed system.
When data is partitioned across nodes according to the timestamp, new data bottlenecks at a single node, causing a hot spot.
As the number of clients writing data increases, that single node is easily overwhelmed.
Now let’s see what HBase can bring to the table for the OpenTSDB application.
HBase makes an excellent choice for applications such as OpenTSDB because it provides scalable data storage with support for low-latency queries.
Persisting data into structures that arrange themselves based on data values can result in worst-case data distribution.
In this case, that schema is customized for time-series measurements and their associated tags.
HBase provides strong consistency, so reports generated by OpenTSDB can be used for real-time reporting.
The view of collected data HBase provides is always as current as possible.
The horizontal scalability of HBase is critical because of the data volume required of OpenTSDB.
Can you serve the ad-hoc queries required by your operational team for diagnosing a system outage?
All this is possible with a traditional relational database deployment.
There’s an impressive list of stories describing massive, successful deployments of these technologies.
Scaling a relational system to cope with this volume of data requires a partitioning strategy.
Such an approach often places the burden of partitioning in the application code.
Your application can’t request a bit of data from the database.
Instead, it’s forced to resolve which database hosts the data in question based on its current knowledge of all available hosts and all ranges of data.
Plus, in partitioning the data, you lose a primary advantage of relational systems: the powerful query language.
Partitioned data is spread across multiple systems unaware of each other, which means queries are reduced to simple value lookups.
Any further query complexity is again pressed to client code.
HBase hides the details of partitioning from the client applications.
Partitions are allocated and managed by the cluster so your application code remains blissfully unaware.
That means less complexity for you to manage in your code.
Although HBase doesn’t support a rich query language like SQL, you can design your HBase schema such that most of your online query complexity resides on the cluster.
HBase coprocessors give you the freedom to embed arbitrary online code on the nodes hosting the data, as well.
Plus, you have the power of MapReduce for offline queries, giving you a rich variety of tools for constructing your reports.
At this point you should have a feel for the goals of OpenTSDB and the technical challenges those goals present.
Let’s dig into the details of how to design an application to meet these challenges.
Although OpenTSDB could have been built on a relational database, it’s an HBase application.
It’s built by individuals who think about scalable data systems in the same way HBase does.
These differences can be seen in both the schema design and application architecture of OpenTSDB.
This section begins with a study of the OpenTSDB schema.
For many of you, this will be your first glimpse of a nontrivial HBase schema.
We hope this working example will provide useful insight into taking advantage of the HBase data model.
After that, you’ll see how to use the key features of HBase as a model for your own applications.
The tsdb table provides storage and query support over time-series data.
The tsdb-uid table maintains an index of globally unique values for use as metric tags.
We’ll first look at the script used to generate these two tables and dive deeper into the usage and design of each one.
The first thing to notice is how similar the script is to any script containing Data Definition Language (DDL) code for a relational database.
The term DDL is often used to distinguish code that provides schema definition and modification from code performing data updates.
A relational database uses SQL for schema modifications; HBase depends on the API.
As you’ve seen, the most convenient way to access the API for this purpose is through the HBase shell.
The tsdb-uid table contains two column families: id and name.
The tsdb table also specifies a column family, named t.
Listing 7.1 Scripting the HBase shell to create the tables used by OpenTSDB.
This is because of an implementation detail of the HFile storage format of the current version of HBase—shorter names mean less data to store per KeyValue instance.
Unlike most popular relational databases, there is no concept of table groups.
All table names in HBase exist in a common namespace managed by the HBase master.
Now that you’ve seen how these two tables are created in HBase, let’s explore how they’re used.
Although this table is ancillary to the tsdb table, we explore it first because understanding why it exists will provide insight into the overall design.
The OpenTSDB schema design is optimized for the management of time-series measurements and their associated tags.
By tags, we mean anything used to further identify a measurement recorded in the system.
In OpenTSDB, this includes the observed metric, the metadata name, and the metadata value.
It uses a single class, UniqueId, to manage all of these different tags, hence uid in the table name.
UIDs are of a fixed 3-byte width and used in a foreign-key relationship from the tsdb table; more on that later.
Registering a new UID results in two rows in this table, one mapping tag name-to-UID, the other is UID-to-name.
For instance, registering the mysql.bytes_sent metric generates a new UID used as the rowkey in the UID-to-name row.
The name column family for that row stores the tag name.
The column qualifier is used as a kind of namespace for UIDs, distinguishing this UID as a metric (as opposed to a metadata tag name or value)
The name-to-UID row uses the name as the row key and stores the UID in the id column family, again qualified by the tag type.
The following listing shows how to use the tsdb application to register two new metrics.
The name-to-UID rows enable support for autocomplete of tag names.
OpenTSDB’s UI allows a user to start typing a UID name, and OpenTSDB populates a list of suggestions with UIDs from this table.
It does this using an HBase row scan bounded by rowkey range.
Designing an HBase application service that receives incoming data to map metric names to their associated UIDs when recording new values.
This is the heart of the time-series database: the table that stores time series of measurements and metadata.
This table is designed to support queries of this data filtered by date range and tag.
Remember the UIDs generated by tag registration in the tsdb-uid table? They’re used here in the rowkey of this table.
OpenTSDB is optimized for metric-centric queries, so the metric UID comes first.
HBase stores rows ordered by rowkey, so the entire history for a single metric is stored as contiguous rows.
Within the run of rows for a metric, they’re ordered by timestamp.
The timestamp in the rowkey is rounded down to the nearest 60 minutes so a single row stores a bucket of measurements for the hour.
The tag name and value UIDs come last in the rowkey.
Storing all these attributes in the rowkey allows them to be considered while filtering search results.
Now that we’ve covered rowkeys, let’s look at how measurements are stored.
Notice that the schema contains only a single column family, t.
This is because HBase requires a table to contain at least one column family.
This table doesn’t use the column family to organize data, but HBase requires one all the same.
The measurement value is stored on 8 bytes in the cell.
The timestamp is represented as a UNIX epoch value of 1292148123
The rowkey and cell as inserted into the tsdb table are shown in figure 7.6
Other measurements collected during the same hour for the same metric on the same host are all stored in other cells in this row.
Figure 7.5 Column qualifiers store the final precision of the timestamp as well as a bitmask.
The first bit in that mask indicates whether the value in the cell is an integer or a float value.
It’s not often we see this kind of bit-wise consideration in Java applications, is it? Much of this is done as a performance optimization.
Storing multiple observations per row lets filtered scans disqualify more data in a single exclusion.
It also drastically reduces the overall number of rows that must be tracked by the Bloom Filter on rowkey.
Now that you’ve seen the design of an HBase schema, let’s look at how to build a reliable, scalable application using the same methods as those used for OpenTSDB.
While pursuing study of OpenTSDB, it’s useful to keep these HBase design fundamentals in mind:
High availability and linear scalability are frequently primary motivators behind the decision to build on HBase.
Let’s look at how OpenTSDB achieves these goals through its architectural choices.
Conceptually speaking, OpenTSDB has three responsibilities: data collection, data storage, and serving queries.
As you might guess, data storage is provided by HBase, which already meets these requirements.
How does OpenTSDB provide these features for the other responsibilities? Let’s look at them individually, and you’ll see how they’re tied back together through HBase.
OpenTSDB includes a process called tsd for handling interactions with HBase.
It exposes a simple HTTP interface2 for serving queries against HBase.
Requests can query for either metadata or an image representing the requested time series.
All tsd processes are identical and stateless, so high availability is achieved by running multiple tsd machines.
Traffic to these machines is routed using a load balancer, just like striping any other HTTP traffic.
A client doesn’t suffer from the outage of a single tsd machine because the request is routed to a different one.
Each query is self-contained and can be answered by a single tsd process independently.
Support for an increasing number of client requests is handled by running more tsd machines.
The selfcontained nature of the OpenTSDB query has the added bonus of making the results served by tsd cacheable.
The three areas of concern are data collection, data storage, and serving queries.
Some process somewhere needs to gather data from the hosts being monitored and store it in HBase.
OpenTSDB makes data collection linearly scalable by placing the burden of collection on the hosts being monitored.
Each machine runs local processes that collect measurements, and each machine is responsible for sending this data off to OpenTSDB.
Adding a new host to your infrastructure places no additional workload exclusively on any individual node in the OpenTSDB cluster.
How does OpenTSDB guarantee observation delivery? Attaining high availability, it turns out, is mundane.
The tcollector3 daemon, also running on each monitored host, takes care of these concerns by gathering measurements locally.
It’s responsible for ensuring that observations are delivered to OpenTSDB by waiting out such a network outage.
It also manages collection scripts, running them on the appropriate interval or restarting them when they crash.
As an added bonus, collection agents written for tcollector can be simple shell scripts.
HBase scans key range, omitting filtered records, and returns results.
Requests are routed to an available tsd process that queries HBase and serves the results in the appropriate format.
Doing so would require the tcollector installation to ship an HBase client library along with all its dependencies and configuration.
It would also put an unnecessarily large load on HBase.
Because the tsd is already deployed to support query load, it’s also used for receiving data.
The tsd process exposes a simple telnet-like protocol for receiving observations.
The tsd does little work supporting writes, so a small number of tsd instances can handle many times their number in tcollector agents.
More important, you’ve seen how an application can take advantage of HBase’s strengths.
Nothing here should be particularly surprising, especially if you’ve developed a highly available system before.
It’s worth noting how much simpler such an application can be when the data-storage system provides these features out of the box.
Collection scripts on monitored hosts report measurements to the local tcollector process.
Measurements are then transmitted to a tsd process that handles writing observations to HBase.
HBase wants to be used! Notice these interface features directly listed on the HBase home page:
To keep the discussion as generally applicable as possible, we’ll present first pseudocode for HBase interactions and then show you the snippets from OpenTSDB.
It’s easier to understand how data is read if you know how it’s written, so this time we’ll begin with the write path.
As you saw while studying the schema, OpenTSDB stores data in two tables.
Before a row can be inserted into the tsdb table, all UIDs must first be generated.
Before a measurement can be written to the tsdb table, all of its tags must first be written to tsdb-uid.
Listing 7.3 Pseudo-code for inserting a tag into the tsdb-uid table.
One UniqueId class is instantiated by a tsd process for each kind of UID stored in the table.
In this case, metric, tag name, and tag value are the three kinds of UIDs in the system.
The local variable kind will be set appropriately in the constructor, along with the variable table for the table name, tsdb-uid by default.
Otherwise, a new UID needs to be generated and registered for this mapping.
New UIDs are generated by way of a counter stored in this table, increased using the Increment command.
A new UID is generated, and the two mappings are stored to the table.
For this reason, the UID-toname mapping is written before the name-to-UID mapping.
A failure here results in a wasted UID but no further harm.
A name-to-UID mapping without its reciprocal means the name is available in the system but can never be resolved from a measurement record.
That’s a bad thing because it can lead to orphaned data.
Finally, having assigned the bidirectional mapping, the UID is returned.
The Java code for this method contains additional complexity due to error handling and a workaround for a feature not yet implemented in the client API.
It’s included here but with these additional concerns removed for the sake of brevity.
Rowlock used only to work around a feature lacking from RPC protocol.
Verify that row still doesn't exist, to avoid race condition.
Having registered the tags, you can move on to generating a rowkey for an entry in the tsdb table.
Every rowkey in the tsdb table for the same metric and tag name value pairs looks the same except for the timestamp.
The primary concern of this method is correct placement of the rowkey components.
As you saw earlier in figure 7.5, this order is metric UID, partial timestamp, and tag pair UIDs.
This guarantees that the same metric and tags map to the same rowkey every time.
The Java implementation in the following listing is almost identical to the pseudocode in listing 7.5
That’s all there is to it! You now have all the pieces.
Width of rowkey is variable based on number of tags.
With all the necessary helper methods in place, it’s time to write a record to the tsdb table.
Those tsdb instances in the previous code listings are instances of this class.
Let’s start once more with pseudocode before diving into the Java implementation.
Writing the value is as simple as that! Now let’s look at the same thing in Java.
The code for writing Longs and Floats is almost identical.
Looking back over these listings, both pseudo-code and Java, there’s not much interaction with HBase going on.
The most complicated part of writing a row to HBase is assembling the values you want to write.
With data stored in HBase, it’s useful to pull it out again.
OpenTSDB does this for two distinct use cases: UID name auto-completion and querying time series.
Let’s see what it takes to implement auto-complete for time-series metadata.
Figure 7.10 OpenTSDB metric auto-completion is supported by the name-to-UID mapping stored in the tsdb-uid table.
HBase supports this application feature with the rowkey scan pattern of data access.
HBase keeps an index over the rowkeys in each table so locating the starting point is very fast.
From there, the HBase BlockCache takes over, rapidly reading consecutive blocks from memory and off the HDFS when necessary.
In this case, those consecutive blocks contain rows in the tsdb-uid table.
In figure 7.10, the user entered my in the Metric field.
These characters are taken as the start row of the scan.
You want to display entries matching only this prefix, so the end row of the scan is calculated to be mz.
You also only want records where the id column family is populated; otherwise you’ll interpret UIDs as text.
The Java code is readable, so we’ll skip the pseudo-code.
With a scanner constructed, consuming records out of HBase is like reading any other iterator.
Reading suggestions off the scanner is a matter of extracting the byte array and interpreting it as a string.
Lists are used to maintain the sorted order of returned results.
The same technique is used to read segments of time-series data from the tsdb table.
The query is more complex because this table’s rowkey is more complex than tsdbuid.
Against this table, metric, date range, and tags are all considered in the filter.
That filter is applied on the HBase servers, not on the client.
That detail is crucial because it drastically reduces the amount of data transferred to the tsd client.
Keep in mind that this is a regex over the un-interpreted bytes in the rowkey.
The other primary difference between this scan and the previous example is timeseries aggregation.
The OpenTSDB UI allows multiple time series over common tags to be aggregated into a single time series for display.
These groups of tags must also be considered while building the filter.
All this filter business is implemented through the TsdbQuery.run() method.
This method works just like before, creating a filtered scanner, iterating over the returned rows, and gathering data to display.
It handles the interesting part of setting up a regular expression filter over the rowkeys.
Building a byte-wise regular expression isn’t as scary as it sounds.
With this filter in place, OpenTSDB submits the query to HBase.
Each node in the cluster hosting data between the start and end keys handles its portion of the scan, filtering relevant records.
The resulting rows are sent back to tsd for rendering.
Earlier we said that HBase is a flexible, scalable, accessible database.
A flexible data model allows HBase to store all manner of data, time-series being just one example.
HBase is designed for scale, and now you’ve seen how to design an application to scale right along with it.
You also have some insight into how to use the API.
We hope the idea of building against HBase is no longer so daunting.
We’ll continue exploring building real-world applications on HBase in the next chapter.
We’ll use the lens of GIS to demonstrate how to adapt HBase to tackle these challenges.
To do so, you’ll need to use domain-specific knowledge to your advantage.
Geographic systems are frequently used as the foundation of an online, interactive user experience.
These services strive to provide relevant information about hundreds of millions of locations all over the globe.
Users of these applications depend on them to find, for instance, the nearest coffee shop in an unfamiliar Scaling GIS on HBase.
They don’t want a MapReduce job standing between them and their latte.
We’ve already discussed HBase as a platform for online data access, so this first constraint seems a reasonable match for HBase.
Still, as you’ve seen in previous chapters, HBase can only provide low request latency when your schema is designed to use the physical storage of data.
This brings you conveniently to the second challenge: spatial locality.
We’ll spend a major portion of this chapter explaining an algorithm called the geohash, which is a solution to this problem.
The idea is to store data so that all the information about a place on Earth is stored close together.
That way, when you want to investigate that location, you need to make as few data requests as possible.
You also want the information about places that are close together on Earth to be stored close together on disk.
If you’re accessing information about Midtown Manhattan, it’s likely you’ll also want information about Chelsea and Greenwich Village.
You want to store that data closer to the Midtown data than, say, data about Brooklyn or Queens.
By storing information about these spatially similar places so that the information is physically close together, you can potentially achieve a faster user experience.
The simplest form of geographic data, a single point on Earth, is composed of two equally relevant dimensions: longitude (X-axis) and latitude (Y-axis)
Many professional GIS systems must also consider a Z-axis, such as elevation or altitude, in addition to the X- and Y-axes.
Many GIS applications also track position over time, which presents all the challenges of time-series data discussed in the previous chapter.
Both kinds of data locality are critical when designing systems providing low-latency data access.
HBase makes this clear through schema design and use of the rowkey.
The sorted rowkey gives you direct control over the locality of storage of your data.
Spatial locality isn’t Hadoop’s data locality This idea of spatial locality is similar to but not the same as Hadoop’s concept of data locality.
In both cases, we’re considering the work of moving data.
Spatial locality in GIS is about storing data with a similar spatial context in a similar place.
Data locality in Hadoop is about performing the data access and computation on the machine in the cluster where that data is physically stored.
Both cases are about minimizing the overhead of working with the data, but that’s where the similarity ends.
Toward that end, we’ve employed a browser-based cartography library called Leaflet to build these illustrations with repeatable precision.
The map tiles behind the figures are of the beautiful Watercolor tile set from Stamen Design and are built from completely open data.
The underlying data is from OpenStreetMap, a project like Wikipedia, but for geographic data.
Building an index of the world’s cities over only longitude, the X-axis, would order data inaccurately for a certain set of queries.
The second implementation moves as much work as possible to the server side, in the form of a custom filter.
This will maximize the work performed in your HBase cluster and minimize the superfluous data returned to the client.
Along the way, you’ll learn enough of this new domain to turn HBase into a fully capable GIS machine.
The devil, as they say, is in the details, so let’s zoom in from this question of distance between international cities and solve a much more local problem.
The code and data used through the course of this chapter are available on our GitHub account.
Let’s say you’re visiting NYC and need an internet connection.
You know you want fast access to a relevant subset of the data.
To achieve that, let’s start with two simple and related goals:
We don’t expect you to be familiar with GIS or GIS data, so we’ve preprocessed it a bit.
Some of those datasets are pretty cool, in particular the Street Tree Census data.
The columns X and Y are the longitude and latitude values, respectively.
Each record has an ID, a NAME, and a number of other columns.
Based on the goals outlined earlier, you now have a pretty good spot-check for your schema designs.
As goal C states, if you want to retrieve those two points, you shouldn’t have to retrieve point 219 as well.
Now you know the goals and you know the data.
As you learned in chapter 4, design of the rowkey is the single most important thing you can do in your HBase schema, so let’s start there.
Geographic data wants to be seen, so draw it on a map.
Here’s a sampling of the full dataset—a handful of places to find a wifi connection in Midtown Manhattan.
At least that way you could keep all that extra data from hitting the client.
A filter is reading records out of the store in order to execute the filter logic.
It would be better to never touch that data, if you can avoid it.
This schema design, placing one dimension ahead of the other in the rowkey, also implies an ordered relationship between dimensions that doesn’t exist.
To do so, you need to learn about a trick the GIS community devised for solving these kinds of problems: the geohash.
As the previous example shows, longitude and latitude are equally important in defining the location of a point.
In order to use them as the basis for the spatial index, you need an algorithm to combine them.
Such an algorithm will create a value based on the two dimensions.
That way, two values produced by the algorithm are related to each other in a way that considers both dimensions equally.
A geohash is a function that turns some number of values into a single value.
For it to work, each of those values must be from a dimension with a fixed domain.
In this case, you want to turn both longitude and latitude into a single value.
There are a number of ways to reduce multiple dimensions to a single one, but we’re using the geohash here because its output preserves spatial locality.
A geohash isn’t a flawless encoding of the input data.
For you audiophiles, it’s a bit like an MP3 of your source recording.
Like an MP3, you must specify a precision when calculating a geohash.
By truncating characters from the end of the hash, you get a less precise geohash and a correspondingly less precise selection of the map.
Where full precision represents a point, partial precision gives you an area on the map, effectively a bounding box around an area in space.
Figure 8.4 illustrates the decreasing precision of a truncated geohash.
For a given geohash prefix, all points within that space match the common prefix.
If you can fit your query inside a geohash prefix’s bounding box, all matching points will share a common prefix.
That means you can use HBase’s prefix scan on the rowkeys to get back a set of points that are all relevant to the query.
But as figure 8.4 illustrates, if you have to choose an overly generous precision, you’ll end up with much more data than you need.
You need to work around these edge cases, but we’ll cover that a little later.
You can look at those points on the map in figure 8.5 and see that Central Park is closer to LaGuardia than JFK.
Because they’re closer to each other spatially, you expect Central Park and LaGuardia to share more common prefix characters than Central Park and JFK.
Now that you understand how a geohash can work for you, we’ll show you how to calculate one.
Don’t worry; you won’t be hashing all these points by hand.
With HBase, it’s useful to understand how it works in order to use it effectively.
Likewise with the geohash, understanding how it’s constructed will help you understand its edge cases.
By dropping characters from the end of a geohash, you drop precision from the space that hash represents.
Base32 is an encoding used to represent a binary value as a sequence of ASCII characters.
When viewed on a map, it’s easy to see that the distance between Central Park and JFK is much farther than the distance between Central Park and LaGuardia.
This is precisely the relationship you want to reproduce with your hashing algorithm.
The contribution provided by each dimension is calculated by halving the value range and determining which half the point resides in.
If the point is greater than or equal to the midpoint, it’s a 1-bit.
This binary partitioning is performed on both the longitude and latitude values.
Rather than using the bit sequence from each dimension independently, the encoding weaves the bits together to create the hash.
The spatial partitioning is why geohashes have the spatial locality property.
The weaving of bits from each dimension is what allows for the prefix-match precision trickery.
Now that you understand how each component is encoded, let’s calculate a full value.
This process of bisecting the range and selecting a bit is repeated until the desired precision is achieved.
A bit sequence is calculated for both longitude and latitude, and the bits are interwoven, longitude first, then latitude, out to the target precision.
Once the bit sequence is calculated, it’s encoded to produce the final hash value.
Now that you understand why the geohash is useful to you and how it works, let’s plug it in for your rowkey.
The geohash makes a great choice for the rowkey because it’s inexpensive to calculate and the prefix gets you a long way toward finding nearest neighbors.
Let’s apply it to the sample data, sort by geohash, and see how you’re doing on prefixes.
We’ve calculated the geohash for each point using a library5 and added it to the data.
Designing a spatial index data in the sample is relatively close together, so you expect a good deal of prefix overlap across the points:
That’s not bad at all! This means you’re a long way toward the distance query and goal B with a simple range scan.
For context, figure 8.7 puts this data on a map.
This is much better than the compound rowkey approach, but it’s by no means perfect.
All these points are close together, within a couple blocks of each other.
If the target search is in this area, a simple rowkey scan will get the data you need.
Not only that, but the order of results makes a lot more sense than the order in figure 8.3
You’d make strides toward goal C if you could make two scans of prefix six rather than a single scan of prefix five.
The geohash boxes for both the six-character and seven-character geohash prefixes are overlaid.
Compared to the target query area, the six-character prefix match areas are huge.
Worse still, the query spans two of those larger prefixes.
Seen in this context, those five characters of common prefix include far more data than you need.
Relying on prefix match results in scanning a huge amount of extra area.
If your data isn’t dense at this precision level, executing fewer, longer scans isn’t such a big deal.
The scans don’t return too much superfluous data, and you can minimize the remote procedure call (RPC) overhead.
Lots of additional, unnecessary area is introduced into the query result by using the 6-character prefix.
An ideal implementation would use only 7-character prefixes to minimize the amount of extra data transmitted over the wire.
Designing a spatial index more, shorter scans will reduce the number of excess points transported over the wire.
Plus, if there’s one thing that computers are getting good at these days, it’s parallelism.
Execute each of those shorter scans on its own CPU core, and the query is still as fast as the slowest scan.
Let’s scroll the map over to a different part of Manhattan, not far from the space we’ve explored thus far.
Notice that the geohash of the center box has six characters (dr5ruz) of prefix in common with the boxes to its east, southeast, and south.
But there are only five characters (dr5ru) in common with the west and southwest boxes.
If five characters of common prefix is bad, then the prefix match with the entire northern row is abysmal, with only two characters (dr) in common! This doesn’t happen every time, but it does happen with a surprisingly high frequency.
As a counterexample, all eight neighbors of the southeast box (dr5ruz9) share a common six-character prefix.
Imagine a nearest-neighbor search falling on the point under the arrow in this illustration.
It’s possible you’ll find a neighbor in a tile with only two characters of common prefix.
Explaining the details of that manipulation is beyond the scope of our interest, so we’ll trust the geohash library to provide that feature.
Now it’s time to put your newfound geohash knowledge into practice by implementing the query.
QueryMatch is a data class you’ll use to keep track of, well, a query result.
Rank and limit the results of the nine scans to compute the final n results returned to the caller.
You’ll implement this in two functions: one to handle the HBase scan and the other to handle the geohash and aggregation.
The Z-order curve is extremely similar to the geohash, involving the interleaving of bits.
Not all linearization techniques are created equal The geohash is approximating the data space.
That is, it’s a function that computes a value on a single output dimension based on input from multiple dimensions.
In this case, the dimensionality of the input is only 2, but you can imagine how this could work for more.
This is a form of linearization, and it’s not the only one.
These are both classes of space-filling curves:3 curves defined by a single, uninterrupted line that touches all partitions of a space.
None of these techniques can perfectly model a two-dimensional plane on a one-dimensional line and maintain the relative characteristics of objects in those spaces.
We choose the geohash because, for our purposes, its error cases are less bad than the others.
There’s nothing particularly special here; you’re interacting with HBase as you’ve done before.
You don’t need to hang onto all the query results from each scan, only the closest n.
That cuts down on the memory usage of the query process, especially if you’re forced to use a shorter prefix than desired.
The main query function builds on the takeN helper function.
The queryKNN function handles generating the geohash from the query target, calculating the nine prefixes to scan, and consolidating the results.
As you saw in figure 8.9, all nine prefixes must be scanned to guarantee correct results.
The same technique used to limit memory usage in takeN is used to pare down the final results.
This is also where you’d want to put any concurrency code, if you’re so inclined.
It accepts a custom Comparator for order maintenance and enforcing the eviction policy; you’ll need to build one for your QueryMatch class.
The Comparator is based on distance from the origin of the query target.
If you’re a professional Java developer and you’ve never explored it, you’re missing out.
Realistically, you don’t want to use a simple distance function, especially if you’re calculating distances spanning a large area.
In general, take extra care when calculating nonrelative values, especially when you want to think in uniform geometries like circles and squares or return human-meaningful units like miles or kilometers.
With the result sorting in place, you need a Java version of takeN, the method to perform the HBase scan.
Each prefix needs to sort and limit the set of partial results returned, so it takes a Comparator in addition to the prefix and n.
That’s instead of receiving the origin point as you did in pseudo-code:
It’s not customary to modify an object from within a Comparator Normally you wouldn’t write Comparators the way we did in the code example.
Don’t do this in your normal code! We’ve done so here to make it easier to inspect the results from within the text.
This is the same kind of table scan used when you learned about scans in chapter 2
That method call sets the number of records returned per RPC call the scanner makes to 50—a somewhat arbitrary number, based on the number of records traversed by the scan and the size of each record.
For this dataset, the records are small and the idea is to restrict the number of records scanned via the geohash.
Fifty should be far more data than you expect to pull from a single scan at this precision.
You’ll want to play with that number to determine an optimal setting for your use case.
Be sure to play with it, because anything is likely better than the default of 1
It computes a GeoHash from the target query point and calls takeN over that prefix as well as the eight surrounding neighbors.
Setting scan cache higher than 1 dramatically cuts down RPC calls.
Instantiating a Comparator is simple, instantiating the queue is simple, and the for loop over the geohash neighbors is simple.
The only odd thing here is the construction of the GeoHash.
Earlier in the chapter, you wanted to hash a point in space, so you used the maximum precision you could get: 12 characters.
You’re not after a single point, but a bounding box.
Choose a precision that’s too high, and you won’t query over enough space to find n matches, particularly when n is small.
Choose a precision that’s too low, and your scans will traverse orders of magnitude more data than you need.
Using seven characters of precision makes sense for this dataset and this query.
Different data or different values of n will require a different precision.
Striking that balance can be tricky, so our best advice is to profile your queries and experiment.
If all the queries look roughly the same, perhaps you can decide on a value.
Otherwise, you’ll want to build a heuristic to decide on a precision based on the query parameters.
In either case, you need to get to know your data and your application!
Toss together a simple main(), and then you can see if it all works.
The details of parsing a tab-separated values (TSV) file aren’t terribly interesting.
The part you care about is using the GeoHash library to construct the hash you use for a rowkey.
These are points, so you use 12 characters of precision.
Again, that’s the longest printable geohash you can construct and still fit in a Java long:
The column family isn’t particularly important here, so let’s choose something short:
Design your scans according to the query, not the data Notice that we said to choose your geohash prefix precision based on the applicationlevel query.
You always want to design your HBase scans according to the query instead of designing them based on the data.
Your data will change over time, long after your application is “finished.” If you tie your queries to the data, your query performance will change along with the data.
That means a fast query today may become a slow query tomorrow.
The test data is packaged in the project, so you have everything you need.
Build the application, and run the Ingest tool against the full dataset:
For the target point, let’s cheat a little and choose the coordinates of one of the existing data points.
If the distance algorithm isn’t completely broken, that point should be the first result.
The first set of output is the contributions from each of the prefix scans.
The fields printed are ID, geohash, longitude, latitude, and distance from the query target.
That’s pretty cool, right? As you likely noticed, all the comparison work happened on the client side of the operation.
The scans pulled down all the data, and postprocessing happened in the client.
You have a cluster of machines in your HBase deployment, so let’s see if you can put them to work.
Perhaps you can use some other features to extend HBase into a full-fledged distributed geographic query engine.
The sample dataset is pretty small, only 1,200 points and not too many attributes per point.
Still, your data will grow, and your users will always demand a faster experience.
It’s generally a good idea to push as much work server-side as you can.
As you know, HBase gives you two mechanisms for pushing work into the RegionServers: filters and coprocessors.
In this section, you’ll extend the wifi example you’ve started.
You’ll implement a new kind of geographic query, and you’ll do so using a custom filter.
Implementing a custom filter has some operational overhead, so before you do that you’ll make an improvement on the way you use the geohash.
This simple spiraling technique searches out around the query coordinate looking for matches.
A smarter implementation would take into account the query coordinate’s position within the central spatial extent.
Once the minimum number of matches had been found, it would skip any neighbors that are too far away to contribute.
Pushing work server-side query region, along with the data, is illustrated in figure 8.11
As you can see, you expect to receive about 25 points in the query results.
This is a pretty simple shape, drawn by hand and overlaid on the map.
There are plenty of sources for polygons you might use in your query.
For instance, a service like Yelp might provide a user with predefined polygons describing local neighborhood boundaries.
You could even allow the user of your application to sketch their query polygon by hand.
The approach you’re going to take works as well with this simple rectangle as with a more complex shape.
With the query shape defined, it’s time to devise a plan for implementing the query.
You have the geohash index, which takes you fairly far along.
The first step is to translate the query polygon into a set of geohash scans.
As you know from the previous query, that will give you all candidate points without too many extra.
The second step is to pull out only the points that are contained by the query polygon.
We used Google Earth to eyeball the four corners of the query space.
It looks like all those flashy sign boards sucked up the wifi; it’s not very dense compared to other parts of the city.
You can expect about 25 points to match your query.
Luckily, you have such a companion in the JTS Topology Suite (JTS).13 You’ll use that library to bridge the gap between the geohash and the query polygon.
For this step of query building, you need to work out exactly which prefixes you want to scan.
As before, you want to minimize both the number of scans made and the spatial extent covered by the scans.
Let’s use that to find a suitable set of scans—a minimal bounding set of prefixes.
Before we describe the algorithm, it’s helpful to know a couple of geometry tricks.
The first trick you want to use is the centroid,14 a point at the geometric center of a polygon.
The query parameter is a polygon, and every polygon has a centroid.
You’ll use the centroid to start your search for a minimum bounding prefix scan.
Thus you need a way to make Geometry an object from your query argument.
There’s a simple text format for describing geometries called well-known text (WKT).15 The query around Times Square translated into WKT looks like this:
Technically speaking, a polygon is a closed shape, so the first and last point must match.
Once you have that, the centroid is just a method call away:
Now that you know the query polygon’s centroid, you have a place to begin calculating the geohash.
The problem is, you don’t know how large a geohash is required to fully contain the query polygon.
You need a way to compute a geohash and see if it fully contains the user’s query.
The Geometry class in JTS has a contains() method that does just that.
You also don’t want to step down the precision level if you don’t.
Centroid is a mathematical term with a strict meaning in formal geometry.
One point of note is that the centroid of a polygon isn’t always contained by it.
That isn’t the case with the query example; but in real life data is messy, and this does happen.
More examples of well-known text can be found at http://en.wikipedia.org/wiki/Well-known_text.
If the geohash at the current precision doesn’t contain the query geometry, you should try the geohash plus all its immediate neighbors.
Thus, you need a way to convert a GeoHash or a group of GeoHashes into a Geometry.
This brings you to our second geometry trick: the convex hull.
The convex hull is formally defined in terms of the intersections of sets of geometries.
The Wikipedia page16 has a simpler description that is adequate for your needs.
It says you can think of the convex hull of a collection of geometries as the shape a rubber band makes when you stretch it over the geometries.
These geometric concepts are easily explained in pictures, so figure 8.1317 shows the convex hull over a random scattering of points.
The convex hull is useful for the case when you want to know if the query polygon falls inside the full set of geohash neighbors.
You can find the formal definition of the convex hull at http://en.wikipedia.org/wiki/Convex_hull.
The centroid point is where you’ll begin with the calculation for a minimum bounding set of geohashes.
In the case of the full set of neighbors, you loop though all of them, calling getCoords() on each one, and collect their corners.
Using the Coordinates, you can create a simple kind of Geometry instance, the MultiPoint.
You’re using this instead of something like a Polygon because the Multipoint doesn’t impose additional geometric restrictions.
You can put all this together in another helper method:
Figure 8.13 The convex hull is the shape made by fully containing a collection of geometries.
You’ll use this to test query containment of the full set of neighbors of a geohash.
Now you have everything you need to calculate the minimum bounding set of geohash prefixes from the query polygon.
Thus far, you’ve used a geohash precision of seven characters with reasonable success on this dataset, so you’ll start there.
For this algorithm, you’ll begin by calculating the geohash at seven characters from the query polygon’s centroid.
If it’s not big enough, you’ll perform the same calculation over the complete set of the geohash and its neighbors.
If that set of prefixes still isn’t large enough, you’ll step the precision level back to six and try the whole thing again.
Figure 8.14 illustrates the attempt to bind the query with geohashes at seven and six characters of precision.
Seven characters is insufficient, so a level of precision must be dropped.
Figure 8.14 also emphasizes the imperfection in the current approach.
At sixcharacter precision, you do cover the entire query extent, but the entire western set of panels isn’t contributing any data that falls inside the query.
You could be smarter in choosing your prefix panels, but that involves much more complex logic.
We’ll call this good enough for now and move on to continue implementing the query.
Before building out the server-side filter, let’s finish building and testing the query logic on the client side.
Deploying, testing, and redeploying any server-side component can be annoying, even when running locally, so let’s build and test the core logic client-side first.
Not only that, but you’ll build it in a way that’s reusable for other kinds of queries.
The main body of client-side logic is nearly identical to that of KNNQuery.
In both cases, you’re building a list of geohash prefixes to scan, running the scan, and collecting results.
What you’re interested in is checking to see if a returned point is inside of the query polygon.
To do that, you’ll need to create a Geometry instance from each QueryMatch instance.
From there, the same contains() call you used earlier will do the trick:
Figure 8.14 Checking for containment at seven and six characters of precision.
At seven characters, both the central geohash and the combined set of all its neighbors aren’t sufficiently large to cover the entire query extent.
The QueryMatch results contain latitude and longitude values, so you turn those into a Coordinate instance.
That Coordinate is translated into a Point, a subclass of Geometry, using the same GeometryFactory class you used earlier.
That’s good news, because it means the harness you’ve built to support this within query will work for many other kinds of spatial operations.
Again, the main() method isn’t terribly interesting, just parsing arguments and dispatching the query, so you’ll skip listing it.
The data is already loaded so you can get right to running the code.
Rebuild and then run a query over the target area around Times Square:
For a taste of things to come, notice how many points were excluded by the contains() predicate.
By pushing the filter logic into the cluster, you can reduce the amount of data transmitted over the network by about 500%! First, though, let’s double-check that the results are correct.
QueryMatch lines are interesting, but it’ll be easier to notice a bug if you can see the results.
Figure 8.15 illustrates the query results in context of the query.
It’s also good to know that the geometry library appears to agree with the cartography library.
It also looks like you might want to expand the borders of the query a little.
That way, it will catch the handful of locations that sit just outside the line.
Now that you know the logic works, let’s push the work out to those lazy RegionServers.
Now that you have a working implementation, let’s move the predicate logic into a filter.
That way you can keep all the extra data on the cluster.
You have everything in place to verify the implementation via the client-side version.
The only difference you should see is that the filtered version will have drastically reduced network overhead and thus, ideally, run faster.
Unless, that is, you’re running against a dataset on a standalone HBase.
That’s where you’ll move the logic from the client-side implementation.
That method will update the state variable in the cases when you want to exclude a row.
Minus a little error-checking, the filterRow() method looks like this:
Methods that iterate over every KeyValue in every column family in every row can be slow.
HBase will optimize away calls to filterRow() if it can; you must explicitly enable it in your extension to FilterBase.
Tell the filter to tell HBase to call this method by providing one more override:
When you want to exclude a row because it doesn’t fall within the query bounds, you set the exclude flag.
That flag is used in boolean filterRow() as the condition for exclusion:
You’ll construct your filter from the query Geometry parsed from main()’s arguments.
Other than moving the exclusion logic out to the Filter implementation, the updated method doesn’t look very different.
In your own filters, don’t forget to include a default constructor with no arguments.
Now it’s time to install the filter and give it a go.
The filter must be installed on the HBase cluster in order for your RegionServers to be able to instantiate it.
Add the JAR to the classpath, and bounce the process.
If your JAR includes dependencies as this one does, be sure to register those classes as well.
You can add those JARs to the classpath, or you can create an uber-JAR, exploding all of those JARs’ classes inside your own.
In practice, we recommend that you keep your JAR lean and ship the dependencies just as you do your own.
It will simplify debugging the version conflicts that will inevitably pop up later down the line.
To find out exactly which external JARs your Filter or Coprocessor depends on, and which JARs those dependencies depend on, Maven can help.
In this case, it shows only two dependencies not already provided by Hadoop and HBase:
A road less traveled At the time of this writing, there aren’t many examples of custom Filter implementations.
We have the list of filters that ship with HBase (an impressive list) but not much beyond that.
Thus if you choose to implement your own filters, you may find yourself scratching your head.
If you’re debugging a misbehaving filter, you’ll have to stop and start HBase with each iteration so it picks up the changes to your JAR.
That’s why in the example, you tested the logic on the client side first.
Were there any, they’d show up in the tree view.
You install the JAR and any dependencies by editing the file hbase-env.sh in.
You can add multiple JARs by separating them with a colon (:)
Notice that you change the first parameter of the query tool’s launch command from local to remote:
A quick cat, cut, sort, diff will prove the output is identical.
The final test would be to load lots of data on a distributed cluster and time the two implementations.
Queries over a large area will show significant performance gains.
If your queries are really big, or you build up a complex filter hierarchy, you may run into RPC timeouts and the like.
Refer to our previous comments about setting scanner caching (section 8.3) to help mitigate that.
This chapter was as much about GIS as about HBase.
To use it effectively, you need to know both the tool and the domain in which you want to apply it.
This chapter showed you how to combine that domain knowledge with your understanding of HBase to create an efficient tool for churning through mounds of GIS data efficiently and in parallel.
It also showed you how to push application logic server-side and provided advice on when and why that might be a good idea.
It’s also worth noting that these queries are only the beginning.
The same techniques can be used to implement a number of other spatial predicates.
It’s also only the beginning of exploring how to implement these kinds of multidimensional queries on top of HBase.
As an interesting follow-up, a paper was published in 201120 that explores methods for porting traditional data structures like quad-trees and kd-trees to HBase in the form of a secondary index.
This chapter concludes the portion of this book dedicated to building applications on HBase.
Once your code is written and your JARs ship, the fun has only begun.
From here on out, you’ll get a sense of what it takes to plan an HBase deployment and how to run HBase in production.
Whether you’re working on the project plan as a project manager or a network administrator, we hope you’ll find what you need to get started.
Your application’s performance depends quite a bit on configuring the client to match your cluster configuration.
And of course, the more you know about how the cluster works, the better equipped you are to solve production bugs in your application.
PostGIS is a set of extensions to the PostgreSQL database and is the canonical open source GIS database in the open source world.
If you thought the geohash algorithm was clever, peek under the hood of this system: http://postgis.refractions.net/
The two chapters in this part of the book are geared to help you take your HBase application from a development prototype to a full-fledged production system.
You can provision and prepare the hardware for your HBase cluster using the guidance provided by chapter 9
Use that advice to deploy and configure HBase specifically for your application.
Chapter 10 explains how to set up your HBase cluster for success in production.
From hard-earned performance configuration strategies to health monitoring and data-preservation techniques, chapter 10 will guide you through the tough scenarios that pop up in a production HBase cluster.
A single-node standalone HBase install is only meant for basic access, which you typically do either while learning how to use the system or while developing an application.
When planning a fully distributed HBase setup, you have to think about all the individual components: HBase Master, ZooKeeper, RegionServers, and HDFS DataNodes.
Each of these has different requirements in terms of hardware resources.
This chapter will teach you in detail about the requirements for all the components and how you should choose hardware for a fully distributed HBase install.
We’ll then talk about the different HBase distributions available and considerations you should take into Deploying HBase.
By now, you’ve learned a lot about HBase as a system and how to use it.
We’ll also discuss deployment strategies and what you should consider when architecting your deployment system.
Remember the cloud? We shied away from talking about it in the preceding chapters, but we’ll discuss it now.
Once you have everything set up and the HBase components deployed, you have to configure the system too.
We’ll cover the important configuration parameters and what each means.
Planning an HBase cluster includes planning the underlying Hadoop cluster.
This section will highlight the considerations to keep in mind when choosing hardware and how the roles (HBase Master, RegionServers, ZooKeeper, and so on) should be deployed on the cluster.
Hardware will probably be your single largest investment in your Hadoop and HBase deployment, outside of hiring engineers to build the application that will use the systems.
It means nonexotic parts that are easily available from several manufacturers.
In other words, you don’t need to buy top-of-the-line, enterprise-grade servers to have a successful deployment.
When choosing hardware for any application, you have to make choices such as the number of CPUs, the amount of RAM, the number and size of disks, and so on.
For an HBase deployment, it’s important to have the right ratio of all these resources in order to maximize the performance and minimize costs.
You don’t want to have a cluster with lots of CPU but not enough RAM to hold the cache or the MemStore.
A slightly lower CPU but more RAM would probably be a better choice, but the cost would remain the same.
As you’ve learned by now, there are multiple roles in an HBase deployment.
Each has specific hardware requirements, some more extensive than others.
The hardware selection and what is deployed to which location is governed by the size of the cluster.
In clusters up to 25 nodes, having a single node running the Hadoop JobTracker and NameNode isn’t uncommon.
You can put the Secondary NameNode there too, but it’s generally recommended that you keep it separate.
Clusters larger than 25 nodes typically have dedicated hardware for each of the Hadoop NameNode, JobTracker, and Secondary NameNode.
Don’t think that 25 is a magic number; it’s a general guideline to give you an idea about the direction to consider when planning your cluster.
When planning a cluster, SLAs come into the picture, and planning carefully becomes crucial.
If your use case doesn’t contain any MapReduce jobs, it’s a good idea to not set up the MapReduce framework at all—that is, don’t install the JobTracker and the TaskTrackers.
If you have MapReduce as well as real-time workloads, use two separate clusters—one for MapReduce and one for HBase.
Your MapReduce jobs can read from the remote HBase cluster.
Yes, you do lose data locality and will be transferring data over the network for every job, but that’s the only way to reliably guarantee SLAs for the realtime workloads.
We typically don’t recommend serving MapReduce and real-time workloads at the same time from the same HBase cluster.
If you absolutely have to, make sure you tune the number of tasks way down so as to not overwhelm the HBase RegionServers.
Having a higher number of disks also helps alleviate I/O contention issues by distributing the load across the disks.
Get more RAM, because your tasks will need resources too.
If the primary use case is doing MapReduce jobs over the data in HBase, collocating RegionServers and TaskTrackers is fine.
Now, let’s look at some common deployment scenarios and how you should plan them.
It generally helps to think in terms of the kind of cluster you’re looking to deploy.
Some of the common kinds of cluster types are listed next.
If you’re building a simple prototype cluster, you can collocate the HBase Master with the Hadoop NameNode and JobTracker on the same node.
If those already reside on separate nodes, you can collocate the HBase Master with either of them and call it a day.
ZooKeeper can be hosted on any of these nodes too.
Given that you’ll have the Hadoop NameNode, JobTracker, HBase Master, and ZooKeeper on the same node, it helps to have a node with sufficient memory and disks to sustain this load.
A prototype cluster would most likely be less than 10 nodes, which limits the capacity of your HDFS.
There is no need to get redundant power supplies, SAS disks, and so on; you don’t need a lot of high availability in a prototype cluster, so save yourself some money that you can invest in the production cluster when your application becomes a hit!
A prototype cluster is one that doesn’t have strict SLAs, and it’s okay for it to go down.
This assumes you aren’t collocating MapReduce with HBase, which is the recommended way of running HBase if you’re using it for low-latency access.
Collocating the two would require more cores, RAM, and spindles.
Generally, you shouldn’t have fewer than 10 nodes in a production HBase cluster.
It’s hard to operate a small cluster with performance guarantees and tight SLAs (this statement is more anecdotal than logic based)
In a small production cluster, the Hadoop NameNode and JobTracker can remain collocated.
There isn’t enough load on either of them to warrant extra hardware.
But given that you need a reliable system, you want to consider better quality hardware than you did for a prototype cluster.
We cover typical hardware for each of the role types later.
The HBase Master should be on its own hardware, but not because it’s doing a lot of work.
The reason to separate it from the NameNode and JobTracker is to reduce the load on the node hosting those roles.
The HBase Master node can have a lowergrade hardware profile than the other two.
You can get by with a single Master, but given that it’s a production system, it’s a good idea to have redundancy.
Thus you should have multiple HBase Masters, each deployed on dedicated hardware.
A single ZooKeeper instance is usually enough in a small production cluster.
ZooKeeper doesn’t do resource-intensive work and can be hosted on modest hardware as well.
You can also consider hosting ZooKeeper and HBase Master together on the same host, as long as you give ZooKeeper a dedicated disk to write its data to.
Having multiple ZooKeeper nodes increases availability; but on a small cluster, you most likely won’t expect high traffic, and maintaining availability with a single ZooKeeper instance is doable.
Also, having the NameNode act as a single point of failure is a problem even if you have multiple ZooKeepers.
The downside of having a single ZooKeeper and HBase Master instance hosted on the same node is that it limits serviceability.
Things like kernel upgrades, minor reboots, and so on become impossible to do without downtime.
But in a small cluster, having more than one ZooKeeper and HBase Master means the cost goes up.
Dual power supplies and perhaps RAID are the order of the day.
Small production clusters with not much traffic/workload can have services collocated.
If the host running the NameNode and JobTracker is beefy enough, put ZooKeeper and HBase Master on it too.
This will save you having to buy an extra machine.
Things change as you scale up to a greater number of servers than in a small deployment.
The cluster has more data, more servers doing work, and more processes to manage.
Separate out the NameNode and JobTracker, and give them dedicated hardware.
Keep the HBase Masters and ZooKeeper on the same hardware, as in a small deployment.
The work the Master will do doesn’t scale up linearly with the size of the cluster; in fact, the Master’s load doesn’t increase much.
You could get by with a single ZooKeeper instance in a small deployment.
As the deployment scales, you’ll probably have more client threads as well.
Why not two? Because ZooKeeper needs an odd number of instances in order to have a quorum of servers to make decisions.
If you do collocate, deploy NameNode and JobTracker on separate hardware.
Three ZooKeeper and three HBase Master nodes should be deployed, especially if this is a production system.
You don’t need three HBase Masters and can do with two; but given that you already have three ZooKeeper nodes and are sharing ZooKeeper and HBase Master, it doesn’t hurt to have a third Master.
Don’t cheap out on the hardware for the NameNode and Secondary NameNodes.
A large cluster can be approached almost like a medium-sized cluster, except that we recommend increasing the number of ZooKeeper instances to five.
Make sure you give ZooKeeper a dedicated disk for it to write its data to.
The hardware profiles of the Hadoop NameNode and Secondary NameNode change as you look at larger-scale deployments; we’ll talk about that shortly.
Everything for the medium-sized cluster holds true, except that you may need five ZooKeeper instances that can also collocate with HBase Masters.
Make sure NameNode and Secondary NameNode have enough memory, depending on the storage capacity of the cluster.
As you read earlier, depending on the size of the cluster, these are either deployed together or on separate nodes of similar hardware configuration.
All of these are single processes and don’t have any failover strategy built in.
Of course, you don’t want to go overboard and get the most expensive system.
For the nodes hosting these processes, it’s recommended that you have redundancy at the hardware level for the various components: dual power supplies, bonded network interface cards (NICs), and possibly RAID disks.
If the disks holding the metadata on the NameNode go down and you don’t have redundancy or backups built into your deployment, you’ll lose the data in the cluster, and that’s something you don’t want to experience when running in production.
Either get RAID 1 and write to a single location, or get multiple disks and configure the NameNode to write to multiple locations.
It’s also not uncommon to use an NFS mount as one of the metadata directories for the NameNode in order to write the metadata to storage outside of the NameNode server.
The OS on any of these nodes needs to be highly available too.
Medium and large clusters can benefit from additional RAM, with the rest of the hardware configuration remaining the same.
The Secondary NameNode should have the same hardware as the NameNode.
Apart from doing its job of checkpointing and backing up the metadata, it’s also typically the server you fall back on if the NameNode server goes to lunch and doesn’t come back.
The HBase Master doesn’t do much heavy-duty work, and you can have multiple Masters for failover purposes.
Because of these two factors, having expensive hardware with redundancy built in is overkill for the HBase Master.
Build redundancy into the system by having multiple HBase Masters, and you should be good to go.
You can read more about non-RAID drive architectures at http:// mng.bz/Ta1c.
The Hadoop DataNodes and HBase RegionServers are typically referred to as the slave nodes in the system.
They don’t have fancy hardware requirements like the Master nodes because of the built-in redundancy in the architecture.
All slave nodes are alike, and any one of them can replace the function of any other.
The job of the slave nodes is to store the HDFS data, do MapReduce computation, and serve requests from the HBase RegionServer.
To do all that work well, they need ample RAM, disk storage, and CPU cores.
Remember, commodity doesn’t mean a low-end configuration but instead modestquality hardware.
No single hardware configuration is optimal for all workloads; some workloads can be more memory intensive and others can be more CPU intensive.
And then there are archival storage workloads, which don’t need a lot of CPU resources.
HBase RegionServers are memory hogs and will happily consume all the RAM you give them.
That doesn’t mean you should allocate 30 GB of heap to the RegionServer process.
You’ll run into stop-the-world garbage collectors (GCs), and that will bring down your system in no time.
Remember, HBase is latency sensitive, and stop-the-world garbage collection is the bane of its existence.
Anecdotally, a 10–15 GB heap for the RegionServer performs well, but you should test it against your workload to find the optimal number.
If all you’re running is HBase (and of course HDFS), the slave nodes need a total of 8–12 cores for the DataNode, RegionServer, OS, and other processes (monitoring agents and so on)
Extra RAM on the box never hurts and can be used up by the file-system cache.
We generally recommend keeping TaskTrackers and HBase RegionServers separate unless your primary workload is MapReduce over HBase tables and you don’t expect a guaranteed low-latency response from HBase all the time.
Like the HBase Master, ZooKeeper is a relatively lightweight process.
But ZooKeeper is more latency sensitive than the HBase Master.
Because of that, we recommend giving ZooKeeper a dedicated spindle to write its data to.
ZooKeeper serves everything out of memory, but it persists its data onto the disk as well; and if that is slow (because of I/O contention), it can degrade ZooKeeper’s functioning.
You can easily have the same hardware configuration as the HBase Master and call it a day.
Add a disk (for the ZooKeeper data to be persisted on) to the configuration mentioned in the HBase Master section if you’re collocating.
We’ve talked about the various components of HBase and what kind of hardware you need to provision for them to function optimally.
Recently, the cloud is becoming popular because of the flexibility it offers users.
In the context of HBase, we consider the cloud to be just another set of hardware choices with a different cost model.
This may be a restrictive view, but let’s start with that.
It’s important to understand the various properties the cloud has to offer and what the implications are from the perspective of deploying a production-quality HBase instance.
The biggest (and oldest) player right now in the cloud infrastructure space is Amazon Web Services (AWS)
We haven’t come across many instances deployed in Rackspace or in Microsoft.
It’s possible that those deployments are just top-secret ones and haven’t been shared openly, but we’ll never know! For this section, we’ll focus more on what AWS has to offer, and most of what we talk about will hold true for other providers as well.
As you’ve probably realized by now, you need plain servers for an HBase deployment, and EC2 is the service that provides virtual servers to work with.
We recommend using instances with at least 16 GB RAM and ample compute and storage.
That’s keeping it a little vague, but given the dynamic nature of the landscape, chances are that by the time you get your hands on this book to read this section, there will be something new out there that’s better than the best we mention here.
But don’t give them too much, or you’ll run into Java GC issues.
Most EC2 instances at the time of writing don’t provide a high number of disks.
Some EC2 instances are full machines, and the physical server isn’t shared by multiple instance types.
Those are better fits for HBase and even Hadoop for the most part.
When a single physical server is being shared by multiple instances, chatty neighbors can cause a significant performance impact.
If your neighbor is doing heavy I/O, you’ll be seeking more and possibly getting much lower I/O performance in your instance than you would with a quieter neighbor instance.
You’ll often hear people talk about S3 and EBS when discussing Hadoop or HBase in the cloud.
It can be used to back up your HBase instance by running export jobs on your table and writing the output to S3
This can come in handy if you want to look at starting and stopping your HBase cluster pretty often.
You could possibly store your HDFS purely in EBS and shut down the EC2 instances when you want to stop the HBase instances and save some money.
To resume the HBase instances, provision new EC2 instances and mount the same EBS volumes to them, and start Hadoop and HBase.
Now that you know about your options in the cloud and how to think about them, it’s important that you’re aware of the arguments in favor of and against deploying HBase in the cloud.
You’ll hear strong opinions from people, and we’ll try to limit this discussion to pure facts and their implications:
You don’t have to invest a bunch of money and buy the hardware up front before you can start using HBase.
You can provision a few instances, pay per hour, and deploy the software on them.
If you’re running 24x7 clusters, do the math on the cost.
Chances are that the instances in the cloud will work out to be more expensive than having hardware in your own data center or even a shared data center.
Ease of use—Provisioning instances in the cloud can be done with just a couple of API calls.
Reliability—EC2 instances aren’t as reliable as dedicated hardware you’ll buy.
We have personally seen instances go down randomly without any degradation in performance that could have hinted at an issue.
Reliability has increased over time, but it isn’t comparable to the dedicated boxes you’ll buy.
Lack of customization—You have to choose from the instance types that AWS provides and can’t customize for your use case.
If you’re buying your own hardware, you can customize it.
For instance, you need denser storage but not much compute power if you’re only storing large amounts of data in an archival manner.
But if you want to do a lot of computation, you need to flip it around and get more compute with less storage density per node.
Some virtualization types are better than others, but none come without an impact on performance.
The impact is more on I/O than other factors, and that hurts HBase most.
Security—Look into the security guarantees that the cloud provider has in place.
Sometimes this can be an issue for sensitive data, and you may want to get hardware that you manage and can guarantee security on.
At the end of the day, it’s all about the cost of ownership, and we recommend looking at the cost in terms of dollars per amount of data stored or dollars per read/write operation.
Those are difficult numbers to calculate, but they will give you the insight you need if you’re trying to choose between dedicated on-premises hardware and the public cloud.
Once you’ve made up your mind, bought the hardware, or provisioned the instances, it’s time to deploy the software.
Managing and deploying on a cluster of machines, especially in production, is nontrivial and needs careful work.
There are numerous challenges in doing so, and we’ll list a few of the major ones here.
It’s not an unsolvable problem or one that people haven’t already solved, but it’s one that shouldn’t be ignored.
When deploying to a large number of machines, we recommend that you automate the process as much as possible.
First, you don’t want to repeat the same process on all the machines that need to be set up.
Second, when you add nodes to the cluster, you don’t want to have to manually ensure that the new node is set up correctly.
Having an automated system that does all this for you is desirable, and most companies have it in some form or other.
There are some proprietary tools as well, such as HP Opsware.
If you’re deploying in the cloud, Apache Whirr (http://whirr.apache.org) is a framework that can come to your rescue and make spinning up and configuring instances easy.
They’ll set up the OS and install and manage various packages, including Hadoop and HBase.
They can also help manage configurations from a centralized place, which is what you want.
Specialized tools like Cloudera Manager are specifically designed to manage Hadoop and HBase clusters.
These tools have a bunch of Hadoop-specific management features that are otherwise not available in general package-management frameworks.
Going into the details of all these options is beyond the scope of this book; our intent is to introduce you to all the ways you can think about deployments.
Invest up front in one of these frameworks, and operating your cluster over time will be much easier.
If you’re looking to deploy HBase in the cloud, you should get Apache Whirr to make your life easier.
Put this recipe into a file that you can pass as a configuration to the Whirr script, such as my_cdh_recipe.
You can use these recipes and spin up the cluster like this:
Once you’ve spun up a cluster, you can use the list command to list the nodes that form the cluster:
When you’re done with your cluster and want to kill it, use the destroy-cluster command like this:
This isn’t a reference guide to building out a full-fledged production deployment but is instead a starting point for setting up a fully distributed install that you can use for your application.
Making HBase operational requires a little more work than that, and we cover various aspects in the next chapter.
Numerous distributions (or packages) of HBase are available, and each has multiple releases.
The most notable distributions currently are the stock Apache distribution and Cloudera’s CDH:
Apache—The Apache HBase project is the parent project where all the development for HBase happens.
All the code goes there, and developers across multiple companies contribute to it.
As with any other open source project, the release cycle depends on the stakeholders (that is, the companies that hire the developers who work on the project) and what features they want to put into a particular release.
The HBase community in general has been consistent with their releases.
It typically includes more patches than the stock releases to add stability, performance improvements, and sometimes features.
These are points we recommend thinking about before you choose the distribution for your cluster.
The installation steps provided assume that you have Java, Hadoop, and ZooKeeper already installed.
For instructions on setting up Hadoop and ZooKeeper, refer to their documentation for the distribution you’re choosing.
To install the stock Apache distribution, you need to download the tarballs and install those into a directory of your choice.
Many people create a special user that runs all the daemons and put the directory into the home directory of that user.
Detailed installation instructions are available on the HBase home page and sometimes change with different releases.
These are specific to the 0.92.1 release, but you can adapt them to whatever release you’re working with:
As root, untar the tarball into /usr/local/lib and create a symlink from /usr/ local/hbase to the newly created directory.
The installation instructions are environment specific; the fundamental steps are as follows:
If you’re using a Red Hat-based system, you use the yum package-management tool:
The names of the packages in CDH4 are hbase, hbase-master, and hbase-regionserver.
The other two packages contain init scripts that help you start and stop the Master and RegionServer processes, respectively.
The following commands install the HBase binaries on Red Hat-based systems:
And these commands install the HBase binaries on ebian/Ubuntu-based systems:
Installing these packages lays down the libraries in /usr/lib/hbase/ and the configuration files in /etc/hbase/conf/
Note that you won’t be installing the Master and RegionServer scripts on all the nodes.
Install the hbase-regionserver package on the slave nodes and the hbasemaster package on the nodes that will run the HBase Master process.
The hbase package needs to be installed on all the nodes because it contains the actual binaries.
Some of the configurations are straightforward, and recommendations are available based on experience from multiple production deployments.
Some configurations are more iterative and depend on the use case and SLAs the HBase deployment will be serving.
No single set of configurations will work for everyone, and chances are you’ll make several configuration changes before you finalize what you’ll run in production serving your application.
In order to configure the system in the most optimal manner, it’s important that you understand the parameters and the implications of tuning them one way or another.
This section gives you some insight into the important configuration parameters you’ll most likely be working with while deploying your HBase instance.
It covers the HBase-specific configurations first and then goes into the relevant Hadoop and Linux configurations that impact the HBase installation.
One is the Linux-specific configuration (or environment configurations), which is different from the OS-level configuration we’ll explain later.
The other set is the configuration for the HBase daemons, which are read by them at start time.
On the HBase cluster, the location of the configuration files depends on the installation path you followed.
If you used the Apache distribution, the configuration files reside in $HBASE_HOME/conf/; and if you used CDH, they reside in /etc/hbase/ conf/
In general, we recommend that you keep permissions and file locations consistent with the best practices at your company.
This is acceptable to most system administrators and IT departments.
This file is sourced by the script running the HBase processes (Master and RegionServer), and therefore things like the Java heap size, garbage-collection parameters, and other environment variables are set here.
You can set other parameters here, such as the niceness of the HBase processes.
You can look at the default hbase-env.sh file from your installation to see the other available options.
Listed here are the ones you’ll work with 95% of the time.
You won’t need to configure the others in most cases.
Two of the important things configured here are the memory allocation and GC.
It’s critical to pay attention to these if you want to extract decent performance from your HBase deployment.
HBase is a database and needs lots of memory to provide lowlatency reads and writes.
The word real-time is commonly used as well—the idea is that it doesn’t take on the order of minutes to find the contents of the one row you want to read.
Indexing, albeit by rowkey only, enables you to quickly find the location where the row should be read from or written to.
Indexes are held in memory, and so are the write buffers.
We don’t recommend that you give the RegionServers more than 15 GB of heap in a production HBase deployment.
The reason for not going over the top and allocating larger heaps than that is that GC starts to become too expensive.
It will happen less frequently because you won’t hit memory limits soon enough, and every time it happens, it will last for a longer period of time because it will be working through a much larger amount of memory.
That doesn’t mean 15 GB is a magic number and the maximum you should configure your RegionServer heap to; it’s just a good place to start.
We recommend that you experiment with heap sizes in your environment and see what works best for you and delivers performance that enables your application to meet its SLAs.
Allocating an optimal amount of heap doesn’t solve all problems.
That’s a little trickier than coming up with a number for your heap allocation to the RegionServers.
The HBase RegionServers don’t perform well with the default Java GC configuration and need careful tuning on many occasions if you want to serve much load off.
Needed only if you’re using start and stop scripts in $HBASE_HOME/bin.
Automatically configured in CDH; you need to do it manually if using Apache distro.
HBase can manage ZooKeeper for you, but recommended that you manage it in production environments.
This configuration goes into the hbase-env.sh file on all the nodes in the cluster.
A good place to start is setting the HBase Java options to the following:
It’s a good idea to allocate the maximum amount of heap when the process starts up.
This avoids the extra overhead of increasing the heap as the RegionServers want more.
Again, it’s not a magic number that is always correct but a good place to start.
The default new generation size is too small, and the RegionServer will start to GC aggressively as you put load on it.
Setting the new generation to be much bigger puts you at risk of not GCing enough and thereby moving objects into the old/tenured generation as well as causing much larger pauses when the GC happens.
Once the MemStore is flushed, which happens frequently when you insert data into an HBase table, the objects will be dereferenced and need to be GCed.
Letting them move to the old generation causes the heap to become fragmented when objects are cleared out.
This collector pauses the Java process and does the GC.
This mode of working is acceptable for the new generation because it’s small and the process isn’t stopped for a long period (usually a few milliseconds)
The pauses are sometimes also referred to as stop-the-world GC pauses, and they can be lethal if they’re too long.
A stop-the-world GC for the old generation would last seconds and cause timeouts.
Java GC In Java programs, you create new objects mostly by using the new operator.
When these objects are freed up, the Java GC clears up the memory they were occupying by removing the unreferenced objects.
The default configuration with which the GC runs makes certain assumptions about what your program is doing in terms of creating and deleting objects, which isn’t necessarily optimal for all use cases.
The CMS garbage-collects in parallel with other things happening in the JVM and doesn’t pause the process until it fails to do its job and gives a promotion error.
At that point, the process needs to be paused and GC has to be performed.
The CMS incurs a load on the CPU because it’s doing GC in parallel while the process is still running.
Setting the percentage too low causes the CMS to kick in often, and setting it too high causes the CMS to kick in late, leading to more promotion errors.
A good place to start is 70%; you can increase/decrease this value as required once you do benchmarking on your system.
Logging the GC activity can be useful in debugging issues when they happen.
You can enable logging by adding the following to the GC configs:
HBase heap and GC tuning are critical to the performance of the system, and we encourage that you test your setting heavily while planning a production system.
The tuning can vary based on the kind of hardware on which you’re running HBase and the kind of workload you’re looking to run.
For instance, a write-heavy workload needs a slightly larger new generation size than a read-heavy workload.
The configuration parameters for HBase daemons are put in an XML file called hbasesite.xml.
The XML configuration file can also be used by your client application.
You keep it in the classpath of the application; when the HBaseConfiguration object is instantiated, it reads through the XML config file and picks up the relevant bits.
Now that you know where the configuration file is, let’s look at its contents and how the parameters are specified.
A sample configuration XML file is shown in the next listing.
This isn’t a complete file and contains only a single parameter to show you the format.
Configuration <description>The directory shared by region servers and into which HBase persists.
The configuration file is a standard XML file with each <property> tag representing a configuration parameter.
This is the configuration parameter where you put that information.
Standalone and pseudo-distributed modes are only for testing and playing around; they aren’t intended for use in a production environment.
These three configuration parameters in the hbase-site.xml file absolutely have to be set to run HBase in a distributed fashion.
Other configuration parameters are generally used to optimize the cluster’s performance; you’ll probably tackle them while tuning the system based on your use case and SLA definitions.
This isn’t a complete list of all the configurations you can put in hbase-site.xml; these are the configurations you’re likely to want to tweak.
The higher the number, the fewer remote calls the client needs to make to the RegionServer during scans.
A higher number also means more memory consumption at the client side.
This can be set on a per-client basis in the configuration object as well.
This property defines the time interval at which you want it to run.
A larger buffer means fewer RPCs during writes but higher memory consumption.
If any store file of any column family exceeds this size, the region is split.
The MemStore is flushed to disk when it exceeds this size.
A thread that runs periodically checks the size of the MemStore.
In some cases, enabling this feature can help alleviate issues of long GC pauses if the heaps are too large.
Setting a high value for this parameter results in infrequent compactions that take longer when they do occur.
The HFile block size is set at a per-column-family level for each table.
This dictates the granularity at which the HFile is indexed.
A smaller block size results in better random reads but a larger block index, which means more memory consumption.
When you use the HFileOutputFormat in a MapReduce job to write directly into HFiles, the block size must be defined using this property so the MapReduce code doesn’t have access to the table definition and doesn’t know how the column families are configured.
For the most part, you don’t need to change the default ports unless you need to close certain ports, including the default HBase port.
The moment the upperLimit is hit, MemStores are flushed until the lowerLimit is hit.
Setting these values equal to each other means the minimum amount of flushing happens when writes are blocked due to the upperLimit being hit.
This minimizes the pauses during writes but also causes more frequent flushing.
How often the HLog must be flushed to the file system, regardless of the number of edits in it.
This is the session timeout for their sessions with ZooKeeper.
All of HBase’s ZooKeeper files are configured keeping this as the parent path.
HBase uses the HDFS, and the way Hadoop is configured impacts HBase.
Tuning HDFS well can significantly improve the performance you can extract from HBase.
Some of the important configuration parameters are described in table 9.2
Not only the HDFS configurations but also MapReduce framework configurations have an impact on HBase if you’re doing MapReduce jobs over HBase tables.
If your use case doesn’t include running MapReduce jobs against HBase tables, you can safely turn off the MapReduce framework: that is, stop the JobTracker and TaskTracker processes, and give more resources to HBase.
If you’re planning to run MapReduce jobs with HBase tables as the source or sink, tune the number of tasks per node to a lower number than you would on a standard MapReduce cluster.
Cutting down on the heap you allocate to the RegionServer processes will impact the performance you’ll extract from HBase during those MapReduce jobs.
In general, mixing workloads that involve running MapReduce jobs with workloads that have relatively low-latency random reads and writes isn’t recommended.
You won’t be able to extract good performance in either of those.
If you’re running MapReduce against HBase, the random read/write performance will be impacted, and the latencies will go up.
The total throughput you can extract from a single HBase.
Without durable sync, HBase can lose data if RegionServers go down without the data being persisted to disk.
This configuration parameter has to be explicitly set to true to enable syncs on HDFS.
This feature is available in Hadoop 0.20.205 and later versions.
The max xcievers on DataNodes is an important configuration parameter and often not understood well by Hadoop administrators.
It defines the maximum number of sockets/threads per DataNode that HDFS clients can use to read/write data.
Lars George wrote one of the most comprehensive descriptions,b and we recommend reading it to get a good understanding of what’s going on.
For the most part, you’re okay setting this number to 4,096
The default of 256 is low, and you’ll see IOExceptions in the RegionServer logs if you have even slightly heavy I/O.
Also, it’s relatively more difficult to run HBase stably if you mix it with heavy MapReduce on the same cluster.
It’s not impossible, but it requires a little more careful resource allocation (heap to RegionServers, number of tasks per node, heap to tasks, and so on) than if you kept them separate.
In most production systems running HBase and Hadoop, Linux is the underlying OS.
You don’t need to tune much except the ulimits for the number of open files.
HBase is a database and needs to keep files open so you can read from and write to them without incurring the overhead of opening and closing them on each operation.
In a system under any real load, you can quickly hit the limits on the number of open files.
We recommend that you increase this limit, especially if you’re deploying in production.
You don’t have to increase it as a system-wide setting and can only do it for the DataNode and RegionServer processes.
To keep it simple, you can increase it for the user under which you’ll be running these processes.
You’ll need to log out and log back in to your box for these to take effect.
These configuration parameters increase the limit on the number of open files and the number of processes that the hadoopuser and hbaseuser can run.
Another important configuration parameter to tune is the swap behavior.
Swapping on HBase RegionServers is lethal and will degrade performance drastically, if not entirely kill the RegionServer process because of ZooKeeper timeouts.
There’s a fair bit to operating a production HBase deployment, and the next chapter will focus on the details.
Successfully deploying and bringing up the various services is one of the first steps in making a system operational.
Until now, we’ve been talking about deploying the right components, configuring the OS, configuring Hadoop, and configuring HBase.
Now that all that is done, you’ll start the system and get the machine ready to take some writes and reads.
The Apache distribution uses the hbase-daemon.sh script from the $HBASE_HOME/bin/ directory, whereas CDH comes bundled with init scripts.
The relevant services need to be started on each node of the cluster.
You probably already have a scheme for doing that, because you had Hadoop installed prior to HBase.
If you don’t have a method yet, here are some of the options:
Both Hadoop and HBase come bundled with start and stop scripts that can remotely log in to all the machines in the cluster and start the correct processes.
The downside is that they need passwordless SSH, which some IT departments don’t allow because of security concerns.
You may argue that you can enter the password every time the script is logging on to a node to start/stop a process.
Sure, but think of entering the password over and over again for each start/stop action across hundreds of nodes.
Sometimes you don’t even have the password to the accounts—you can only su into it from your own account.
Cluster SSH (http://sourceforge.net/projects/clusterssh) is a useful tool if you’re dealing with a cluster of machines.
It allows you to simultaneously run the same shell commands on a cluster of machines that you’re logged in to in separate windows.
You can start the daemons on all the slave nodes by running the same command simultaneously on all the nodes.
This is neat, but it’s hairy to manage on a large number of machines.
Combine them with Chef/Puppet or your favorite deployment system, and you can put a script onto each host that starts the appropriate services.
Use management software like Cloudera Manager that allows you to manage all the services on the cluster from a single web-based UI.
The basic idea is to start the appropriate daemons on each node.
As we discussed earlier in this chapter, they’re all on separate servers.
Once you’ve started the RegionServer processes on all the slaves and the Master process on the Master nodes, you can see the status of the system using the HBase shell and also the HBase Master web UI.
In this chapter, we covered the various aspects of deploying HBase in a fully distributed environment for your production application.
We talked about the considerations to take into account when choosing hardware for your cluster, including whether to deploy on your own hardware or in the cloud.
We next discussed installing and configuring the various distributions, followed by managing your cluster.
This chapter gets you ready to think about putting HBase in production.
There is a lot more to it in terms of monitoring the system, and that’s what the next chapter is all about.
All this information is useful in enabling you to take your application and HBase into production.
But there is one last piece of the puzzle left to be covered—operations.
As a developer of the application, you wouldn’t be expected to operate the underlying HBase cluster when everything is in production and the machines are churning full speed.
But in the initial part of your project’s HBase adoption, chances are that you’ll be playing an integral role in the operations and helping the ops team get up to speed with all the aspects of operating an HBase cluster in production successfully.
Our goal for this chapter is to touch on the basic operational concepts pertaining to HBase.
Monitoring your cluster your cluster and have your application serve the end users that it was built to serve.
To do this, we’ll start with covering the concepts of monitoring and metrics as they pertain to HBase.
This will consist of the different ways you can monitor your HBase deployment and the metrics you need to monitor.
Monitoring is an important step, and once you have that in place, you’ll be in a good place to start thinking about performance testing your HBase cluster and your application.
There’s no point making all that effort and taking a system to production if it can’t sustain the load of all the users who want to use it!
We’ll then cover common management and operations tasks that you’ll need during the course of operating a cluster.
These include things like starting and stopping services, upgrades, and detecting and fixing inconsistencies.
The last topic in the chapter pertains to backup and replication of HBase clusters.
Some of the recommendations may change with future releases, and we encourage you to look into those if you’re using a later release.
A critical aspect of any production system is the ability of its operators to monitor its state and behavior.
When issues happen, the last thing an operator wants to do is to sift through GBs and TBs of logs to make sense of the state of the system and the root cause of the issue.
Not many people are champions at reading thousands of log lines across multiple servers to make sense of what’s going on.
Many things are happening in a production-quality database like HBase, and each of them can be measured in different ways.
These measurements are exposed by the system and can be captured by external frameworks that are designed to record them and make them available to operators in a consumable fashion.
Collecting and graphing metrics isn’t unique to HBase and can be found in any successful system, large or small scale.
In this section, we’ll talk about how HBase exposes metrics and the frameworks that are available to you to capture these metrics and use them to make sense of how your cluster is performing.
We’ll also talk about the metrics HBase exposes, what they mean, and how you can use them to alert you about issues when they happen.
This will enable you to become familiar with the various aspects of operating HBase and will make the transition to production much smoother.
Plus, it’s fun to see pretty graphs showing requests hitting the system when they do.
It will also help you in the process of building your application because you’ll know more about what’s going on in the underlying system when your application interacts with it.
The metrics framework is another of the many ways that HBase depends on Hadoop.
HBase is tightly integrated with Hadoop and uses Hadoop’s underlying metrics framework to expose its metrics.
It isn’t necessary to delve deeply into how the metrics frameworks are implemented unless you want to get involved in the development of these frameworks.
If that’s your intention, by all means dive right into the code.
If you’re just interested in getting metrics out of HBase that you can use for your application, all you need to know is how to configure the framework and the ways it will expose the metrics, which we’ll talk about next.
The metrics framework works by outputting metrics based on a context implementation that implements the MetricsContext interface.
A couple of implementations come out of the box that you can use: Ganglia context and File context.
In addition to these contexts, HBase also exposes metrics using Java Management Extensions (JMX).3
Typically these are both built into the same framework, but that’s not a requirement.
Collection frameworks collect the metrics being generated by the system that is being monitored and store them efficiently so they can be used later.
These frameworks also do things like rollups on a daily, monthly, or yearly basis.
For the most part, granular metrics that are a year old aren’t as useful as a yearly summary of the same metrics.
Graphing tools use the data captured and stored by collection frameworks and make it easily consumable for the end user in the form of graphs and pretty pictures.
These graphs are what the operator looks at to quickly get insight into the status of the system.
Add to these graphs things like thresholds, and you can easily find out if the system isn’t performing in the expected range of operation.
Monitoring your cluster these, you can take actions to prevent the end application from being impacted when Murphy strikes.4
But not all of them are tightly integrated with how Hadoop and HBase expose metrics.
You’re limited to Ganglia (which has native support from the Hadoop metrics framework) or to frameworks that can collect metrics via JMX.
Ganglia (http://ganglia.sourceforge.net/)5 is a distributed monitoring framework designed to monitor clusters.
The Hadoop and HBase communities have been using it as the de facto solution to monitor clusters.
The context you’ll configure depends on the version of Ganglia you choose to use.
For versions older than 3.1, the GangliaContext should be used.
Once you have Ganglia set up and the HBase daemons started with these configuration properties, the metrics list in Ganglia will show metrics being spewed out by HBase, as shown in figure 10.1
Apart from exposing metrics using the Hadoop metrics framework, HBase also exposes metrics via JMX.
Several open source tools such as Cacti and OpenTSDB can be used to collect metrics via JMX.
HBase can also be configured to output metrics into a flat file.
Every time a metric is to be output, it’s appended to that file.
This can be done with or without timestamps, depending on the context.
File-based metrics aren’t a useful way of recording metrics because they’re hard to consume thereafter.
Although we haven’t come across any production system where metrics are recorded into files for active monitoring purposes, it’s still an option for recording metrics for later analysis:
Let’s look at the metrics that HBase exposes that you can use to get insights into the health and performance of your cluster.
You don’t need to look at the HBase code to understand these, but if you’re curious and want to learn about how they’re.
Figure 10.1 Ganglia, set up to take metrics from HBase.
Notice the list of HBase and JVM metrics in the drop-down Metrics list.
Monitoring your cluster reported and the inner workings of the metrics framework, we encourage you to browse through the code.
The metrics of interest depend on the workload the cluster is sustaining, and we’ll categorize them accordingly.
First we’ll cover the general metrics that are relevant regardless of the workload, and then we’ll look at metrics that are relevant to writes and reads independently.
Metrics related to the system load, network statistics, RPCs, alive regions, JVM heap, and JVM threads are of interest regardless of the kind of workload being run; they can be used to explain the system’s behavior.
The Master UI shows the heap usage and the requests per second being served by the RegionServers (figure 10.2)
HBase metrics are important, but so are the metrics from dependency systems— HDFS, underlying OS, hardware, and the network.
Often the root cause for behavior that is out of the normal range lies in the way the underlying systems are functioning.
Issues there typically result in a cascading effect on the rest of the stack and end up impacting the client.
The client either doesn’t perform properly or fails due to unexpected behavior.
This is even more pronounced in distributed systems that have more components that can fail and more dependencies.
Covering detailed metrics and monitoring for all dependencies is beyond the scope of this book, but plenty of resources exist that you can use to study those.6
The important bits that you absolutely need to monitor are as follows:
System- and network-level information can be seen from Ganglia (figure 10.3) and from several Linux tools such as lsof, top, iostat, netstat, and so on.
These are handy tools to learn if you’re administering HBase.
Hadoop Operations, by Eric Sammer, is a good resource for all things related to operating Hadoop in production.
Figure 10.2 The HBase Master web UI shows the number of requests per second being served by each of the RegionServers, the number of regions that are online on the RegionServers, and the used and max heap.
This is a useful place to start when you’re trying to find out the state of the system.
Often, you can find issues here when RegionServers have fallen over, aren’t balanced in terms of the regions and requests they’re serving, or are misconfigured to use less heap than you had planned to give them.
One interesting metric to keep an eye on is the CPU I/O wait percentage.
This indicates the amount of time the CPU spends waiting for disk I/O and is a good indicator of whether your system is I/O bound.
If it is I/O bound, you need more disks in almost all cases.
Ganglia graphs for CPU I/O wait percentage from a cluster running a heavy write workload are shown in figure 10.4
This metric is useful when the read I/O is high as well.
We’ve talked about some of the generic metrics that are of interest in a running cluster.
To understand the system state during writes, the metrics of interest are the ones that are collected as data is written into the system.
This translates into metrics related to MemStore, flushes, compactions, garbage collection, and HDFS I/O.
During writes, the ideal MemStore metrics graph should look like saw teeth.
That indicates smooth flushing of the MemStore and predictable garbage collection.
Figure 10.3 Ganglia graphs showing a summary of the entire cluster for load, CPU, memory, and network metrics.
Figure 10.4 CPU I/O wait percentage is a useful metric to use to understand whether your system is I/O bound.
These Ganglia graphs show significant I/O load on five out of the six boxes.
More disks on the boxes would speed up the writes by distributing the load.
Figure 10.5 shows the MemStore size metrics from Ganglia during heavy writes.
To understand HDFS write latencies, the fsWriteLatency and fsSyncLatency metrics are useful.
The write-latency metric includes the latency while writing HFiles as well as the WAL.
Write latencies going up typically also causes the compaction queues to increase (figure 10.6)
This is useful information when dealing with unresponsive RegionServer processes during heavy writes.
A common cause for that is long garbage-collection pauses, which typically means garbage collection isn’t tuned properly.
Reads are different than writes, and so are the metrics you should monitor to understand them.
During reads, the metrics of interest relate to the block cache primarily,
This isn’t an ideal graph: it indicates that tuning garbage collection and other HBase configs might help improve performance.
Figure 10.6 The compaction queues going up during heavy writes.
Notice that the queue is higher in some boxes than the others.
This likely indicates that the write load on those RegionServers is higher than on the others.
The block-cache metrics for cache hits, evictions, and cache size are useful in understanding the read performance; you can tune your cache and table properties accordingly.
Tools monitoring HBase may be giving you great-looking graphs, and everything at the system level may be running stably.
But that doesn’t mean your entire application stack is running well.
In a production environment, we recommend that you add to the system-level monitoring that Ganglia and other tools provide and also monitor how HBase looks from your application’s perspective.
This is likely to be a custom implementation based on how your application is using HBase.
The HBase community has not yet come up with templates for doing this, but that may change over time.
The following can be useful while monitoring HBase as seen by the application:
Checks like these enable you to keep track of your application’s view of HBase, and you can correlate that with HBase-level metrics to better understand the application’s behavior.
This is a solution for which you’ll have to work with your system administrators and operations team.
It will benefit you in the long run when operating your application in production.
If this happens, you should configure your ops systems to alert you.
It’s not critical enough that you should be paged in the middle of the night if only one box goes down.
Performance of any database is measured in terms of the response times of the operations that it supports.
This is important to measure in the context of your application so you can set the right expectations for users.
For instance, a user of an application backed by an HBase cluster shouldn’t have to wait for tens of seconds to get a response when they click a button.
Of course, this isn’t a general rule and will depend a lot on the type of interaction the user is engaged in.
To make sure your HBase cluster is performing within the expected SLAs, you must test performance thoroughly and tune the cluster to extract the maximum performance you can get out of it.
This section will cover the various ways you can test the performance of your cluster and then will look at what impacts the performance.
From there, we’ll cover the various knobs that are available to you to tune the system.
There are different ways you can test the performance of your HBase cluster.
The best way is to put it under a real workload that emulates what your application is likely to see in production.
But it’s not always possible to test with real workloads without launching a beta version of the application where a select few users interact with it.
Ideally, you’ll want to do some level of testing before that so you can be confident of the performance to some degree.
You can use a couple of options to achieve that.
Install it! You’ll be able to get much more insight into the system’s behavior with it than without it.
To get its usage details, you can run the tool without any arguments:
Options: miniCluster     Run the test on an HBaseMiniCluster nomapred        Run multiple clients using threads (rather than use mapreduce) rows            Rows each client runs.
Default: One million flushCommits    Used to determine if the test should flush the table.
As you can see from the usage details, you can run all kinds of tests using this tool.
They all run as MapReduce jobs unless you set the number of clients as 1, in which case they run as a single-threaded client.
You can configure the number of rows to be written/read per client and the number of clients.
Run the sequentialWrite or the randomWrite commands first so they create a table and put some data in it.
That table and data can thereafter be used for read tests like randomRead, scan, and sequentialRead.
The tool doesn’t need you to create a table manually; it does that on its own when you run the commands to write data into HBase.
If you care about random reads and writes only, you can run this tool from anywhere outside the cluster as long as the HBase JARs and configs are deployed there.
MapReduce jobs will run from wherever the MapReduce framework is installed, which ideally shouldn’t be collocated with the HBase cluster (as we talked about previously)
The limitation of this testing utility is that you can’t run mixed workloads without.
The test has to be one of the bundled ones, and they have to be run individually as separate runs.
If your workload consists of Scans and Gets and Puts happening at the same time, this tool doesn’t give you the ability to truly test your cluster by mixing it all up.
In chapter 1, we talked about NoSQL systems that were developed at various companies to solve their data-management problems.
This led to flame wars and bake-offs about who was better than whom.
Although it was fun to watch, it also made things unclear when it came to comparing the performance of the different systems.
That’s a hard task to do in general because these systems are designed for different use cases and with different trade-offs.
But we need a standardized way of comparing them, and the industry still lacks that.
Although YCSB is built for comparing systems, you can use it to test the performance of any of the databases it supports, including HBase.
Now you’re ready to run workloads to test your cluster.
We’ll use one of those for this example, but you can create your own workloads based on what you want to test from your cluster.
Before running the workload, you need to create the HBase table YCSB will write to.
You can do all sorts of fancy stuff with YCSB workloads, including configuring multiple clients, configuring multiple threads, and running mixed workloads with different statistical distributions of the data.
You now know a couple of ways to test the performance of your HBase cluster; you’ll likely do this testing before taking the cluster to production.
There may be areas in which you can improve the performance of the cluster.
To understand that, it’s important to be familiar with all the factors that impact HBase’s performance.
HBase is a distributed database and is tightly coupled with Hadoop.
That makes it susceptible to the entire stack under it (figure 10.8) when it comes to performance.
Performance is affected by everything from the underlying hardware that makes up the boxes in the cluster to the network connecting them to the OS (specifically the file system) to the JVM to HDFS.
Performance of your HBase cluster instance, performance is different during a compaction or during MemStore flushes compared to when nothing is going on in the cluster.
Your application’s performance depends on how it interacts with HBase, and your schema design plays an integral role as much as anything else.
When looking at HBase performance, all of these factors matter; and when you tune your cluster, you need to look into all of them.
Going into tuning each of those layers is beyond the scope of this text.
We covered JVM tuning (garbage collection specifically) in chapter 9
We’ll discuss some key aspects of tuning your HBase cluster next.
Tuning an HBase cluster to extract maximum performance involves tuning all dependencies.
There’s not a lot you need to do with things like the hardware and OS if you choose them wisely and install them correctly, based on the best practices outlined by the HBase community and highlighted by us in chapter 9
We recommend working with your system administrators on these to make sure you get them right.
We’ll start with the most basic building block of your HBase cluster—the hardware.
Make sure to choose the hardware based on the recommendations we provided in chapter 9
But to sum it up, get enough disks and RAM, but don’t go overboard shopping for the state of the art.
Scaling out pays off much better in the case of Hadoop and HBase clusters.
Any self-respecting distributed system based on current-generation hardware is network bound.
GbE networks between the nodes and the TOR switches are recommended.
Don’t oversubscribe the network a lot, or you’ll see performance impact during high load.
Linux has been the choice of OS as far as Hadoop and HBase systems go.
There have been successful deployments on both Red Hat-based (Red Hat Enterprise Linux [RHEL], CentOS) and Debian-based (Ubuntu and so on) flavors of Linux.
Local Linux file systems play an important role in the stack and impact the performance of HBase significantly.
Tune the file systems based on our recommendations in chapter 9
There’s not a lot to tune if you have the underlying network, disks, and local file system configured correctly.
The one additional configuration you may consider is short-circuiting local client reads.
This feature is new with Hadoop 1.0 and allows an HDFS client to read blocks directly from the local file system when possible.
This feature is particularly relevant to both read-heavy and mixed workloads.
All you need beyond that is to tune the data xcievers, which we highlighted in chapter 9
Tuning an HBase cluster typically involves tuning multiple different configuration parameters to suit the workload that you plan to put on the cluster.
Do this as you do performance testing on the cluster, and use the configurations mentioned in chapter 9 to get your combination right.
No out-of-the-box recipes are available to configure HBase for certain workloads, but you can attempt to categorize them as one of the following:
Each of these workloads demands a different kind of configuration tuning, and we recommend that you experiment to figure out the best combination for you.
Here are a few guidelines for you to work with when trying to tune your cluster based on the categories mentioned.
For random-read-heavy workloads, effective use of the cache and better indexing will get you higher performance.
Pay attention to the configuration parameters listing in table 10.1
This property defines the maximum percentage of heap that the block cache can use.
For random-read workloads, increase the percentage of heap that the cache uses.
The moment upperLimit is hit, MemStores are flushed until lowerLimit is hit.
Setting these values equal to each other means the minimum amount of flushing happens when writes are blocked because of upperLimit being hit.
This minimizes the pauses during writes but also causes more frequent flushing.
For random-read-heavy workloads, where you increase the amount of heap that the block cache takes up, you need to reduce the percentage taken up by the MemStore using these parameters.
HFile block size This is the parameter you set as a part of the column-family configuration for a given table, like this:
Bloom filters You can enable bloom filters at a column-family level like this:
Enabling bloom filters can reduce the number of HFiles that need to be read to find the KeyValue objects for a given row.
Aggressive caching Column families can be configured so that they cache more aggressively than others.
Enable this, and test to see how much it helps in your use case.
Column families can be configured to not be cached into the block cache at read time like this:
If some of your column families are used for random reads and others aren’t, the ones that aren’t used could be polluting the cache.
Disable them from being cached, and it will improve your cache hits.
HFile block size This is the parameter you set as a part of the column family configuration for a given table like this:
Higher block size gives you more data read per disk seek.
Very high values compromise performance in finding the start key for your scans.
This defines the number of rows that will be fetched when the next method is called on a scanner.
The higher the number, the fewer remote calls the client needs to make to the RegionServer during scans.
A higher number also means more memory consumption at the client side.
This can be set on a per-client basis in the configuration object as well.
Set a higher scanner-caching value so the scanner gets more rows back per RPC request while doing large sequential reads.
Increase it to a slightly higher number than what you expect to read in every scan iteration.
You can also set this on a per-Scan instance basis using the Scan .setCaching(int) method.
This setting defines whether the blocks being scanned should be put into the BlockCache.
Loading all blocks read by a scanner into the BlockCache causes a lot of cache churn.
For large scans, you can disable the caching of blocks by setting this value to false.
Disable caching on table Column families can be configured to not be cached into the block cache at read time like this:
If the table is primarily accessed using large scans, the cache most likely won’t buy you much performance.
Instead you’ll be churning the cache and impacting other tables that are being accessed for smaller random reads.
You can disable the BlockCache so it doesn’t churn the cache on every scan.
Writes always go into the MemStore and are flushed to form new HFiles, which later are compacted.
The way to get good write performance is by not flushing, compacting, or splitting too often because the I/O load goes up during that time, slowing the system.
The configuration parameters in table 10.3 are of interest while tuning for a write-heavy workload.
If any store file of any column family exceeds this size, the region is split.
Increase this number, and see where you get optimal performance for your use case.
This parameter defines the size of the MemStore and is configured in bytes.
The MemStore is flushed to disk when it exceeds this size.
A thread that runs periodically checks the size of the MemStore.
Flushing more data to HDFS and creating larger HFiles reduce the number of compactions required by reducing the number of files created during writes.
The moment upperLimit is hit, MemStores are flushed until lowerLimit is hit.
Setting these values equal to each other means that a minimum amount of flushing happens when writes are blocked because of upperLimit being hit.
This minimizes pauses during writes but also causes more frequent flushing.
You can increase the percentage of heap allocated to the MemStore on every RegionServer.
Don’t go overboard with this because it can cause garbage-collection issues.
Configure upperLimit such that it can accommodate the MemStore per region multiplied by the number of expected regions per RegionServer.
You have to tweak a mix of the parameters described earlier to achieve the optimal combination.
Iterate over various combinations, and run performance tests to see where you get the best results.
Outside of the previously mentioned configuration, the following impact performance in general:
Compression—Enable compression to reduce the I/O load on the cluster.
Compression can be enabled at a column-family level as described in chapter 4
Rowkey design—The performance you extract out of your HBase cluster isn’t limited to how well the cluster is performing.
A big part of it is how you use the cluster.
All the previous chapters were geared toward equipping you with information so you can design your application optimally.
A big part of this is optimal rowkey design based on your access patterns.
If you think you’ve designed the best rowkey possible, look again.
We can’t stress enough the importance of good rowkey design.
Major compactions—Major compaction entails all RegionServers compacting all HFiles they’re serving.
We recommend that this be made a manual process that is carried out at the time the cluster is expected to have minimal load.
Garbage collection tuning Java garbage collection plays an important role when it comes to the write performance of an HBase cluster.
See the recommendations provided in chapter 9, and tune based on them.
MemStore-Local Allocation Buffer is a feature in HBase that helps prevent heap fragmentation when there are heavy writes going on.
In some cases, enabling this feature can help alleviate issues of long garbage-collection pauses if the heaps are too large.
Enabling this feature can give you better write performance and more stable operations.
During the course of running a production system, management tasks need to be performed at different stages.
Even though HBase is a distributed system with various failure-resistance techniques and high availability built into it, it still needs a moderate amount of care on a daily basis.
Things like starting or stopping the cluster, upgrading the OS on the nodes, replacing bad hardware, and backing up data are important tasks and need to be done right to keep the cluster running smoothly.
Sometimes these tasks are in response to events like hardware going bad, and other times they’re purely to stay up to date with the latest and greatest releases.
This section highlights some of the important tasks you may need to perform and teaches how to do them.
HBase is a fast-evolving system, and not all problems are solved.
Until recently, it was operated mostly by people intimately familiar with the internals, including some of the committers.
There wasn’t a lot of focus on making automated management tools that simplify life on the operations side.
Therefore, some things that we’ll cover in this section require more manual intervention than others.
These will likely go into an operations manual that cluster administrators can refer to when required.
Starting and stopping the HBase daemons will probably be more common than you expect, especially in the early stages of setting up the cluster and getting things going.
Configuration changes are the most common reason for this activity.
You can do this different ways, but the underlying principles are the same.
The order in which the HBase daemons are stopped and started matters only to the extent that the dependency systems (HDFS and ZooKeeper) need to be up before HBase is started and should be shut down only after HBase has shut down.
The stock Apache distribution has the following scripts (in the $HBASE_HOME/bin directory) available that you can use:
It has to be run on every box where any HBase daemon needs to be run, which means you need to manually log in to all boxes in the cluster.
Typically, this script is run on the HBase Master node.
It runs the HBase Master on the local node and backup masters on the nodes specified in the backup-masters file in the configuration directory.
The list of RegionServers is compiled by this script from the RegionServers file in the configuration directory.
Similar to the start-hbase.sh script in the way it’s implemented.
Cluster-management frameworks like Puppet and Chef can be used to manage the starting and stopping of daemons from a central location.
Proprietary tools like Cloudera Manager can also be used for this purpose.
Typically, there are security concerns associated with passwordless SSH, and many system administrators try to find alternate solutions.
When you need to shut down daemons on individual servers for any management purpose (upgrading, replacing hardware, and so on), you need to ensure that the rest of the cluster keeps working fine and there is minimal outage as seen by client applications.
This entails moving the regions being served by that RegionServer to some other RegionServer proactively rather than having HBase react to a RegionServer going down.
HBase will recover from a RegionServer going down, but it will wait for the RegionServer to be detected as down and then start reassigning the regions elsewhere.
Meanwhile, the application may possibly experience a slightly degraded availability.
Moving the regions proactively to other RegionServers and then killing the RegionServer makes the process safer.
Like the other scripts we’ve talked about, this script is also located in the $HBASE_HOME/bin directory:
Cluster management hbase stop/start rest        If we should stop/start rest before/after the hbase stop/start restart     If we should restart after graceful stop reload      Move offloaded regions back on to the stopped server debug       Move offloaded regions back on to the stopped server hostname    Hostname of server we are to stop.
The script follows these steps (in order) to gracefully stop a RegionServer:
Move the regions off the RegionServer, and randomly assign them to other servers in the cluster.
This script also needs passwordless SSH from the node you’re running it on to the RegionServer node you’re trying to stop.
If passwordless SSH isn’t an option, you can look at the source code of the script and implement one that works for your environment.
Decommissioning nodes is an important management task, and using the gracefulshutdown mechanism to cleanly shut down the RegionServer is the first part.
As your application gets more successful or more use cases crop up, chances are you’ll need to scale up your HBase cluster.
It could also be that you’re replacing a node for some reason.
The process to add a node to the HBase cluster is the same in both cases.
Presumably, you’re running the HDFS DataNode on the same physical node.
The first part of adding a RegionServer to the cluster is to add the DataNode to HDFS.
Depending on how you’re managing your cluster (using the provided start/stop scripts or using centralized management software), start the DataNode process and wait for it to join the HDFS cluster.
You’ll see the node be added to the list of nodes in the Master UI.
After this, if you want to balance out the regions being served by each node and move some load onto the newly added RegionServer, run the balancer using the following:
The downside of running the balancer is that you’ll likely lose data locality for the regions that are moved.
But this will be taken care of during the next round of major compactions.
Often, it isn’t possible to take downtime on the cluster to do upgrades.
In some cases, the only option is to take downtime.
This generally happens when you’re looking to upgrade between major releases where the RPC protocol doesn’t match the older releases, or other changes aren’t backward compatible.
When this happens, you have no choice but to plan a scheduled downtime and do the upgrade.
One by one, gracefully stop the RegionServers and bring them back up.
Because this graceful stop isn’t meant for decommissioning nodes, the regions that the RegionServer was serving at the time it was brought down should be moved back to it when it comes back up.
The gracefulstop.sh script can be run with the --reload argument to do this.
Once all the RegionServers have been restarted, turn the balancer back on.
If ZooKeeper requires a restart, restart all the nodes in the quorum one by one.
When these steps are finished, your cluster is running with the upgraded HBase version.
These steps assume that you’ve taken care of upgrading the underlying HDFS.
You can use the same steps to do a rolling restart for any other purpose as well.
Throughout the book, you have used the shell to interact with HBase.
Chapter 6 also covered scripting of the shell commands and extending the shell using JRuby.
These are useful tools to have for managing your cluster on an everyday basis.
The shell exposes several commands that come in handy to perform simple operations on the cluster or find out the cluster’s health.
Before we go into that, let’s see the options that the bin/hbase script provides, which you use to start the shell.
The script basically runs the Java class associated with the command you choose to pass it:
We’ll cover the hbck, hlog, and hfile commands in future sections.
To get a list of commands that the shell has to offer, type help in the shell, and here’s what you’ll see:
Type 'help "COMMAND_GROUP"', (e.g., 'help "general"') for help on a command group.
Group name: dml Commands: count, delete, deleteall, get, get_counter, incr, put, scan, truncate.
Dictionaries of configuration used in the creation and alteration of tables are Ruby Hashes.
Usually keys are predefined constants such as NAME, VERSIONS, COMPRESSION, etc.
If you are using binary keys or values and need to enter them in the shell, use double-quote'd hexadecimal representation.
The HBase shell is the (J)Ruby IRB with the above HBase-specific commands added.
We’ll focus on the tools group of commands (shown in bold)
To get a description for any command, you can run help 'command_name' in the shell like this:
You can use the zk_dump command to find out the current state of ZooKeeper:
This tells you the current active HBase Master, the list of RegionServers that form the cluster, the location of the -ROOT- table, and the list of servers that form the ZooKeeper quorum.
ZooKeeper is the starting point of the HBase cluster and the source of truth when it comes to the membership in the cluster.
The information spewed out by zk_dump can come in handy while trying to debug issues about the cluster such as finding out which server is the active Master Server or which RegionServer is hosting -ROOT-
You can use the status command to determine the status of the cluster.
We show all three here, to give you an idea of the information included with each of them:
As you can see, the detailed status command gives out a bunch of information about the RegionServers and the regions they’re serving.
This can come in handy when you’re trying to diagnose problems where you need in-depth information about the regions and the servers that are serving them.
Otherwise, the summary option gives you the number of live and dead servers and the average load at that point.
This is mostly useful as a sanity check to see if nodes are up and not overloaded.
Triggering compactions from the shell isn’t something you’ll need to do often, but the shell does give you the option to do so if you need it.
You can use the shell to trigger compactions, both minor and major, using the compact and major_compact commands, respectively:
If you disable automatic major compactions and make it a manual process, this comes in handy; you can script the major compaction and run it as a cron job at a time that’s suitable (when the load on the cluster is low)
The balancer is responsible for making sure all RegionServers are serving an equivalent number of regions.
The current implementation of the balancer takes into consideration the number of regions per RegionServer and attempts to redistribute them if the distribution isn’t even.
You can run the balancer through the shell like this:
The returned value when you run the balancer is true or false, and this pertains to whether the balancer ran.
You can turn off the balancer by using the balance_switch command.
When you run the command, it returns true or false.
The value it returns represents the state of the balancer before the command is run.
To enable the balancer to run automatically, pass true as the argument to balance_switch.
It was turned on before the command was run, as shown by the value returned.
The shell gives you the ability to split existing tables.
But there are cases like region hot-spotting where you may need to manually split the region that’s being hot-spotted.
Region hot-spotting typically points to another problem, though—bad key design leading to suboptimal load distribution.
The split command can be given a table name, and it will split all the regions in that table; or you can specify a particular region to be split.
If you specify the split key, it splits only around that key:
You can split an entire table or pass a region to split an individual region.
With the second parameter, you can specify an explicit split key for the region.
Tables can also be presplit at the time of table creation.
Using the shell, you can alter properties of existing tables.
For instance, suppose you want to add compression to some column families or increase the number of versions.
For this, you have to disable the table, make the alterations, and re-enable the table, as shown here:
You can check that the table properties changed by using the describe 'tablename' command in the shell.
Truncating tables means deleting all the data but preserving the table structure.
The table still exists in the system, but it’s empty after the truncate command is run on it.
Truncating a table in HBase involves disabling it, dropping it, and re-creating it.
Cluster management truncate command does all of this for you.
On large tables, truncating can take time, because all regions have to be shut down and disabled before they can be deleted:
File systems come with a file-system check utility like fsck that checks for the consistency of a file system.
These are typically run periodically to keep track of the state of the file system or especially to check integrity when the system is behaving abnormally.
HBase comes with a similar tool called hbck (or HBaseFsck) that checks for the consistency and integrity of the HBase cluster.
Hbck recently underwent an overhaul, and the resulting tool was nicknamed uberhbck.
We’ll describe the functionality that this tool has to offer and where you’ll find it useful.10
Hbck is a tool that helps in checking for inconsistencies in HBase clusters.
If this property is violated, the cluster is considered to be in an inconsistent state.
Violation of this property renders the HBase cluster in an inconsistent state.
Hbck performs two primary functions: detect inconsistencies and fix inconsistencies.
Detecting inconsistencies in your cluster can be done proactively using hbck.
You could wait for your application to start spewing exceptions about not finding regions.
We hope you don’t run into issues that make you need to run this.
But as we said earlier, Murphy strikes sometimes, and you have to troubleshoot.
Read the manual! Depending on the release of HBase you’re using, the functionality that hbck provides may differ.
We recommend that you read the documentation for your release and understand what the tool provides in your environment.
You can run the hbck tool to detect inconsistencies as shown here:
When this command runs, it gives you a list of inconsistencies it found.
Occasionally when you run hbck, it catches inconsistencies that are transient.
For instance, during a region split, it looks like more than one region is serving the same rowkey range, which hbck detects as an inconsistency.
But the RegionServers know that the daughter regions should get all the requests and the parent region is on its way out, so this isn’t really an inconsistency.
Run hbck a few times over a few minutes to see if the inconsistency remains and isn’t just an apparent one caught during a transition in the system.
To get more details about the inconsistencies reported, you can run hbck with the -details flag, as shown here:
You can also run hbck on a regular basis in an automated manner to monitor the health of your cluster over time and alert you if hbck is consistently reporting inconsistencies.
Running it every 10–15 minutes or so should be sufficient unless you have a lot of load on your cluster that could cause excessive splitting, compactions, and regions moving around.
In this case, running it more frequently might be worth considering.
If you find inconsistencies in your HBase cluster, you need to fix them as soon as possible to avoid running into further issues and unexpected behavior.
Until recently, there was no automated tool that helped with this.
This changed in the newer hbck versions: hbck can now fix inconsistencies in your cluster.
Other inconsistencies, such as regions with overlapping key ranges, are trickier; we advise you not to have any workload running on HBase while fixing those.
Fixing inconsistencies in HBase tables is like performing surgery—often, advanced surgery.
You don’t want to perform it unless you know what you’re doing and are comfortable.
Before you start operating on a production cluster, try out the tool in dev/testing environments and get comfortable with it, understand the internals and what it’s doing, and talk to the developers on the mailing lists to pick their brains.
The fact that you’re having to fix inconsistencies points at potential bugs in HBase or maybe even a suboptimal application design that is pushing HBase to its limits in ways it isn’t designed to work.
Next, we’ll explain the various types of inconsistencies and how you can use hbck to fix them:
There are three such cases: regions are assigned to multiple RegionServers, regions are incorrectly assigned to a RegionServer but are being served by some other RegionServer; and regions exist in .META.
These kind of inconsistencies can be fixed by running hbck with the -fixAssignments flag.
In the older hbck versions, the -fix flag did this job.
These can be fixed by running hbck with the -fixMeta flag.
The previously mentioned fixes are low risk and typically run together.
To perform them together, run hbck with the -repairHoles flag.
Inconsistencies can be more complicated than those we have covered so far and may require careful fixing:
Missing region metadata on HDFS —Every region has a .regioninfo file stored in HDFS that holds metadata for the region.
Adopting a region that doesn’t have the .regioninfo file present can be done by running hbck with the -fixHdfsOrphans flag.
Overlapping regions—This is by far the trickiest of all inconsistencies to fix.
You can fix this by running hbck with the -fixHdfsOverlaps flag.
If the number of regions overlapping is large and the merge will result in a big region, it could cause heavy compactions and splitting later.
To avoid that, the underlying HFiles in such cases can be sidelined into a separate directory and later bulk-imported.
There is an overlap in the ranges for which the regions are responsible.
To limit the number of merges, use the -maxMerge <n> flag.
If the number of regions to merge is greater than n, they’re sidelined rather than merged.
Often, if you’re willing to run through all these fixes, you can use the -repair flag rather than specify each of the previous flags individually.
You can also limit the repair to particular tables by passing the table name to the repair flag (-repair MyTable)
We encourage you to read the online manual and also try running hbck on a development environment before running it on your production cluster.
HBase provides utilities to examine the HFiles and HLogs (WAL) that are being created at write time.
The HLogs are located in the .logs directory in the HBase root directory on the file system.
You can examine them by using the hlog command of the bin/hbase script, like this:
The output is a list of edits that have been recorded in that particular HLog file.
The script has a similar utility for examining the HFiles.
To print the help for the command, run the command without any arguments:
Pass region name; e.g., '.META.,,1' -s,--stats          Print statistics -v,--verbose        Verbose output; emits file and meta data delimiters.
Here is an example of examining the stats of a particular HFile:
You can see that there is a lot of information about the HFile.
Other options can be used to get different bits of information.
The ability to examine HLogs and HFiles can be handy if you’re trying to understand the behavior of the system when you run into issues.
Table splitting during heavy write loads can result in increased latencies.
Splitting is typically followed by regions moving around to balance the cluster, which adds to the overhead.
Presplitting tables is also desirable for bulk loads, which we cover later in the chapter.
If the key distribution is well known, you can split the table into the desired number of regions at the time of table creation.
A good place to start is the low tens of regions per RegionServer.
If you set that number to the size you want your regions to be, HBase will split them when they get to that size.
But setting that number much higher than the desired region size gives you the ability to manually manage the region size and split it before HBase splits it.
That means more work for the system administrator but finer-grained control over the region sizes.
Managing table splitting manually is an advanced operations concept and should be done only once you’ve tried it on a development cluster and are comfortable with it.
If you oversplit, you’ll end up with lots of small regions.
The HBase shell can be used to presplit regions at the time of table creation.
The way to do that is to have a list of split keys in a file, with one key per line.
To create a table with the listed keys as the split boundary, run the following command in the shell:
You can confirm that from your Master web UI (figure 10.10)
Figure 10.10 The HBase Master UI showing the presplit table that was created by providing the split keys at creation time.
We have an implementation available for you in the provided code under the utils package.
We’ve covered a lot of operations and management tasks in this section and equipped you with enough information to run your HBase cluster.
Successful operations of a system also include the ability to handle failure scenarios of different kinds and to keep running with minimal degradation when disaster strikes.
The next section explores the concept of backups in the context of HBase and where these are important.
Backups tend to be one of the favorite topics of system administrators and the people responsible for operations of a system.
In the world of Hadoop and HBase, the conversation changes a little.
In traditional systems, backups were done to achieve redundancy in order to safeguard against system failures (hardware and/or software)
Failures were considered to be something outside the system, affecting the normal operations of the system.
For instance, if a relational database system goes down because the memory on the host fails, the system is unavailable until you replace the memory.
If the hard disk crashes, chances are you’ll lose part or all of your data (depending on how the hard disks are configured and how many disks are being used)
Hadoop and HBase are built with failure as a first-class concern, and their design is such that they’re resilient to individual nodes failing.
If a DataNode or a RegionServer host falls off the cluster, it’s no problem.
Other hosts will take over the workload (stored data or regions being served), and the system will continue to function normally.
The entire Hadoop stack as it exists today has high availability, which means that there is no single point of failure within the system that can bring it down or make it unavailable.
Individual nodes failing isn’t a problem, but the entire data center hosting your cluster going down will cause the system to go down because Hadoop and HBase don’t span multiple data centers as of today.11 But if your requirement is to safeguard against that kind of failure, you need some sort of a backup strategy in place.
Another reason to have a separate copy of the data available is to do offline processing.
As we recommended in chapter 9, collocating real-time and batch-processing workloads on the same HBase cluster impacts the latencies and the performance of the cluster for both the access patterns (as compared to running them independently)
The high network latency between data centers make it impractical.
The alternative is to run a replica cluster in another data center.
By having a second copy of data in another cluster, you can segregate the online access pattern from the batch-processing access pattern and have both of them perform optimally.
There are various ways of achieving backups or second copies of the data, and each has different properties.
Replication as a feature has been in an experimental state until recently, and only savvy users have used it in production.
Active development and more user demand are getting the feature to a more stable state.
You don’t necessarily have to understand the ins and outs of how replication works, but we recommend that you have a good understanding of it if you plan to use it in production.
One way to copy data from one cluster to another is by replicating the writes as they come into the first cluster.
This is a common operating mechanism for relational database systems.
Inter-cluster replication in HBase is achieved by log shipping and is done asynchronously.
That means the replication is done by sending the edits (Puts and Deletes) that go into the HLog at the time of writes to the secondary cluster to which they have to be replicated.
The write to the first cluster doesn’t block on the edits being replicated.
The replication happens asynchronously after the writes are done and therefore can be done across data centers because it doesn’t affect the latencies of the writes when they take place.
This configures the column family colfam1 to replicate to the secondary cluster when data is written to it.
The same table name and column family must exist on the secondary cluster.
HBase won’t create it if it doesn’t exist, and replication will fail.
Nothing is ever written to the replicated column family in the secondary cluster directly.
Given that this is a relatively new feature that hasn’t seen a lot of production usage until now, there will still be active development and the addition of new features in the near term.
We encourage you to look at the release notes of the release you’re using and not take our description as set in stone.
Backup and replication writes to the replicated slave; you need to ensure this at the application level.
If you by mistake end up writing to the slave cluster, that data won’t be replicated back to the master cluster.
The slave cluster can have other tables and column families that aren’t being replicated from the master cluster.
The replication between any two clusters can be either in master-master mode or master-slave mode.
The mastermaster replication scheme can be considered to be a cyclic replication with only two clusters involved.
Depending on your application, you can choose which replication model will work best.
If it’s only for a backup purpose or for having a second copy over which to do.
Figure 10.11 Master-slave replication configuration, where replication happens only in a single direction.
Figure 10.12 Master-master replication scheme, where replication happens both ways.
Writes to either cluster are replicated to the other cluster.
Master-master and cyclic replication are useful in special cases where you either want a third cluster with the same data or have data coming in from different sources into different tables and the end goal is to have an identical state across both clusters.
Put the following configuration parameter into the hbase-site.xml file of both clusters (the primary and the secondary):
After you add this configuration on all the nodes in both clusters, you need to restart the HBase daemons (RegionServer as well as Master)
Keep in mind that ZooKeeper needs to be self-managed for this to work.
This setting enables the cluster to participate in the replication setup.
Add secondary clusters to the list of clusters where the logs will be shipped from the primary cluster.
You do so using the add_peer command in the HBase shell.
This registers the secondary cluster as the destination where the edits need to be sent for the purpose of replication.
You do so at the column-family level, as explained earlier.
To enable replication on existing tables, disable them, modify the column-family description, and re-enable them.
Ensure that the same table and column families exist on both clusters (the master and the destination slave cluster)
Replication scope must be set to 1 only on the master cluster, though.
Both clusters can have other tables and column families that aren’t replicated.
After setting up replication, you should verify that it’s working as desired before putting any load on the cluster.
The easiest way to test that replication is working is to put a few rows into the table on the master cluster and check whether they exist on the Slave cluster.
Backup and replication much larger, this may not be feasible, as can be the case if you enabled replication on a production cluster.
HBase ships with a MapReduce job called VerifyReplication that you can run to compare the contents of the two tables:
Options: starttime    beginning of the time range without endtime means from starttime to forever stoptime     end of the time range families     comma-separated list of families to copy.
Args: peerid       Id of the peer used for verification, must match the one given for replication tablename    Name of the table to verify.
But if you aren’t running the MapReduce framework, that’s not a choice.
You’ll need to manage with a manual scan of the tables on the two clusters to ensure that things are working fine.
There’s not much you need to do to manage replication after it’s enabled on a cluster.
To stop replication in a running cluster where it’s configured, you can run the stop_replication command in the HBase shell.
A few gotchas in the current implementation make some management tasks tricky.
Replication is handled at the column-family level and is configured in the active HLog file.
Thus if you stop replication and then start it again, and the HLogs haven’t rolled, everything that was written between the time you stopped and restarted replication will also be replicated.
This is a function of the current implementation of replication, and it may change in future releases.
To remove a peer cluster, you can use the remove_peer command with the peer ID:
To see a list of the currently configured peers, you can use the list_peers command:
Inter-cluster replication is an advanced feature and can make it easy to keep multiple copies of data.
The hot-failover mechanism is something you need to build into your application.
This can be done purely in the application logic, or you can use DNS tricks to get the application to talk to the secondary cluster if the primary one goes down.
When the primary cluster is back up and running, you can use the same DNS trick and flip back to the primary cluster.
The issue now is to get the newly written data from the secondary cluster back to the primary one.
This can be accomplished using the CopyTable or Export/Import job, which is what we talk about next.
MapReduce jobs can be configured to use HBase tables as the source and sink, as we covered in chapter 3
This ability can come in handy to do point-in-time backups of tables by scanning through them and outputting the data into flat files or other HBase tables.
This is different from inter-cluster replication, which the last section described.
Inter-cluster replication is a push mechanism: new edits are pushed to the replica cluster as they come in, albeit asynchronously.
Running MapReduce jobs over tables is a pull mechanism: jobs are read from the HBase tables (that is, data is pulled out) and written to a sink of your choice.
There are a couple of ways you can use MapReduce over HBase for backups.
HBase ships with prebundled jobs for this purpose, as we explain in detail in appendix B.
We’ll explain how you can use them for backups here.
The prebundled Export MapReduce job can be used to export data from HBase tables into flat files.
That data can then later be imported into another HBase table on the same or a different cluster using the Import job.
The Export job takes the source table name and the output directory name as inputs.
You can also give it the number of versions, start timestamp, end timestamp, and filters to have finer-grained control over what data it reads from the source table.
Using the start and end timestamps can come in handy in doing incremental reads from the tables.
The data is written out efficiently in Hadoop SequenceFiles in the specified output directory, which can later be imported into another HBase table using the Import job.
A note about time synchronization For replication to work properly, the time on the primary and secondary clusters needs to be in sync.
As we described earlier, this can be achieved using NTP.
Keeping time synchronized across all nodes running HBase is important in ensuring that the system operates reliably.
Note: -D properties will be applied to the conf used.
Here’s an example command to export table mytable to the directory export_out:
It should contain a bunch of output files from the map tasks:
The Import job is the inverse of the Export job.
It reads over the records in the source files, creating Put instances from the persisted Result instances.
It then writes those Puts to the target table through the HTable API.
Import doesn’t provide any fancy filtering or manipulation of the data along the way.
If you want to perform additional manipulation, you’ll need to subclass its Importer implementation and override the map function.
The command to import the table exported in the earlier example into another table named myimporttable is as follows:
Upon job completion, your target table contains the exported data.
Although Import is a simple complement to Export, ImportTsv is more feature-rich.
Most commonly, this is a tab-separated format, but the delimiter is configurable (for loading comma-separated files)
You specify a destination table and provide it with a mapping from columns in your data file(s) to columns in HBase:
Imports the given input directory of TSV data into the specified table.
The special column name HBASE_ROW_KEY is used to designate that this column should be used as the row key for each imported record.
You must specify exactly one column to be the row key, and you must specify a column name for every column that exists in the input data.
It’s intended to be a flexible utility, allowing you even to override the Mapper class, which is used when parsing input files.
You can also have ImportTsv create HFiles instead of executing Puts against the target deployment.
It bypasses the HTable API, making it faster than the regular import.
It does have a runtime requirement of access to the target table.
ImportTsv inspects that table’s region boundaries and uses those split delimiters to decide how many HFiles to create.
Once the HFiles are created, they have to be loaded into the table.
The operation is messy because careful consideration must be given to ensure that the new HFiles match the destination table’s configuration.
Backup and replication source data disappears after you run this command.
With your HFiles staged on the HDFS, run the tool like this:
Let’s create a presplit table and bulk-load a tab-separated file into it:
You’ll use the third column in the file as the rowkey for the HBase table.
Complete the bulk load by moving the newly created HFiles into the presplit table:
You can use the CopyTable MapReduce job to scan through an HBase table and directly write to another table.
The sink of the CopyTable job can be another table on the same cluster or a table on an entirely different cluster.
It also supports scenarios where source and destination HBase deployments differ—that is, with different RegionServer implementations.
Executing CopyTable involves running a MapReduce job on the source deployment and populating the destination deployment.
To keep the same name, just give "cfName" Args: tablename    Name of the table to copy.
Here is an example command for copying table mytable from a cluster to a remote cluster where a table with the same name exists:
HBase stores its data in the directory specified by the hbase.rootdir configuration property.
This directory contains all the region information, all the HFiles for the tables, as well as the WALs for all RegionServers.
But copying over this directory (using distcp) doesn’t make for a great backup solution, especially in a running system.
When an HBase cluster is up and running, several things are going on: MemStore flushes, region splits, compactions, and so on.
All of these cause changes in the underlying stored data, which makes copying the HBase root directory a futile effort.
Another factor that plays in is the fact that in a running system, there is data in the MemStore that hasn’t been flushed.
Even if nothing else is going on, a copy of the HBase root directory doesn’t necessarily completely represent the current state of the system.
But if you stop the HBase daemons cleanly, the MemStore is flushed and the root directory isn’t altered by any process.
At this moment, copying over the entire root directory could be a good point-in-time backup solution.
But incremental backups still present challenges, which make this solution less viable.
Restoring from the backed-up root directory is as simple as starting HBase when it’s pointing to this new root directory.
Production-quality operations of any software system are learned over time.
This chapter covered several aspects of operating HBase in production with the intention of getting you started on the path to understanding the concepts.
New tools and scripts probably will be developed by HBase users and will benefit you.
These basic concepts of HBase operations will enable you to understand when, where, and how to use them to your advantage.
The first aspect of operations is instrumenting and monitoring the system, and that’s where we began this chapter.
We covered the various monitoring systems and mechanisms and then went into the different metrics that are of interest.
There are general metrics that you should monitor regardless of the workload being put on the system, and then there are metrics that are specific to the workload (read or write)
From monitoring, the chapter transitioned into talking about performance testing, measuring performance, and tuning HBase for different kinds of workloads.
Performance testing is key to understanding how the cluster is tuned and what you can do to extract better performance from the cluster.
Tuning HBase involves working with multiple different configuration parameters, and configurations depend on the kind of workload for which you’re planning to use your cluster.
From there we covered a list of common management tasks and how and when to do them.
Some of them are common tasks that you perform more often than others, which are more specific to certain situations.
The chapter concluded with backup and replication strategies, talking about the common approaches to disaster recovery and what your options are currently.
Mastering HBase operations requires an understanding of the internals and experience gained by working with the system.
As much as we’d wish for HBase to be a selftuning and self-managing system, it isn’t there yet.
We hope it gets there soon, and your experience could certainly feed into that goal.
Over the course of the book, you’ve learned a bit of theory about how HBase is designed and how it distributes the load across different servers.
Let’s poke around the system a little and get familiar with how these things work in practice.
First, we’ll look at what ZooKeeper says about your HBase instance.
When running HBase in standalone mode, ZooKeeper runs in the same JVM as the HBase Master.
In chapter 9, you learned about fully distributed deployments, where ZooKeeper runs as a separate service.
For now, let’s examine the commands and see what ZooKeeper has to tell you about your deployment.
A.1 Exploring ZooKeeper Your main interface to interact directly with ZooKeeper is through the HBase shell.
Outputs information that ZooKeeper has about HBase install Shows parent znode.
ZooKeeper holds a list of RegionServers that are part of cluster.
Let’s look at a zk_dump from a fully distributed HBase instance.
We’ve included the output from a running cluster and masked the server names.
The portions in bold are analogous to the things we mentioned:
If you have access to one, run the command on the shell and see what it tells you about the system.
This is useful information when you’re trying to understand the state of the system—what hosts are participating in the cluster, which host is playing what role, and, most important, which host is serving the -ROOT- table.
The HBase client needs all this information to perform reads and writes on your application’s behalf.
Note that your application code isn’t involved in this process; the client library handles all of this for you.
The client automatically handles communicating with ZooKeeper and finding the relevant RegionServer with which to interact.
A.2 Exploring -ROOTLet’s look at our standalone instance we’ve used so far for TwitBase.
It’s the first place a client application looks when it needs to locate data stored in HBase.
In this example, there is only one row in -ROOT-, and it corresponds to the entire .META.
The corresponding entry in -ROOT- has the rowkey defined by the table name and the start key for that region.
Because there is only one region, the start key and end key for that region are empty.
This indicates the entire key range is hosted by that region.
The previous entry in the -ROOT- table also tells you which server the .META.
In this case, because it’s a standalone instance and everything is on localhost, that column contains the value localhost:port.
There is also a column for regioninfo that contains the name of the region, start key, end key, and encoded name.
The encoded name is used internally in the system and isn’t of any consequence to you.) The HBase client library uses all this information to locate the correct region to talk to while performing the operations in your application code.
This is because there are no userdefined tables in this HBase instance.
In your current setup, that’s probably what it looks like.
If you want to play around a bit, you can disable and delete the users table, examine .META., and re-create and repopulate the users table.
Disabling and deletion can be done in the HBase shell just like creating a table.
When the users table outgrows a single region, that region will split.
You can also split the table manually for experimentation right now:
After you split users, new entries are made in the .META.
These daughter regions replace the parent region that was split.
The entry for the parent region contains the information about the splits, and requests are no longer served by the parent region.
For a brief time, the information for the parent region remains in .META.
Once the hosting RegionServer has completed the split and cleaned up the parent region, the entry is deleted from .META..
You may wonder why the start and end keys contain such long, funny values that don’t look anything like the entries you put in.
This is because the values you see are byteencoded versions of the strings you entered.
Let’s tie this back to how the client application interacts with an HBase instance.
To perform any of these operations, the HBase client library that you’re using has to find the correct region(s) that will serve these requests.
It starts with ZooKeeper, from which it finds the location of -ROOT-
It contacts the server serving -ROOT- and reads the relevant records from the table that point to the .META.
Once the client library gets the server location and the name of the region, it contacts the RegionServer with the region information and asks it to serve the requests.
These are the various steps at play that allow HBase to distribute data across a cluster of machines and find the relevant portion of the system that serves the requests for any given client.
Hadoop Distributed File System (HDFS) is the underlying distributed file system that is the most common choice for running HBase.
Many HBase features depend on the semantics of the HDFS to function properly.
For this reason, it’s important to understand a little about how the HDFS works.
In order to understand the inner working of HDFS, you first need to understand what a distributed file system is.
Ordinarily, the concepts at play in the inner workings of a distributed file system can consume an entire semester’s work for a graduate class.
But in the context of this appendix, we’ll briefly introduce the concept and then discuss the details you need to know about HDFS.
B.1 Distributed file systems Traditionally, an individual computer could handle the amount of data that people wanted to store and process in the context of a given application.
The computer might have multiple disks, and that sufficed for the most part—until the recent explosion of data.
With more data to store and process than a single computer could handle, we somehow needed to combine the power of multiple computers to solve these new storage and compute problems.
Such systems in which a network of computers (also sometimes referred to as a cluster) work together as a single system to solve a certain problem are called distributed systems.
As the name suggests, the work is distributed across the participating computers.
In other words, they’re storage systems that span multiple computers.
If you’re curious to know more about the placement strategy of HDFS, the best way to learn is to dive into the HDFS code.
Distributed file systems provide the scale required to store and process the vast amount of data that is being generated on the web and elsewhere.
Providing such scale is challenging because the number of moving parts causes more susceptibility to failure.
In large distributed systems, failure is a norm, and that must be taken into account while designing the systems.
In the sections that follow, we’ll examine the challenges of designing a distributed file system and how HDFS addresses them.
Specifically, you’ll learn how HDFS achieves scale by separating metadata and the contents of files.
Then, we’ll explain the consistency model of HDFS by going into details of the HDFS read and write paths, followed by a discussion of how HDFS handles various failure scenarios.
We’ll then wrap up by examining how files are split and stored across multiple nodes that make up HDFS.
B.2 Separating metadata and data: NameNode and DataNode Every file that you want to store on a file system has metadata attached to it.
For instance, the logs coming in from your web servers are all individual files.
The metadata includes things like filename, inode number, block location, and so on; the data is the actual content of the file.
In traditional file systems, metadata and data are stored together on the same machine because the file systems never span beyond that.
When a client wants to perform any operation on the file and it needs the metadata, it interacts with that single machine and gives it the instructions to perform the operation.
To access this file, the client application only needs to talk to the particular disk (through the operating system, of course) to get the metadata as well as the contents of the file.
The only way this model can work with data that’s more than a single system can handle is to make the client aware of how you distribute the data among the different disks, which makes the client stateful and difficult to maintain.
Stateful clients are even more complicated to manage as the number grows, because they have to share the state information with each other.
For instance, one client may write a file on one machine.
The other client needs the file location in order to access the file later, and has to get the information from the first client.
As you can see, this can quickly become unwieldy in large systems and is hard to scale.
The easiest way to do this is to have the file system itself manage the metadata.
But storing both metadata and data together at a single location doesn’t work either, as we discussed earlier.
One way to solve this is to dedicate one or more machines to hold the metadata and have the rest of the machines store the file contents.
The data, on the other hand, is stored on a cluster of DataNodes.
The NameNode not only manages the metadata for the content stored in HDFS but also keeps account of things like which nodes are part of the cluster and how many copies of a particular file exist.
It also decides what needs to be done when nodes fall out of the cluster and replicas are lost.
This is the first time we’ve mentioned the word replica.
We’ll talk about it in detail later—for now, all you need to know is that every piece of data stored in HDFS has multiple copies residing on different servers.
Suppose you have a large distributed file system at your disposal, and you want to store that file on it.
It’s hard to justify the cost of all those machines otherwise, isn’t it? To store data in HDFS, you have various options.
The underlying operations that happen when you write data are the same regardless of what interface you use to write the data (Java API, Hadoop command-line client, and so on)
But it’s not required for this section, and you don’t need to do so to understand the concepts.
Let’s say you’re using the Hadoop command-line client and you want to copy a file Web01.log to HDFS.
It’s important that you understand what happens when you write this command.
We’ll go over the write process step by step while referring to figures B.1–B.4
Just to remind you, the client is simple and doesn’t know anything about the internals of HDFS and how the data is distributed.
The client does, however, know from the configuration files which node is the NameNode.
As you know, the NameNode is responsible for managing the metadata about everything stored in HDFS.
The NameNode acknowledges the client’s request and internally makes a note about the filename and a set of DataNodes that will store the file.
It stores this information in a file-allocation table in its memory.
It then sends this information back to the client (figure B.2)
The client is now aware of the DataNodes to which it has to send the contents of Web01.log.
The next step for it is to send the contents over to the DataNodes (figure B.3)
The primary DataNode streams the contents of the file synchronously to other DataNodes that will hold the replicas of this particular file.
Figure B.2 Write operation: NameNode acknowledges the write operation and sends back a DataNode list.
We’ll cover the topic of replication in detail later in the appendix.
The primary DataNode sends a confirmation to the client that the file has been written to HDFS (figure B.4)
At the end of this process, the file is considered written to HDFS and the write operation is complete.
Note that the file is still in the DataNodes’ main memory and hasn’t yet been persisted to disk.
This is done for performance reasons: committing all replicas to disk would increase the time taken to complete a write operation.
Once the data goes into the main memory, the DataNode persists it to disk as soon as it can.
In distributed file systems, one of the challenges is consistency.
In other words, how do you make sure the view of the data residing on the system is consistent across all nodes? Because all nodes store data independently and don’t typically communicate with each other, there has to be a way to make sure all nodes contain the same data.
For example, when a client wants to read file Web01.log, it should be able to read exactly the same data from all the DataNodes.
Looking back at the write path, notice that the data isn’t considered written unless all DataNodes that will hold that data have acknowledged that they have a copy of it.
This means all the DataNodes that are supposed to hold replicas of a given set of data have exactly the same contents before the write completes—in other words, consistency is accomplished during the write phase.
A client attempting to read the data will get the same bytes back from whichever DataNode it chooses to read from.
B.4 HDFS read path Now you know how a file is written into HDFS.
It would be strange to have a system in which you could write all you want but not read anything back.
Reading a file from HDFS is as easy as writing a file.
Let’s see how the file you wrote earlier is read back when you want to see its contents.
Once again, the underlying process that takes place while reading a file is independent of the interface used.
If you’re using the command-line client, you write the following command to copy the file to your local file system so you can use your favorite editor to open it:
Let’s look at what happens when you run this command.
The client asks the NameNode where it should read the file from (figure B.5)
The NameNode sends back block information to the client (figure B.6)
The block information contains the IP addresses of the DataNodes that have copies.
These IDs are unique for all blocks, and this is the only information the DataNodes need in order to identify the block on their local storage.
The client examines this information, approaches the relevant DataNodes, and asks for the blocks (figure B.7)
The DataNodes serve the contents back to the client (figure B.8), and the connection is closed.
This is the first time we’ve mentioned the word block in the context of files in HDFS.
In order to understand the read process, consider that a file is made up of blocks that are stored on the DataNodes.
We’ll dig deeper into this concept later in the appendix.
Note that the client gets separate blocks for a file in parallel from different DataNodes.
The client joins these blocks to make the full file.
The logic for this is in the client library, and the user who’s writing the code doesn’t have to do anything manually.
B.5 Resilience to hardware failures via replication In large distributed systems, disk and network failures are commonplace.
In case of a failure, the system is expected to function normally without losing data.
Let’s examine the importance of replication and how HDFS handles failure scenarios.
You may be thinking that we should have covered this earlier—hang on for a bit and it will make sense.)
When everything is working fine, DataNodes periodically send heartbeat messages to the NameNode (by default, every three seconds)
If the NameNode doesn’t receive a heartbeat for a predefined time period (by default, 10 minutes), it considers the DataNode to have failed, removes it from the cluster, and starts a process to recover.
Figure B.7 Read operation: client contacts the relevant DataNodes and asks for the contents of the blocks.
Figure B.8 Read operation: DataNodes serve the block contents to the client.
DataNodes can fall out of the cluster for various reasons—disk failures, motherboard failures, power outages, and network failures.
The way HDFS recovers from each of these is the same.
For HDFS, losing a DataNode means losing replicas of the blocks stored on that disk.
Given that there is always more than one replica at any point in time (the default is three), failures don’t lead to data loss.
When a disk fails, HDFS detects that the blocks that were stored on that disk are under-replicated and proactively creates the number of replicas required to reach a fully replicated state.
There could be a situation in which multiple disks failed together and all replicas of a block were lost, in which case HDFS would lose data.
For instance, it’s theoretically possible to lose all the nodes that are holding replicas of a given file because there is a network partition.
It’s also possible for a power outage to take down entire racks.
But such situations are rare; and when systems are designed that have to store mission-critical data that absolutely can’t be lost, measures are taken to safeguard against such failures—for instances, multiple clusters in different data centers for backups.
From the context of HBase as a system, this means HBase doesn’t have to worry about replicating the data that is written to it.
This is an important factor and affects the consistency that HBase offers to its clients.
B.6 Splitting files across multiple DataNodes Earlier, we examined the HDFS write path.
We said that files are replicated three ways before a write is committed, but there’s a little more to that.
Files in HDFS are broken into blocks, typically 64–128 MB each, and each block is written onto the file system.
Different blocks belonging to the same file don’t necessarily reside on the same DataNode.
In fact, it’s beneficial for different blocks to reside on different DataNodes.
When you have a distributed file system that can store large amounts of data, you may want to put large files on it—for example, outputs of large simulations of subatomic particles, like those done by research labs.
Sometimes, such files can be larger than the size of a single hard drive.
Storing them on a distributed system by breaking them into blocks and spreading them across multiple nodes solves that problem.
There are other benefits of distributing blocks to multiple DataNodes.
When you perform computations on these files, you can benefit from reading and processing different parts of the files in parallel.
You may wonder how the files are split into blocks and who determines which DataNodes the various blocks should go to.
When the client is writing to HDFS and talks to the NameNode about where it should write the files, the NameNode tells it the DataNodes where it should write the blocks.
After every few blocks, the client goes back to the NameNode to get a fresh list of DataNodes to which the next few blocks should be written.
Believe it or not, at this point, you know enough about HDFS to understand how it functions.
You may not win an architectural argument with a distributed systems expert, but you’ll be able to understand what they’re talking about.
It runs on commodity hardware and scales smoothly from modest datasets to.
HBase in Action is an experience-driven guide that shows you how to design, build, and run applications using HBase.
First, it introduces you to the fundamentals of handling big data.
Th en, you’ll explore HBase with the help of real applications and code samples and with just enough theory to back up the practical techniques.
You’ll take advantage of the MapReduce processing framework and benefi t from seeing HBase best practices in action.
Written for developers and architects familiar with data storage and processing.
No prior knowledge of HBase, Hadoop, or MapReduce is required.
Nick Dimiduk is a Data Architect with experience in social media analytics, digital marketing, and GIS.
A diffi  cult topic lucidly explained.”—John Griffi  n, coauthor of Hibernate Search in Action.
HBase in Action brief contents contents foreword letter to the HBase community preface acknowledgments about this book Roadmap Intended audience Code conventions Code downloads Author Online.
