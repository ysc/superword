Offers clear explanations of concepts with very good examples in an easy-to-read format.
The one book you need on your desk when working with Spring.
Using Spring is not difficult—but with this book it becomes much easier.
The right dose of humor with a load of technical wisdom is the perfect mix for learning Spring.
The publisher offers discounts on this book when ordered in quantity.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the publisher.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in the book, and Manning Publications was aware of a trademark claim, the designations have been printed in initial caps or all caps.
Recognizing the importance of preserving what has been written, it is Manning’s policy to have the books we publish printed on acid-free paper, and we exert our best efforts to that end.
Recognizing also our responsibility to conserve the resources of our planet, Manning books are printed on paper that is at least 15 percent recycled and processed without the use of elemental chlorine.
More than a dozen years ago, Spring entered the Java development scene with the ambitious goal of simplifying enterprise Java development.
It challenged the heavyweight programming models of the time with a simpler and lighter programming model based on plain old Java objects.
Now, several years and many releases later, we see that Spring has had a tremendous impact on enterprise application development.
It has become a de facto standard framework for countless Java projects and has had an impact on the evolution of some of the specifications and frameworks that it originally set out to replace.
It’d be hard to deny that the current Enterprise JavaBeans (EJB) specification may have turned out very differently had Spring not challenged earlier versions of the EJB spec.
But Spring itself continues to evolve and improve upon itself, always seeking to make the difficult development tasks simpler and empower Java developers with innovative features.
Where Spring had first set out to challenge the status quo, Spring now has leapt ahead and is paving trails in Java application development.
Therefore, it’s time for an updated edition of this book to expose the current state of Spring.
There’s so much that has happened in the past few years since the previous edition of this book; it’d be impossible to cover everything in a single edition.
Nevertheless, I still tried to pack this fourth edition of Spring in Action with as much as I could.
Here are just a few of the exciting new things that have been added in this edition:
An emphasis on Java-based Spring configuration with Java configuration options available for almost every area of Spring development.
Conditional configuration and profiles that make runtime decisions regarding what Spring configuration should be used or ignored.
Several enhancements and improvements to Spring MVC, especially with regard to creating REST services.
If you’re a seasoned Spring veteran, you’ll find that these new elements will become valuable additions to your Spring toolkit.
On the other hand, if you’re new to Spring, you’ve picked a good time to learn Spring, and this book will help you get started.
This is, indeed, an exciting time to be working with Spring.
It’s been a blast to develop with Spring and write about it during the past 12 years.
Even if you have an eBook copy that didn’t go through that process, there were numerous hands on the bits and bytes that you downloaded— hands that edited it, reviewed it, typeset it, and proofread it.
If it weren’t for all of those hands, this book wouldn’t exist.
First, a big thank you to everyone at Manning for working hard, for their patience when the writing wasn’t moving as fast as it should have, and for prodding me along to get it done: Marjan Bace, Michael Stephens, Cynthia Kane, Andy Carroll, Benjamin Berg, Alyson Brener, Dottie Marisco, Mary Piergies, Janet Vail, and many others behind the scenes.
Getting feedback early and often is just as critical when writing a book as it is when developing software.
While the pages of this book were still in a very rough form, there were several great reviewers who took the time to read the drafts and provide feedback that helped shape the final product.
And special thanks to John Ryan for his thorough technical review of the manuscript shortly before it went into production.
Of course, I want to thank my beautiful wife for enduring yet another writing project and for her encouragement along the way.
I love you more than you could possibly ever know.
To Maisy and Madi, the most awesome little girls in the world, thank you again for your hugs, laughs, and unusual insights into what should go into the book.
I never cease to be amazed at the never-ending awesomeness that you crank out.
And many thanks to everyone I encounter as I travel the country speaking at user groups and No Fluff/Just Stuff conferences.
Along the same lines, Spring in Action, Fourth Edition was written to make learning how to use Spring easier.
My goal is not to give you a blow-by-blow listing of Spring APIs.
Instead, I hope to present the Spring Framework in a way that is most relevant to a Java EE developer by providing practical code examples from real-world experiences.
Since Spring is a modular framework, this book was written in the same way.
I recognize that not all developers have the same needs.
Some may want to learn the Spring Framework from the ground up, while others may want to pick and choose different topics and go at their own pace.
That way, the book can act as a tool for learning Spring for the first time as well as a guide and reference for those wanting to dig deeper into specific features.
Spring in Action, Fourth Edition is for all Java developers, but enterprise Java developers will find it particularly useful.
While I will guide you along gently through code examples that build in complexity throughout each chapter, the true power of Spring lies in its ability to make enterprise applications easier to develop.
Therefore, enterprise developers will most fully appreciate the examples presented in this book.
Because a vast portion of Spring is devoted to providing enterprise services, many parallels can be drawn between Spring and EJB.
The first part introduces you to the essentials of the Spring Framework.
Part 2 expands on that by showing how to build web applications with Spring.
Part 3 steps behind the front end and shows where.
The final part shows how Spring can be used to integrate with other applications and services.
This will give you a foundation upon which the rest of the book will build.
In chapter 1, you’ll be given an overview of Spring, including some basic examples of DI and AOP.
You’ll also get an overview of the greater Spring ecosystem.
With the basics of bean wiring down, chapter 3 presents several advanced wiring techniques.
You won’t need these techniques that often, but when you do need them this chapter will show you how to get the most power out of the Spring container.
Chapter 4 explores how to use Spring AOP to decouple cross-cutting concerns from the objects that they service.
This chapter also sets the stage for later chapters where you’ll use AOP to provide declarative services such as transactions, security, and caching.
You’ll see how to write controllers to handle web requests and respond with model data.
Once a controller is finished with its work, the model data must be rendered using a view.
Chapter 6 will explore various view technologies that can be used with Spring, including JSP, Apache Tiles, and Thymeleaf.
In this chapter, you’ll learn how to customize Spring MVC configuration, handle multipart file uploads, deal with exceptions that may occur in a controller, and pass data between requests with flash attributes.
Chapter 8 explores Spring Web Flow, an extension to Spring MVC that enables development of conversational web applications.
In this chapter, you’ll learn how to build web applications that lead the user through a specific, guided flow.
In chapter 9 you’ll learn how to apply security to the web layer of your application using Spring Security.
Part 3 goes behind the front end of an application and looks at how data is processed and persisted.
Data persistence is first tackled in chapter 10 using Spring’s abstraction over JDBC to work with data stored in a relational database.
Chapter 11 takes on data persistence from another angle, using the Java Persistence API (JPA) to store data in a relational database.
Regardless of where the data is stored, caching can help improve performance by not hitting the database any more than necessary.
Asynchronous messaging takes a different twist in chapter 18 where you’ll see how to use Spring with WebSocket and STOMP for asynchronous communication between the server and a client.
Extensions (JMX), enabling you to monitor and modify runtime settings for a Spring application.
Finally, in chapter 21 you’ll be introduced to a game-changing and very new way to work with Spring called Spring Boot.
You’ll see how Spring Boot can take away much of the boilerplate configuration required in a Spring application, enabling you to focus on the business functionality.
Code conventions and downloads There are many code examples throughout this book.
These examples will always appear in a fixed-width code font like this.
Any class name, method name, or XML fragment within the normal text of the book will appear in code font as well.
Not all code examples in this book will be complete.
Often I only show a method or two from a class to focus on a particular topic.
Author Online Purchase of Spring in Action, Fourth Edition includes free access to a private web forum run by Manning Publications where you can make comments about the book, ask technical questions, and receive help from the author and from other users.
This page provides information on how to get on the forum once you are registered, what kind of help is available, and the rules of conduct on the forum.
Manning’s commitment to our readers is to provide a venue where a meaningful dialogue between individual readers and between readers and the author can take place.
It is not a commitment to any specific amount of participation on the part of the author, whose contribution to the book’s forum remains voluntary (and unpaid)
We suggest you try asking the author some challenging questions, lest his interest stray!
The Author Online forum and the archives of previous discussions will be accessible from the publisher’s website as long as the book is in print.
About the author Craig Walls is a senior engineer with Pivotal as the project lead for Spring Social and Spring Sync, and is the author of Manning’s Spring in Action books, now updated in this Fourth Edition.
He’s a zealous promoter of the Spring Framework, speaking frequently at local user groups and conferences and writing about Spring.
When he’s not slinging code, Craig spends as much time as he can with his wife, two daughters, two birds, and two dogs.
Dress codes have changed since then and the diversity by region, so rich at the time, has faded away.
It is now often hard to tell the inhabitants of one continent from another.
Perhaps, trying to view it optimistically, we have traded a cultural and visual diversity for a more varied personal life—or a more varied and interesting intellectual and technical life.
We at Manning celebrate the inventiveness, the initiative, and the fun of the computer business with book covers based on the rich diversity of regional life two centuries ago brought back to life by the pictures from this travel guide.
But underneath all of the fantastic functionality it adds to enterprise development, its primary features are dependency injection (DI) and aspect-oriented programming (AOP)
We’ll look at automatic configuration, Javabased configuration, and XML configuration options offered by Spring.
In its almost 20 year history, Java has seen some good times and some bad.
Despite a handful of rough spots, such as applets, Enterprise JavaBeans (EJB), Java Data Objects (JDO), and countless logging frameworks, Java has enjoyed a rich and diverse history as the platform on which much enterprise software has been built.
And Spring has been a big part of that story.
In its early days, Spring was created as an alternative to heavier enterprise Java technologies, especially EJB.
Spring offered a lighter and leaner programming model as compared to EJB.
It empowered plain old Java objects (POJOs) with powers previously only available using EJB and other enterprise Java specifications.
Now EJB employs ideas such as dependency injection (DI) and aspect-oriented programming (AOP), arguably inspired by the success of Spring.
Although J2EE (now known as JEE) was able to catch up with Spring, Spring never stopped moving forward.
Spring has continued to progress in areas where, even now, JEE is just starting to explore or isn’t innovating at all.
Mobile development, social API integration, NoSQL databases, cloud computing, and big data are just a few areas where Spring has been and is innovating.
As I said, it’s a good time to be a Java developer.
This chapter will give you a good idea of the types of problems Spring solves, and it will set the stage for the rest of the book.
Spring was created to address the complexity of enterprise application development and makes it possible to use plain-vanilla JavaBeans to achieve things that were previously only possible with EJB.
Any Java application can benefit from Spring in terms of simplicity, testability, and loose coupling.
A bean by any other name… Although Spring uses the words bean and JavaBean liberally when referring to application components, this doesn’t mean a Spring component must follow the JavaBeans specification to the letter.
In this book, I assume a loose definition of JavaBean, which is synonymous with POJO.
As you’ll see throughout this book, Spring does many things.
But at the root of almost everything Spring provides are a few foundational ideas, all focused on Spring’s fundamental mission: Spring simplifies Java development.
That’s a bold statement! A lot of frameworks claim to simplify something or other.
But Spring aims to simplify the broad subject of Java development.
To back up its attack on Java complexity, Spring employs four key strategies:
Almost everything Spring does can be traced back to one or more of these four strategies.
Throughout the rest of this chapter, I’ll expand on each of these ideas, showing concrete examples of how Spring makes good on its promise to simplify Java development.
Let’s start with seeing how Spring remains minimally invasive by encouraging POJO-oriented development.
If you’ve been doing Java development for long, you’ve probably seen (and may have even worked with) frameworks that lock you in by forcing you to extend one of their classes or implement one of their interfaces.
The easy-target example of such an invasive programming model was EJB 2-era stateless session beans.
But even though early EJBs were such an easy target, invasive programming could easily be found in earlier versions of Struts, WebWork, Tapestry, and countless other Java specifications and frameworks.
Spring avoids (as much as possible) littering your application code with its API.
Spring almost never forces you to implement a Spring-specific interface or extend a Spring-specific class.
Instead, the classes in a Spring-based application often have no indication that they’re being used by Spring.
At worst, a class may be annotated with one of Spring’s annotations, but it’s otherwise a POJO.
To illustrate, consider the HelloWorldBean class shown in the following listing.
As you can see, this is a simple, garden-variety Java class—a POJO.
Nothing special about it indicates that it’s a Spring component.
Spring’s non-invasive programming model means this class could function equally well in a Spring application as it could in a non-Spring application.
One of the ways Spring empowers POJOs is by assembling them using DI.
Let’s see how DI can help keep application objects decoupled from each other.
The phrase dependency injection may sound intimidating, conjuring up notions of a complex programming technique or design pattern.
But as it turns out, DI isn’t nearly as complex as it sounds.
By applying DI in your projects, you’ll find that your code will become significantly simpler, easier to understand, and easier to test.
Traditionally, each object is responsible for obtaining its own references to the objects it collaborates with (its dependencies)
Listing 1.1 Spring doesn’t make any unreasonable demands on HelloWorldBean.
In such a test, you’d like to be able to assert that the quest’s embark() method is called when the knight’s embarkOnQuest() method is called.
On the one hand, tightly coupled code is difficult to test, difficult to reuse, and difficult to understand, and it typically exhibits “whack-amole” bug behavior (fixing one bug results in the creation of one or more new bugs)
In order to do anything useful, classes need to know about each other somehow.
With DI, objects are given their dependencies at creation time by some third party that coordinates each object in the system.
As illustrated in figure 1.1, dependencies are injected into the objects that need them.
To illustrate this point, let’s look at BraveKnight in the next listing: a knight who’s not only brave, but also capable of embarking on any kind of quest that comes along.
Figure 1.1 Dependency injection involves giving an object its dependencies as opposed to an object having to acquire those dependencies on its own.
Instead, he’s given a quest at construction time as a constructor argument.
This is a type of DI known as constructor injection.
What’s more, the quest he’s given is typed as Quest, an interface that all quests implement.
The point is that BraveKnight isn’t coupled to any specific implementation of Quest.
It doesn’t matter to him what kind of quest he’s asked to embark on, as long as it implements the Quest interface.
If an object only knows about its dependencies by their interface (not by their implementation or how they’re instantiated), then the dependency can be swapped out with a different implementation without the depending object knowing the difference.
One of the most common ways a dependency is swapped out is with a mock implementation during testing.
Listing 1.3 A BraveKnight is flexible enough to take on any Quest he’s given.
Listing 1.4 To test BraveKnight, inject it with a mock Quest.
Here you use a mock object framework known as Mockito to create a mock implementation of the Quest interface.
With the mock object in hand, you create a new instance of BraveKnight, injecting the mock Quest via the constructor.
After calling the embarkOnQuest() method, you ask Mockito to verify that the mock Quest’s embark() method was called exactly once.
Perhaps SlayDragonQuest, shown in the following listing, would be appropriate.
As you can see, SlayDragonQuest implements the Quest interface, making it a good fit for BraveKnight.
You may also notice that rather than lean on System.out .println() like many small getting-started Java samples, SlayDragonQuest more generically asks for a PrintStream through its constructor.
The act of creating associations between application components is commonly referred to as wiring.
In Spring, there are many ways to wire components together, but a common approach has always been via XML.
The next listing shows a simple Spring configuration file, knights.xml, that wires a BraveKnight, a SlayDragonQuest, and a PrintStream together.
Listing 1.5 SlayDragonQuest is a Quest to be injected into BraveKnight.
Here, BraveKnight and SlayDragonQuest are declared as beans in Spring.
In the case of the BraveKnight bean, it’s constructed, passing a reference to the SlayDragonQuest bean as a constructor argument.
Meanwhile, the SlayDragonQuest bean declaration uses the Spring Expression Language to pass System.out (which is a PrintStream) to SlayDragonQuest’s constructor.
If XML configuration doesn’t suit your tastes, you might like to know that Spring also allows you to express configuration using Java.
For example, here you see a Javabased equivalent to listing 1.6
Whether you use XML-based or Java-based configuration, the benefits of DI are the same.
Although BraveKnight depends on a Quest, it doesn’t know what type of Quest it will be given or where that Quest will come from.
Listing 1.7 Spring offers Java-based configuration as an alternative to XML.
Only Spring, through its configuration, knows how all the pieces come together.
This makes it possible to change those dependencies with no changes to the depending classes.
This example has shown a simple approach to wiring beans in Spring.
Don’t concern yourself too much with the details right now.
We’ll dig more into Spring configuration when we get to chapter 2
We’ll also look at other ways that beans can be wired in Spring, including a way to let Spring automatically discover beans and create the relationships between them.
Now that you’ve declared the relationship between BraveKnight and a Quest, you need to load the XML configuration file and kick off the application.
The Spring application context is fully responsible for the creation of and wiring of the objects that make up the application.
Spring comes with several implementations of its application context, each primarily differing only in how it loads its configuration.
Listing 1.8 KnightMain.java loads the Spring context containing a Knight.
Here the main() method creates the Spring application context based on the knights.xml file.
Then it uses the application context as a factory to retrieve the bean whose ID is knight.
With a reference to the Knight object, it calls the embarkOnQuest() method to have the knight embark on the quest he was given.
Note that this class knows nothing about which type of Quest your hero has.
For that matter, it’s blissfully unaware of the fact that it’s dealing with BraveKnight.
Only the knights.xml file knows for sure what the implementations are.
And with that you have a quick introduction to dependency injection.
But if you want even more DI, I encourage you to look at Dhanji R.
Now let’s look at another of Spring’s Java-simplifying strategies: declarative programming through aspects.
Although DI makes it possible to tie software components together loosely, aspectoriented programming (AOP) enables you to capture functionality that’s used throughout your application in reusable components.
Systems are composed of several components, each responsible for a specific piece of functionality.
But often these components also carry additional responsibilities beyond their core functionality.
System services such as logging, transaction management, and security often find their way into components whose core responsibilities is something else.
These system services are commonly referred to as cross-cutting concerns because they tend to cut across multiple components in a system.
By spreading these concerns across multiple components, you introduce two levels of complexity to your code:
The code that implements the system-wide concerns is duplicated across multiple components.
This means that if you need to change how those concerns work, you’ll need to visit multiple components.
Even if you’ve abstracted the concern to a separate module so that the impact to your components is a single method call, that method call is duplicated in multiple places.
Your components are littered with code that isn’t aligned with their core functionality.
A method that adds an entry to an address book should only be concerned with how to add the address and not with whether it’s secure or transactional.
The business objects on the left are too intimately involved with the system services on the right.
Not only does each object know that it’s being logged, secured, and involved in a transactional context, but each object also is responsible for performing those services for itself.
This results in components that are more cohesive and that focus on their own specific concerns, completely ignorant of any system services that may be involved.
It may help to think of aspects as blankets that cover many components of an application, as illustrated in figure 1.3
At its core, an application consists of modules that implement business functionality.
With AOP, you can then cover your core application with layers of functionality.
These layers can be applied declaratively throughout your application in a flexible manner without your core application even knowing they exist.
This is a powerful concept, because it keeps the security, transaction, and logging concerns from littering the application’s core business logic.
To demonstrate how aspects can be applied in Spring, let’s revisit the knight example, adding a basic Spring aspect to the mix.
Figure 1.2 Calls to system-wide concerns such as logging and security are often scattered about in modules where those tasks are not their primary concern.
Figure 1.3 Using AOP, system-wide concerns blanket the components they impact.
This leaves the application components to focus on their specific business functionality.
Let’s suppose that you want to record the comings and goings of your BraveKnight using the services of a minstrel.
The following listing shows the Minstrel class you might use.
As you can see, Minstrel is a simple class with two methods.
The singBeforeQuest() method is intended to be invoked before a knight embarks on a quest, and the singAfterQuest() method should be invoked after the knight has completed a quest.
In both cases, the Minstrel sings of the knight’s deeds via a PrintStream injected through its constructor.
The next listing shows a first attempt at bringing BraveKnight and Minstrel together.
Listing 1.9 A Minstrel is a musically inclined logging system from medieval times.
Now all you need to do is go back to your Spring configuration to declare a Minstrel bean and inject it into the BraveKnight bean’s constructor.
Is it really within the knight’s range of concern to manage his minstrel? It seems to me that minstrels should just do their job without having to be asked to do so.
After all, that’s a minstrel’s job—to sing about the knight’s endeavors.
Why should the knight have to keep reminding the minstrel?
Furthermore, because the knight needs to know about the minstrel, you’re forced to inject Minstrel into BraveKnight.
This not only complicates the BraveKnight code but also makes me wonder if you’d ever want a knight who didn’t have a minstrel.
Your simple BraveKnight class is starting to get more complicated and would become more so if you were to handle the nullMinstrel scenario.
But using AOP, you can declare that the minstrel should sing about a knight’s quests and free the knight from having to deal with the Minstrel methods directly.
To turn Minstrel into an aspect, all you need to do is declare it as one in the Spring configuration file.
Here’s the updated knights.xml file, revised to declare Minstrel as an aspect.
Here you’re using Spring’s aop configuration namespace to declare that the Minstrel bean is an aspect.
Then you refer to that bean in the <aop:aspect> element.
Defining the aspect further, you declare (using <aop:before>) that before the embarkOnQuest() method is executed, the Minstrel’s singBeforeQuest() should be called.
And you (using <aop:after>) declare that the singAfterQuest() method should be called after embarkOnQuest() has executed.
In both cases, the pointcut-ref attribute refers to a pointcut named embark.
This pointcut is defined in the preceding <pointcut> element with an expression attribute set to select where the advice should be applied.
Don’t worry if you don’t know AspectJ or the details of how AspectJ pointcut expressions are written.
We’ll talk more about Spring AOP later, in chapter 4
For now it’s enough to know that you’ve asked Spring to call Minstrel’s singBeforeQuest() and singAfterQuest() methods before and after BraveKnight embarks on a quest.
That’s all there is to it! With a tiny bit of XML, you’ve turned Minstrel into a Spring aspect.
For now, there are two important points to take away from this example.
First, Minstrel is still a POJO—nothing about it indicates that it’s to be used as an aspect.
Instead, Minstrel became an aspect when you declared it as such in the Spring context.
Second, and most important, Minstrel can be applied to BraveKnight without BraveKnight needing to explicitly call on it.
I should also point out that although you used some Spring magic to turn Minstrel into an aspect, it was declared as a Spring <bean> first.
But Spring’s AOP can be used for even more practical things.
But for now, let’s look at one more way that Spring simplifies Java development.
Unfortunately, there are a lot of places where Java APIs involve a bunch of boilerplate code.
A common example of boilerplate code can be seen when working with JDBC to query data from a database.
If you’ve ever worked with JDBC, you’ve probably written something similar to the following.
As you can see, this JDBC code queries the database for an employee’s name and salary.
But I’ll bet you had to look hard to see that.
That’s because the small bit of code that’s specific to querying for an employee is buried in a heap of JDBC ceremony.
You first have to create a connection, then create a statement, and finally query for the results.
And, to appease JDBC’s anger, you must catch SQLException, a checked exception, even though there’s not a lot you can do if it’s thrown.
Finally, after all is said and done, you have to clean up the mess, closing down the connection, statement, and result set.
This could also stir JDBC’s anger, so you must catch SQLException here as well.
What’s most notable about listing 1.12 is that much of it is the exact same code you’d write for pretty much any JDBC operation.
Little of it has anything to do with querying for an employee, and much of it is JDBC boilerplate.
JMS, JNDI, and the consumption of REST services often involve a lot of commonly repeated code.
Spring seeks to eliminate boilerplate code by encapsulating it in templates.
Spring’s JdbcTemplate makes it possible to perform database operations without all the ceremony required by traditional JDBC.
For example, using Spring’s SimpleJdbcTemplate (a specialization of JdbcTemplate that takes advantage of Java 5 features), the getEmployeeById() method can be rewritten so that its focus is on the task of retrieving employee data and not catering to the demands of the JDBC API.
The following shows what such an updated getEmployeeById() method might look like.
Listing 1.13 Templates let your code focus on the task at hand.
As you can see, this new version of getEmployeeById() is much simpler and acutely focused on selecting an employee from the database.
The template’s queryForObject() method is given the SQL query, a RowMapper (for mapping result set data to a domain object), and zero or more query parameters.
What you don’t see in getEmployeeById() is any of the JDBC boilerplate from before.
I’ve shown you how Spring attacks complexity in Java development using POJOoriented development, DI, aspects, and templates.
Along the way, I showed you how to configure beans and aspects in XML-based configuration files.
In a Spring-based application, your application objects live in the Spring container.
As illustrated in figure 1.4, the container creates the objects, wires them together, configures them, and manages their complete lifecycle from cradle to grave (or new to finalize(), as the case may be)
In the next chapter, you’ll see how to configure Spring so it knows what objects it should create, configure, and wire together.
First, though, it’s important to get to know the container where your objects will be hanging out.
Understanding the container will help you grasp how your objects will be managed.
The container is at the core of the Spring Framework.
Spring’s container uses DI to manage the components that make up an application.
As such, these objects are cleaner and easier to understand, they support reuse, and they’re easy to unit test.
Spring comes with several container implementations that can be categorized into two distinct types.
Figure 1.4 In a Spring application, objects are created, are wired together, and live in the Spring container.
Although it’s possible to work with Spring using either bean factories or application contexts, bean factories are often too low-level for most applications.
We’ll focus on working with application contexts and not spend any more time talking about bean factories.
Loading an application context from the filesystem or from the classpath is similar to how you load beans into a bean factory.
With an application context in hand, you can retrieve beans from the Spring container by calling the context’s getBean() method.
Now that you know the basics of how to create a Spring container, let’s take a closer look at the lifecycle of a bean in the bean container.
In a traditional Java application, the lifecycle of a bean is simple.
Java’s new keyword is used to instantiate the bean, and it’s ready to use.
Once the bean is no longer in use, it’s eligible for garbage collection and eventually goes to the big bit bucket in the sky.
In contrast, the lifecycle of a bean in a Spring container is more elaborate.
It’s important to understand the lifecycle of a Spring bean, because you may want to take advantage of some of the opportunities that Spring offers to customize how a bean is created.
Figure 1.5 shows the startup lifecycle of a typical bean as it’s loaded into a Spring application context.
Figure 1.5 A bean goes through several steps between creation and destruction in the Spring container.
Each step is an opportunity to customize how the bean is managed in Spring.
As you can see, a bean factory performs several setup steps before a bean is ready to use.
Spring injects values and bean references into the bean’s properties.
If the bean implements BeanNameAware, Spring passes the bean’s ID to the setBeanName() method.
Similarly, if the bean was declared with an initmethod, then the specified initialization method is called.
At this point, the bean is ready to be used by the application and remains in the application context until the application context is destroyed.
If the bean implements the DisposableBean interface, Spring calls its destroy() method.
Likewise, if the bean was declared with a destroy-method, the specified method is called.
Now you know how to create and load a Spring container.
But an empty container isn’t much good by itself; it doesn’t contain anything unless you put something in it.
To achieve the benefits of Spring DI, you must wire your application objects into the Spring container.
We’ll go into bean wiring in more detail in chapter 2
First, let’s survey the modern Spring landscape to see what the Spring Framework is made up of and what the latest versions of Spring have to offer.
As you’ve seen, the Spring Framework is focused on simplifying enterprise Java development through DI, AOP, and boilerplate reduction.
Even if that were all Spring did, it’d be worth using.
Within the Spring Framework proper, you’ll find several ways that Spring can ease Java development.
But beyond the Spring Framework is a greater ecosystem of projects that build on the core framework, extending Spring into areas such as web services, REST, mobile, and NoSQL.
Let’s first break down the core Spring Framework to see what it brings to the table.
Then we’ll expand our sights to review the other members of the greater Spring portfolio.
When you download the Spring distribution and dig into its libs folder, you’ll find several JAR files.
The complete list of library JAR files is shown in figure 1.6
These modules can be arranged into six categories of functionality, as illustrated in figure 1.7
Taken as a whole, these modules give you everything you need to develop enterprise-ready applications.
But you don’t have to base your application fully on the Spring Framework.
You’re free to choose the modules that suit your application and look to other options when.
Figure 1.7 The Spring Framework is made up of six well-defined module categories.
Spring even offers integration points with several other frameworks and libraries so that you don’t have to write them yourself.
Let’s look at each of Spring’s modules, one at a time, to see how each fits in the overall Spring picture.
In this module is the Spring bean factory, which is the portion of Spring that provides DI.
Building on the bean factory, you’ll find several implementations of Spring’s application context, each of which provides a different way to configure Spring.
In addition to the bean factory and application context, this module also supplies many enterprise services such as email, JNDI access, EJB integration, and scheduling.
All of Spring’s modules are built on top of the core container.
You’ll implicitly use these classes when you configure your application.
We’ll discuss the core module throughout this book, starting in chapter 2 where we’ll dig deep into Spring DI.
SPRING’S AOP MODULE Spring provides rich support for aspect-oriented programming in its AOP module.
This module serves as the basis for developing your own aspects for your Springenabled application.
But with AOP, application-wide concerns (such as transactions and security) are decoupled from the objects to which they’re applied.
Spring’s JDBC and data-access objects (DAO) module abstracts away the boilerplate code so that you can keep your database code clean and simple, and prevents problems that result from a failure to close database resources.
This module also builds a layer of meaningful exceptions on top of the error messages given by several database servers.
No more trying to decipher cryptic and proprietary SQL error messages!
For those who prefer using an object-relational mapping (ORM) tool over straight JDBC, Spring provides the ORM module.
Spring’s ORM support builds on the DAO support, providing a convenient way to build DAOs for several ORM solutions.
Spring doesn’t attempt to implement its own ORM solution but does provide hooks into several popular ORM frameworks, including Hibernate, Java Persistence API, Java Data Objects, and iBATIS SQL Maps.
Spring’s transaction management supports each of these ORM frameworks as well as JDBC.
You’ll see how Spring’s template-based JDBC abstraction can greatly simplify JDBC code when we look at Spring data access in chapter 10
This module also includes a Spring abstraction over the Java Message Service (JMS) for asynchronous integration with other applications through messaging.
Spring 3.0, this module includes the object-to-XML mapping features that were originally part of the Spring Web Services project.
Java has no shortage of MVC frameworks, with Apache Struts, JSF, WebWork, and Tapestry being among the most popular MVC choices.
Even though Spring integrates with several popular MVC frameworks, its web and remoting module comes with a capable MVC framework that promotes Spring’s loosely coupled techniques in the web layer of an application.
In addition to user-facing web applications, this module also provides several remoting options for building applications that interact with other applications.
Spring also offers first-class support for exposing and consuming REST APIs.
And you’ll learn how to create and consume REST APIs in chapter 16
Specifically, it provides a weaving agent for Tomcat that transforms class files as they’re loaded by the classloader.
If that sounds like a lot to understand, don’t worry too much about it.
The instrumentation provided by this module has a narrow set of use cases and we won’t be dealing with this module at all in this book.
In this module you’ll find a collection of mock object implementations for writing unit tests against code that works with JNDI, servlets, and portlets.
For integration-level testing, this module provides support for loading a collection of beans in a Spring application context and working with the beans in that context.
Throughout this book, many of the examples will be driven by tests, utilizing the testing facilities offered by Spring.
When it comes to Spring, there’s more than meets the eye.
In fact, there’s more than what comes in the Spring Framework download.
If you stop at just the core Spring Framework, you’ll miss out on a wealth of potential afforded by the larger Spring.
The whole Spring portfolio includes several frameworks and libraries that build on the core Spring Framework and on each other.
All together, the entire Spring portfolio brings the Spring programming model to almost every facet of Java development.
It would take several volumes to cover everything the Spring portfolio has to offer, and much of it is outside the scope of this book.
But we’ll look at some of the elements of the Spring portfolio; here’s a taste of what lies beyond the core Spring Framework.
We’ll talk more about Spring Web Flow in chapter 8, and you can learn more about it at http://projects.spring.io/spring-webflow/
The contract for the service is determined from the bean’s interface.
Spring Web Services offers a contract-first web services model where service implementations are written to satisfy the service contract.
I won’t be talking about Spring-WS in this book, but you can read more about it at http://docs.spring.io/spring-ws/site/
You’ll see how to add Spring Security to an application’s web layer in chapter 9
We’ll return to Spring Security again in chapter 14 to examine how to secure method invocations.
Spring Integration offers implementations of several common integration patterns in Spring’s declarative style.
Or you can visit the Spring Integration home page at http://projects.spring.io/spring-integration/
If you’re going to be developing a batch application, you can use Spring’s robust, POJO-oriented development model to do it using Spring Batch.
You can also learn about Spring Batch from its home page at http://projects.spring.io/spring-batch/
Although the relational database has been ubiquitous in enterprise applications for many years, modern applications are recognizing that not all data is best served by columns and rows in a table.
A new breed of databases, commonly referred to as NoSQL databases,2 offer new ways of working with data that are more fitting than the traditional relational database.
Whether you’re using a document database like MongoDB, a graph database such as Neo4j, or even a traditional relational database, Spring Data offers a simplified programming model for persistence.
This includes, for many database types, an automatic repository mechanism that creates repository implementations for you.
If this is the kind of thing that interests you, you’ll want to look at Spring Social, a social networking extension to Spring.
But Spring Social is about more than just tweets and friends.
Despite its name, Spring Social is less about the word social and more about the word connect.
It helps you connect your Spring application with REST APIs, including many that may not have any social purpose to them.
Due to space constraints, we won’t cover Spring Social in this book.
Smartphones and tablet devices are taking over as the preferred client for many users.
Spring Mobile is a new extension to Spring MVC to support development of mobile web applications.
This project aims to bring some of the simplicity afforded by the Spring Framework to development of native.
Calling these databases NoSQL places the blame on the query language and not the database model.
Initially, this project is offering a version of Spring’s RestTemplate that can be used in an Android application.
It also works with Spring Social to enable native Android apps to connect with REST APIs.
I won’t discuss Spring for Android in this book, but you can learn more about it at http://projects.spring.io/spring-android/
Spring Boot is an exciting new project that takes an opinionated view of developing with Spring to simplify Spring itself.
Spring Boot heavily employs automatic configuration techniques that can eliminate most (and in many cases, all) Spring configuration.
It also provides several starter projects to help reduce the size of your Spring project build files, whether you’re using Maven or Gradle.
We’ll look at Spring Boot near the end of the book in chapter 21
When the third edition of this book went to press, the latest version of Spring was version 3.0.5
That was around three years ago, and a lot has changed since then.
And several of the other members of the Spring portfolio have undergone major changes.
This edition of Spring in Action has been updated to cover many of the most exciting and useful features in these releases.
But for now, let’s briefly size up what’s new in Spring.
Spring 3.1 had several useful new features and improvements, many of which were focused on simplifying and improving configuration.
In addition, Spring 3.1 provided declarative caching support as well as many improvements to Spring MVC.
Here’s a brief list of some of the highlights of Spring 3.1:
To address the common issue of selecting distinct configurations for various environments (such as development, test, and production), Spring 3.1 introduced environment profiles.
Profiles make it possible, for instance, to select a different data source bean depending on which environment the application is deployed in.
Declarative caching support made its way into Spring, making it possible to declare caching boundaries and rules with simple annotations, similar to how you could already declare transaction boundaries.
A new c namespace brought constructor injection the same succinct attributeoriented style as Spring 2.0’s p namespace brought to property injection.
Spring began to support Servlet 3.0, including the ability to declare servlets and filters in Java-based configuration instead of web.xml.
Improvements to Spring’s JPA support made it possible to completely configure JPA in Spring without needing a persistence.xml file.
Specifically, Spring’s JpaTemplate and JpaDaoSupport classes were deprecated in favor of native EntityManager usage.
Even though they were deprecated, they were still around in Spring 3.2
Now let’s look at what was new in Spring 3.2
In addition to improved controller testing, Spring 3.2 included support for testing RestTemplate-based clients without sending requests to the real REST endpoint.
Although Spring MVC was the main story of Spring 3.2, a few other non-MVC improvements were added as well.
Here are a few of the most interesting new features in Spring 3.2:
The @DateTimeFormat annotation no longer has a hard dependency on JodaTime.
You’ll see a lot of Spring 3.2’s features across several chapters in this book, especially in the web and REST chapters.
There are a lot of exciting new features in Spring 4.0, including the following:
Spring now includes support for WebSocket programming, including support for JSR-356: Java API for WebSocket.
Recognizing that WebSocket offers a low-level API, screaming for a higher-level abstraction, Spring 4.0 includes a higher level message-oriented programming model on top of WebSocket that’s based on SockJS and includes STOMP subprotocol support.
A new messaging module with many types carried over from the Spring Integration project.
Among other things, this makes working with certain callback interfaces (such as RowMapper with JdbcTemplate) much cleaner and easier to read.
A smooth programming experience for applications developed in Groovy has also been added, essentially enabling a Spring application to be developed easily entirely in Groovy.
With this comes the BeanBuilder from Grails, enabling Spring applications to be configured with Groovy.
Generalized support for conditional bean creation has been added, wherein beans can be declared to be created only if a developer-defined condition is met.
Spring 4.0 also includes a new asynchronous implementation of Spring’s RestTemplate that returns immediately but allows for callbacks once the operation completes.
As you can see, a lot of exciting new stuff has found its way into the latest versions of the Spring Framework.
Throughout this book, we’ll look at many of these new features as well as many of the long-standing features of Spring.
You should now have a good idea of what Spring brings to the table.
Spring aims to make enterprise Java development easier and to promote loosely coupled code.
In this chapter, you got a taste of DI in Spring.
Rather than acquiring dependencies on their own, dependent objects are given the objects that they depend on.
Because dependent objects often only know about their injected objects through interfaces, coupling is kept low.
In addition to DI, you also saw a glimpse of Spring’s AOP support.
When Spring wires your beans together, these aspects can be woven in at runtime, effectively giving the beans new behavior.
Thus you must understand how to use these principal functions of Spring to be able to use the rest of the framework.
In this chapter, we’ve just scratched the surface of Spring’s DI and AOP features.
Over the next few chapters, we’ll dig deeper into DI and AOP.
Without further ado, let’s move on to chapter 2 to learn how to wire objects together in Spring using DI.
Have you ever stuck around long enough after a movie to watch the credits? It’s incredible how many different people it takes to pull together a major motion picture.
And that’s not to mention the key grip, sound mixer, costumers, makeup artists, stunt coordinators, publicists, first assistant to the cameraperson, second assistant to the cameraperson, set designers, gaffer, and (perhaps most important) caterers.
Now imagine what your favorite movie would’ve been like had none of these people talked to one another.
Let’s say that they all showed up at the studio and started doing their own thing without any coordination of any kind.
It probably wouldn’t matter anyway, because the lead actress would still be in her trailer and the lighting wouldn’t work because the gaffer wouldn’t have been hired.
Maybe you’ve seen a movie where it looks like this is what happened.
But most movies (the good ones, anyway) are the product of thousands of people working together toward the common goal of making a blockbuster film.
In this respect, a great piece of software isn’t much different.
Any nontrivial application is made up of several objects that must work together to meet some business goal.
These objects must be aware of one another and communicate with one another to get their jobs done.
In an online shopping application, for instance, an ordermanager component may need to work with a product-manager component and a credit-card authorization component.
All of these will likely need to work with a dataaccess component to read from and write to a database.
But as you saw in chapter 1, the traditional approach to creating associations between application objects (via construction or lookup) leads to complicated code that’s difficult to reuse and unit-test.
At best, these objects do more work than they should.
At worst, they’re highly coupled to one another, making them hard to reuse and hard to test.
In Spring, objects aren’t responsible for finding or creating the other objects that they need to do their jobs.
Instead, the container gives them references to the objects that they collaborate with.
An order-manager component, for example, may need a credit-card authorizer—but it doesn’t have to create the credit-card authorizer.
It just needs to show up empty-handed, and it’s given a credit-card authorizer to work with.
The act of creating these associations between application objects is the essence of dependency injection (DI) and is commonly referred to as wiring.
In this chapter, we’ll explore the basics of bean wiring using Spring.
To begin, let’s take a moment to get a feel for the three most common approaches for configuring the Spring container.
As mentioned in chapter 1, the Spring container is responsible for creating the beans in your application and coordinating the relationships between those objects via DI.
But it’s your responsibility as a developer to tell Spring which beans to create and how to wire them together.
When it comes to expressing a bean wiring specification, Spring is incredibly flexible, offering three primary wiring mechanisms:
At first glance, it may seem that offering these three configuration options complicates Spring.
There is some overlap in what each configuration technique offers, and it can be overwhelming to decide which technique is most applicable for a given situation.
But don’t be distressed—in many cases, the choice is largely a matter of personal taste, and you’re welcome to choose the approach that feels best for you.
It’s great that you have many choices about how to wire beans in Spring, but at some point you must select one.
Any choice you make must be suitable for you and your project.
And who says that you must make one choice? Spring’s configuration styles are mix-and-match, so you could choose XML to wire up some beans, use Spring’s Java-based configuration (JavaConfig) for other beans, and let other beans be automatically discovered by Spring.
Even so, my recommendation is to lean on automatic configuration as much as you can.
The less configuration you have to do explicitly, the better.
When you must explicitly configure beans (such as when you’re configuring beans for which you don’t maintain the source code), I’d favor the type-safe and more powerful JavaConfig over XML.
Finally, fall back on XML only in situations where there’s a convenient XML namespace you want to use that has no equivalent in JavaConfig.
We’ll explore all three of these techniques in detail in this chapter and apply them throughout the book.
At this point, let’s test-taste each one to get an idea of what they’re like.
For your first sampling of Spring configuration, let’s look at Spring’s automatic configuration.
A little bit later in this chapter, you’ll see how to express Spring wiring in both Java and XML.
Even though you’ll find a lot of use for those explicit wiring techniques, nothing beats Spring’s automatic configuration for ease of use.
Why bother explicitly wiring beans together if Spring can be configured to automatically do it for you?
Component scanning—Spring automatically discovers beans to be created in the application context.
Working together, component scanning and autowiring are a powerful force and can help keep explicit configuration to a minimum.
To demonstrate component scanning and autowiring, you’re going to create a few beans that represent some of the components in a stereo system.
You’ll start by creating a CompactDisc class that Spring will discover and create as a bean.
Then you’ll create a CDPlayer class and have Spring discover it and inject it with the CompactDisc bean.
In this age of MP3 files and streaming music, the compact disc may seem a bit quaint and archaic.
Not as much as cassette tapes, eight-tracks, or vinyl records, of course, but CDs are becoming more and more scarce as the last remnant of physical music delivery.
In spite of that, the CD provides a nice illustration of how DI works.
You could say that a CD player depends on a CD to do its job.
To bring this illustration to life in Spring, let’s establish the concept of a CD in Java.
The following listing shows CompactDisc, an interface that defines a CD.
What is important is that you’ve defined it as an interface.
As an interface, it defines the contract through which a CD player can operate on the CD.
And it keeps the coupling between any CD player implementation and the CD itself to a minimum.
In this case, you’ll start with one: the SgtPeppers class, as shown in the next listing.
As with the CompactDisc interface, the specifics of SgtPeppers aren’t important to this discussion.
What you should take note of is that SgtPeppers is annotated with @Component.
This simple annotation identifies this class as a component class and serves as a clue to Spring that a bean should be created for the class.
There’s no need to explicitly configure a SgtPeppers bean; Spring will do it for you because this class is annotated with @Component.
You’ll still need to write an explicit configuration to tell Spring to seek out classes annotated with @Component and to create beans from them.
The configuration class in the following listing shows the minimal configuration to make this possible.
Listing 2.1 The CompactDisc interface defines the concept of a CD in Java.
The CDPlayerConfig class defines a Spring wiring specification, expressed in Java.
We’ll look at Java-based Spring configuration more in section 2.3
But for now, observe that CDPlayerConfig doesn’t explicitly define any beans itself.
Instead, it’s annotated with @ComponentScan to enable component scanning in Spring.
With no further configuration, @ComponentScan will default to scanning the same package as the configuration class.
Therefore, because CDPlayerConfig is in the soundsystem package, Spring will scan that package and any subpackages underneath it, looking for classes that are annotated with @Component.
It should find the CompactDisc class and automatically create a bean for it in Spring.
Here is a minimal XML configuration to enable component scanning.
Even though XML is an option for enabling component scanning, I’m going to focus on using the preferred Java-based configuration for the remainder of this discussion.
Believe it or not, with only two classes created, you already have something that you can try out.
To test that component scanning works, let’s write a simple JUnit test that creates a Spring application context and asserts that the CompactDisc bean is, in fact, created.
Because that configuration class includes @ComponentScan, the resulting application context should include the CompactDisc bean.
To prove that, the test has a property of type CompactDisc that is annotated with @Autowired to inject the CompactDisc bean into the test.
I’ll talk more about @Autowired in a moment.) Finally, a simple test method asserts that the cd property isn’t null.
If it’s not null, that means Spring was able to discover the CompactDisc class, automatically create it as a bean in the Spring application context, and inject it into the test.
The test should pass with flying colors (or, hopefully, the color green in your test runner)
Your first simple component-scanning exercise was a success! Even though you’ve only used it to create a single bean, that same small amount of configuration is good for discovering and creating any number of beans.
Any classes in or under the soundsystem package that are annotated with @Component will also be created as beans.
One line with @ComponentScan in exchange for countless automatically created beans is a good trade-off.
Listing 2.5 Testing that a CompactDisc was found by component scanning.
All beans in a Spring application context are given an ID.
What may not have been apparent from the previous example is that although you didn’t explicitly give the SgtPeppers bean an ID, it was given one derived from its class name.
Specifically, the bean was given an ID of sgtPeppers by lowercasing the first letter of the class name.
If you’d rather give the bean a different ID, all you have to do is pass the desired ID as a value to the @Component annotation.
For example, if you wanted to identify the bean as lonelyHeartsClub, then you’d annotate the SgtPeppers class with @Component like this:
Another way to name a bean is to not use the @Component annotation at all.
There are a few subtle differences, but in most common cases they’re interchangeable.
It doesn’t describe what it does as well as @Component.
Therefore, I won’t use @Named any further in this book or its examples.
That means it will default to the configuration class’s package as its base package to scan for components.
One common reason for explicitly setting the base package is so that you can keep all of your configuration code in a package of its own, separate from the rest of your application’s code.
To specify a different base package, you only need to specify the package in @ComponentScan’s value attribute:
Or, if you’d rather it be clear that you’re setting the base package, you can do so with the basePackages attribute:
If you’re wondering whether that means you can specify multiple base packages, you can.
All you need to do is set basePackages to an array of packages to be scanned:
The one thing about setting the base packages as shown here is that they’re expressed as String values.
If you were to refactor the package names, the specified base packages would be wrong.
Rather than specify the packages as simple String values, @ComponentScan also offers you the option of specifying them via classes or interfaces that are in the packages:
As you can see, the basePackages attribute has been replaced with basePackageClasses.
And instead of identifying the packages with String names, the array given to basePackageClasses includes classes.
Whatever packages those classes are in will be used as the base package for component scanning.
With a marker interface, you can still have a refactor-friendly reference to an interface, but without references to any actual application code (that could later be refactored out of the package you intended to component-scan)
If all the objects in your applications were standalone and had no dependencies, like the SgtPeppers bean, then component scanning would be everything you need.
But many objects lean on other objects for help to get their job done.
You need a way to wire up your component-scanned beans with any dependencies they have.
To do that, we’ll need to look at autowiring, the other side of automatic Spring configuration.
Put succinctly, autowiring is a means of letting Spring automatically satisfy a bean’s dependencies by finding other beans in the application context that are a match to the bean’s needs.
To indicate that autowiring should be performed, you can use Spring’s @Autowired annotation.
For example, consider the CDPlayer class in the following listing.
Its constructor is annotated with @Autowired, indicating that when Spring creates the CDPlayer bean,
It can also be used on a property’s setter method.
For example, if CDPlayer had a setCompactDisc() method, you might annotate it for autowiring like this:
After Spring has instantiated the bean, it will try to satisfy the dependencies expressed through methods such as the setCompactDisc() method that are annotated with @Autowired.
Autowired can also be applied on any method on the class.
Pretending that CDPlayer has an insertDisc() method, @Autowired would work equally well there as on setCompactDisc():
Whether it’s a constructor, a setter method, or any other method, Spring will attempt to satisfy the dependency expressed in the method’s parameters.
Assuming that one and only one bean matches, that bean will be wired in.
If there are no matching beans, Spring will throw an exception as the application context is being created.
To avoid that exception, you can set the required attribute on @Autowired to false:
Listing 2.6 Injecting a CompactDisc into a CDPlayer bean using autowiring.
When required is false, Spring will attempt to perform autowiring; but if there are no matching beans, it will leave the bean unwired.
In the event that multiple beans can satisfy the dependency, Spring will throw an exception indicating ambiguity in selecting a bean for autowiring.
We’ll talk more about managing ambiguity in autowiring later, in chapter 3
Inject comes from the Java Dependency Injection specification, the same specification that gave us @Named.
In fact, I sometimes find myself using both in a given project.
For the purposes of the examples in this book, however, I’ll consistently use @Autowired.
Now that you’ve annotated CDPlayer’s constructor with @Autowired, you can be assured that Spring will automatically inject it with a bean assignable to CompactDisc.
To be certain, let’s change CDPlayerTest to play the compact disc through the CDPlayer bean:
Now, in addition to injecting CompactDisc, you’re injecting the CDPlayer bean into the test’s player member variable (as the more generic MediaPlayer type)
In the play() test method, you call the play() method on the CDPlayer and assert that it does what you expect.
Now you know the basics of component scanning and autowiring.
We’ll revisit component scanning in chapter 3 when we look at ways to address autowiring ambiguity.
But at this point, let’s set aside component scanning and autowiring and see how you can explicitly wire beans in Spring.
We’ll start with Spring’s facility for expressing configuration in Java.
Although automatic Spring configuration with component scanning and automatic wiring is preferable in many cases, there are times when automatic configuration isn’t an option and you must configure Spring explicitly.
For instance, let’s say that you want to wire components from some third-party library into your application.
You have two choices for explicit configuration: Java and XML.
In this section, we’ll look at how to use JavaConfig.
We’ll then follow up in the next section on Spring’s XML configuration.
As I mentioned earlier, JavaConfig is the preferred option for explicit configuration because it’s more powerful, type-safe, and refactor-friendly.
That’s because it’s just Java code, like any other Java code in your application.
At the same time, it’s important to recognize that JavaConfig code isn’t just any other Java code.
It’s conceptually set apart from the business logic and domain code in your application.
Even though it’s expressed in the same language as those components, JavaConfig is configuration code.
This means it shouldn’t contain any business logic, nor should JavaConfig invade any code where business logic resides.
In fact, although it’s not required, JavaConfig is often set apart in a separate package from the rest of an application’s logic so there’s no confusion as to its purpose.
Earlier in this chapter, in listing 2.3, you got your first taste of JavaConfig.
The key to creating a JavaConfig class is to annotate it with @Configuration.
The @Configuration annotation identifies this as a configuration class, and it’s expected to contain details on beans that are to be created in the Spring application context.
So far, you’ve relied on component scanning to discover the beans that Spring should create.
Although there’s no reason you can’t use component scanning and explicit configuration together, we’re focusing on explicit configuration in this section, so I’ve removed the @ComponentScan annotation from CDPlayerConfig.
The test expects to be injected with CDPlayer and CompactDisc, but those beans are never created because they’re never discovered by component scanning.
To make the test happy again, you could put @ComponentScan back in.
Keeping the focus on explicit configuration, however, let’s see how you can wire the CDPlayer and CompactDisc beans in JavaConfig.
To declare a bean in JavaConfig, you write a method that creates an instance of the desired type and annotate it with @Bean.
The @Bean annotation tells Spring that this method will return an object that should be registered as a bean in the Spring application context.
The body of the method contains logic that ultimately results in the creation of the bean instance.
By default, the bean will be given an ID that is the same as the @Bean-annotated method’s name.
If you’d rather it have a different name, you can either rename the method or prescribe a different name with the name attribute:
No matter how you name the bean, this bean declaration is about as simple as they come.
The body of the method returns a new instance of SgtPeppers.
But because it’s expressed in Java, it has every capability afforded it by the Java language to do almost anything to arrive at the CompactDisc that is returned.
Unleashing your imagination a bit, you might do something crazy like randomly selecting a CompactDisc from a selection of choices:
I’ll let you daydream a bit about all the ways you can exploit the power of Java to produce a bean from an @Bean-annotated method.
When you’re done, we’ll pick it back up and look at how you can inject the CompactDisc bean into the CDPlayer in JavaConfig.
The CompactDisc bean you declared was simple and had no dependencies of its own.
But now you must declare the CDPlayer bean, which depends on a CompactDisc.
The simplest way to wire up beans in JavaConfig is to refer to the referenced bean’s method.
For example, here’s how you might declare the CDPlayer bean:
The cdPlayer() method, like the sgtPeppers() method, is annotated with @Bean to indicate that it will produce an instance of a bean to be registered in the Spring application context.
The ID of the bean will be cdPlayer, the same as the method’s name.
The body of the cdPlayer() method differs subtly from that of the sgtPeppers() method.
Rather than construct an instance via its default method, the CDPlayer instance is created by calling its constructor that takes a CompactDisc.
It appears that the CompactDisc is provided by calling sgtPeppers, but that’s not exactly true.
Because the sgtPeppers() method is annotated with @Bean, Spring will intercept any calls to it and ensure that the bean produced by that method is returned rather than allowing it to be invoked again.
For example, suppose you were to introduce another CDPlayer bean that is just like the first:
If the call to sgtPeppers() was treated like any other call to a Java method, then each CDPlayer would be given its own instance of SgtPeppers.
That would make sense if we were talking about real CD players and compact discs.
If you have two CD players, there’s no physical way for a single compact disc to simultaneously be inserted into two CD players.
In software, however, there’s no reason you couldn’t inject the same instance of SgtPeppers into as many other beans as you want.
By default, all beans in Spring are singletons, and there’s no reason you need to create a duplicate instance for the second CDPlayer bean.
So Spring intercepts the call to sgtPeppers() and makes sure that what is returned is the Spring bean that was created when Spring itself called sgtPeppers() to create the CompactDisc bean.
Therefore, both CDPlayer beans will be given the same instance of SgtPeppers.
I can see how referring to a bean by calling its method can be confusing.
Here, the cdPlayer() method asks for a CompactDisc as a parameter.
When Spring calls cdPlayer() to create the CDPlayer bean, it autowires a CompactDisc into the configuration method.
Then the body of the method can use it however it sees fit.
With this technique, the cdPlayer() method can still inject the CompactDisc into the CDPlayer’s constructor without explicitly referring to the CompactDisc’s @Bean method.
This approach to referring to other beans is usually the best choice because it doesn’t depend on the CompactDisc bean being declared in the same configuration class.
In fact, there’s nothing that says the CompactDisc bean even needs to be declared in JavaConfig; it could have been discovered by component scanning or declared in XML.
You could break up your configuration into a healthy mix of configuration classes, XML files, and automatically scanned and wired beans.
No matter how the CompactDisc was created, Spring will be happy to hand it to this configuration method to create the CDPlayer bean.
In any event, it’s important to recognize that although you’re performing DI via the CDPlayer’s constructor, there’s no reason you couldn’t apply other styles of DI here.
For example, if you wanted to inject a CompactDisc via a setter method, it might look like this:
Once again, it bears repeating that the body of an @Bean method can utilize whatever Java is necessary to produce the bean instance.
Constructor and setter injection just happen to be two simple examples of what you can do in an @Bean-annotated method.
The possibilities are limited only by the capabilities of the Java language.
So far, you’ve seen how to let Spring automatically discover and wire beans.
And you’ve seen how to step in and explicitly wire beans using JavaConfig.
But there’s another option for bean wiring that, although less desirable, has a long history with Spring.
Since the beginning of Spring, XML has been the primary way of expressing configuration.
Countless lines of XML have been created in the name of Spring.
And for many, Spring has become synonymous with XML configuration.
Although it’s true that Spring has long been associated with XML, let’s be clear that XML isn’t the only option for configuring Spring.
And now that Spring has strong support for automatic configuration and Java-based configuration, XML should not be your first choice.
Nevertheless, because so much XML-based Spring configuration has already been written, it’s important to understand how to use XML with Spring.
I hope, however, that this section will only serve to help you work with existing XML configuration, and that you’ll lean on automatic configuration and JavaConfig for any new Spring work you do.
Before you can start using XML to wire together beans in Spring, you’ll need to create the empty configuration specification.
With JavaConfig, that meant creating a class annotated with @Configuration.
For XML configuration, that means creating an XML file rooted with a <beans> element.
It doesn’t take much to see that this basic XML configuration is already much more complex than an equivalent JavaConfig class.
Whereas JavaConfig’s @Configuration annotation was all you needed to get started, the XML elements for configuring Spring are defined in several XML schema (XSD) files that must be declared in the preamble of the XML configuration file.
The most basic XML elements for wiring beans are contained in the spring-beans schema, which is declared as the root namespace of this XML file.
The <beans> element, the root element of any Spring configuration file, is one of the elements in this schema.
Several other schemas are available for configuring Spring in XML.
Although I’m going to focus on automatic and Java configuration throughout this book, I’ll at least.
As it is, you have a perfectly valid Spring XML configuration.
It’s also a perfectly useless configuration, because it doesn’t (yet) declare any beans.
To give it some life, let’s re-create the CD example, this time using XML configuration instead of JavaConfig or automatic configuration.
To declare a bean in Spring’s XML-based configuration, you’re going to use another element from the spring-beans schema: the <bean> element.
You can use it to declare the CompactDisc bean like this:
The class used to create this bean is specified in the class attribute and is expressed as the fully qualified class name.
For lack of an explicitly given ID, the bean will be named according to the fully qualified class name.
The #0 is an enumeration used to differentiate this bean from any other bean of the same type.
Even though it’s convenient to have beans named automatically for you, the generated names will be less useful if you need to refer to them later.
Therefore, it’s usually a good idea to give each bean a name of your own choosing via the id attribute:
You’ll use this explicit name in a moment when you wire this bean into the CDPlayer bean.
But before we go any further, let’s take a moment to examine some of the characteristics of this simple bean declaration.
The first thing to notice is that you aren’t directly responsible for creating an instance of SgtPeppers as you were when using JavaConfig.
When Spring sees this <bean> element, it will create a SgtPeppers bean for you by calling its default constructor.
But it’s also less powerful than JavaConfig, where you can do almost anything imaginable to arrive at the bean instance.
Another notable thing about this simple <bean> declaration is that you express the type of the bean as a string set to the class attribute.
Who’s to say that the value given to class even refers to a real class? Spring’s XML configuration doesn’t benefit from.
And even if it does refer to an actual type, what will happen if you rename the class?
These are just a few of the reasons why JavaConfig is preferable over XML configuration.
I encourage you to be mindful of these shortcomings of XML configuration when choosing the configuration style for your application.
Nevertheless, let’s continue this study of Spring’s XML configuration to see how you can inject your SgtPeppers bean into the CDPlayer.
There’s only one way to declare a bean in Spring XML configuration: use the <bean> element, and specify a class attribute.
But when it comes to declaring DI in XML, there are several options and styles.
With specific regard to constructor injection, you have two basic options to choose from:
The difference between these two choices is largely one of verbosity.
As you’ll see, the <constructor-arg> element is generally more verbose than using the c-namespace and results in XML that is more difficult to read.
On the other hand, <constructorarg> can do a few things that the c-namespace can’t.
As we look at constructor injection in Spring XML, we’ll stack these two options side by side.
First, let’s see how each fares at injecting bean references.
This makes it a perfect candidate for injection with a bean reference.
Because you’ve already declared a SgtPeppers bean, and because the SgtPeppers class implements the CompactDisc interface, you have a bean to inject into a CDPlayer bean.
All you need to do is declare the CDPlayer bean in XML and reference the SgtPeppers bean by its ID:
When Spring encounters this <bean> element, it will create an instance of CDPlayer.
The <constructor-arg> element tells it to pass a reference to the bean whose ID is compactDisc to the CDPlayer’s constructor.
The c-namespace was introduced in Spring 3.0 as a more succinct way of expressing constructor args in XML.
To use it, you must declare its schema in the preamble of the XML, like this:
With the c-namespace and schema declared, you can use it to declare a constructor argument like this:
Here you’re using the c-namespace to declare the constructor argument as an attribute of the <bean> element.
Figure 2.1 illustrates how the pieces of the attribute name come together.
Following that is the name of the constructor argument being wired.
After that is -ref, a naming convention that indicates to Spring that you’re wiring a reference to a bean named compactDisc and not the literal String value "compactDisc"
It’s clear that using c-namespace attributes is much more terse than using the <constructor-arg> element.
That’s one of the reasons that I like it a lot.
Aside from being slightly easier to read, c-namespace attributes are especially helpful when I have to write code samples that fit neatly within the margins of a book.
But one thing that bugs me about the c-namespace as I’ve used it in the previous example is that it directly refers to the name of the constructor argument.
Referring to a parameter name seems a bit flaky to me.
Referring to a parameter by name requires that you compile your code with debug symbols stored in the class code.
If you optimize your builds to leave out debug symbols, then this probably won’t work.
Instead, you could refer to the parameter’s position in the parameter list:
This c-namespace attribute looks even more bizarre than the last one.
I’ve replaced the name of the parameter with 0, the parameter index.
But because XML doesn’t allow digits as the first character of an attribute, I had to add an underscore as a prefix.
Using an index to identify the constructor argument feels better than referencing it by its name.
Even if debug symbols are excluded from the build, the parameters will.
Figure 2.1 Injecting a bean reference into a constructor argument with Spring’s c-namespace.
And if there were multiple constructor arguments, it would certainly be useful.
But because you have only one constructor argument, you have one more option—don’t identify the parameter at all:
There’s just an underscore placeholder followed by -ref to indicate that you’re wiring a reference.
Now that you’ve tried wiring a reference to other beans, let’s see how to wire literal values into constructors.
To illustrate, suppose you were to create a new implementation of CompactDisc, as shown here:
Unlike SgtPeppers, which was hard-coded with a title and artist, this implementation of CompactDisc is considerably more flexible.
Much like a real-world blank disc, it can be set to contain any artist and title you want.
Now you can change the existing SgtPeppers bean to use this class instead:
Once again, the <constructor-arg> element is used to inject into constructor arguments.
But this time, instead of using the ref attribute to reference another bean, you use the value attribute to indicate that the given value is to be taken literally and injected into the constructor.
How would this look if you were to use c-namespace attributes instead? One possible rendition might reference the constructor arguments by name:
As you can see, wiring literal values via the c-namespace differs from wiring references in that the -ref suffix is left off the attribute name.
Similarly, you could wire the same literal values using parameter indexes, like this:
Therefore, you can’t use the simple underscore when you have two or more constructor arguments.
But you can use it when there’s only one constructor argument.
For the sake of completeness, let’s pretend that BlankDisc has a singleargument constructor that takes the album’s title.
In that case, you could declare it in Spring like this:
When it comes to wiring bean reference and literal values, both <constructor-arg> and the c-namespace attributes are equally capable.
But there’s one thing that <constructor-arg> can do that the c-namespace can’t do.
Let’s look at how to wire collections to constructor arguments.
But if that’s all that came with a real-world CD, the technology would’ve never taken off.
What makes CDs worth buying is that they carry music on them.
Most CDs carry roughly a dozen tracks, each holding a song.
If CompactDisc is to truly model a real-world CD, then it must also have the notion of a list of tracks.
This change has implications for how you configure the bean in Spring.
You must provide a list of tracks when declaring the bean.
The simplest thing you could do is leave the list null.
Because it’s a constructor argument, you must specify it, but you can still pass null like this:
The <null/> element does as you’d expect: it passes null into the constructor.
It’s a dirty fix, but it will work at injection time.
A better fix would be to supply a list of track names.
First, you could specify it as a list, using the <list> element:
The <value> element is used to specify each element of the list.
For example, suppose you have a Discography class with the following constructor:
It makes sense to use <list> when wiring a constructor argument of type java.util.List.
The main difference is that when Spring creates the collection to be wired, it will create it as either a java.util.Set or a java.util.List.
If it’s a Set, then any duplicate values will be discarded and the ordering may not be honored.
Wiring collections is one place where the <constructor-arg> has an advantage over the c-namespace attributes.
There’s no obvious way to wire collections like this via c-namespace attributes.
There are a handful of other nuances to using both <constructor-arg> and the cnamespace for constructor injection.
But what we’ve covered here should carry you quite far, especially considering my earlier advice to favor Java configuration over XML configuration.
Therefore, rather than belabor the topic of constructor injection in XML, let’s move on to see how to wire properties in XML.
Up to this point, the CDPlayer and BlankDisc classes have been configured entirely through constructor injection and don’t have any property setter methods.
In contrast, let’s examine how property injection works in Spring XML.
In light of that rule, we could argue that the title, artist, and track list are hard dependencies for a BlankDisc and that constructor injection was the right choice.
It’s debatable, however, whether a CompactDisc is a hard or optional dependency for a CDPlayer.
I stand by that choice, but you could say that a CDPlayer might still have some limited functionality even without a CompactDisc being injected into it.
Now that CDPlayer doesn’t have any constructors (aside from the implicit default constructor), it also doesn’t have any hard dependencies.
Therefore, you could declare it as a Spring bean like this:
But you can fix that with the following change to the XML:
In this case, it references (with the ref attribute) the bean whose ID is compactDisc to be injected into the compactDisc property (via the setCompactDisc() method)
To enable the p-namespace, you must declare it among the other namespaces in the XML file:
Using the p-namespace, you can wire the compactDisc property like this:
The p-namespace attributes follow a naming convention similar to that of the c-namespace attributes.
Figure 2.2 illustrates how this p-namespace attribute name breaks down.
First, the attribute name is prefixed with p: to indicate that you’re setting a property.
Next up is the name of the property to be injected.
Finally, the name ends with -ref as a clue to Spring that you’re wiring a reference to a bean and not a literal value.
This time, however, BlankDiscs will be configured entirely by property injection, not constructor injection.
Figure 2.2 Injecting a bean reference into a property with Spring’s p-namespace.
Now you’re no longer obligated to wire any of these properties.
You could create a BlankDisc bean in its most blank form as follows:
Of course, wiring the bean without setting those properties wouldn’t play out well at runtime.
You can do that using the value attribute of the <property> element:
Optionally, you can accomplish the same thing using p-namespace attributes:
As with c-namespace attributes, the only difference between wiring a bean reference and wiring a literal value is the presence or absence of a -ref suffix.
Notice, however, that you can’t use the p-namespace when wiring a collection.
Unfortunately, there’s no convenient way to specify a list of values (or bean references) with the p-namespace.
But you can take advantage of something from Spring’s util-namespace to simplify the BlankDisc bean.
First, you need to declare the util-namespace and its schema in the XML:
One of the things that the util-namespace offers is the <util:list> element, which creates a list bean.
Using <util:list>, you can shift the track list out of the BlankDisc bean and into a bean of its own, like this:
Now you can wire the track-list bean into the BlankDisc bean’s tracks property just like any other bean:
The <util:list> element is just one of several elements in the util-namespace.
You’ll occasionally call on members of the util-namespace as you need them.
For now, though, let’s wrap up this chapter by seeing how you can mix and match automatic configuration, JavaConfig, and XML configuration.
In a typical Spring application, you’re likely to need to use both automatic and explicit configuration.
And even if you favor JavaConfig for explicit configuration, there may be times when XML configuration is the best choice.
Fortunately, none of the configuration options available in Spring are mutually exclusive.
You’re free to mix component scanning and autowiring with JavaConfig and/or XML configuration.
In fact, as you saw in section 2.2.1, you’ll need at least a little explicit configuration to enable component scanning and autowiring.
The first thing to know about mixing configuration styles is that when it comes to autowiring, it doesn’t matter where the bean to be wired comes from.
Autowiring considers all beans in the Spring container, regardless of whether they were declared in JavaConfig or XML or picked up by component scanning.
That leaves you with how to reference beans when doing explicit configuration, either with XML configuration or with Java configuration.
Let’s start by seeing how to reference XML-configured beans from JavaConfig.
Pretend for a moment that CDPlayerConfig is getting unwieldy and you want to split it apart.
Sure, it only declares two beans, which is a far cry from a complex Spring configuration.
Nevertheless, let’s pretend that two beans is two beans too many.
What you could do is break out the BlankDisc bean from CDPlayerConfig into its own CDConfig class, like this:
Now that the compactDisc() method is gone from CDPlayerConfig, you need a way to bring the two configuration classes together.
One way is to import CDConfig from CDPlayerConfig using the @Import annotation:
Either way, you’ve separated the configuration of CDPlayer from the configuration of BlankDisc.
Now let’s suppose that (for whatever reason) you want to configure the BlankDisc bean in XML like this:
With BlankDisc being declared in XML, how can you have Spring load it in along with the rest of your Java-based configuration?
Assuming that the BlankDisc bean is declared in a file named cd-config.xml that can be found at the root of the classpath, you can change SoundSystemConfig to use @ImportResource like this:
And because CDPlayer’s @Bean method accepts a CompactDisc as a parameter, the BlankDisc bean will be wired into it, even though it’s configured in XML.
But this time, you’ll reference a JavaConfigdeclared bean from XML.
Suppose you’re working with Spring’s XML-based configuration and you’ve decided that the XML is getting out of hand.
As before, you’re only dealing with two beans, and things could be worse.
But before you’re inundated with a flood of angle brackets, you decide to break the XML configuration file apart.
In XML, you can use the <import> element to split up the XML configuration.
For example, suppose you were to split out the BlankDisc bean into its own configuration file called cd-config.xml, as you did when working with @ImportResource.
You can reference that file from the XML configuration file using <import>:
Now, suppose that instead of configuring BlankDisc in XML, you want to configure it in XML while leaving the CDPlayer configuration in JavaConfig.
The <import> element only works to import other XML configuration files, and there isn’t an XML element whose job it is to import JavaConfig classes.
There is, however, an element you already know that can be used to bring a Java configuration into an XML configuration: the <bean> element.
To import a JavaConfig class into an XML configuration, you declare it as a bean like this:
Similarly, you might consider creating a higherlevel configuration file that doesn’t declare any beans but that brings two or more configurations together.
For example, you could leave the CDConfig bean out of the previous XML configuration and instead have a third configuration file that joins them:
Whether I’m using JavaConfig or XML wiring, I often create a root configuration, as I’ve shown here, that brings together two or more wiring classes and/or XML files.
You’ll see this technique employed for many of the examples in this book.
At the core of the Spring Framework is the Spring container.
This container manages the lifecycle of the components of an application, creating those components and ensuring that their dependencies are met so that they can do their job.
In this chapter, we’ve looked at three primary ways of wiring beans together in Spring: automatic configuration, explicit Java-based configuration, and explicit XMLbased configuration.
No matter which you choose, these techniques describe the components in a Spring application and the relationships between those components.
I’ve also strongly recommended that you favor automatic configuration as much as possible to avoid the maintenance costs involved with explicit configuration.
This preference will guide my choice of wiring techniques as I present the examples throughout this book.
Because dependency injection is an essential part of working with Spring, the techniques shown in this chapter will play a role in almost everything else you do in this book.
Building on this foundation, the next chapter will present some more advanced bean-wiring techniques that will help you make the most of the Spring container.
In the previous chapter, we looked at some essential bean-wiring techniques.
You’re likely to find a lot of use for what you learned in that chapter.
But there’s more to bean wiring than what we explored in chapter 2
Spring has several other tricks up its sleeve for more advanced bean wiring.
In this chapter, we’ll dig in to some of these advanced techniques.
You won’t get as much day-to-day use out of the techniques in this chapter, but that doesn’t mean they’re any less valuable.
One of the most challenging things about developing software is transitioning an application from one environment to another.
In a development environment, you’re likely to use an embedded database preloaded with test data.
But it’s how that bean is created that’s most interesting.
This DataSource is useful in a development environment when you’re running integration tests or firing up an application for manual testing.
You can count on your database being in a given state every time you start it.
In a production setting, you may want to retrieve a DataSource from your container using JNDI.
In that case, the following @Bean method is more appropriate:
Retrieving a DataSource from JNDI allows your container to make decisions about how it’s created, including handing off a DataSource from a container-managed connection pool.
Even so, using a JNDI-managed DataSource is more fitting for production and unnecessarily complicated for a simple integration test or developer test.
Meanwhile, in a QA environment you could select a completely different DataSource configuration.
You might choose to configure a Commons DBCP connection pool like this:
Clearly, all three versions of the dataSource() method presented here are different from each other.
Each applies a completely different strategy for producing the DataSource bean.
Again, this discussion isn’t about how to configure a DataSource (we’ll talk more about that in chapter 10)
But certainly the seemingly simple DataSource bean isn’t so simple.
It’s a good example of a bean that might vary across different environments.
You must find a way to configure a DataSource bean so that the most appropriate configuration is chosen for each environment.
One way of doing this is to configure each bean in a separate configuration class (or XML file) and then make a build-time decision (perhaps using Maven profiles) about which to compile into the deployable application.
The problem with this solution is that it requires that the application be rebuilt for each environment.
A rebuild might not be that big a problem when going from development to QA.
But requiring a rebuild between QA and production has the potential to introduce bugs and cause an epidemic of ulcers among the members of your QA team.
Fortunately, Spring has a solution that doesn’t require a rebuild.
But rather than make that decision at build time, Spring waits to make the decision at runtime.
Consequently, the same deployment unit (perhaps a WAR file) will work in all environments without being rebuilt.
To use profiles, you must gather all the varying bean definitions into one or more profiles and then make sure the proper profile is active when your application is deployed in each environment.
In Java configuration, you can use the @Profile annotation to specify which profile a bean belongs to.
For example, the embedded database DataSource bean might be configured in a configuration class like this:
The main thing I want to draw your attention to is the @Profile annotation applied at the class level.
It tells Spring that the beans in this configuration class should be created only if the dev profile is active.
If the dev profile isn’t active, then the @Bean methods will be ignored.
Meanwhile, you may have another configuration class for production that looks like this:
In this case, the bean won’t be created unless the prod profile is active.
This makes it possible to combine both bean declarations into a single configuration class, as shown in the following listing.
What’s not apparent here is that although each of the DataSource beans is in a profile and will only be created if the prescribed profile is active, there are probably other beans that aren’t defined in the scope of a given profile.
Any bean that isn’t given a profile will always be created, regardless of what profile is active.
For example, to define the embedded database DataSource bean for development in XML, you can create a configuration XML file that looks like this:
Likewise, you could create another configuration file, with profile set to prod for the production-ready JNDI-obtained DataSource bean.
And you could create yet another XML file for the connection pool–defined DataSource bean specified by the qa profile.
All the configuration XML files are collected into the deployment unit (likely a WAR file), but only those whose profile attribute matches the active profile will be used.
This helps to collect all profiled bean definitions into a single XML file, as shown next.
Aside from the fact that all these beans are now defined in the same XML file, the effect is the same as if they were defined in separate XML files.
But at runtime, only one bean will be created, depending on which profile is active.
That raises the question: how do you make a profile active?
Listing 3.3 Setting default profiles in a web application’s web.xml file.
This means you can activate multiple profiles at the same time by listing the profile names, separated by commas.
Of course, it probably doesn’t make much sense to enable both dev and prod profiles at the same time, but you could enable multiple orthogonal profiles simultaneously.
Spring offers the @ActiveProfiles annotation to let you specify which profile(s) should be active when a test is run.
Often it’s the development profile that you’ll want to activate during an integration test.
For example, here’s a snippet of a test class that uses @ActiveProfiles to activate the dev profile:
Spring profiles are a great way to conditionally define beans where the condition is based on which profile is active.
But Spring 4 offers a more general-purpose mechanism for conditional bean definitions where the condition is up to you.
Suppose you want one or more beans to be configured if and only if some library is available in the application’s classpath.
Or let’s say you want a bean to be created only if a certain other bean is also declared.
Maybe you want a bean to be created if and only if a specific environment variable is set.
If the prescribed condition evaluates to true, then the bean is created.
For example, suppose you have a class named MagicBean that you only want Spring to instantiate if a magic environment property has been set.
If the environment has no such property, then the MagicBean should be ignored.
The following listing shows a configuration that conditionally configures the MagicBean using @Conditional.
The class given to @Conditional can be any type that implements the Condition interface.
As you can see, it’s a straightforward interface to implement, requiring only that you provide an implementation for the matches() method.
For this example, you need to create an implementation of Condition that hinges its decision on the presence of a magic property in the environment.
The matches() method in this listing is simple but powerful.
It uses the Environment obtained from the given ConditionContext object to check for the presence of an environment property named magic.
For this example, the value of the property is irrelevant; it only needs to exist.
On the other hand, if the property doesn’t exist, the condition will fail, false will be returned from matches(), and none of those beans will be created.
Listing 3.5 Checking for the presence of magic in a Condition.
Check for the presence and values of environment variables via the Environment retrieved from getEnvironment()
Load and check for the presence of classes via the ClassLoader returned from getClassLoader()
Using the isAnnotated() method, you can check to see if the @Bean method is annotated with any particular annotation type.
Using the other methods, you can check on the attributes of any annotation applied to the @Bean method.
With that, it checks explicitly for the value attribute, which contains the name of the bean’s profile.
It then consults with the Environment retrieved from the ConditionContext to see whether the profile is active (by calling the acceptsProfiles() method)
In chapter 2, you saw how to use autowiring to let Spring do all the work when injecting bean references into constructor arguments or properties.
Autowiring is a huge help because it reduces the amount of explicit configuration necessary to assemble application components.
But autowiring only works when exactly one bean matches the desired result.
When there’s more than one matching bean, the ambiguity prevents Spring from autowiring the property, constructor argument, or method parameter.
To illustrate autowiring ambiguity, suppose you’ve annotated the following setDessert() method with @Autowired:
In this example, Dessert is an interface and is implemented by three classes: Cake, Cookies, and IceCream:
Listing 3.6 ProfileCondition checking whether a bean profile is acceptable.
Because all three implementations are annotated by @Component, they’re all picked up during component-scanning and created as beans in the Spring application context.
Then, when Spring tries to autowire the Dessert parameter in setDessert(), it doesn’t have a single, unambiguous choice.
Although most people wouldn’t have any problem making choices when faced with multiple dessert options, Spring can’t choose.
Spring has no option but to fail and throw an exception.
Of course, this dessert-eating example is contrived to illustrate how autowiring can run into trouble with ambiguity.
In reality, autowiring ambiguity is more rare than you’d expect.
Even though such ambiguity is a real problem, more often than not there’s only one implementation of a given type, and autowiring works perfectly.
For those times when ambiguity does happen, however, Spring offers a couple of options.
You can declare one of the candidate beans as the primary choice, or you can use qualifiers to help Spring narrow its choices to a single candidate.
If you’re like me, you enjoy all kinds of desserts.
But if you were forced to choose only a single dessert, which is your favorite?
When declaring beans, you can avoid autowiring ambiguity by designating one of the candidate beans as a primary bean.
In the event of any ambiguity, Spring will choose the primary bean over any other candidate beans.
You can express that favorite choice in Spring using the @Primary annotation.
Or, if you’re declaring the IceCream bean explicitly in Java configuration, the @Bean method might look like this:
If you’re configuring your beans in XML, you’re not left out.
The <bean> element has a primary attribute to specify a primary bean:
No matter how you designate a primary bean, the effect is the same.
You’re telling Spring that it should choose the primary bean in the case of ambiguity.
This works well right up to the point where you designate two or more primary beans.
Now there are two primary Dessert beans: Cake and IceCream.
Just as Spring couldn’t choose among multiple candidate beans, it can’t choose among multiple primary beans.
Clearly, when more than one bean is designated as primary, there are no primary candidates.
For a more powerful ambiguity-busting mechanism, let’s look at qualifiers.
The limitation of primary beans is that @Primary doesn’t limit the choices to a single unambiguous option.
When there’s more than one primary, there’s not much else you can do to narrow the choices further.
In contrast, Spring’s qualifiers apply a narrowing operation to all candidate beans, ultimately arriving at the single bean that meets the prescribed qualifications.
If ambiguity still exists after applying all qualifiers, you can always apply more qualifiers to narrow the choices further.
The @Qualifier annotation is the main way to work with qualifiers.
For example, let’s say you want to ensure that the IceCream bean is injected into setDessert():
This is a prime example of qualifiers in their simplest form.
The parameter given to @Qualifier is the ID of the bean that you want to inject.
Actually, there’s a bit more to the story than that.
Therefore, the setDessert() method will be injected with the bean that has “iceCream” as a qualifier.
That just happens to be the bean whose ID is iceCream, created when the IceCream class was component-scanned.
Basing qualification on the default bean ID qualifier is simple but can pose some problems.
What do you suppose would happen if you refactored the IceCream class, renaming it Gelato? In that case, the bean’s ID and default qualifier would be gelato, which doesn’t match the qualifier on setDessert()
The problem is that you specified a qualifier on setDessert() that is tightly coupled to the class name of the bean being injected.
Any change to that class name will render the qualifier ineffective.
All you need to do is place the @Qualifier annotation on the bean declaration.
For example, it can be applied alongside @Component like this:
In this case, a qualifier of cold is assigned to the IceCream bean.
Because it’s not coupled to the class name, you can refactor the name of the IceCream class all you want without worrying about breaking autowiring.
It will work as long as you refer to the cold qualifier at the injection point:
When defining custom @Qualifier values, it’s a good practice to use a trait or descriptive term for the bean, rather than using an arbitrary name.
In this case, I’ve described the IceCream bean as a “cold” bean.
But they still run into trouble when you have multiple beans that share common traits.
For example, imagine what would happen if you introduced this new Dessert bean:
Once again you’re faced with ambiguity in autowiring dessert beans.
You need more qualifiers to narrow the selection to a single bean.
Perhaps the solution is to tack on another @Qualifier at both the injection point and at the bean definition.
And at the injection point, you could narrow it down to IceCream like this:
There’s only one small problem: Java doesn’t allow multiple annotations of the same type to be repeated on the same item.1 The compiler will complain with errors if you try this.
There’s no way you can use @Qualifier (at least not directly) to narrow the list of autowiring candidates to a single choice.
What you can do, however, is create custom qualifier annotations to represent the traits you want your beans to be qualified with.
All you have to do is create an annotation that is itself annotated with @Qualifier.
They are, in fact, qualifier annotations in their own right.
Finally, at the injection point, you can use any combination of qualifier annotations necessary to narrow the selection to the one bean that meets your specifications.
To arrive at the IceCream bean, the setDessert() method can be annotated like this:
By defining custom qualifier annotations, you’re able to use multiple qualifiers together with no limitations or complaints from the Java compiler.
Also, your custom annotations are more type-safe than using the raw @Qualifier annotation and specifying the qualifier as a String.
Take a closer look at the setDessert() method and how it’s annotated.
Nowhere do you explicitly say that you want that method to be autowired with the IceCream bean.
It just so happens that in your current selection of Dessert implementations, the IceCream bean is the single matching candidate.
In this section and the previous section, we explored a couple of ways to extend Spring with custom annotations.
To create a custom conditional annotation, you create a new annotation and annotate it with @Conditional.
And to create a custom qualifier annotation, you can create a new annotation and annotate it with @Qualifier.
Now let’s take a moment to see how you can declare beans to be created in different scopes.
By default, all beans created in the Spring application context are created as singletons.
That is to say, no matter how many times a given bean is injected into other beans, it’s always the same instance that is injected each time.
The cost of instantiating and garbagecollecting instances of objects that are only used for small tasks can’t be justified when an object is stateless and can be reused over and over again in an application.
But sometimes you may find yourself working with a mutable class that does maintain some state and therefore isn’t safe for reuse.
In that case, declaring the class as a singleton bean probably isn’t a good idea because that object can be tainted and create unexpected problems when reused later.
Spring defines several scopes under which a bean can be created, including the following:
Singleton scope is the default scope, but as we’ve discussed, it isn’t ideal for mutable types.
For example, if you’re relying on component-scanning to discover and declare a bean, then you can annotate the bean class with @Scope to make it a prototype bean:
And, in the event that you’re configuring the bean in XML, you can set the scope using the scope attribute of the <bean> element:
Regardless of how you specify prototype scope, an instance of the bean will be created each and every time it’s injected into or retrieved from the Spring application context.
In a web application, it may be useful to instantiate a bean that’s shared within the scope of a given request or session.
For instance, in a typical e-commerce application, you may have a bean that represents the user’s shopping cart.
If the shopping cart bean is a singleton, then all users will be adding products to the same cart.
On the other hand, if the shopping cart is prototype-scoped, then products added to the cart in one area of the application may not be available in another part of the application where a different prototype-scoped shopping cart was injected.
In the case of a shopping cart bean, session scope makes the most sense, because it’s most directly attached to a given user.
To apply session scope, you can use the @Scope annotation in a way similar to how you specified prototype scope:
This tells Spring to create an instance of the ShoppingCart bean for each session in a web application.
There will be multiple instances of the ShoppingCart bean, but only one will be created for a given session and it will essentially be a singleton as far as that session is concerned.
This attribute addresses a problem encountered when injecting a session- or requestscoped bean into a singleton-scoped bean.
But before I explain proxyMode, let’s look at a scenario that presents the problem that proxyMode addresses.
Suppose you want to inject the ShoppingCart bean into the following setter method on a singleton StoreService bean:
Because StoreService is a singleton bean, it will be created as the Spring application context is loaded.
As it’s created, Spring will attempt to inject ShoppingCart into the setShoppingCart() method.
But the ShoppingCart bean, being session scoped, doesn’t exist yet.
There won’t be an instance of ShoppingCart until a user comes along and a session is created.
Moreover, there will be many instances of ShoppingCart: one per user.
You don’t want Spring to inject just any single instance of ShoppingCart into StoreService.
You want StoreService to work with the ShoppingCart instance for whichever session happens to be in play when StoreService needs to work with the shopping cart.
Instead of injecting the actual ShoppingCart bean into StoreService, Spring should inject a proxy to the ShoppingCart bean, as illustrated in listing 3.2
This proxy will expose the same methods as ShoppingCart so that for all StoreService knows, it is the shopping cart.
But when StoreService calls methods on ShoppingCart, the proxy will lazily resolve it and delegate the call to the actual session-scoped ShoppingCart bean.
Now let’s take this understanding of scoped proxies and discuss the proxyMode attribute.
This is fine (and the most ideal proxy mode) as long as ShoppingCart is an interface and not a class.
But if ShoppingCart is a concrete class, there’s no way Spring can create an interface-based proxy.
Instead, it must use CGLib to generate a class-based proxy.
Although I’ve focused on session scope, know that request-scoped beans pose the same wiring challenges as session-scoped beans.
Therefore, request-scoped beans should also be injected as scoped proxies.
Figure 3.1 Scoped proxies enable deferred injection of request- and session-scoped beans.
If you’re declaring your session-scoped or request-scoped beans in XML, then you can’t use the @Scope annotation or its proxyMode attribute.
To set the proxy mode, you must use a new element from Spring’s aop namespace:
In order to use the <aop:scoped-proxy> element, you must declare Spring’s aop namespace in your XML configuration:
We’ll talk more about Spring’s aop namespace in chapter 4 when you work with Spring and aspect-oriented programming.
For now, let’s wrap up this chapter by looking at one more of Spring’s advanced wiring options: Spring Expression Language.
When we talk about dependency injection and wiring, we’re often talking about wiring a bean reference into a property or constructor argument of another bean.
But another side to bean wiring is when you wire a value into a bean property or into its constructor as an argument.
You did a lot of value wiring in chapter 2, such as.
For example, you might have wired up a BlankDisc like this:
Although this accomplished what you needed, setting the title and artist for the BlankDisc bean, it did so with values hard-coded in the configuration class.
Likewise, if you had done this in XML, the values would have also been hard-coded:
Other times, however, you may want to avoid hard-coded values and let the values be determined at runtime.
For those cases, Spring offers two ways of evaluating values at runtime:
You’ll soon see that the application of these two techniques is similar, although their purposes and behavior are different.
Let’s start with a look at property placeholders, the simpler of the two, and then dig into the more powerful SpEL.
The simplest way to resolve external values in Spring is to declare a property source and retrieve the properties via the Spring Environment.
For example, the following listing shows a basic Spring configuration class that uses external properties to wire up a BlankDisc bean.
In this example, @PropertySource references a file named app.properties in the classpath.
This properties file is loaded into Spring’s Environment, from which it can be retrieved later.
Meanwhile, in the disc() method, a new BlankDisc is created; its constructor arguments are resolved from the properties file by calling getProperty()
The first two forms of getProperty() always return a String value.
You saw how to use the first form in listing 3.7
But you can tweak the @Bean method slightly to work with default values if the specified properties don’t exist:
The second two forms of getProperty() work much like the first two, but they recognize that not all values may be Strings.
For example, suppose you’re retrieving a value representing the number of connections to maintain in a connection pool.
If you receive a String value from the properties file, then you’ll need to convert it to an Integer before you can use it.
But using one of the overloaded getProperty() methods handles that conversion for you:
If you use either of the getProperty() methods without specifying a default value, you’ll receive null if the property isn’t defined.
If you want to check for the existence of a property, you can call containsProperty() on Environment:
Digressing a bit from the subject of properties, Environment also offers some methods for checking which profiles are active:
You saw how to use the acceptsProfiles() method in listing 3.6
In that case, Environment was retrieved from ConditionContext, and the acceptsProfiles() method was used to ensure that a given bean’s profile was in play before allowing the bean to be created.
You often won’t need the profile-focused methods from Environment, but it’s good to know that they’re available.
Retrieving properties directly from Environment is handy, especially when you’re wiring beans in Java configuration.
But Spring also offers the option of wiring properties with placeholder values that are resolved from a property source.
As shown here, the title constructor argument is given a value that’s resolved from the property whose name is disc.title.
And the artist argument is wired with the value of the property whose name is disc.artist.
Instead, the values are resolved from a source external to the configuration file.
We’ll talk about how those properties are resolved in a moment.)
When relying on component-scanning and autowiring to create and initialize your application components, there’s no configuration file or class where you can specify the placeholders.
In the BlankDisc class, for example, the constructor might be written like this:
Resolving external properties is one way to defer value resolution until runtime, but its focus is finely tuned on resolving properties, by name, from Spring’s Environment and property sources.
Spring Expression Language, on the other hand, offers a more general way of calculating values for injection at runtime.
Spring 3 introduced Spring Expression Language (SpEL), a powerful yet succinct way of wiring values into a bean’s properties or constructor arguments using expressions that are evaluated at runtime.
Using SpEL, you can pull off amazing feats of bean wiring that would be much more difficult (or in some cases impossible) using other wiring techniques.
SpEL has a lot of tricks up its sleeves, including the following:
As you’ll see later in this book, SpEL can also be used for purposes other than dependency injection.
Spring Security, for example, supports defining security constraints using SpEL expressions.
And if you’re using Thymeleaf templates as the views in your Spring MVC application, those templates can use SpEL expressions to reference model data.
To get started, let’s consider a few examples of SpEL expressions and see how to wire them into beans.
Then we’ll take a deeper dive into some of SpEL’s primitive expressions that can be pieced together into more powerful expressions.
A FEW SPEL EXAMPLES SpEL is such a flexible expression language that it would be impossible to show you all the ways it can be used in the space allowed in this book.
But there is enough room to show you a few basic examples from which you can draw inspiration for your own expressions.
Of course, you’re not likely to use such a simple expression in a real application.
You’re more likely to build up more interesting expressions, such as this one:
Ultimately this expression evaluates to the current time in milliseconds at the moment when the expression is evaluated.
SpEL expressions can also refer to other beans or properties on those beans.
For example, the following expression evaluates to the value of the artist property on a bean whose ID is sgtPeppers:
You can also refer to system properties via the systemProperties object:
But first, let’s consider how you might use these expressions during bean wiring.
Rather than use a placeholder expression, however, you use a SpEL expression.
For example, here’s what the BlankDisc constructor might look like, drawing the album title and artist from system properties:
For example, here’s the XML declaration of the BlankDisc bean that has its constructor arguments set from a SpEL expression:
Now that we’ve looked at a few simple examples and how to inject values resolved from SpEL expressions, let’s go over some of the primitive expressions supported in SpEL.
But it can also be used for floating-point numbers, String values, and Boolean values.
Here’s an example of a SpEL expression that is a floating-point value:
A SpEL expression can also evaluate literal String values, such as.
Finally, Boolean literals true and false are evaluated to their Boolean value.
After all, you don’t need SpEL to set an integer property to 1 or a Boolean property to false.
I admit there’s not much use in SpEL expressions that only contain literal values.
But remember that more interesting SpEL expressions are composed of simpler expressions, so it’s good to know how to work with literal values in SpEL.
You’ll eventually need them as you compose more complex expressions.
For example, you could use SpEL to wire one bean into another bean’s property by using the bean ID as the SpEL expression (in this case, a bean whose ID is sgtPeppers):
Now let’s say that you want to refer to the artist property of the sgtPeppers bean in an expression:
The first part of the expression body refers to the bean whose ID is sgtPeppers.
What follows the period delimiter is a reference to the artist property.
In addition to referencing a bean’s properties, you can also call methods on a bean.
For example, suppose you have another bean whose ID is artistSelector.
You can call that bean’s selectArtist() method in a SpEL expression like this:
You can also call methods on the value returned from the invoked method.
For example, if selectArtist() returns a String, you can call toUpperCase() to make the entire artist name uppercase lettering:
This will work fine, as long as selectArtist() doesn’t return null.
Instead of a lonely dot (.) to access the toUpperCase() method, now you’re using the ?
This operator makes sure the item to its left isn’t null before accessing the thing on its right.
So, if selectArtist() returns null, then SpEL won’t even try to invoke toUpperCase()
For example, to express Java’s Math class in SpEL, you need to use the T() operator like this:
The result of the T() operator, as shown here, is a Class object that represents java.lang.Math.
You can even wire it into a bean property of type Class, if you want.
But the real value of the T() operator is that it gives you access to static methods and constants on the evaluated type.
For example, suppose you need to wire the value of pi into a bean property.
Similarly, static methods can be invoked in the type resolved with the T() operator.
As a simple example of using one of these operators, consider the following SpEL expression:
Not only is this a great example of using SpEL’s multiplication operator (*), but it also shows how you can compose simpler expressions into a more complex expression.
Here the value of pi is multiplied by 2, and that result is multiplied by the value of the radius property of a bean whose ID is circle.
Essentially, it evaluates to the circumference of the circle defined in the circle bean.
Similarly, you can use the carat symbol (^) in an expression to calculate a circle’s area:
In this case, it’s used to calculate the square of the circle’s radius.
When working with String values, the + operator performs concatenation, just as in Java:
SpEL also offers comparison operators for comparing values in an expression.
Notice in table 3.1 that the comparison operators come in two forms: symbolic and textual.
For the most part, the symbolic operators are equivalent to their textual counterparts, and you’re welcome to use whichever one suits you best.
For example, to compare two numbers for equality, you can use the double-equal (==) operator:
The expression evaluates to a Boolean: true if counter.total is equal to 100 or false if it’s not.
SpEL also offers a ternary operator that works much like Java’s ternary operator.
A common use of the ternary operator is to check for a null value and offer a default value in place of the null.
For example, the following expression evaluates to the value of disc.title if it isn’t null.
This expression is commonly referred to as the Elvis operator.
This strange name comes from using the operator as an emoticon, where the question mark appears to form the shape of Elvis Presley’s hair style.2
SpEL supports pattern matching in expressions with its matches operator.
The matches operator attempts to apply a regular expression (given as its rightside argument) against a String value (given as the left-side argument)
But you gotta admit—it does kinda look like Elvis’s hair.
To demonstrate, suppose you want to check whether a String contains a valid email address.
Exploring the mysteries of the enigmatic regular-expression syntax is outside the scope of this book.
And I realize that the regular expression given here isn’t robust enough to cover all scenarios.
But for the purposes of showing off the matches operator, it’ll have to suffice.
The most basic thing you can do is reference a single element from a list:
This evaluates to the title property of the fifth (zero-based) element from the songs collection property on the bean whose ID is jukebox.
To spice things up a bit, I suppose you could randomly select a song from the jukebox:
As it turns out, the [] operator used to fetch an indexed element from a collection or array can also be used to fetch a single character from a String.
This references the fourth (zero-based) character in the String, or s.
SpEL also offers a selection operator (.?[]) to filter a collection into a subset of.
As a demonstration, suppose you want a list of all songs in the jukebox where the artist property is Aerosmith.
The following expression uses the selection operator to arrive at the list of available Aerosmith songs:
As you can see, the selection operator accepts another expression within its square brackets.
As SpEL iterates over the list of songs, it evaluates that expression for each entry in the songs collection.
If the expression evaluates to true, then the entry is carried over into the new collection.
In this case, the inner expression checks to see if the song’s artist property equals Aerosmith.
To demonstrate, consider this expression, which finds the first song in the list whose artist property is Aerosmith:
Finally, SpEL offers a projection operator (.![]) to project properties from the elements in the collection onto a new collection.
As an example, suppose you don’t want a collection of the song objects, but a collection of all the song titles.
The following expression projects the title property into a new collection of Strings:
Naturally, the projection operator can be combined with any of SpEL’s other operators, including the selection operator.
For example, you could use this expression to obtain a list of all of Aerosmith’s songs:
We’ve only scratched the surface of what SpEL can do.
There will be more opportunities to tinker with SpEL throughout this book, especially when defining security constraints.
For now, however, let me wrap up this discussion of SpEL with a warning.
SpEL expressions are handy and powerful ways to dynamically inject values into Spring beans.
It can be tempting to get crafty and write very involved expressions.
But take care not to get too clever with your expressions.
The more clever your expressions become, the more important it will be to test them.
Ultimately, SpEL expressions are given as String values and can be difficult to test.
For that reason, I encourage you to keep your expressions simple so that testing isn’t as big a concern.
In doing so, we’ve built on the foundational bean-wiring techniques explored in chapter 2 with some powerful advanced wiring tricks.
We started by using Spring profiles to address a common problem where Spring beans must vary across deployment environments.
Profiled beans are one way to conditionally create beans at runtime, but Spring 4 offers a more generic way to declare beans that are created (or not created) depending on the outcome of a given condition.
The @Conditional annotation, paired with an implementation of Spring’s Condition interface, offers developers a powerful and flexible mechanism for conditionally creating beans.
We also looked at two techniques for resolving autowiring ambiguity: primary beans and qualifiers.
Although designating a bean as a primary bean is simple, it’s also limited, so we discussed using qualifiers to narrow the list of autowire candidates to a single bean.
In addition, you saw how to create custom qualifier annotations that describe a bean by its traits.
Although most Spring beans are created as singletons, there are times when other creation strategies are more appropriate.
Out of the box, Spring allows beans to be created as singletons, prototypes, request-scoped, or session-scoped.
Finally, we looked at the Spring Expression Language, which gives you a way to resolve values to be injected into bean properties at runtime.
With a strong foundation in bean wiring established, we’ll now turn our attention to aspect-oriented programming (AOP)
Much as dependency injection helps decouple components from the other components they collaborate with, AOP helps decouple your application components from tasks that span multiple components in an application.
In the next chapter, we’ll dig into creating and working with aspects in Spring.
As I’m writing this chapter, summertime is upon Texas (where I reside)
And in Texas, it’s very common to go through several days of record-high temperatures.
But the downside of air conditioning is that it uses electricity, and electricity costs money.
There’s little we can do to avoid paying for a cool and comfortable home.
That’s because every home has a meter that measures every kilowatt, and once a month someone comes by to read that meter so that the electric company knows how much to bill us.
Now imagine what would happen if the meter went away and nobody came by to measure our electricity usage.
Suppose it was up to each homeowner to contact the electric company and report their electricity usage.
Although it’s possible that some obsessive homeowners would keep careful records of how much they used their lights, televisions, and air conditioning, most wouldn’t bother.
Electricity on the honor system might be great for consumers, but it would be less than ideal for the electric companies.
Monitoring electricity consumption is an important function, but it isn’t foremost in most homeowners’ minds.
Mowing the lawn, vacuuming the carpet, and cleaning the bathroom are the kinds of things that homeowners are actively involved in.
Monitoring the amount of electricity used by their house is a passive event from the homeowner’s point of view.
Although it’d be great if mowing the lawn was also a passive event—especially on these hot days.)
Some functions of software systems are like the electric meters on our homes.
The functions need to be applied at multiple points within the application, but it’s undesirable to explicitly call them at every point.
In software development, functions that span multiple points of an application are called cross-cutting concerns.
Typically, these cross-cutting concerns are conceptually separate from (but often embedded directly within) the application’s business logic.
Separating these cross-cutting concerns from the business logic is where aspectoriented programming (AOP) goes to work.
In chapter 2, you learned how to use dependency injection to manage and configure application objects.
Whereas DI helps you decouple application objects from each other, AOP helps you decouple cross-cutting concerns from the objects they affect.
Logging is a common example of the application of aspects, but it’s not the only thing aspects are good for.
Throughout this book, you’ll see several practical applications of aspects, including declarative transactions, security, and caching.
This chapter explores Spring’s support for aspects, including how to declare regular classes to be aspects and how to use annotations to create aspects.
But first, before we get carried away with transactions, security, and caching, let’s see how aspects are implemented in Spring, starting with a primer on a few of AOP’s fundamentals.
In short, a crosscutting concern can be described as any functionality that affects multiple points of an application.
Security, for example, is a cross-cutting concern, in that many methods in an application can have security rules applied to them.
This figure represents a typical application that’s broken down into modules.
Each module’s main concern is to provide services for its particular domain.
But each module also requires similar ancillary functionality, such as security and transaction management.
A common object-oriented technique for reusing common functionality is to apply inheritance or delegation.
But inheritance can lead to a brittle object hierarchy if the same base class is used throughout an application, and delegation can be cumbersome because complicated calls to the delegate object may be required.
Aspects offer an alternative to inheritance and delegation that can be cleaner in many circumstances.
With AOP, you still define the common functionality in one place, but you can declaratively define how and where this functionality is applied without having to modify the class to which you’re applying the new feature.
Crosscutting concerns can now be modularized into special classes called aspects.
First, the logic for each concern is in one place, as opposed to being scattered all over the code base.
Second, your service modules are cleaner because they only contain code for their primary concern (or core functionality), and secondary concerns have been moved to aspects.
Aspects are often described in terms of advice, pointcuts, and join points.
Unfortunately, many of the terms used to describe AOP features aren’t intuitive.
Nevertheless, they’re now part of the AOP idiom, and in order to understand AOP, you must know these terms.
Before you walk the walk, you have to learn to talk the talk.
Sure, he has a list of houses that he must visit, and the information he reports is important.
But the actual act of recording electricity usage is the meter reader’s main job.
Likewise, aspects have a purpose—a job they’re meant to do.
In AOP terms, the job of an aspect is called advice.
Advice defines both the what and the when of an aspect.
In addition to describing the job that an aspect will perform, advice addresses the question of when to perform.
Figure 4.1 Aspects modularize crosscutting concerns, applying logic that spans multiple application objects.
Figure 4.2 An aspect’s functionality (advice) is woven into a program’s execution at one or more join points.
Before—The advice functionality takes place before the advised method is invoked.
After—The advice functionality takes place after the advised method completes, regardless of the outcome.
After-throwing—The advice functionality takes place after the advised method throws an exception.
Around—The advice wraps the advised method, providing some functionality before and after the advised method is invoked.
Each house has an electric meter that needs to be read, so each house is a potential target for the meter reader.
The meter reader could potentially read all kinds of devices, but to do her job, she needs to target electric meters that are attached to houses.
In the same way, your application may have thousands of opportunities for advice to be applied.
A join point is a point in the execution of the application where an aspect can be plugged in.
This point could be a method being called, an exception being thrown, or even a field being modified.
These are the points where your aspect’s code can be inserted into the normal flow of your application to add new behavior.
Instead, each one is assigned a subset of all the houses to visit.
Likewise, an aspect doesn’t necessarily advise all join points in an application.
Pointcuts help narrow down the join points advised by an aspect.
If advice defines the what and when of aspects, then pointcuts define the where.
A pointcut definition matches one or more join points at which advice should be woven.
Often you specify these pointcuts using explicit class and method names or through regular expressions that define matching class and method name patterns.
Some AOP frameworks allow you to create dynamic pointcuts that determine whether to apply advice based on runtime decisions, such as the value of method parameters.
Thus he knows everything he needs to know to get his job done.
Taken together, advice and pointcuts define everything there is to know about an aspect—what it does and where and when it does it.
For example, you could create an Auditable advice class that keeps the state of when an object was last modified.
The new method and instance variable can then be introduced to existing classes without having to change them, giving them new behavior and state.
The aspects are woven into the target object at the specified join points.
The weaving can take place at several points in the target object’s lifetime:
Compile time—Aspects are woven in when the target class is compiled.
Class load time—Aspects are woven in when the target class is loaded into the JVM.
This requires a special ClassLoader that enhances the target class’s bytecode before the class is introduced into the application.
AspectJ 5’s load-time weaving (LTW) support weaves aspects this way.
Runtime—Aspects are woven in sometime during the execution of the application.
Typically, an AOP container dynamically generates a proxy object that delegates to the target object while weaving in the aspects.
That’s a lot of new terms to get to know.
Revisiting figure 4.1, you can now see how advice contains the cross-cutting behavior that needs to be applied to an application’s objects.
The join points are all the points within the execution flow of the application that are candidates to have advice applied.
The pointcut defines where (at what join points) that advice is applied.
The key concept you should take from this is that pointcuts define which join points get advised.
Now that you’re familiar with some basic AOP terminology, let’s see how these core AOP concepts are implemented in Spring.
They may differ in how rich their join point models are.
Some allow you to apply advice at the field-modification level, whereas others only expose the join points related to method invocations.
They may also differ in how and when they weave the aspects.
Whatever the case, the ability to create pointcuts that define the join points at which aspects should be woven is what makes it an AOP framework.
Because this is a Spring book, we’ll focus on Spring AOP.
Even so, there’s a lot of synergy between the Spring and AspectJ projects, and the AOP support in Spring borrows a lot from the AspectJ project.
The first three styles are all variations on Spring’s own AOP implementation.
Classic cars, classic golf tournaments, and classic Coca-Cola are all good things.
But now Spring supports much cleaner and easier ways to work with aspects.
When held up against simple declarative AOP and annotation-based AOP, Spring’s classic AOP seems bulky and overcomplicated.
With Spring’s aop namespace, you can turn pure POJOs into aspects.
In truth, those POJOs will only supply methods that are called in reaction to a pointcut.
Unfortunately, this technique requires XML configuration, but it’s an easy way to declaratively turn any object into an aspect.
Under the covers, it’s still Spring’s proxy-based AOP, but the programming model is almost identical to writing full-blown AspectJ annotated aspects.
The perk of this AOP style is that it can be done without any XML configuration.
If your AOP needs exceed simple method interception (constructor or property interception, for example), you’ll want to consider implementing aspects in AspectJ.
In that case, the fourth style listed will enable you to inject values into AspectJ-driven aspects.
We’ll explore more of these Spring AOP techniques in this chapter.
But before we get started, it’s important to understand a few key points of Spring’s AOP framework.
That way, you get the benefit of developing your aspects in the same integrated development environment (IDE) you’d use for normal Java development.
The pointcuts that define where advice should be applied may be specified with annotations or configured in a Spring XML configuration, but either will be familiar to Java developers.
Although AspectJ now supports annotation-based aspects, it also comes as a language extension to Java.
By having an AOP-specific language, you get more power and fine-grained control, as well as a richer AOP toolset.
But you’re required to learn a new tool and syntax to accomplish this.
As illustrated in figure 4.3, the proxy class poses as the target bean, intercepting advised method calls and forwarding those calls to the target bean.
Between the time when the proxy intercepts the method call and the time when it invokes the target bean’s method, the proxy performs the aspect logic.
Spring doesn’t create a proxied object until that proxied bean is needed by the application.
Because Spring creates proxies at runtime, you don’t need a special compiler to weave aspects in Spring’s AOP.
Because it’s based on dynamic proxies, Spring only supports method join points.
This is in contrast to some other AOP frameworks, such as AspectJ and JBoss, which provide field and constructor join points in addition to method pointcuts.
Spring’s lack of field pointcuts prevents you from creating very fine-grained advice, such as intercepting updates to an object’s field.
And without constructor pointcuts, there’s no way to apply advice when a bean is instantiated.
But method interception should suit most, if not all, of your needs.
If you find yourself in need of more than method interception, you’ll want to complement Spring AOP with AspectJ.
Now you have a general idea of what AOP does and how it’s supported by Spring.
It’s time to get your hands dirty creating aspects in Spring.
As mentioned before, pointcuts are used to pinpoint where an aspect’s advice should be applied.
Along with an aspect’s advice, pointcuts are among the most fundamental elements of an aspect.
In Spring AOP, pointcuts are defined using AspectJ’s pointcut expression language.
If you’re already familiar with AspectJ, then defining pointcuts in Spring should feel.
TargetCaller Figure 4.3 Spring aspects are implemented as proxies that wrap the target object.
The proxy handles method calls, performs additional aspect logic, and then invokes the target method.
But in case you’re new to AspectJ, this section will serve as a quick lesson on writing AspectJ-style pointcuts.
The most important thing to know about AspectJ pointcuts as they pertain to Spring AOP is that Spring only supports a subset of the pointcut designators available in AspectJ.
Recall that Spring AOP is proxy-based, and certain pointcut expressions aren’t relevant to proxy-based AOP.
Table 4.1 lists the AspectJ pointcut designators that are supported in Spring AOP.
As you browse through the supported designators, note that the execution designator is the only one that actually performs matches.
This means execution is the primary designator you’ll use in every pointcut definition you write.
You’ll use the other designators to constrain the pointcut’s reach.
To demonstrate aspects in Spring, you need something to be the subject of the aspect’s pointcuts.
Table 4.1 Spring uses AspectJ’s pointcut expression language to define Spring aspects.
Performance represents any kind of live performance, such as a stage play, a movie, or a concert.
Let’s say that you want to write an aspect that triggers off Performance’s perform() method.
Figure 4.4 shows a pointcut expression that can be used to apply advice whenever the perform() method is executed.
You use the execution() designator to select Performance’s perform() method.
The method specification starts with an asterisk, which indicates that you don’t care what type the method returns.
Then you specify the fully qualified class name and the name of the method you want to select.
For the method’s parameter list, you use the double dot (..), indicating that the pointcut should select any perform() method, no matter what the argument list is.
Now let’s suppose that you want to confine the reach of that pointcut to only the concert package.
In that case, you can limit the match by tacking on a within() designator, as shown in figure 4.5
And the ! operator can be used to negate the effect of a designator.
Because ampersands have special meaning in XML, you’re free to use and in place of && when specifying pointcuts in a Spring XML-based configuration.
Figure 4.4 Selecting Performance’s perform() method with an AspectJ pointcut expression.
When the method is called from within any class in the concert package.
Figure 4.5 Limiting a pointcut’s reach by using the within() designator.
In addition to the designators listed in table 4.1, Spring adds a bean() designator that lets you identify beans by their ID in a pointcut expression.
Here you’re saying that you want to apply aspect advice to the execution of Performance’s perform() method, but limited to the bean whose ID is woodstock.
Narrowing a pointcut to a specific bean may be valuable in some cases, but you can also use negation to apply an aspect to all beans that don’t have a specific ID:
In this case, the aspect’s advice will be woven into all beans whose ID isn’t woodstock.
Now that we’ve covered the basics of writing pointcuts, let’s see how to write the.
A key feature introduced in AspectJ 5 is the ability to use annotations to create aspects.
Prior to AspectJ 5, writing AspectJ aspects involved learning a Java language extension.
You’ve already defined the Performance interface as the subject of your aspect’s pointcuts.
Or is it? When you think about it from the perspective of a performance, an audience is important but isn’t central to the function of the performance itself; it’s a separate concern.
Therefore, it makes sense to define the audience as an aspect that’s applied to a performance.
The following listing shows the Audience class that defines the aspect you’ll need.
Listing 4.1 Audience class: an aspect that watches a performance.
This annotation indicates that Audience isn’t just any POJO—it’s an aspect.
And throughout the Audience class are methods that are annotated to define the specifics of the aspect.
Audience has four methods that define things an audience might do as it observes a performance.
If the performance goes well, the audience should applaud (applause())
But if the performance fails to meet the audience’s expectations, then the audience should demand a refund (demandRefund())
As you can see, those methods are annotated with advice annotations to indicate when those methods should be called.
AspectJ provides five annotations for defining advice, as listed in table 4.2
The Audience class makes use of three out of the five advice annotations.
The applause() method is annotated with @AfterReturning so that it will be called.
Table 4.2 Spring uses AspectJ annotations to declare advice methods.
After The advice method is called after the advised method returns or throws an exception.
AfterReturning The advice method is called after the advised method returns.
AfterThrowing The advice method is called after the advised method throws an exception.
Before The advice method is called before the advised method is called.
And the @AfterThrowing annotation is placed on demandRefund() so that it will be called if any exceptions are thrown during a performance.
You’ve probably noticed that all of these annotations are given a pointcut expression as a value.
And you may have noticed that it’s the same pointcut expression on all four methods.
They could each be given a different pointcut expression, but this particular pointcut suits your needs for all the advice methods.
Taking a closer look at the pointcut expression given to the advice annotations, you’ll see that it triggers on the execution of the perform() method on a Performance.
It’s a shame that you had to repeat that same pointcut expression four times.
It’d be nice if you could define the pointcut once and then reference it every time you need it.
The next listing shows the Audience aspect, updated to use @Pointcut.
The value given to the @Pointcut annotation is a pointcut expression, just like the ones you used previously with the advice annotations.
By annotating performance() with @Pointcut in this way, you essentially extend the pointcut expression language so that you can use performance() in your pointcut expressions anywhere you’d otherwise use the longer expression.
As you can see, you replace the longer expression in all the advice annotations with performance()
The body of the performance() method is irrelevant and, in fact, should be empty.
The method itself is just a marker, giving the @Pointcut annotation something to attach itself to.
Note that aside from the annotations and the no-op performance() method, the Audience class is essentially a POJO.
Its methods can be called just like methods on any other Java class.
Its methods can be individually unit-tested just as in any other Java class.
Audience is just another Java class that happens to be annotated to be used as an aspect.
And, just like any other Java class, it can be wired as a bean in Spring:
If you were to stop here, Audience would only be a bean in the Spring container.
Even though it’s annotated with AspectJ annotations, it wouldn’t be treated as an aspect without something that interpreted those annotations and created the proxies that turn it into an aspect.
The following configuration class shows how to enable auto-proxying in JavaConfig.
The XML configuration in the following listing shows how this is done.
Whether you use JavaConfig or XML, AspectJ auto-proxying uses the @Aspectannotated bean to create a proxy around any other beans for which the aspect’s pointcuts are a match.
In this case, a proxy will be created for the Concert bean, with the advice methods in Audience being applied before and after the perform() method.
It’s important to understand that Spring’s AspectJ auto-proxying only uses @AspectJ annotations as a guide for creating proxy-based aspects.
This is significant because it means that although you’re using @AspectJ annotations, you’re still limited to proxying method invocations.
If you want to be able to exploit the full power of AspectJ, you’ll have to use the AspectJ runtime and not rely on Spring to create proxy-based aspects.
At this point, your aspect is defined using distinct advice methods for before and after advice.
But table 4.2 mentions another kind of advice: around advice.
Around advice is just different enough from the other advice types that it’s worth spending a moment seeing how to write it.
It allows you to write logic that completely wraps the advised method.
It’s essentially like writing both before advice and after advice in a single advice method.
This time you’ll use a single around advice method instead of distinct before and after advice methods.
Here the @Around annotation indicates that the watchPerformance() method is to be applied as around advice to the performance() pointcut.
In this advice, the audience will silence their cell phones and take their seats before the performance and will applaud after the performance.
And just like before, if an exception is thrown during the performance, the audience will ask for their money back.
As you can see, the effect of this advice is identical to what you did earlier with before and after advice.
But here it’s all in a single advice method, whereas before it was spread across four distinct advice methods.
This object is necessary because it’s how you can invoke the advised method from within your advice.
Note that it’s crucial that you remember to include a call to the proceed() method.
If you don’t, then your advice will effectively block access to the advised method.
Maybe that’s what you want, but chances are good that you do want the advised method to be executed at some point.
What’s also interesting is that just as you can omit a call to the proceed() method to block access to the advised method, you can also invoke it multiple times from within the advice.
One reason for doing this may be to implement retry logic to perform repeated attempts on the advised method should it fail.
So far, your aspects have been simple, taking no parameters.
Other than that, the advice you’ve written hasn’t bothered to look at any parameters passed to the advised methods.
That’s been okay, though, because the perform() method you were advising didn’t take any parameters.
To illustrate, let’s revisit the BlankDisc class from section 2.4.4
As it is, the play() method cycles through all the tracks and calls playTrack() for each track.
But you could call the playTrack() method directly to play an individual track.
Suppose you want to keep a count of how many times each track is played.
One way to do this is to change the playTrack() method to directly keep track of that count each time it’s called.
But track-counting logic is a separate concern from playing a track and therefore doesn’t belong in the playTrack() method.
To keep a running count of how many times a track is played, let’s create TrackCounter, an aspect that advises playTrack()
Listing 4.6 Using parameterized advice to count how many times a track is played.
What’s different here, however, is that the pointcut also declares parameters to be supplied to the advice method.
Figure 4.6 breaks down the pointcut expression to show where the parameter is specified.
The thing to focus on in the figure is the args(trackNumber) qualifier in the pointcut expression.
This indicates that any int argument that is passed into the execution of playTrack() should also be passed into the advice.
The parameter name, trackNumber, also matches the parameter in the pointcut method signature.
The parameter in the pointcut aligns with the parameter of the same name in the pointcut method, completing the path of the parameter from the named pointcut to the advice method.
Now you can configure BlankDisc and TrackCounter as beans in the Spring configuration and enable AspectJ auto-proxying, as shown next.
Listing 4.7 Configuring TrackCounter to count the number of times a track is played.
Figure 4.6 Declaring a parameter in a pointcut expression that’s to be passed into an advice method.
Finally, to prove that this all works, you can write the following simple test.
It plays a few tracks and then asserts the play count through the TrackCounter bean.
The aspects you’ve worked with thus far wrap existing methods on the advised object.
But method wrapping is just one of the tricks that aspects can perform.
Let’s see how to write aspects that introduce completely new functionality into an advised object.
Some languages, such as Ruby and Groovy, have the notion of open classes.
They make it possible to add new methods to an object or class without directly changing the definition of those objects or classes.
Once a class has been compiled, there’s little you can do to append new functionality to it.
But if you think about it, isn’t that what you’ve been doing in this chapter with aspects? Sure, you haven’t added any new methods to objects, but you’re adding new functionality around the methods that the objects already have.
If an aspect can wrap existing methods with additional functionality, why not add new methods to the object? In fact, using an AOP concept known as introduction, aspects can attach new methods to Spring beans.
Recall that in Spring, aspects are proxies that implement the same interfaces as the beans they wrap.
What if, in addition to implementing those interfaces, the proxy is also exposed through some new interface? Then any bean that’s advised by the aspect will appear to implement the new interface, even if its underlying implementation class doesn’t.
Figure 4.7 With Spring AOP, you can introduce new methods to a bean.
A proxy intercepts the calls and delegates to a different object that provides the implementation.
Notice that when a method on the introduced interface is called, the proxy delegates the call to some other object that provides the implementation of the new interface.
Effectively, this gives you one bean whose implementation is split across multiple classes.
Putting this idea to work, let’s say you want to introduce the following Encoreable interface to any implementation of Performance:
Setting aside any debates as to whether Encoreable is a real word, you need a way to apply this interface to your Performance implementations.
I suppose you could visit all implementations of Performance and change them so that they also implement Encoreable.
But from a design standpoint, that may not be the best move.
Moreover, it may not be possible to change all implementations of Performance, especially if you’re working with thirdparty implementations and don’t have the source code.
Fortunately, AOP introductions can help you without compromising design choices or requiring invasive changes to the existing implementations.
But unlike the aspects you’ve created so far, it doesn’t provide before, after, or around advice.
Instead, it introduces the Encoreable interface to Performance beans using the @DeclareParents annotation.
The value attribute identifies the kinds of beans that should be introduced with the interface.
In this case, that’s anything that implements the Performance interface.
The plus sign at the end specifies any subtype of Performance, as opposed to Performance itself.)
The defaultImpl attribute identifies the class that will provide the implementation for the introduction.
The static property that is annotated by @DeclareParents specifies the interface that’s to be introduced.
When Spring discovers a bean annotated with @Aspect, it will automatically create a proxy that delegates calls to either the proxied bean or to the introduction implementation, depending on whether the method called belongs to the proxied bean or to the introduced interface.
Annotations and auto-proxying provide a convenient programming model for creating aspects in Spring.
And to do that, you must have the source code.
When you don’t have the source code, or if you don’t want to place AspectJ annotations in your code, Spring offers another option for aspects.
Let’s see how you can declare aspects in a Spring XML configuration file.
Early in this book, I established a preference for annotation-based configuration over Java-based configuration, and Java-based configuration over XML configuration.
But if you need to declare aspects without annotating the advice class, then you must turn to XML configuration.
Spring’s aop namespace offers several elements that are useful for declaring aspects in XML, as described in table 4.3
Table 4.3 Spring’s AOP configuration elements enable non-invasive declaration of aspects.
But the other elements in the aop namespace let you declare aspects directly in your Spring configuration without using annotations.
For example, let’s have another look at the Audience class.
As you can see, without the AspectJ annotations, there’s nothing remarkable about the Audience class.
It’s a basic Java class with a handful of methods.
And you can register it as a bean in the Spring application context like any other class.
Despite its unassuming appearance, what’s remarkable about Audience is that it has all the makings of AOP advice.
It just needs a little help to become the advice it’s meant to be.
You could put back all the AspectJ annotations, but that isn’t the point of this section.
Instead, you’ll use some of the elements from Spring’s aop namespace to turn the annotation-free Audience into an aspect.
Table 4.3 Spring’s AOP configuration elements enable non-invasive declaration of aspects.
The first thing to notice about the Spring AOP configuration elements is that most of them must be used in the context of the <aop:config> element.
There are a few exceptions to this rule, but when it comes to declaring beans as aspects, you’ll always start with <aop:config>
In <aop:config>, you may declare one or more advisers, aspects, or pointcuts.
The ref attribute references the POJO bean that will be used to supply the functionality of the aspect—in this case, audience.
The bean that’s referenced by the ref attribute will supply the methods called by any advice in the aspect.
It’s worth noting that the referenced advice bean can be any type that provides methods to be called at the designated pointcuts.
This makes Spring’s XML configuration for AOP a handy way to use types defined in third-party libraries as advice, even though you can’t annotate them with AspectJ aspects.
Figure 4.8 shows how the advice logic is woven into the business logic.
In all advice elements, the pointcut attribute defines the pointcut where the advice will be applied.
The value given to the pointcut attribute is a pointcut defined in AspectJ’s pointcut expression syntax.
Listing 4.9 Annotation-free Audience class, declared in XML as an aspect.
You’ve probably noticed that the value of the pointcut attribute is the same for all the advice elements.
That’s because all the advice is being applied to the same pointcut.
When you found the same kind of duplication in your AspectJ-annotated advice, you eliminated it by using the @Pointcut annotation.
For XML-based aspect declarations, however, you’ll need to use the <aop:pointcut> element.
The following XML shows how to extract the common pointcut expression into a single pointcut declaration that can be used across all advice elements.
Figure 4.8 The Audience aspect includes four bits of advice that weave advice logic around methods that match the aspect’s pointcut.
Now the pointcut is defined in a single location and is referenced across multiple advice elements.
The <aop:pointcut> element defines the pointcut to have an id of performance.
Meanwhile, all the advice elements have been changed to reference the named pointcut with the pointcut-ref attribute.
Specifically, it’s tricky to share information between before advice and after advice without resorting to storing that information in member variables.
For example, suppose that in addition to putting away cell phones and applauding at the end, you also want the audience to keep their eyes on their watches and report how long the performance takes.
The only way to accomplish this with before and after advice is to note the start time in before advice and report the length of time in after advice.
But you’d have to store the start time in a member variable.
Because Audience is a singleton, it wouldn’t be thread-safe to retain state like that.
Around advice has an advantage over before and after advice in this regard.
With around advice, you can accomplish the same thing you could with distinct before and after advice, but you can do it in a single method.
Because the entire set of advice takes place in a single method, there’s no need to retain state in a member variable.
For example, consider the new annotation-free Audience class with a single watchPerformance() method.
In the case of the audience aspect, the watchPerformance() method contains all the functionality of the previous four advice methods.
But all of it is contained in this single method, and this method is responsible for its own exception handling.
Declaring around advice isn’t dramatically different from declaring other types of advice.
All you need to do is use the <aop:around> element, as shown next.
As with the other advice XML elements, <aop:around> is given a pointcut and the name of an advice method.
Here you’re using the same pointcut as before, but you set the method attribute to point to the new watchPerformance() method.
In section 4.3.3, you used AspectJ annotations to create an aspect that kept a running count of the number of times tracks were played on a CompactDisc.
Now that you’re configuring your aspects in XML, let’s see how you can accomplish the same thing.
First, let’s strip all the @AspectJ annotations out of the TrackCounter.
And as it stands now, TrackCounter won’t count any tracks unless you explicitly call the countTrack() method.
But with a little XML Spring configuration, you can reinstate TrackCounter’s status as an aspect.
The following listing shows the complete Spring configuration that declares both the TrackCounter bean and the BlankDisc bean and enables TrackCounter as an aspect.
Listing 4.14 Configuring TrackCounter as a parameterized aspect in XML.
As you can see, you’re using the same XML elements from the aop namespace as before; they declare a POJO to be treated as an aspect.
The only significant difference is that your pointcut expression now includes a parameter to be passed into the advice method.
If you compare this expression with the one from listing 4.6, you’ll see that they’re almost identical.
The only real difference is that here you use the and keyword instead of && (because ampersands are interpreted as the beginning of an entity in XML)
Now that you’ve exercised Spring’s aop namespace to declare a few basic aspects in XML, let’s see how the aop namespace can help you declare introduction aspects.
The following snippet of XML is equivalent to the AspectJ-based introduction you created earlier:
The final matter to settle is where the implementation of the Encoreable’s methods will come from.
There are two ways to identify the implementation of the introduced interface.
In this case, you’re using the default-impl attribute to explicitly identify the implementation by its fully qualified class name.
The delegate-ref attribute refers to a Spring bean as the introduction delegate.
This assumes that a bean with an ID of encoreableDelegate exists in the Spring context:
The difference between directly identifying the delegate using default-impl and indirectly using delegate-ref is that the latter will be a Spring bean that itself may be injected, advised, or otherwise configured through Spring.
Although Spring AOP is sufficient for many applications of aspects, it’s a weak AOP solution when contrasted with AspectJ.
AspectJ offers many types of pointcuts that aren’t possible with Spring AOP.
Constructor pointcuts, for example, are convenient when you need to apply advice on the creation of an object.
Unlike constructors in some other object-oriented languages, Java constructors are different from normal methods.
This makes Spring’s proxy-based AOP woefully inadequate for advising the creation of an object.
For the most part, AspectJ aspects are independent of Spring.
Although they can be woven into any Java-based application, including Spring applications, there’s little involvement on Spring’s part in applying AspectJ aspects.
But any well-designed and meaningful aspect will likely depend on other classes to assist in its work.
If an aspect depends on one or more classes when executing its advice, you can instantiate those collaborating objects with the aspect itself.
Or, better yet, you can use Spring’s dependency injection to inject beans into AspectJ aspects.
Specifically, let’s create an aspect that plays the role of a critic who watches a performance and provides a critical review afterward.
The chief responsibility for CriticAspect is to comment on a performance after the performance has completed.
The performance() pointcut in listing 4.15 matches the perform() method.
When it’s married with the afterReturning() advice, you get an aspect that reacts to the completion of a performance.
What makes listing 4.15 interesting is that the critic doesn’t make commentary on its own.
Instead, CriticAspect collaborates with a CriticismEngine object, calling its getCriticism() method, to produce critical commentary after a performance.
To avoid unnecessary coupling between CriticAspect and CriticismEngine, CriticAspect is given a reference to CriticismEngine through setter injection.
CriticismEngine is an interface that declares a simple getCriticism() method.
This class can be declared as a Spring <bean> using the following XML:
Spring can inject AspectJ aspects with dependencies just as if they were another bean.
You now have a CriticismEngine implementation to give to CriticAspect.
Before I show you how to do the injection, you should know that AspectJ aspects can be woven into your application without involving Spring at all.
But if you want to use Spring’s dependency injection to inject collaborators into an AspectJ aspect, you’ll need to declare the aspect as a <bean> in Spring’s configuration.
The following <bean> declaration injects the criticismEngine bean into CriticAspect:
The big difference is the use of the factory-method attribute.
Normally, Spring beans are instantiated by the Spring container, but AspectJ aspects are created by the AspectJ runtime.
By the time Spring gets a chance to inject CriticismEngine into CriticAspect, CriticAspect has already been instantiated.
Because Spring isn’t responsible for the creation of CriticAspect, it isn’t possible to declare CriticAspect as a bean in Spring.
Instead, you need a way for Spring to get a handle to the CriticAspect instance that has already been created by AspectJ so that you can inject it with a CriticismEngine.
Conveniently, all AspectJ aspects provide a static aspectOf() method that returns the singleton instance of the aspect.
So to get an instance of the aspect, you must use factory-method to invoke the aspectOf() method instead of trying to call CriticAspect’s constructor.
Instead, Spring retrieves a reference to the aspect through the aspectOf() factory method and then performs dependency injection on it as prescribed by the <bean> element.
With aspects, you can group application behavior that was once spread throughout your applications into reusable modules.
You can then declare exactly where and how this behavior is applied.
This reduces code duplication and lets your classes focus on their main functionality.
Spring provides an AOP framework that lets you insert aspects around method executions.
You’ve learned how to weave advice before, after, and around a method invocation, as well as to add custom behavior for handling exceptions.
You have several choices in how you can use aspects in your Spring applications.
Wiring advice and pointcuts in Spring is much easier with the addition of @AspectJ annotation support and a simplified configuration schema.
Finally, there are times when Spring AOP isn’t enough, and you must turn to AspectJ for more powerful aspects.
For those situations, we looked at how to use Spring to inject dependencies into AspectJ aspects.
At this point, we’ve covered the basics of the Spring Framework.
You’ve seen how to configure the Spring container and how to apply aspects to Spring-managed objects.
These core techniques offer you a great opportunity to create applications composed of loosely coupled objects.
Now we’ll move past the essentials and look at what it takes to build real applications in Spring.
Starting in the next chapter, you’ll see how to build web applications using Spring.
Therefore, in part 2 you’ll see how to use Spring’s MVC framework to add a web front end to your application.
You’ll discover how to write controllers to handle web requests and see how to transparently bind request parameters and payload to your business objects while providing validation and error handling at the same time.
As an enterprise Java developer, you’ve likely developed a web-based application or two.
For many Java developers, web-based applications are their primary focus.
If this is your experience, then you’re well aware of the challenges that come with these systems.
Specifically, state management, workflow, and validation are all important features that need to be addressed.
None of these is made any easier given the HTTP protocol’s stateless nature.
Spring’s web framework is designed to help you address these concerns.
In this chapter, we’ll explore the essentials of Spring’s MVC web framework.
We’ll focus on using annotations to create controllers that handle various kinds of web requests, parameters, and form input.
Have you ever seen the children’s game Mousetrap? It’s crazy.
The goal is to send a small steel ball through a series of wacky contraptions in order to trigger a mousetrap.
The ball navigates all kinds of intricate gadgets, from rolling down a curvy ramp to springing off a teeter-totter to spinning on a miniature Ferris wheel to being kicked out of a bucket by a rubber boot.
It goes through all this to spring a trap on a poor, unsuspecting plastic mouse.
At first glance, you may think that Spring’s MVC framework is a lot like Mousetrap.
Instead of moving a ball through various ramps, teeter-totters, and wheels, Spring moves requests between a dispatcher servlet, handler mappings, controllers, and view resolvers.
But don’t draw too strong a comparison between Spring MVC and the Rube Goldberg-esque game of Mousetrap.
Each of the components in Spring MVC performs a specific purpose.
Let’s take a look at how a request makes its way from the client through the components in Spring MVC, ultimately resulting in a request that goes back to the client.
Every time a user clicks a link or submits a form in their web browser, a request goes to work.
Just like a postal carrier or a FedEx delivery person, a request lives to carry information from one place to another.
From the time it leaves the browser until it returns with a response, it makes several stops, each time dropping off a bit of information and picking up some more.
Figure 5.1 shows all the stops the request makes as it travels through Spring MVC.
When the request leaves the browser B, it carries information about what the user is asking for.
At the least, the request will be carrying the requested URL.
But it may also carry additional data, such as the information submitted in a form by the user.
Figure 5.1 A request couriers information to several stops on its way to producing the desired results.
The first stop in the request’s travels is at Spring’s DispatcherServlet.
Like most Javabased web frameworks, Spring MVC funnels requests through a single front controller servlet.
A front controller is a common web application pattern where a single servlet delegates responsibility for a request to other components of an application to perform actual processing.
In the case of Spring MVC, DispatcherServlet is the front controller.
A controller is a Spring component that processes the request.
But a typical application may have several controllers, and DispatcherServlet needs some help deciding which controller to send the request to.
So the DispatcherServlet consults one or more handler mappings C to figure out where the request’s next stop will be.
The handler mapping pays particular attention to the URL carried by the request when making its decision.
Once an appropriate controller has been chosen, DispatcherServlet sends the request on its merry way to the chosen controller D.
At the controller, the request drops off its payload (the information submitted by the user) and patiently waits while the controller processes that information.
Actually, a well-designed controller performs little or no processing itself and instead delegates responsibility for the business logic to one or more service objects.)
The logic performed by a controller often results in some information that needs to be carried back to the user and displayed in the browser.
But sending raw information back to the user isn’t sufficient—it needs to be formatted in a user-friendly format, typically HTML.
For that, the information needs to be given to a view, typically a JavaServer Page (JSP)
One of the last things a controller does is package up the model data and identify the name of a view that should render the output.
It then sends the request, along with the model and view name, back to the DispatcherServlet E.
So that the controller doesn’t get coupled to a particular view, the view name passed back to DispatcherServlet doesn’t directly identify a specific JSP.
It doesn’t even necessarily suggest that the view is a JSP.
Instead, it only carries a logical name that will be used to look up the actual view that will produce the result.
The DispatcherServlet consults a view resolver F to map the logical view name to a specific view implementation, which may or may not be a JSP.
Now that DispatcherServlet knows which view will render the result, the request’s job is almost over.
Its final stop is at the view implementation G, typically a JSP, where it delivers the model data.
As you can see, a request goes through several steps along its way to producing a response for the client.
Most of these steps take place within the Spring MVC framework, in the components shown in figure 5.1
Although the bulk of this chapter will focus on writing controllers, let’s take a moment to set up the essential components of Spring MVC.
Based on figure 5.1, it looks like there are a lot of moving parts to be configured.
Fortunately, thanks to some advancements in the most recent versions of Spring, it’s easy to get started with Spring MVC.
For now, you’ll take the simplest approach to configuring Spring MVC: you’ll do just enough configuring to be able to run the controllers you create.
In chapter 7, we’ll look at some additional setup options.
It’s where the request first hits the framework, and it’s responsible for routing the request through all the other components.
Historically, servlets like DispatcherServlet have been configured in a web.xml file that’s carried in the web application’s WAR file.
And it’s not the option we’ll go with in this chapter.
Instead of a web.xml file, you’re going to use Java to configure DispatcherServlet in the servlet container.
Before we dive into the details of listing 5.1, you may wonder what the word spittr has to do with anything.
I’ll explain that in a moment (in section 5.1.3), but for now, suffice it to say that the application you’ll create is named Spittr.
In this case, it’s mapped to /, indicating that it will be the application’s default servlet.
A TALE OF TWO APPLICATION CONTEXTS When DispatcherServlet starts up, it creates a Spring application context and starts loading it with beans declared in the configuration files or classes that it’s given.
But in Spring web applications, there’s often another application context.
These beans are typically the middle-tier and data-tier components that drive the back end of the application.
You’ll see what those two configuration classes look like in a moment.
You’ll have no choice but to configure DispatcherServlet in web.xml.
We’ll look at web.xml and other configuration options in chapter 7
For now, though, let’s look at WebConfig and RootConfig, the two configuration classes referred to in listing 5.1, and see how to enable Spring MVC.
But for now, you’ll keep your Spring MVC setup simple and Java-based.
The very simplest Spring MVC configuration you can create is a class annotated with @EnableWebMvc:
Consequently, the only way Spring will find any controllers is if you declare them explicitly in the configuration.
As it is, DispatcherServlet is mapped as the default servlet for the application and will handle all requests, including requests for static resources, such as images and stylesheets (which is probably not what you want in most cases)
Therefore, you need to add a bit more configuration in WebConfig on top of this bare minimum Spring MVC configuration to make it useful.
The new WebConfig in the next listing addresses these concerns.
Listing 5.2 A minimal yet useful configuration for Spring MVC.
As you’ll soon see, the controllers you write will be annotated with @Controller, which will make them candidates for component-scanning.
Consequently, you won’t have to explicitly declare any controllers in the configuration class.
For now, just know that it’s configured to look for JSP files by wrapping view names with a specific prefix and suffix (for example, a view name of home will be resolved as /WEB-INF/ views/home.jsp)
With WebConfig settled, what about RootConfig? Because this chapter is focused on web development, and web configuration is done in the application context created by DispatcherServlet, you’ll keep RootConfig relatively simple for now:
The only significant thing to note in RootConfig is that it’s annotated with @ComponentScan.
There will be plenty of opportunities throughout this book to flesh out RootConfig with non-web components.
You’re almost ready to start building a web application with Spring MVC.
The big question at this point is what application you’ll build.
In an attempt to get in on the online social networking game, you’re going to develop a simple microblogging application.
In many ways, your application will be much like the original microblogging application, Twitter.
You’ll add some little twists on the idea along the way.
Borrowing some ideas from Twitter and implementing them in Spring gives the application a working title: Spitter.
Taking it a step further and applying a naming pattern that’s popular with sites like Flickr, let’s drop the e and call the app Spittr.
This name will also be helpful in differentiating the application name from a domain type you’ll create called Spitter.
The Spittr application has two essential domain concepts: spitters (the users of the application) and spittles (the brief status updates that users publish)
We’ll draw primarily on these two domain concepts throughout this book as we flesh out the functionality of the Spittr application.
Initially, in this chapter, you’ll build out the web layer of the application, create controllers that display spittles, and process forms where users register as spitters.
You’ve configured DispatcherServlet, enabled essential Spring MVC components, and established a target application.
Let’s turn to the meat of the chapter: handling web requests with Spring MVC controllers.
In Spring MVC, controllers are just classes with methods that are annotated with @RequestMapping to declare the kind of requests they’ll handle.
Starting simple, let’s imagine a controller class that handles requests for / and renders the application’s home page.
HomeController, shown in the following listing, is an example of what might be the simplest possible Spring MVC controller class.
The first thing you’ll notice about HomeController is that it’s annotated with @Controller.
Although it’s clear that this annotation declares a controller, the annotation has little to do with Spring MVC.
Controller is a stereotype annotation, based on the @Component annotation.
Its purpose here is entirely for the benefit of component-scanning.
Because HomeController is annotated with @Controller, the component scanner will automatically pick up HomeController and declare it as a bean in the Spring application context.
Listing 5.3 HomeController: an example of an extremely simple controller.
You could have annotated HomeController with @Component, and it would have had the same effect, but it would have been less expressive about what type of component HomeController is.
HomeController’s only method, the home() method, is annotated with @RequestMapping.
The value attribute specifies the request path that this method will handle, and the method attribute details the HTTP method that it can handle.
In this case, whenever an HTTP GET request comes in for /, the home() method will be called.
As you can see, the home() method doesn’t do much: it returns a String value of “home”
This String will be interpreted by Spring MVC as the name of the view that will be rendered.
DispatcherServlet will ask the view resolver to resolve this logical view name into an actual view.
For now, you’ll keep the Spittr application’s home page rather basic, as shown next.
It merely welcomes the user to the application and offers two links: one to view a Spittle list and another to register with the application.
Figure 5.2 shows what the home page looks like at this point.
Before this chapter is complete, you’ll have implemented the controller methods to handle those requests.
But for now, let’s throw some requests at this controller and see if it works.
The obvious way to test a controller may be to build and deploy the application and poke at it with a web browser, but an automated test will give you quicker feedback and more consistent hands-off results.
Listing 5.4 Spittr home page, defined as a simple JSP.
Therefore, you can test HomeController by writing a simple test like the following.
Although the test in listing 5.5 is straightforward, it only tests what happens in the home() method.
It calls home() directly and asserts that a String containing the value “home” is returned.
It completely fails to test what makes that method a Spring MVC controller method.
Nothing about the test asserts that home() will be called when a GET request for / comes in.
And just because it returns “home”, there’s nothing to truly test that home is the name of the view.
Starting with Spring 3.2, however, you have a way to test Spring MVC controllers as controllers, not merely as POJOs.
This will enable you to test your controllers without firing up a web server or web browser.
To demonstrate proper testing of a Spring MVC controller, you can rewrite HomeControllerTest to take advantage of the new Spring MVC testing features.
Even though this new version of the test is a few lines longer than its predecessor, it more completely tests HomeController.
Rather than call home() directly and test its return value, this test issues a GET request for / and asserts that the resulting view is named home.
Then it asks the MockMvc instance to perform a GET request for / and sets an expectation for the view name.
Now that you have a test around HomeController, you can do a bit of refactoring to be certain that nothing breaks.
One thing you can do is split up @RequestMapping by placing the path-mapping portion of it at the class level.
In this new version of HomeController, the path has been moved up to a new classlevel @RequestMapping, whereas the HTTP method is still mapped at the method level.
Any time there’s a class-level @RequestMapping on a controller class, it applies to all handler methods in the controller.
In the case of HomeController, there’s only one handler method.
You’ve moved a few things around, but HomeController still does the same thing as before.
Because you have a test, you can be sure you haven’t broken anything along the way.
While you’re tinkering with the @RequestMapping annotations, you can make another tweak to HomeController.
The value attribute of @RequestMapping accepts an array of String.
So far, you’ve only given it a single String value of “/”
But you can also map it to requests whose path is /homepage by changing the class-level @RequestMapping to look like this:
Now HomeController’s home() method is mapped to handle GET requests for both / and /homepage requests.
As it stands now, HomeController is a great example of how to write an extremely simple controller.
In the Spittr application, you’ll need a page that displays a list of the most recent spittles that have been submitted.
Therefore, you’ll need a new method to serve such a page.
First you need to define a repository for data access.
For decoupling purposes, and so you don’t get bogged down in database specifics, you’ll define the repository as an interface now and create an implementation of it later (in chapter 10)
At the moment, you only need a repository that can fetch a list of the spittles.
The max parameter is a Spittle ID that represents the maximum ID of any Spittle that should be returned.
As for the count parameter, it indicates how many Spittle objects to return.
In order to get the 20 most recent Spittle objects, you can call findSpittles() like this:
You’ll keep the Spittle class fairly simple for now, as shown next.
It will have properties to carry a message, a timestamp, and the latitude/longitude of the location from which the spittle was posted.
Listing 5.8 Spittle class: carries a message, a timestamp, and a location.
For the most part, Spittle is a basic POJO data object—nothing complicated.
The only thing to note is that you’re using Apache Commons Lang for easy implementation of the equals() and hashCode() methods.
Aside from the general utility value of those methods, they’ll be valuable in writing a test for the controller handler method.
While we’re on the subject of testing, let’s go ahead and write a test for the new controller method.
The following listing uses Spring’s MockMvc to assert the behavior you want in the new handler method.
Listing 5.9 Testing that SpittleController handles GET requests for /spittles.
This test starts by creating a mock implementation of the SpittleRepository interface that will return a list of 20 Spittle objects from its findSpittles() method.
It then injects that repository into a new SpittleController instance and sets up MockMvc to use that controller.
This is so the mock framework won’t try to resolve the view name coming from the controller on its own.
But for this controller method, the view name will be similar to the request’s path; left to its default view resolution, MockMvc will fail because the view path will be confused with the controller’s path.
The test wraps up by performing a GET request for /spittles and asserting that the view name is spittles and that the model has an attribute named spittleList with the expected contents.
Of course, if you ran the test at this point, it would fail.
It wouldn’t just fail to run; it would fail to compile.
Let’s create a SpittleController so that it satisfies the expectations of the test in listing 5.9
Here’s an implementation of SpittleController that should satisfy the test.
Listing 5.10 SpittleController: places a list of recent spittles in the model.
As you can see, SpittleController has a constructor that’s annotated with @Autowired to be given a SpittleRepository.
That SpittleRepository is then used in the spittles() method to fetch a list of recent spittles.
Notice that the spittles() method is given a Model as a parameter.
This is so that spittles() can populate the model with the Spittle list it retrieves from the repository.
The Model is essentially a map (that is, a collection of key-value pairs) that will be handed off to the view so that the data can be rendered to the client.
When addAttribute() is called without specifying a key, the key is inferred from the type of object being set as the value.
In this case, because it’s a List<Spittle>, the key will be inferred as spittleList.
The last thing spittles() does is return spittles as the name of the view that will render the model.
If you’d prefer to be explicit about the model key, you’re welcome to specify it.
For example, the following version of spittles() is equivalent to the one in listing 5.10:
Likewise, if you’d prefer to work with a non-Spring type, you can ask for a java .util.Map instead of Model.
Here’s another version of spittles() that’s functionally equivalent to the others:
And while we’re on the subject of alternate implementations, here’s another way to write the spittles() method:
This version is quite a bit different from the others.
Rather than return a logical view name and explicitly setting the model, this method returns the Spittle list.
When a handler method returns an object or a collection like this, the value returned is put into the model, and the model key is inferred from its type (spittleList, as in the other examples)
As for the logical view name, it’s inferred from the request path.
Because this method handles GET requests for /spittles, the view name is spittles (chopping off the leading slash)
No matter which way you choose to write the spittles() method, the result is the same.
A list of Spittle objects is stored in the model with a key of spittleList and given to the view whose name is spittles.
Now that there’s data in the model, how does the JSP access it? As it turns out, when the view is a JSP, the model data is copied into the request as request attributes.
Therefore, the spittles.jsp file can use JavaServer Pages Standard Tag Library’s (JSTL) <c:forEach> tag to render the list of spittles:
Figure 5.3 will help you visualize how this might look in your web browser.
Although SpittleController is simple, it’s still a step up from what you wrote in.
One thing that neither HomeController nor SpittleController does, however, is handle any form of input.
Let’s expand on SpittleController to take some input from the client.
Humans poke about on the website in their web browser, reading whatever content the server sends to the browser.
The good news is that it doesn’t have to be that way.
Many web applications give the user an opportunity to chime in and send data back to the server.
Without this capability, the web would be a very different place.
Spring MVC provides several ways that a client can pass data into a controller’s handler method.
You’ll see how to write controllers to handle input using all of these mechanisms.
For a start, let’s look at handling requests with query parameters, the simplest and most straightforward way to send data from the client to the server.
One thing that your Spittr application will need to do is display a paged list of spittles.
As it is, SpittleController only displays the most recent spittles; it offers no way to page back through the history of the spittles that have been written.
If you’re going to let users go through spittle history a page at a time, you’ll need to offer a way for them to pass in parameters that determine which set of spittles to display.
In deciding how to do this, consider that if you’re viewing a page of spittles, it’s ordered with the most recent spittle first.
Therefore, the first spittle on the next page should have an ID that is before the ID of the last spittle on the current page.
So, in order to display the next page of spittles, you should be able to pass in a spittle ID that is just less than the ID of the last spittle on the current page.
You can also pass in a parameter saying how many spittles to display.
Figure 5.3 Spittle model data from a controller is made available as request parameters and rendered as a list on a web page.
To implement this paging solution, you’ll need to write a handler method that accepts the following:
A before parameter (which indicates the ID of the Spittle that all Spittle objects in the results are before)
A count parameter (which indicates how many spittles to include in the result)
To achieve this, let’s replace the spittles() method you created in listing 5.10 with a new spittles() method that works with the before and count parameters.
You’ll start by adding a test to reflect the functionality you want to see from the new spittles() method.
The key difference between this test method and the one in listing 5.9 is that it performs a GET request against /spittles, passing in values for the max and count parameters.
This tests the handler method when those parameters are present; the other test method tests for when those parameters are absent.
With both tests in place, you can be assured that no matter what changes you make to the controller, it will still be able to handle both kinds of requests:
If the handler method in SpittleController is going to handle requests with or without the max and count parameters, you’ll need to change it to accept those parameters.
Listing 5.11 New method to test for a paged list of spittles.
Now, if the max parameter isn’t specified, it will default to the maximum value of Long.
Because query parameters are always of type String, the defaultValue attribute requires a String value.
Even though the defaultValue is given as a String, it will be converted to a Long when bound to the method’s max parameter.
The count parameter will default to 20 if the request doesn’t have a count parameter.
Query parameters are a common way to pass information to a controller in a.
Another way that’s popular, especially in a discussion of building resourceoriented controllers, is to pass parameters as part of the request path.
Let’s see how to use path variables to take input as part of the request path.
Let’s say your application needs to support the display of a single Spittle, given its ID.
One option you have is to write a handler method that accepts the ID as a query parameter using @RequestParam:
Ideally, the resource being identified (the Spittle) would be identified by the URL path, not by query parameters.
As a general rule, query parameters should not be used to identify a resource.
With the goal of resource-oriented controllers in mind, let’s capture this requirement in a test.
The following listing shows a new test method to assert resourceoriented request handling in SpittleController.
As you can see, this test sets up a mock repository, a controller, and MockMvc, much like the other tests you’ve written in this chapter.
The most important part of the test is in the last few lines, where it performs a GET request for /spittles/12345 and asserts that the view name is spittle and that the expected Spittle object is placed in the model.
Because you haven’t yet implemented the handler method for that kind of request, the request will fail.
But you can fix that by adding a new method to SpittleController.
Up to this point, all of your controller methods have been mapped (via @RequestMapping) to a statically defined path.
But if you’re going to make this test pass, you’ll need to write an @RequestMapping that has a variable portion of the path that represents the Spittle ID.
Here’s a handler method that uses placeholders to accept a Spittle ID as part of the path:
Listing 5.12 Testing a request for a Spittle with ID specified in a path variable.
This indicates that whatever value is at the placeholder position in the request path will be passed into the handler method’s spittleId parameter.
Because the method parameter name happens to be the same as the placeholder name, you can optionally omit the value parameter on @PathVariable:
If no value attribute is given for @PathVariable, it assumes the placeholder’s name is the same as the method parameter name.
This can make the code a little cleaner by not duplicating the placeholder name any more than necessary.
But be cautioned: if you decide to rename the parameter, you must also change the placeholder name to match.
The spittle() method will pass the parameter along to the findOne() method on the SpittleRepository to find a single Spittle object and will add that Spittle to the model.
The model key will be spittle, inferred by the type passed in to addAttribute()
The data in the Spittle object can then be rendered in the view by referring to the request attribute whose key is spittle (the same as the model key)
Here’s a snippet of a JSP view that renders the Spittle:
There’s nothing flashy about this view, as you can see from the screenshot in figure 5.4
Query parameters and path parameters are fine for passing small amounts of data.
But often you need to pass a lot of data (perhaps data coming from a form submission), and query parameters are too awkward and limited for that.
Let’s see how you can write controller methods that handle form submissions.
Web applications typically do more than just push content out to the user.
Most also let users participate in the conversation by filling out forms and submitting data back into the application.
Spring MVC controllers are well-suited for form processing as well as serving content.
There are two sides to working with forms: displaying the form and processing the data the user submits from the form.
In the Spittr application, you’ll need a form for new users to register with the application.
SpitterController is a new controller with a single request-handling method for displaying the registration form.
Listing 5.13 SpitterController: displays a form for users to sign up with the app.
It’s a simple method, taking no input and only returning a logical view named registerForm.
Because it’s a simple method, its test will be equally simple.
This test method is very similar to the test for the home page controller method.
It performs a GET request for /spitter/register and then asserts that the resulting view is named registerForm.
Because the view name is registerForm, you’ll need a JSP named registerForm.jsp.
This JSP must include an HTML <form> where the user will enter information to sign up with the application.
It has HTML form fields to capture the user’s first name, last name, a username, and a password, as well as a button to submit the form.
Rendered in the browser, it looks a little something like figure 5.5
Notice that the <form> tag doesn’t have an action parameter set.
Because of that, when this form is submitted, it will be posted back to the same URL path that displayed it.
That means you’ll need something back on the server to handle the HTTP POST request.
Let’s add another method to SpitterController to handle form submission.
When processing the POST request from the registration form, the controller needs to accept the form data and save the form data as a Spitter object.
Finally, in order to prevent a duplicate submission (such as might happen if the user clicked their browser’s Refresh button), it should redirect the browser to the newly created user’s profile page.
Figure 5.5 The registration page offers a form that will be processed by SpitterController to add a new user to the application.
Clearly, this test is more involved than the test for displaying the registration form.
As part of that POST request, user information is passed as parameters on the request to simulate a form being submitted.
When handling a POST request, it’s usually a good idea to send a redirect after the POST has completed processing so that a browser refresh won’t accidentally submit the form a second time.
This test expects that the request will end in a redirect to /spitter /jbauer, the URL path of the new user’s profile page.
Finally, the test verifies that the mocked SpitterRepository was actually used to save the data coming in on the form.
Now let’s implement the controller method that will handle this form submission test.
But as you can see in the new SpitterController in this listing, there’s not much to it.
Listing 5.17 Handling form submission to register a new user.
This object has firstName, lastName, username, and password properties that will be populated from the request parameters of the same name.
But this view specification is different from what you’ve seen before.
Rather than just return a view name and let the view resolver sort it out, here you’re returning a redirect specification.
In this case, it will redirect to the path for a user’s profile page.
For example, if the Spitter .username property is jbauer, then the view will redirect to /spitter/jbauer.
When it sees a view specification prefixed with forward:, the request is forwarded to the given URL path instead of redirected.
Because you’re redirecting to the user’s profile page, you should probably add a handler method to SpitterController to handle requests for the profile page.
It adds the Spitter to the model and then returns profile, the logical view name for the profile view.
Like all the other views presented in this chapter, you’ll keep the profile view simple for now:
Figure 5.6 shows the profile page as rendered in a web browser.
What will happen if the form doesn’t send a username or password parameter? Or.
If the user were to leave the username or password field empty when submitting the form, it could result in the creation of a new Spitter object whose username and password were empty Strings.
Figure 5.6 The Spittr profile page displays a user’s information, as populated into the model by SpitterController.
Also, you should take steps to prevent the user from submitting an empty firstName and/or lastName in an effort to maintain some level of anonymity.
And it’s probably a good idea to limit the length of the values given in those fields, keeping them at a reasonable size and avoiding misuse of the fields.
It’s a short method, so tossing in a few extra if statements won’t do much harm.
Rather than litter your handler methods with validation logic, however, you can take advantage of Spring’s support for the Java Validation API (a.k.a.
No extra configuration is required to make Java Validation work in Spring MVC.
You just need to make sure an implementation of the Java API, such as Hibernate Validator, is in the project’s classpath.
The Java Validation API defines several annotations that you can put on properties to place constraints on the values of those properties.
AssertFalse The annotated element must be a Boolean type and be false.
AssertTrue The annotated element must be a Boolean type and be true.
DecimalMax The annotated element must be a number whose value is less than or equal to a given BigDecimalString value.
DecimalMin The annotated element must be a number whose value is greater than or equal to a given BigDecimalString value.
Digits The annotated element must be a number whose value has a specified number of digits.
Future The value of the annotated element must be a date in the future.
Max The annotated element must be a number whose value is less than or equal to a given value.
Min The annotated element must be a number whose value is greater than or equal to a given value.
NotNull The value of the annotated element must not be null.
Null The value of the annotated element must be null.
Past The value of the annotated element must be a date in the past.
Pattern The value of the annotated element must match a given regular expression.
In addition to the annotations in table 5.1, Java Validation API implementations may provide additional validation annotations.
But for our purposes, we’ll focus on a couple of the core constraint validations from the table.
All you need to do is toss those annotations around on the properties of Spitter.
The next listing shows Spitter with its properties annotated for validation.
All the properties of Spitter are now annotated with @NotNull to ensure that they aren’t left null.
Similarly, the @Size annotation is placed on the properties to constrain them between minimum and maximum lengths.
Size The value of the annotated element must be either a String, a collection, or an array whose length fits within the given range.
Listing 5.18 SpittleForm: carries only fields submitted in a SpittlePOST request.
The Spitter parameter is now annotated with @Valid to indicate to Spring that the command object has validation constraints that should be enforced.
Just having validation constraints on the Spitter’s properties won’t prevent the form from being submitted.
This will take the user’s browser back to the registration form so they can correct any problems and try again.
For now, the blank form will be displayed, but in the next chapter, you’ll adapt the form to show the values that were originally submitted and communicate validation problems to the user.
If there are no errors, the Spitter is saved via the repository, and the controller redirects to the profile page as before.
In this chapter, you’ve made a good start on the web portion of your application.
As you’ve seen, Spring comes with a powerful and flexible web framework.
Employing annotations, Spring MVC offers a near-POJO development model, making simple work of developing controllers that handle requests and are easy to test.
When it comes to writing controller handler methods, Spring MVC is extremely flexible.
As a rule of thumb, if your handler method needs something, then it should ask for that object as a parameter.
Likewise, anything it doesn’t need should be left out of the parameter list.
This leads to infinite possibilities in request handling, while maintaining a simple programming model.
Although much of this chapter focused on request handling with controllers, response rendering is also important.
We briefly looked at how to write views for your controllers using JSPs.
But there’s more to Spring MVC views than the basic JSPs you wrote in this chapter.
Coming up in chapter 6, we’ll dig deeper into Spring views, expanding on how you can take advantage of Spring tag libraries in JSP.
You’ll also see how to add consistent layouts to your views using Apache Tiles.
And we’ll look at Thymeleaf, an exciting alternative to JSP that comes with built-in Spring support.
In the previous chapter, we primarily focused on writing the controllers that handle web requests.
You also created some simple views to render the model data produced by those controllers, but we didn’t spend too much time discussing the views or what happens between the time a controller finishes handling a request and the time the results are displayed in the user’s web browser.
None of the methods in the controllers you wrote in chapter 5 directly produce the HTML that is rendered in the browser.
Instead, they populate the model with some data and then pass the model off to a view for rendering.
Those methods return a String value that is the logical name of the view but that doesn’t directly refer to a specific view implementation.
Although you wrote a few simple JavaServer Page (JSP) views, nothing in the controllers is aware of that fact.
Decoupling request-handling logic in the controller from the view-rendering of a view is an important feature of Spring MVC.
If the controller methods were directly responsible for producing HTML, it would be difficult to maintain and update the view without getting your hands dirty in request-handling logic.
At most, the controller methods and view implementations should agree on the contents of the model; apart from that, they should keep an arms-length distance from each other.
But if the controller only knows about the view by a logical view name, how does Spring determine which actual view implementation it should use to render the model? That’s a job for Spring’s view resolvers.
It was configured to apply a prefix of /WEB-INF/views/ and a suffix of .jsp to a view name to arrive at the physical location of the JSP that would render the model.
Now let’s take a step back and look at view resolution in general and some of the other view resolvers that Spring offers.
Spring MVC defines an interface named ViewResolver that looks a little something like this:
The resolveViewName() method, when given a view name and a Locale, returns a View instance.
The View interface’s job is to take the model, as well as the servlet request and response objects, and render output into the response.
All you need to do is start writing implementations of ViewResolver and View to render content into the response to be displayed in your users’ browsers.
Although you can write your own custom implementations of ViewResolver and View, and although there are some special cases where that’s necessary, typically you needn’t worry yourself with these interfaces.
I only mention them to give you some insight into how view resolution works.
Fortunately, Spring provides several out-of-the-box implementations, listed in table 6.1, that fit most circumstances.
We don’t have room in this book to cover all 13 view resolvers offered by Spring.
But that’s okay, because there are only a handful of them that you’ll ever need in most applications.
For the most part, each of the view resolvers in table 6.1 corresponds to a specific view technology available for Java web applications.
In this chapter, we’ll focus our attention on the view technologies that are most relevant to the majority of Java developers.
TilesViewResolver Resolves views as Apache Tile definitions, where the tile ID is the same as the view name.
XmlViewResolver Resolves views as bean definitions from a specified XML file.
XsltViewResolver Resolves views to be rendered as the result of an XSLT transformation.
Then we’ll try out TilesViewResolver to achieve layout control over JSP pages.
To wrap up this chapter, we’ll look at a view-resolver option that isn’t listed in table 6.1
Thymeleaf is a compelling alternative to JSP that offers a view resolver for working with Thymeleaf’s natural templates: templates that have more in common with the HTML they produce than with the Java code that drives them.
Thymeleaf is such an exciting view option that I wouldn’t blame you if you flipped a few pages ahead to section 6.4 to see how to use it with Spring.
If you’re still on this page, it’s probably because you know that JSP has been, and still is, the dominant view technology for Java.
You’ve probably used JSP on several projects before and are likely to need it again.
So let’s start with a look at how you can use JSP views with Spring MVC.
Believe it or not, JavaServer Pages has been the go-to view technology for Java-based web applications for almost 15 years.
Although it started out as an ugly, Java-centric twist on similar templating technologies (such as Microsoft’s Active Server Pages), JSP has evolved over the years to include support for an expression language and custom tag libraries.
Spring provides two JSP tag libraries, one for form-to-model binding and one providing general utility features.
Whether or not you use JSTL or intend to use Spring’s JSP tag libraries, it’s important to configure a view resolver to resolve JSP views.
But that was done in haste just so you could exercise your controllers in a web browser.
As an example, consider the simple case where the logical view name is home.
It’s a common practice to place JSP files under the web application’s WEB-INF folder to prevent direct access.
If you were to keep all your JSP files in /WEB-INF/views/, and if your home page JSP is named home.jsp, then you could derive the physical view path by prefixing the logical view name home with /WEB-INF/views/ and adding a suffix of .jsp.
When a logical view name has a slash in it, that slash is carried over into the resource path name.
Therefore, it maps to a JSP file that’s in a subdirectory of whatever directory is referenced by the prefix property.
This offers a handy way of organizing your view templates under a hierarchy of directories rather than keeping them all in a single directory.
JSTL’s formatting tags need a Locale to properly format locale-specific values such as dates and money.
And its message tags can use a Spring message source and a Locale to properly choose messages to render in HTML.
By resolving JstlView, the JSTL tags will be given the Locale and any message source configured in Spring.
Whether you use Java configuration or XML, this will ensure that JSTL’s formatting and message tags will get the Locale and message sources configured in Spring.
Tag libraries are a powerful way to bring functionality to a JSP template without resorting to writing Java code directly in scriptlet blocks.
Spring offers two JSP tag libraries to help define the view of your Spring MVC web views.
One tag library renders HTML form tags that are bound to a model attribute.
The other has a hodgepodge of utility tags that come in handy from time to time.
You’re likely to find the form-binding tag library to be the more useful of the two tag libraries.
You’ll see how to bind the Spittr application’s registration form to the model so that the form will be prepopulated and validation errors can be displayed after a failed form submission.
But what makes these different from the raw HTML tags is that they’re bound to an object in the model and can be populated with values from the model.
The tag library also includes a tag that can be used to communicate errors to the user by rendering them into the resulting HTML.
To use the form-binding tag library, you’ll need to declare it in the JSP pages that will use it:
Notice that I specified a prefix of sf, but it’s also common to use a prefix of form.
I chose sf because it’s succinct, easy to type, and an abbreviation for Spring forms.
Throughout this book, I’ll assume a prefix of sf whenever the form-binding library is used.
Once you declare the form-binding tag library, you’re afforded 14 tags.
It would be hard to cook up an example to demonstrate all of these tags, and any attempt would certainly be contrived.
For the Spittr example, you’ll only use the tags that are fitting for the Spittr application’s registration form.
Applying those tags to the registration JSP, you get the following:
Table 6.2 Spring’s form-binding tag library includes tags to bind model objects to and from rendered HTML forms.
But it also sets some context around a model object designated in the commandName attribute.
Properties on the model object will be referenced in the other form-binding tags you use.
Therefore, there must be an object in the model whose key is spitter, or else the form won’t be able to render (and you’ll get JSP errors)
That means you need to make a small change to SpitterController to ensure that a Spitter object is in the model under the spitter key:
The model key will be inferred from the object type to be spitter—exactly what you need it to be.
This tag renders an HTML <input> tag with the type attribute set to text.
Its value attribute will be set to the value of the model object’s property specified in the path attribute.
To help you visualize what the resulting HTML will look like, suppose that a user has already submitted the form with invalid values for all the fields.
After validation fails and the user is forwarded back to the registration form, the resulting HTML <form> element looks like this:
For example, you could declare the email field like this:
Using Spring’s form-binding tags gives you a slight improvement over using standard HTML tags—the form is prepopulated with the previously entered values after failed validation.
But it still fails to tell the user what they did wrong.
To guide the user in fixing their mistakes, you’ll need the <sf:errors> tag.
All you need to do is dig into the model and extract the errors to display to the user.
Even though I’m only showing you <sf:errors> as applied to the First Name field, it’s just as easy to use on all the fields in the registration form.
Here its path attribute is set to firstName, the name of the Spitter model object property for which errors should be displayed.
If there are no errors for the firstName property, then <sf:errors> won’t render anything.
But if there is a validation error, it will render that error message in an HTML <span> tag.
For example, if the user submits J as the first name, the following HTML is rendered for the First Name field:
Now you’re communicating the error to the user, and they have a chance to fix it.
You can take this a step further by changing the style of the error so that it stands out.
Again, for brevity’s sake, I’ve only shown how to set the cssClass attribute for the <sf:errors> tag whose path is firstName.
You can certainly apply it to the other fields as well.
Now the errors<span> has a class attribute set to error.
All that’s left is to define a CSS style for that class.
Here’s a simple CSS style that renders the error in red:
Figure 6.2 shows how the form might look in a web browser at this point.
Displaying validation errors next to the fields that have errors is a nice way to draw.
Another way to handle validation errors is to display them all together.
To do this, you can remove the <sf:errors> element from each field and place it at the top of the form like this:
This is a wildcard selector that tells <sf:errors> to render all errors for all properties.
Also notice that you set the element attribute to div.
By default, errors are rendered in an HTML <span> tag, which is fine when there’s only one error to display.
But when you’re rendering errors for all fields, there could easily be more than one error to display, and a <span> tag (an inline tag) is not ideal.
Therefore, you can set the element attribute to div so that errors render in a <div> tag.
As before, cssClass is set to errors so that you can style the <div>
Here’s some CSS to style the <div> with a red border and a light red background:
Now you’ve shoved all the errors to the top of the form, which may make laying out the page easier.
But you’ve lost the ability to highlight the fields that need to be corrected.
That’s easily addressed by setting the cssErrorClass attribute on each field.
You can also wrap each label with <sf:label> and set its cssErrorClass.
Here’s the First Name field with the necessary changes applied:
The <sf:label> tag, much like the other form-binding tags, has a path attribute to indicate which property of the model object it belongs to.
In this case, it’s set to firstName so it will be bound to the Spitter object’s firstName property.
Assuming there are no validation errors, this will render an HTML <label> element like this:
On its own, setting the path attribute on <sf:label> doesn’t accomplish much.
If the bound property has any errors, the rendered <label> element’s class attribute will be set to error like this:
Similarly, the <sf:input> tag now has its cssErrorClass set to error.
If there’s a validation error, the rendered <input> tag’s class attribute will be set to error.
Now you can style the label and the fields so that the user’s attention is drawn to them if there are any errors.
For example, the following CSS renders the label in red and the input field with a light red background:
Now you have a fairly nice way of presenting validation errors to the user.
There’s one more thing you can do to make those errors friendlier to read.
Revisiting the Spitter class, you can set the message attribute on the validation annotations to reference a friendly message that you’ll define in a properties file:
For each of the fields, the @Size annotation has message set to a string whose value is wrapped in curly braces.
If you left the curly braces out, the value given to message would be the error message displayed to the user.
But by using curly braces, you designate a property in a properties file that contains the actual message.
When the user submits a registration form that fails validation, they might see something like figure 6.3 in their browser.
What’s nice about extracting the error messages to a properties file is that you can display language- and locale-specific messages by creating a locale-specific properties file.
For example, to display the errors in Spanish if the user’s browser has its language.
SPRING’S GENERAL TAG LIBRARY In addition to the form-binding tag library, Spring also offers a more general JSP tag library.
In fact, this tag library was the first JSP tag library available in Spring.
It has grown a bit over the years, but it was available in the earliest versions of Spring.
To use Spring’s general tag library, you must declare it in the pages that will use it:
As with any JSP tag library, the prefix can be anything you want.
Commonly, spring is given as the prefix for this tag library.
But I prefer to use s because it’s much more succinct and easier to type and read.
Figure 6.3 Validation errors displayed with friendly error messages pulled from a properties file.
Several of the tags in table 6.3 have been made obsolete by Spring’s form-binding tag library.
The <s:bind> tag, for instance, was Spring’s original form-binding tag, and it was much more complex than the tags covered in the previous section.
Because this tag library sees a lot less action than the form-binding tags, I won’t cover each tag in detail.
Instead, I’ll quickly go over a handful of the most valuable tags and leave it to you to explore the others on your own.
Odds are good that you won’t need them often—if at all.)
There’s nothing horribly wrong with that, but it doesn’t lend itself to easily changing the text.
Moreover, there’s no way to internationalize the text so it’s tailored to the user’s language settings.
For instance, consider the welcome message on the home page:
Table 6.3 Spring’s other JSP tag library offers a handful of convenient utility tags in addition to some legacy data-binding tags.
The only way to modify that message is to open home.jsp and change it.
But spreading your application’s text across multiple templates means changing a lot of JSP files for large-scale changes of the application’s messaging.
A more significant issue is that no matter what text you choose for the welcome message, all users see the same message.
The web is a global network, and the applications you build for it are likely to have a global audience.
Therefore, it’s wise to communicate to your users in their language and not force them to use a single language.
The <s:message> tag is perfect for rendering text that’s externalized in one or more properties files.
Using <s:message>, you can replace the hard-coded welcome message with the following:
As used here, <s:message> will render the text available from a message source where the key is spittr.welcome.
Therefore, you’ll need to configure such a message source if you expect <s:message> to be able to do its job.
Spring has a handful of message-source classes, all implementing the MessageSource interface.
It loads messages from a properties file whose name is derived from a base name.
The key thing in this bean declaration is the setting of the basename property.
You can set it to any value you’d like, but here I’ve chosen to set it to messages.
The basename property can be set to look for messages in the classpath (with a classpath: prefix), in the filesystem (with a file: prefix), or at the root of the web application (with no prefix)
Here, it’s configured to look for messages in properties files in the / etc/spittr directory of the server’s filesystem and with a base filename of “messages”
If you create no other messages files, then all you’ve accomplished is extracting the hard-coded message from the JSP into a properties file as a hard-coded message.
It does give you one-stop editing for all of your application’s messages, but little more than that.
Nevertheless, the essential pieces are in place to start internationalizing the message.
Its main job is to create a URL and either assign it to a variable or render it in the response.
It’s a drop-in replacement for JSTL’s <c:url> tag, but with a few new tricks up its sleeve.
If the application’s servlet context is named spittr, then the following HTML will be rendered in the response:
This enables you to create URLs without worrying about what the servlet context path will be.
Optionally, you can have <s:url> construct the URL and assign it to a variable to be used later in the template:
But you can have <s:url> create them in application, session, or request scope instead by setting the scope attribute:
If you’d like to add parameters to the URL, you can do so with the <s:param> tag.
For instance, suppose you need to create a URL for a particular user’s profile page.
Once again, the <s:param> tag is up to the task:
When the href value is a placeholder that matches a parameter specified by <s:param>, the parameter is inserted into the placeholder’s spot.
If the <s:param> parameter doesn’t match any placeholders in href, then the parameter is used as a query parameter.
The <s:url> tag can also address any escaping needs for the URL.
For example, if you intend to render the URL to be displayed as part of the content on a web page (as opposed to being used as a hypertext link), you may want to ask <s:url> to do HTML escaping on the URL by setting the htmlEscape attribute to true.
For example, the following <s:url> tag renders an HTML-escaped URL:
Speaking of escaping, there’s another tag for escaping content other than tags.
It renders any content nested in its body, escaping as necessary.
For example, suppose you want to display a snippet of HTML code on a page.
Instead, you can use <s:escapeBody> and let Spring take care of it for you:
This renders the following to the body of the response:
Of course, even though it looks horrible in its escaped form, the browser is happy to render it as the un-escaped HTML you want the user to see.
The <s:escapeBody> tag also supports JavaScript escaping with the javaScriptEscape attribute:
Now that you’ve seen how to use JSP to define Spring views, let’s consider what would be required to make them aesthetically appealing.
There’s a lot you can do by adding common elements to the pages, such as inserting a header with a site logo, applying a stylesheet, and maybe even showing a copyright in the footer.
But rather than do that in each of the JSP files in the Spittr application, let’s see how to employ Apache Tiles to bring some common and reusable layouts to your templates.
At this point, you’ve done very little with regard to the layout of your application’s web pages.
Each JSP is fully responsible for defining its own layout, and they’re not doing much in that regard.
Suppose you want to add a common header and footer to all pages in the application.
The naive way to do this is to visit every JSP template and add the HTML for the header and footer.
But that approach doesn’t scale well with regard to maintenance.
There’s an initial cost of adding those elements to each and every page, and any future changes will incur a similar cost.
A better approach is to use a layout engine such as Apache Tiles to define a common page layout that will be applied to all pages.
Spring MVC provides support for Apache Tiles in the form of a view resolver that can resolve logical view names into tile definitions.
In order to use Tiles with Spring, you’ll have to configure a couple of beans.
You need a TilesConfigurer bean whose job is to locate and load tile definitions and generally coordinate Tiles.
In addition, you need a TilesViewResolver bean to resolve logical view names to tile definitions.
The most significant difference between the two sets of Tiles components is in their package names.
For our purposes, I’ll assume that you’re using Tiles 3
First, let’s add the TilesConfigurer bean as shown in the following listing.
When configuring a TilesConfigurer, the most important property you set is definitions.
This property takes an array of Strings where each entry specifies the location of tile-definition XML files.
For the Spittr application, you’ll have it look for a file named tiles.xml in the /WEB-INF/layout/ directory.
Although you’re not taking advantage of it here, it’s also possible to specify multiple tile-definition files and even use wildcards in the location path.
In this case, you’re using Ant-style wildcards (**) so that TilesConfigurer will recursively dig under all subdirectories in /WEB-INF/ in its search for tile definitions.
As you can see, it’s a rather basic bean definition, with no properties to set:
Optionally, if you prefer working with XML configuration, you may choose to configure TilesConfigurer and TilesViewResolver like this:
Whereas TilesConfigurer loads tile definitions and coordinates with Apache Tiles, TilesViewResolver resolves logical view names to views that reference tile definitions.
It does this by looking for a tile definition whose name matches the logical view name.
You’ll need to create a few tile definitions to see how this works.
For example, the following XML document defines several tiles for the Spittr application.
Each <definition> element defines a tile that ultimately references a JSP template.
In the case of the tile whose name is base, the template referenced is at /WEB-INF/ layout/page.jsp.
A tile may also reference other JSP templates to be embedded in the main template.
For the base tile, it references a header JSP template and a footer JSP template.
The page.jsp template referenced by the base tile is shown next.
Listing 6.3 Main layout template: references other templates to create a view.
It’s used to insert the attributes named header, body, and footer.
Ultimately, this gives you a layout that somewhat resembles figure 6.4
The base tile is never expected to be used on its own.
It serves as a base definition (thus the meaning behind its name) for other tile definitions to extend.
Throughout the rest of listing 6.2, you can see that the other tile definitions all extend base.
This means they inherit its settings for the header and footer attributes (although they could choose to override them)
But each also sets a body attribute to reference a JSP template specific to that tile.
Focusing on the home tile, notice that it extends base.
Because it extends base, it inherits the template and all the attributes from base.
Even though the home tile definition is relatively simple, it has the following effective definition:
Figure 6.4 A general layout defining a header, a body, and a footer.
Each tile that extends base defines its own body template, so each will differ from the others.
But to complete the picture for the home tile, here’s home.jsp:
The key point here is that the common elements of a page are captured in page.jsp, header.jsp, and footer.jsp and are absent in each of the other tile templates.
This makes them reusable across all pages and simplifies maintenance of those elements.
To see how this all comes together, look at figure 6.5
As you can see, the page includes some styling and imagery to increase the application’s aesthetics.
These weren’t pertinent to the discussion of page layout with Tiles, so I chose not to cover the details in this section.
Nevertheless, you can see how the various components of the page are brought together by the tile definitions to render the Spittr home page.
But there’s a new contender for the job, known as Thymeleaf.
Let’s see how to use Thymeleaf templates with a Spring MVC application.
Even though JSP has been around for a long time and is ubiquitous among Java web servers, it has a few unfortunate flaws.
One significant issue with JSP is that it appears to be a form of HTML or XML, but it’s really neither.
Most JSP templates take the form of HTML, littered with tags from various JSP tag libraries.
Although these tag libraries bring dynamic rendering power to JSP in a succinct form, they break any hope of authoring a well-formed document.
As an extreme example, consider that a JSP tag can even be used as the value of an HTML parameter:
A side effect of tag libraries and JSP’s lack of good form is that a JSP template often only coincidentally resembles the HTML it produces.
Indeed, viewing an unrendered JSP template in a web browser or an HTML editor gives some puzzling and ugly results.
Also, JSP is a specification that’s tightly coupled to the servlet specification.
This means it can only be used for web views in a servlet-based web application.
Several attempts have been made over the years to supplant JSP as the dominant view technology for Java applications.
The most recent contender, Thymeleaf, shows some real promise and is an exciting choice to consider.
Thymeleaf templates are natural and don’t rely on tag libraries.
They can be edited and rendered anywhere that raw HTML is welcome.
And because they’re not coupled to the servlet specification, Thymeleaf templates can go places JSPs dare not tread.
Let’s look at how to use Thymeleaf with Spring MVC.
In order to use Thymeleaf with Spring, you’ll need to configure three beans that enable Thymeleaf-Spring integration:
If you’d prefer to configure the beans in XML, the following <bean> declarations will do the trick.
No matter which configuration style you use, Thymeleaf is now ready to render its templates in response to requests handled by Spring MVC controllers.
Just like any view resolver, it takes a logical view name and resolves a view.
But in this case, that view is ultimately a Thymeleaf template.
As you can see, it’s injected with a reference to the TemplateResolver bean.
The prefix and suffix are applied to the logical view name to locate the Thymeleaf template.
Now that all the Thymeleaf beans have been configured, it’s time to create a few of those templates.
There are no special tags or tag libraries as with JSP.
What makes Thymeleaf tick, however, is that it adds Thymeleaf attributes to the standard set of HTML tags via a custom namespace.
The following listing shows home.html, the home page template that uses the Thymeleaf namespace.
Even though home.html is a rather basic specimen of a Thymeleaf template, it’s still remarkable in that it’s a near-pure HTML template.
The only thing that stands out is the th:href attribute.
Listing 6.6 home.html: home page template using the Thymeleaf namespace.
This means Thymeleaf templates, unlike JSPs, can be edited and even rendered naturally, without going through any sort of processor.
Sure, you’ll need Thymeleaf to process the templates to fully render the desired output.
But as is, without any special processing, home.html can be loaded into a web browser and will appear much as it will when fully rendered.
To illustrate, figure 6.6 shows a comparison of home.jsp (top) and home.html (bottom) when viewed in a web browser.
As you can see, the JSP template renders poorly in the web browser.
Although you can see familiar elements, the JSP tag library declarations are also displayed.
And there’s some odd unfinished markup just before the links, the result of the <s:url> tag not being properly interpreted by the web browser.
The only things that aren’t quite right are the links.
The web browser doesn’t treat the th:href attribute like href, so the links aren’t rendered as links.
Aside from that minor issue, the template renders exactly as you’d expect.
Simple templates like home.html are a nice introduction to Thymeleaf.
But form binding is something that Spring’s JSP tags excel at.
If you’re abandoning JSP, must you abandon form binding as well? Fear not.
It makes it possible for controllers to receive command objects populated with data submitted in a form and for the form to be prepopulated with values from the command object when displaying the form.
Without proper form binding, you’d have to ensure that the HTML form fields were properly named to map to the backing command object’s properties.
And you’d also be responsible for ensuring that the fields’ values were set to the command object’s properties when redisplaying a form after validation failure.
Figure 6.6 Thymeleaf templates, unlike JSPs, are HTML and can be rendered and edited just like HTML.
But with form binding, this is taken care of for you.
It also uses Spring’s <sf:label> and its cssErrorClass to render the label in red if there are any validation errors.
On the contrary, we’re talking about replacing JSP with Thymeleaf.
So instead of using Spring’s JSP tags to achieve form binding, you’ll take advantage of features of Thymeleaf’s Spring dialect.
As a demonstration, consider this snippet of a Thymeleaf template that renders the First Name field:
Instead of using the cssClassName attribute as you did with Spring’s JSP tags, here you use Thymeleaf’s th:class attribute on standard HTML tags.
The th:class attribute renders a class attribute with a value calculated from the given expression.
In both uses of th:class, it directly checks to see if there are any field errors for the firstName field.
If so, the class attribute is rendered with a value of error.
If there are no field errors, the class attribute isn’t rendered at all.
The <input> tag uses the th:field attribute to reference the firstName field from the backing object.
Many times in a Thymeleaf template, you’ll use a Thymeleaf attribute that mirrors a standard HTML attribute, so it might seem appropriate to use the th:value attribute to set the <input> tag’s value attribute.
Instead, because you’re binding the field to the backing object’s firstName property, you use the th:field attribute, referring to the firstName field.
By using th:field, you get both a value attribute set to the value of firstName and also a name attribute set to firstName.
To demonstrate Thymeleaf data binding in action, the following listing shows the complete registration form template.
Listing 6.7 Registration page, using Thymeleaf to bind a form to a command object.
But also notice that Thymeleaf is used near the top of the form to render all errors.
The <div> element has a th:if attribute that checks to see if there are any errors.
In the <div> is an unordered list to display each of the errors.
This attribute instructs Thymeleaf to evaluate an expression (in this case, the value of the err variable) and render its value as the body of the <li> tag.
In effect, there will be one <li> for each error, displaying the text of that error.
Processing requests is only half of the story of Spring MVC.
If the results coming from the controllers you write are ever to be seen, the model data they produce needs to be rendered into views and displayed in the user’s web browser.
Spring is flexible with regard to view rendering and offers several out-of-the-box options, including conventional JavaServer Pages and the popular Apache Tiles layout engine.
In this chapter, you’ve had a quick look at all the view and view-resolution options offered by Spring.
We also took a deeper dive to show how you can use JSP and Apache Tiles with Spring MVC.
You also saw how to use Thymeleaf, an alternative to JSP, as the view layer of a Spring MVC application.
Thymeleaf is a compelling option because it enables the creation of natural templates that are still pure HTML and can be edited and viewed in the raw as if they were static HTML, but still render dynamic model data at runtime.
Moreover, Thymeleaf templates are largely decoupled from servlets, enabling them to be used in places where JSPs can’t.
With the view of the Spittr application defined, you have a small but deployable and functional web application written with Spring MVC.
We still need to flesh out some other concerns like data persistence and security, and we’ll get to those in due time.
Before we dive deeper into the application stack, the next chapter continues our discussion of Spring MVC, looking at some of the more useful and advanced capabilities in the framework.
In chapter 5, we looked at essential Spring MVC and how to write controllers to handle various kinds of requests.
Then you built on that in chapter 6 to create the JSP and Thymeleaf views that present model data to the user.
Although that is a safe assumption for many Spring applications, it may not always fit what you need.
You may need servlets and filters in addition to DispatcherServlet.
Maybe you need to do some additional configuration on DispatcherServlet itself.
Or, if you’re deploying your application to a pre-Servlet 3.0 container, you may need to configure DispatcherServlet in a traditional web.xml file.
Let’s start by looking at a few ways to customize how DispatcherServlet is configured.
But there are more methods that can be overridden to apply additional configuration.
For instance, a little later in this chapter (in section 7.2) you’ll see how to handle multipart requests and file uploads with Spring MVC.
But what if you want to register additional servlets, filters, or listeners?
One of the nice things about working with a Java-based initializer is that (unlike with web.xml) you can define as many initializer classes as you want.
Therefore, if you need to register any additional components into the web container, you need only create a new initializer class.
It registers a servlet and maps it to a single path.
For example, the next listing shows how to register a filter.
Here it only returns a single filter, but it could return as many filters as you need.
But you don’t have to use any of those if you don’t want to.
If you aren’t deploying your application to a Servlet 3.0 container (or if you just like working with web.xml), then there’s no reason you can’t configure Spring MVC in a legacy manner with web.xml.
DispatcherServlet loads its application context with beans defined in a file whose name is based on the servlet name.
But throughout much of this book, we’ll favor Java configuration over XML configuration.
You can do that by setting the contextClass context parameter and initialization parameter for DispatcherServlet.
The next listing shows a new web.xml file that sets up Spring MVC for Java-based Spring configuration.
Now that we’ve looked at a variety of ways to set up Spring MVC, let’s examine how to use Spring MVC to handle file uploads.
It’s common for a web application to enable its users to upload content.
On sites like Facebook and Flickr, it’s normal for users to upload photos and videos to share with their family and friends.
There are also several services that allow users to upload photos to be printed on paper the old-fashioned way or to be applied to T-shirts and coffee mugs.
The Spittr application calls for file uploads in two places.
When a new user registers with the application, you’d like them to be able to provide a picture to associate with their profile.
And when a user posts a new Spittle, they may want to upload a photo to go along with their message.
The request resulting from a typical form submission is simple and takes the form of multiple name-value pairs separated by ampersands.
For example, when submitting the registration form from the Spittr application, the request might look like this:
Although this encoding scheme is simple and sufficient for typical text-based form submissions, it isn’t robust enough to carry binary data such as an uploaded image.
In contrast, multipart form data breaks a form into individual parts, with one part per.
Typical form fields have textual data in their parts, but when something is being uploaded, the part can be binary, as shown in the following multipart request body:
Among other things, it has its own Content-Type header indicating that it’s a JPEG image.
And although it may not be obvious, the body of the profilePicture part is binary data instead of simple text.
Even though multipart requests look complex, handling them in a Spring MVC controller is easy.
But before you can write controller methods to handle file uploads, you must configure a multipart resolver to tell DispatcherServlet how to read multipart requests.
DispatcherServlet doesn’t implement any logic for parsing the data in a multipart request.
Instead, it delegates to an implementation of Spring’s MultipartResolver strategy interface to resolve the content in a multipart request.
Since Spring 3.1, Spring comes with two out-of-the-box implementations of MultipartResolver to choose from:
It uses existing support in your servlet container and doesn’t require any additional project dependencies.
This makes it extremely simple to declare as a bean in your Spring configuration, as shown here:
At the very least, you must specify the temporary file path where the file will be written during the upload.
Consequently, there’s no handy reference to the Dynamic servlet registration to work with.
But there’s another constructor that lets you set a few constraints on the size of the file being uploaded.
In addition to the temporary location path, the other constructor accepts the following:
You can write your own implementation of the MultipartResolver interface if you’d like.
But unless you need to perform some special handling during multipart request handling, there’s no reason to do that.
By default, the location is the servlet container’s temporary directory.
But you can specify a different location by setting the uploadTempDir property:
Now that you’ve configured multipart support in Spring (and perhaps in the servlet container), you’re ready to write controller methods to accept the uploaded files.
The most common way of doing that is to annotate a controller method parameter with @RequestPart.
Suppose you want to offer people the opportunity to upload an image when they register as users of the Spittr application.
This tells the browser to submit the form as multipart data instead of form data.
Each field has its own part in the multipart request.
In addition to all the existing fields on the registration form, you’ve added a new <input> field whose type is file.
This lets the user select an image file to upload.
The accept attribute is set to limit file types to JPEG, PNG, and GIF images.
And according to its name attribute, the image data will be sent in the multipart request in the profilePicture part.
One way to do that is to add a byte array parameter that’s annotated with @RequestPart.
When the registration form is submitted, the profilePicture attribute is given an array of byte containing the data from the request part (as specified by @RequestPart)
If the user submits the form without selecting a file, then the array will be.
We’ll discuss how to save the image data more in a bit.
But first, consider what you know about the image data that was submitted.
Or, more important, what do you not know? Although you have the image data as an array of byte and from that you can derive the size of the image, there’s little else you know about it.
You have no idea what type of file it is or even what the name of the original file was.
And it’s up to you to figure out how to turn that byte array into a file you can save.
Therefore, Spring also offers MultipartFile as a way to get a richer object for processing multipart data.
The following listing shows what the MultipartFile interface looks like.
As you can see, MultipartFile offers a way to get at the bytes for the uploaded file.
But it offers much more, including the original filename, size, and content type.
It also offers an InputStream for reading the file data as a stream.
What’s more, MultipartFile offers a convenient transferTo() method to help you write the uploaded file to the filesystem.
Saving a file to the local filesystem like this is simple enough, but it leaves the management of the file up to you.
It’s up to you to make sure the file is backed up in case of a hardware failure.
And it’s your job to deal with synchronizing the image files across multiple servers in a cluster.
With only a bit more code, you can save the images to the cloud.
Listing 7.5 Spring’s MultipartFile interface for working with uploaded files.
The first thing that saveImage() does is set up Amazon Web Service (AWS) credentials.
These will be given to you by Amazon when you sign up for S3 service.
This is important—without it, the images wouldn’t be visible to your application’s users.
For the most part (no pun intended), the Part interface isn’t much different from MultipartFile.
As you can see in the next listing, the Part interface has several methods that mirror the methods in MultipartFile.
In many cases, the Part methods are named exactly the same as the MultipartFile methods.
Likewise, write() corresponds to transferTo(), making it possible to write the uploaded file like this:
Up to this point, we’ve been assuming that everything will always work in the Spittr application.
No matter what happens, good or bad, the outcome of a servlet request is a servlet response.
If an exception occurs during request processing, the outcome is still a servlet response.
Spring offers a handful of ways to translate exceptions to responses:
Certain Spring exceptions are automatically mapped to specific HTTP status codes.
An exception can be annotated with @ResponseStatus to map it to an HTTP status code.
A method can be annotated with @ExceptionHandler to handle the exception.
The simplest way to handle an exception is to map it to the HTTP status code to be placed on the response.
Let’s see how to map exceptions to HTTP status codes.
Out of the box, Spring automatically maps a dozen of its own exceptions to appropriate status codes.
The exceptions in table 7.1 are usually thrown by Spring itself as the result of something going wrong in DispatcherServlet or while performing validation.
Although these built-in mappings are helpful, they do no good for any application exceptions that may be thrown.
Fortunately, Spring offers a way to map exceptions to HTTP status codes via the @ResponseStatus annotation.
Table 7.1 Some Spring exceptions are mapped by default to HTTP status codes.
To demonstrate, consider the following request-handling method from SpittleController that could result in an HTTP 404 status (but doesn’t):
Here, a Spittle is retrieved by its ID from the SpittleRepository.
If findOne() returns a Spittle object, that Spittle is put into the model, and the view whose name is spittle is tasked with rendering it in the response.
In fact, in the event of any exception that isn’t otherwise mapped, the response will always have a 500 status code.
The HTTP status code of 404 is precisely the appropriate response status code when a resource isn’t found.
Mapping exceptions to status codes is simple and sufficient for many cases.
But what if you want the response to carry more than just a status code that represents the error that occurred? Rather than treat the exception generically as some HTTP error, maybe you’d like to handle the exception the same way you might handle the request itself.
That means the saveSpittle() method of SpittleController might need to deal with that exception.
As shown in the following listing, saveSpittle() could directly handle the exception.
It works fine, but the method is a bit complex.
Two paths can be taken, each with a different outcome.
It’d be simpler if saveSpittle() could focus on the happy path and let some other method deal with the exception.
Because it’s written to only be concerned with the successful saving of a Spittle, it has only one path and is easy to follow (and test)
Listing 7.9 Handling an exception directly in a request-handling method.
It returns a String, which, just as with the request-handling method, specifies the logical name of the view to render, telling the user that they attempted to create a duplicate entry.
What’s especially interesting about @ExceptionHandler methods is that they handle their exceptions from any handler method in the same controller.
If @ExceptionHandler methods can handle exceptions thrown from any handler method in the same controller class, you might be wondering if there’s a way they can handle exceptions thrown from handler methods in any controller.
As of Spring 3.2 they certainly can, but only if they’re defined in a controller advice class.
What’s a controller advice class? I’m glad you asked, because that’s what we’ll look at next.
Certain aspects of controller classes might be handier if they could be applied broadly across all controllers in a given application.
ExceptionHandler methods, for instance, could prove useful in handling exceptions across multiple controllers.
If a particular exception is thrown from multiple controller classes, you might find yourself duplicating the same @ExceptionHandler method in all of those controllers.
Or, to avoid the duplication, you might create a base controller class that all of your controllers could extend to inherit the common @ExceptionHandler method.
Spring 3.2 brings another option to the table: controller advice.
A controller advice is any class that’s annotated with @ControllerAdvice and has one or more of the following kinds of methods:
As shown in listing 7.10, it returns error/duplicate as the logical view name so that a friendly error page is displayed to the user.
Among other things, this prevents the client from reissuing a dangerous POST request if the user clicks the Refresh or back-arrow button in their browser.
In chapter 5, you used the power of the redirect: prefix in the view names returned from controller methods.
When a controller method returns a String whose value starts with redirect:, that String isn’t used to look up a view, but is instead used as a path to redirect the browser to.
The redirect: prefix makes working with redirects plain and simple.
You’d think there’s nothing more that Spring could do to make working with redirects any simpler.
But wait: Spring has a bit more to offer to help with redirects.
Specifically, how can a redirecting method send data to the method that handles the redirect? Typically, when a handler method completes, any model data specified.
Because it’s the same request that’s handled by both the controller method and the view, the request attributes survive the forward.
But as illustrated in figure 7.1, when a controller method results in a redirect, the original request ends and a new HTTP GET request begins.
Any model data carried in the original request dies with the request.
The new request is devoid of any model data in its attributes and has to figure it out on its own.
Clearly, the model isn’t going to help you carry data across a redirect.
But there are a couple of options to get the data from the redirecting method to the redirecthandling method:
First we’ll look at how Spring can help you send data in path variables and/or query parameters.
Passing data in path variables and query parameters seems simple enough.
But as it’s currently written, the username value is concatenated to the redirect String.
String concatenation is dangerous business when constructing things like URLs and SQL queries.
Instead of concatenating your way to a redirect URL, Spring offers the option of using templates to define redirect URLs.
All you need to do is set the value in the model.
Here’s how it can set the username value in the model so that it can fill in the placeholder in the redirect path:
Figure 7.1 Model attributes are carried in a request as request attributes and don’t survive a redirect.
Because it’s filled into the placeholder in the URL template instead of concatenated into the redirect String, any unsafe characters in the username property are escaped.
This is safer than allowing the user to type in whatever they want for the username and then appending it to the path.
What’s more, any other primitive values in the model are also added to the redirect URL as query parameters.
Suppose, for the sake of example, that in addition to the username, the model also contained the newly created Spitter object’s id property.
Not much has changed with regard to the redirect String being returned.
But because the spitterId attribute from the model doesn’t map to any URL placeholders in the redirect, it’s tacked on to the redirect automatically as a query parameter.
Sending data across a redirect via path variables and query parameters is easy and straightforward, but it’s also somewhat limiting.
It’s only good for sending simple values, such as String and numeric values.
There’s no good way to send anything more complex in a URL.
Let’s say that instead of sending a username or ID in the redirect, you want to send the actual Spitter object.
If you send just the ID, then the method that handles the redirect has to turn around and look up the Spitter from the database.
But before the redirect, you already have the Spitter object in hand.
Why not send it to the redirecthandling method to display?
A Spitter object is a bit more complex than a String or an int.
Therefore, it can’t easily be sent as a path variable or a query parameter.
It can, however, be set as an attribute in the model.
But as we’ve already discussed, model attributes are ultimately copied into the request as request attributes and are lost when the redirect takes place.
Therefore, you need to put the Spitter object somewhere that will survive the redirect.
One option is to put the Spitter into the session.
So you could put the Spitter into the session before the redirect and.
Of course, you’re also responsible for cleaning it up from the session after the redirect.
As it turns out, Spring agrees that putting data into the session is a great way to pass information that survives a redirect.
But Spring doesn’t think you should be responsible for managing that data.
Instead, Spring offers the capability of sending the data as flash attributes.
Flash attributes, by definition, carry data until the next request; then they go away.
RedirectAttributes offers everything that Model offers, plus a few methods for setting flash attributes.
Optionally, you can leave the key parameter out and let the key be inferred from the value type:
Before the redirect takes place, all flash attributes are copied into the session.
After the redirect, the flash attributes stored in the session are moved out of the session and into the model.
The method that handles the redirect request can then access the Spitter from the model, just like any other model object.
Figure 7.2 Flash attributes are stored in the session and then retrieved into the model, surviving a redirect.
If the model contains a spitter attribute, then there’s nothing to do.
The Spitter object contained therein will be carried forward to the view for rendering.
When it comes to Spring, there’s always more: more features, more choices, and more ways to achieve your development goals.
Spring MVC has a lot of capabilities and many tricks up its sleeves.
Spring MVC setup is certainly one area where you have a lot of choices.
Then we took a look at how to handle exceptions thrown from Spring MVC controllers.
Although an @RequestMapping method could handle exceptions itself, your controller code is much cleaner when you extract the exception handling into a separate method.
Finally, we looked at how to carry data across redirects, including Spring’s support for flash attributes: model-like attributes that will survive a redirect.
This enables you to properly respond to POST requests with a redirect, but to still carry model data obtained while handling a POST request and use it or display it after the redirect.
We’ll pick up the discussion of Spring MVC again in chapter 16, when you see how to use it to create REST APIs.
But for now, we’ll set aside Spring MVC and look at Spring Web Flow, a flow framework built on top of Spring MVC for creating applications that walk a user through a series of guided steps.
One of the strangely wonderful things about the internet is that it’s so easy to get lost.
The hyperlink is at the core of the internet’s power.
But at the same time, it’s no wonder they call it the web.
Just like webs built by spiders, it traps anyone who happens to crawl across it.
I’ll confess: one reason it took me so long to write this book is because I once got lost in an endless path of Wikipedia links.
There are times when a web application must take control of a web surfer’s voyage, leading the user step by step through the application.
The quintessential example of such an application is the checkout process on an e-commerce site.
Starting with the shopping cart, the application leads you through a process of entering shipping details and billing information, and ultimately it displays an order confirmation.
Spring Web Flow is a web framework that enables the development of elements following a prescribed flow.
In this chapter, we’ll explore Spring Web Flow and see how it fits into the Spring web framework landscape.
It’s possible to write a flowed application with any web framework.
I’ve even seen a Struts application that had a certain flow built into it.
But without a way to separate the flow from the implementation, you’ll find that the definition of the flow is scattered across the various elements that make up the flow.
There’s no one place to go to fully understand the flow.
Spring Web Flow is an extension to Spring MVC that enables development of flowbased web applications.
It does this by separating the definition of an application’s flow from the classes and views that implement the flow’s behavior.
As you get to know Spring Web Flow, you’ll take a break from the Spittr example and work on a new web application for taking pizza orders.
You’ll use Spring Web Flow to define the order process.
The first step in working with Spring Web Flow is to install it in your project.
That means all requests to a flow first go through Spring MVC’s DispatcherServlet.
From there, a handful of special beans in the Spring application context must be configured to handle the flow request and execute the flow.
At this time, there’s no support for configuring Spring Web Flow in Java, so you have no choice but to configure it in XML.
Several of the web flow beans are declared using elements from Spring Web Flow’s Spring configuration XML namespace.
Therefore, you’ll need to add the namespace declaration to the context definition XML file:
With the namespace declaration in place, you’re ready to start wiring up web flow beans, starting with the flow executor.
As its name implies, the flow executor drives the execution of a flow.
When a user enters a flow, the flow executor creates and launches an instance of the flow execution for that user.
When the flow pauses (such as when a view is presented to the user), the flow executor also resumes the flow once the user has taken some action.
Although the flow executor is responsible for creating and executing flows, it’s not responsible for loading flow definitions.
That responsibility falls to a flow registry, which you’ll create next.
A flow registry’s job is to load flow definitions and make them available to the flow executor.
As declared here, the flow registry will look for flow definitions under the /WEB-INF/flows directory, as specified in the base-path attribute.
Figure 8.1 shows how the flow ID is calculated in this scenario.
Alternatively, you can leave off the base-path attribute and explicitly identify the flow definition file’s location:
When configured this way, the flow’s ID is derived from the base name of the flow definition file, springpizza in this case.
Figure 8.1 When using a flow location pattern, the path to the flow definition file relative to the base path is used as the flow’s ID.
As you saw in the previous chapter, DispatcherServlet typically dispatches requests to controllers.
But for flows, you need a FlowHandlerMapping to help DispatcherServlet know that it should send flow requests to Spring Web Flow.
The FlowHandlerMapping is configured in the Spring application context like this:
As you can see, the FlowHandlerMapping is wired with a reference to the flow registry so it knows when a request’s URL maps to a flow.
For example, if you have a flow whose ID is pizza, then FlowHandlerMapping will know to map a request to that flow if the request’s URL pattern (relative to the application context path) is /pizza.
A FlowHandlerAdapter is equivalent to a Spring MVC controller in that it handles requests coming in for a flow and processes those requests.
The FlowHandlerAdapter is wired as a Spring bean like this:
It handles flow requests and manipulates the flow based on those requests.
Here, it’s wired with a reference to the flow executor to execute the flows for which it handles requests.
You’ve configured all the beans and components that are needed for Spring Web Flow to work.
But first, let’s get to know the elements that are put together to make up a flow.
In Spring Web Flow, a flow is defined by three primary elements: states, transitions, and flow data.
If you imagine a flow as being like a road trip, then states are the towns, truck stops, and scenic stops along the way.
Instead of picking up a bag of Doritos and a Diet Coke, a state in a flow is where some logic is performed, some decision is made, or some page is presented to the user.
If flow states are like the points on a map where you might stop during a road trip, then transitions are the roads that connect those points.
In a flow, you get from one state to another by way of a transition.
As you travel from town to town, you may pick up some souvenirs, memories, and empty snack bags along the way.
I’m tempted to refer to it as the state of the flow, but the word state already has another meaning when talking about flows.
Let’s take a closer look at how these three elements are defined in Spring Web Flow.
Spring Web Flow defines five different kinds of state, as shown in table 8.1
This selection of states makes it possible to construct virtually any arrangement of functionality into a conversational web application.
Although not all flows require all the states described in the table, you’ll probably end up using most of them at one time or another.
In a moment, you’ll see how to piece these different kinds of states together to form a complete flow.
But first, let’s get to know how these flow elements are manifested in a Spring Web Flow definition.
The actual view implementation could be any of the views supported by Spring MVC but is often implemented in JSP.
In the flow definition XML file, the <view-state> element is used to define a view state:
In this simple example, the id attribute serves a dual purpose.
Also, because no view has been specified otherwise, it specifies welcome as the logical name of the view to be rendered when the flow reaches this state.
If you’d rather explicitly identify another view name, then you can do so with the view attribute:
Action Action states are where the logic of a flow takes place.
Decision Decision states branch the flow in two directions, routing the flow based on the outcome of evaluating flow data.
End The end state is the last stop for a flow.
Once a flow has reached its end state, the flow is terminated.
Subflow A subflow state starts a new flow in the context of a flow that is already underway.
View A view state pauses the flow and invites the user to participate in the flow.
If a flow presents a form to the user, you may want to specify the object to which the form will be bound.
Here you specify that the form in the takePayment view will be bound to the flowscoped paymentDetails object.
We’ll talk more about flow scopes and data in a moment.)
Action states typically invoke some method on a Spring-managed bean and then transition to another state depending on the outcome of the method call.
In the flow definition XML, action states are expressed with the <action-state> element.
The <evaluate> element gives an action state something to do.
The expression attribute is given an expression that’s evaluated when the state is entered.
In this case, expression is given a SpEL expression indicating that the saveOrder() method should be called on a bean whose ID is pizzaFlowActions.
But more often, a flow branches at one point or another, depending on the flow’s current circumstances.
Decision states enable a binary branch in a flow execution.
A decision state evaluates a Boolean expression and takes one of two transitions, depending on whether the expression evaluates to true or false.
Spring Web Flow and expression languages Spring Web Flow has been fickle in its choice of expression languages over the years.
It then flirted with the Unified Expression Language (Unified EL) starting in version 2.0
Although it’s possible to configure Spring Web Flow to use any of these expression languages, SpEL is the default and recommended expression language.
Therefore, I’ll focus on SpEL when defining flows and disregard the other options.
A typical example of a decision state might look like this:
As you can see, the <decision-state> element doesn’t work alone.
The <if> element is the heart of a decision state.
If the expression evaluates to true, then the flow transitions to the state identified by the then attribute.
But if it’s false, the flow transitions to the state named in the else attribute.
Instead, you’ll break it up into multiple classes, methods, and other structures.
In the same way, it’s a good idea to break flows down into discrete parts.
The <subflow-state> element lets you call another flow from within an executing flow.
It’s analogous to calling a method from within another method.
Here, the <input> element is used to pass the order object as input to the subflow.
And if the subflow ends with an <end-state> whose ID is orderCreated, then the flow will transition to the state whose ID is payment.
I haven’t talked about the <end-state> element or transitions yet.
As for end states, that’s what we’ll look at next.
And that’s what they do when they transition to an end state.
The <end-state> element designates the end of a flow and typically appears like this:
If the flow that’s ending is a subflow, the calling flow will proceed from the <subflow-state>
If the <end-state> has its view attribute set, the specified view will be rendered.
The view may be a flow-relative path to a view template, prefixed with.
If the ending flow isn’t a subflow and no view is specified, the flow ends.
The browser lands on the flow’s base URL, and, with no current flow active, a new instance of the flow begins.
It’s important to realize that a flow may have more than one end state.
Because the end state’s ID determines the event fired from a subflow, you may want to end the flow through multiple end states to trigger different events in the calling flow.
Even in flows that aren’t subflows, there may be several landing pages that follow the completion of a flow, depending on the course that the flow took.
Now that we’ve looked at the various kinds of states in a flow, we should take a moment to examine how the flow travels between states.
Let’s look at how you can pave some roads in a flow by defining transitions.
As I’ve already mentioned, transitions connect the states within a flow.
Every state in a flow, with the exception of end states, should have at least one transition so that the flow will know where to go once that state has completed.
A state may have multiple transitions, each one representing a different path that could be taken on completion of the state.
In its simplest form, the <transition> element identifies the next state in the flow:
The to attribute is used to specify the next state in the flow.
When <transition> is declared with only a to attribute, the transition is the default transition for that state and will be taken if no other transitions are applicable.
More commonly, transitions are defined to take place on some event being fired.
In a view state, the event is usually an action taken by the user.
In an action state, the event is the result of evaluating an expression.
In the case of a subflow state, the event is determined by the ID of the subflow’s end state.
In any event (no pun intended), you can specify the event to trigger the transition in the on attribute:
In this example, the flow will transition to the state whose ID is lookupCustomer if a phoneEntered event is fired.
The flow can also transition to another state in response to some exception being thrown.
For example, if a customer record can’t be found, you may want the flow to transition to a view state that presents a registration form.
The on-exception attribute is much like the on attribute, except that it specifies an exception to transition on instead of an event.
For example, I wouldn’t be surprised to find the following <transition> sprinkled all over a flow:
With this global transition in place, all states in the flow will have an implicit cancel transition.
Before we get busy writing flows, let’s look at flow data, the remaining member of the web flow triad.
If you’ve ever played one of those old text-based adventure games, you know that as you move from location to location, you occasionally find objects lying around that you can pick up and carry with you.
Other times, you may carry an object through the entire game without knowing what it’s for—until you get to that final puzzle and find that it’s useful after all.
As the flow progresses from one state to another, it picks up data.
Sometimes that data is only needed for a little while (maybe just long enough to display a page to the user)
Other times, that data is carried through the entire flow and is ultimately used as the flow completes.
The simplest way to create a variable in a flow is by using the <var> element:
Here, a new instance of a Customer object is created and placed into the variable whose name is customer.
This variable is available to all states in a flow.
As part of an action state or on entry to a view state, you may also create variables using the <evaluate> element.
In this case, the <evaluate> element evaluates an expression (a SpEL expression) and places the result in a variable named toppingsList that’s view-scoped.
Here, you’re setting a flowscoped pizza variable to a new instance of a Pizza object.
You’ll see more specifics on how these elements are used in an actual flow when you get to section 8.3 and start building a real working web flow.
But first, let’s see what it means for a variable to be flow-scoped, be view-scoped, or use some other scope.
Spring Web Flow defines five scopes, as described in table 8.2
When you declare a variable using the <var> element, the variable is always flowscoped in the flow defining the variable.
For example, here’s how you would assign a value to a flow-scoped variable named theAnswer:
Conversation Created when a top-level flow starts, and destroyed when the top-level flow ends.
Shared by a top-level flow and all of its subflows.
Flow Created when a flow starts, and destroyed when the flow ends.
Request Created when a request is made into a flow, and destroyed when the flow returns.
Flash Created when a flow starts, and destroyed when the flow ends.
View Created when a view state is entered, and destroyed when the state exits.
Now that you’ve seen all the raw materials of a web flow, it’s time to piece them together into a full-blown, fully functional web flow.
As you do, keep your eyes peeled for examples of how to store data in scoped variables.
As I mentioned earlier in this chapter, we’re taking a break from the Spittr application.
Instead, you’ve been asked to build out an online pizza-ordering application where hungry web visitors can order their favorite Italian pie.
As it turns out, the process of ordering a pizza can be defined nicely in a flow.
You’ll start by building a high-level flow that defines the overall process of ordering a pizza.
Then you’ll break that flow down into subflows that define the details at a lower level.
A new pizza chain, Spizza, has decided to relieve the load on its stores’ telephones by allowing customers to place orders online.
When a customer visits the Spizza website, they’ll identify themselves, select one or more pizzas to add to their order, provide payment information, and then submit the order and wait for their pizza to arrive, hot and fresh.
The boxes in the diagram represent states, and the arrows represent transitions.
As you can see, the overall pizza flow is simple and linear.
It should be easy to express this flow in Spring Web Flow.
The only thing that makes it interesting is that the first three states can be more involved than suggested by a simple box.
Figure 8.2 The process of ordering a pizza boils down to a simple flow.
The following listing shows the high-level pizza order flow as defined using Spring Web Flow’s XML-based flow definition.
The first thing you see in the flow definition is the declaration of the order variable.
Each time the flow starts, a new instance of Order is created.
The Order class has properties for carrying all the information about an order, including the customer information, the list of pizzas ordered, and the payment details.
Listing 8.2 Order: carries all the details pertaining to a pizza order.
The main portion of the flow definition is made up of the flow states.
By default, the first state in the flow definition file is also the first state that will be visited in the flow.
In this case, that’s the identifyCustomer state (a subflow state)
But if you’d like, you can explicitly identify any state as the starting state by setting the start-state attribute in the <flow> element:
Identifying a customer, building a pizza order, and taking payment are activities that are too complex to be crammed into a single state.
That’s why you’ll define them later in more detail as flows in their own right.
But for the purposes of the high-level pizza flow, these activities are expressed with the <subflow-state> element.
The order flow variable will be populated by the first three states and then saved in the fourth state.
The identifyCustomer subflow state uses the <output> element to populate the order’s customer property, setting it to the output received from calling.
The buildOrder and takePayment states take a different approach, using <input> to pass the order flow variable as input so that those subflows can populate the order internally.
After the order has been given a customer, some pizzas, and payment details, it’s time to save it.
The saveOrder state is an action state that handles that task.
It uses <evaluate> to make a call to the saveOrder() method on the bean whose ID is pizzaFlowActions, passing in the order to be saved.
When it’s finished saving the order, it transitions to thankCustomer.
This link is the most interesting thing on the page, because it shows one way that a user can interact with the flow.
Spring Web Flow provides a flowExecutionUrl variable, which contains the URL for the flow, for use in the view.
The Finish link attaches an _eventId parameter to the URL to fire a finished event back to the web flow.
Because there are no further details on where to go after the flow ends, the flow will start over again at the identifyCustomer state, ready to take another pizza order.
But there’s more to the flow than what you see in listing 8.1
You still need to define the subflows for the identifyCustomer, buildOrder, and takePayment states.
Let’s build those flows next, starting with the one that identifies the customer.
If you’ve ordered a pizza before, you probably know the drill.
The first thing you’re asked for is your phone number.
Aside from giving the pizza shop a way to call you if the delivery driver can’t find your house, the phone number also serves as your identification.
If you’re a repeat customer, the shop can use that phone number to look up your address so that it will know where to deliver your order.
Listing 8.3 JSP view that thanks the customer for their order.
For a new customer, the phone number won’t turn up any results, so the next information the shop will ask for is your address.
At this point, the pizzeria knows who you are and where to deliver your pizzas.
But before you’re asked what kind of pizza you want, the shop needs to check to make sure your address falls within its delivery area.
If not, you’ll have to go pick up the pizza yourself.
This flow is more interesting than the top-level pizza flow.
It isn’t linear, and it branches in a couple of places depending on different conditions.
For example, after looking up the customer, the flow could either end (if the customer was found) or transition to a registration form (if the customer was not found)
Also, at the checkDeliveryArea state, the customer may or may not be warned that their address isn’t in the delivery area.
The following listing shows the flow definition for identifying the customer.
Listing 8.4 Identifying the hungry pizza customer with a web flow.
Figure 8.3 The flow for identifying a customer has a few more twists than the pizza flow.
This flow introduces a few new tricks, including your first use of the <decisionstate> element.
Also, because it’s a subflow of the pizza flow, it expects to receive an Order object as input.
As before, let’s break down this flow definition state by state, starting with the welcome state.
It has two transitions: one that directs the flow to the lookupCustomer state if a phoneEntered event is fired from the view, and another cancel transition, defined as a global transition, that reacts to a cancel event.
Where the welcome state gets interesting is in the view.
This simple form prompts the user to enter their phone number.
But the form has two special ingredients that enable it to drive the flow.
When a view state is entered, the flow pauses and waits for the user to take some action.
The flow execution key is given to the view as a sort of claim ticket for the flow.
When the user submits the form, the flow execution key is sent along with it in the _flowExecutionKey field, and the flow resumes where it left off.
The _eventId_ portion of the button’s name is a clue to Spring Web Flow that what follows is an event that should be fired.
When the form is submitted by clicking that button, a phoneEntered event is fired, triggering a transition to lookupCustomer.
It pulls the phone number off the request parameters and passes it to the lookupCustomer() method on the pizzaFlowActions bean.
In the former case, the Customer object is assigned to the customer variable (per the result attribute) and the default transition takes the flow to the customerReady.
Listing 8.5 Welcoming the customer and asking for their phone number.
Like other view states you’ve seen, it renders a JSP view.
This isn’t the first form you’ve seen in your flow.
The welcome view state also displays a form to the customer.
That form is simple and has only a single field.
It’s easy enough to pull that field’s value from the request parameters.
The registration form, on the other hand, is more involved.
Instead of dealing with the fields one at a time through the request parameters, it makes more sense to bind the form to a Customer object and let the framework do all the hard work.
If Spizza can’t deliver to them, you should let them know and advise them that they’ll need to come in and pick up the pizzas themselves.
That method returns a Boolean value: true if the customer is in the delivery area, and false otherwise.
If the customer is in the delivery area, the flow transitions to the addCustomer state.
If not, the customer is taken to the deliveryWarning view state.
Using the same flowExecutionUrl variable that you use in the welcome state, these links trigger either an accept event or a cancel event in the flow.
If an accept event is sent, the flow will transition to the addCustomer state.
Otherwise, the global cancel transition will be followed, and the subflow will transition to the cancel end state.
First, let’s take a quick look at the addCustomer state.
For future reference, that address needs to be stored (probably in a database)
The addCustomer state has an <evaluate> element that calls the addCustomer() method on the pizzaFlowActions bean, passing in the customer flow variable.
Once the evaluation is complete, the default transition will be taken, and the flow will transition to the end state whose ID is customerReady.
But in this flow, there’s not just one end state, but two.
When a subflow ends, it fires a flow event that’s equivalent to its end state’s ID.
If the flow only has one end state, then it always fires the same event.
But with two or more end states, a flow can influence the direction of the calling flow.
Listing 8.7 Warning a customer that pizza can’t be delivered to their address.
When the customer flow goes down any of the normal paths, it ultimately lands on the end state whose ID is customerReady.
When the calling pizza flow resumes, it receives a customerReady event, which results in a transition to the buildOrder state.
Note that the customerReady end state includes an <output> element.
This element is a flow’s equivalent of Java’s return statement.
It passes back some data from a subflow to the calling flow.
In this case, <output> returns the customer flow variable so that the identifyCustomer subflow state in the pizza flow can assign it to the order.
On the other hand, if a cancel event is triggered at any time during the customer flow, it exits the flow through the end state whose ID is cancel.
That triggers a cancel event in the pizza flow and results in a transition (via the global transition) to the pizza flow’s end state.
After the customer has been identified, the next step in the main flow is to figure out what kind of pizzas they want.
The order subflow, as illustrated in figure 8.4, is where the user is prompted to create pizzas and add them to the order.
As you can see, the showOrder state is the centerpiece of the order subflow.
It’s the first state the user sees on entering the flow, and it’s the state to which the user is sent after adding a new pizza to the order.
It displays the current state of the order and offers the user a chance to add another pizza to the order.
When the user chooses to add a pizza to the order, the flow transitions to the createPizza state.
This is another view state that gives the user a selection of pizza sizes and toppings with which to build a pizza.
From here, the user may add a pizza or cancel.
In either event, the flow transitions back to the showOrder state.
From the showOrder state, the user may choose to either submit the order or cancel the order.
Either choice ends the order subflow, but the main flow will go down different paths depending on which choice is made.
The following listing shows how the diagram translates into a Spring Web Flow definition.
Listing 8.8 Order subflow view shows states to display the order and create a pizza.
This subflow operates on the Order object created in the main flow.
Therefore, you need a way of passing the Order from the main flow to the subflow.
If you think of this subflow as being analogous to a method in Java, the <input> element used here is effectively defining the subflow’s signature.
Next you find the showOrder state, a basic view state with three different transitions: one for creating a pizza, one for submitting the order, and another to cancel the order.
Its view is a form that submits a new Pizza object to be added to the order.
The <on-entry> element adds a new Pizza object to flow scope to be populated when the form is submitted.
Note that the model of this view state references the same flow-scoped Pizza object.
That Pizza object is bound to the Create Pizza form, shown next.
Listing 8.9 Adding pizzas with an HTML form bound to a flow-scoped object.
When the form is submitted via the Continue button, the size and topping selections are bound to the Pizza object, and the addPizza transition is taken.
The <evaluate> element associated with that transition indicates that the flow-scoped Pizza object should be passed in a call to the order’s addPizza() method before transitioning to the showOrder state.
The user can either click the Cancel button on the showOrder view or click the Checkout button.
But the id of the end state chosen determines the event triggered on the way out of this flow and ultimately determines the next step in the main flow.
The main flow will either transition on cancel or transition on orderCreated.
In the former case, the outer flow ends; in the latter case, it transitions to the takePayment subflow, which we’ll look at next.
It’s not common to get a free pizza, and the Spizza pizzeria wouldn’t stay in business long if it let customers order pizzas without providing some form of payment.
As the pizza flow nears an end, the final subflow prompts the user to enter payment details.
Like the order subflow, the payment subflow accepts an Order object as input using the <input> element.
Figure 8.5 The final step in placing a pizza order is to take payment from the customer through the payment subflow.
As you can see, on entering the payment subflow, the user arrives at the takePayment state.
This is a view state where the user can indicate that they’ll pay by credit card, check, or cash.
On submitting their payment information, they’re taken to the verifyPayment state, an action state that verifies that their payment information is acceptable.
The payment subflow is defined in XML as shown next.
As the flow enters the takePayment view state, the <on-entry> element sets up the payment form by first using a SpEL expression to create a new PaymentDetails instance in flow scope.
It also sets the view-scoped paymentTypeList variable to a list containing the values of the PaymentType enum (shown in the next listing)
SpEL’s T() operator is used to get the PaymentType class so that the static toList() method can be invoked.
Listing 8.10 Payment subflow, with one view state and one action state.
On being presented with the payment form, the user may either submit a payment or cancel.
As with other subflows, either <end-state> will end the subflow and return control to the main flow.
But the id of the <end-state> taken determines the transition taken next in the main flow.
Now we’ve stepped all the way through the pizza flow and its subflows.
You’ve seen a lot of what Spring Web Flow is capable of.
Before we finish with the Web Flow topic, let’s take a quick look at what’s involved in securing access to a flow or any of its states.
In the next chapter, you’ll see how to secure Spring web applications using Spring Security.
But while we’re on the subject of Spring Web Flow, let’s quickly look at how it supports flow-level security when used along with Spring Security.
States, transitions, and entire flows can be secured in Spring Web Flow by using the <secured> element as a child of those elements.
For example, to secure access to a view state, you might use <secured> like this:
As configured here, access to the view state will be restricted to only users who are granted ROLE_ADMIN access (per the attributes attribute)
The attributes attribute takes a comma-separated list of authorities that the user must have to gain access to the state, transition, or flow.
The match attribute can be set to either any or all.
If it’s set to any, then the user must be granted at least one of the authorities listed in attributes.
If it’s set to all, then the user must have been granted all the authorities.
You may be wondering how a user is granted the authorities checked for by the <secured> element.
For that matter, how does the user log in to the application in the first place? The answers to those questions will be addressed in the next chapter.
Sometimes a user must be guided along, asked appropriate questions, and led to specific pages based on their responses.
In these situations, an application feels less like a menu of options and more like a conversation between the application and the user.
In this chapter, we’ve explored Spring Web Flow, a web framework that enables development of conversational applications.
You started by defining the overall path the application should take, beginning with gathering customer information and concluding with the order being saved in the system.
A flow is made up of several states and transitions that define how the conversation traverses from state to state.
The states themselves come in several varieties: action states that perform business logic, view states that involve the user in the flow, decision states that dynamically direct the flow, and end states that signify the end of a flow.
In addition, there are subflow states, which are themselves defined by a flow.
Finally, you saw hints about how access to a flow, state, or transition can be restricted to users who are granted specific authorities.
But we deferred conversation of how the user authenticates to the application and how the user is granted those authorities.
That’s where Spring Security comes in, and Spring Security is what we’ll explore in the next chapter.
Have you ever noticed that most people in television sitcoms don’t lock their doors? It happens all the time.
On Seinfeld, Kramer frequently let himself into Jerry’s apartment to help himself to the goodies in Jerry’s refrigerator.
On Friends, the various characters often entered one another’s apartments without warning or hesitation.
Once, while in London, Ross even burst into Chandler’s hotel room, narrowly missing Chandler in a compromising situation with Ross’s sister.
In the days of Leave it to Beaver, it wasn’t so unusual for people to leave their doors unlocked.
But it seems crazy that in a day when we’re concerned with privacy and security, we see television characters enabling unhindered access to their apartments and homes.
Information is probably the most valuable item we now have; crooks are looking for ways to steal our data and identities by sneaking into unsecured applications.
As software developers, we must take steps to protect the information that resides in.
Whether it’s an email account protected with a username/password pair or a brokerage account protected with a trading PIN, security is a crucial aspect of most applications.
It’s no accident that I chose to describe application security with the word “aspect.” Security is a concern that transcends an application’s functionality.
For the most part, an application should play no part in securing itself.
Although you could write security functionality directly into your application’s code (and that’s not uncommon), it’s better to keep security concerns separate from application concerns.
If you’re thinking that it’s starting to sound as if security is accomplished using aspect-oriented techniques, you’re right.
In this chapter we’re going to explore ways to secure your applications with aspects.
But you won’t have to develop those aspects yourself—we’re going to look at Spring Security, a security framework implemented with Spring AOP and servlet filters.
Spring Security is a security framework that provides declarative security for your Spring-based applications.
Spring Security provides a comprehensive security solution, handling authentication and authorization at both the web request level and at the method invocation level.
Based on the Spring Framework, Spring Security takes full advantage of dependency injection (DI) and aspect-oriented techniques.
Acegi was a powerful security framework, but it had one big turn-off: it required a lot of XML configuration.
I’ll spare you the intricate details of what such a configuration may have looked like.
Suffice it to say that it was common for a typical Acegi configuration to grow to several hundred lines of XML.
But the 2.0 release brought more than just a superficial name change.
Spring Security 2.0 introduced a new security-specific XML namespace for configuring security in Spring.
The new namespace, along with annotations and reasonable defaults, slimmed typical security configuration from hundreds of lines to only a dozen or so lines of XML.
Spring Security 3.0 added SpEL to the mix, simplifying security configuration even more.
Now at version 3.2, Spring Security tackles security from two angles.
To secure web requests and restrict access at the URL level, Spring Security uses servlet filters.
Spring Security can also secure method invocations using Spring AOP, proxying objects and applying advice to ensure that the user has the proper authority to invoke secured methods.
We’ll focus on web-layer security with Spring Security in this chapter.
Later, in chapter 14, we’ll revisit Spring Security and see how it can be used to secure method invocations.
No matter what kind of application you want to secure using Spring Security, the first thing you need to do is to add the Spring Security modules to the application’s classpath.
At the least, you’ll want to include the Core and Configuration modules in your application’s classpath.
Spring Security is often used to secure web applications, and that’s certainly the case with the Spittr application, so you’ll also need to add the Web module.
We’ll also be taking advantage of Spring Security’s JSP tag library, so you’ll need to add that module to the mix.
Spring Security employs several servlet filters to provide various aspects of security.
But thanks to a little Spring magic, you’ll only need to configure one of those filters.
Aspects A small module providing support for AspectJ-based aspects instead of standard Spring AOP when using Spring Security annotations.
If you like configuring servlets and filters in the traditional web.xml file, you can do that with the <filter> element, like this:
It’s a single filter that chains together one or more additional filters.
Those filters will be created when you enable web security.
To get the ball rolling with web security, let’s create the simplest possible security configuration.
In the early days of Spring Security (way back when it was known as Acegi Security), you’d need to write hundreds of lines of XML configuration just to enable simple security in a web application.
Spring Security 2.0 made things better by offering a securityspecific XML configuration namespace.
Spring 3.2 introduced a new Java configuration option, altogether eliminating the need for XML security configuration.
The following listing shows the simplest possible Java configuration for Spring Security.
As its name suggests, the @EnableWebSecurity annotation enables web security.
EnableWebSecurity is generally useful for enabling security in any web application.
Listing 9.1 The simplest configuration class to enable web security for Spring MVC.
Listing 9.2 The simplest configuration class to enable web security for Spring MVC.
It also configures a bean that automatically adds a hidden cross-site request forgery (CSRF) token field on forms using Spring’s form-binding tag library.
Either one will lock down an application so tightly that nobody can get in!
Looking back to listing 9.2, you can see that it doesn’t override any of these three configure() methods, and that explains why the application is now locked down tight.
This simple default configuration specifies how HTTP requests should be secured and what options a client has for authenticating the user.
It also configures Spring Security to support authentication via a form-based login (using a predefined login page) as well as HTTP Basic.
Therefore, all requests require authentication, but there’s nobody who can log in.
You’re going to need to add a bit more configuration to bend Spring Security to fit your application’s needs.
In addition to these facets of Spring Security, you may also want to selectively render certain content in your web views based on security constraints.
Let’s see how to configure user services to access user data during the authentication process.
Suppose you were to go out for a nice dinner at an exclusive restaurant.
Of course, you made the reservation several weeks in advance to be assured that you have a table.
As you enter the restaurant, you give the host your name.
Not one to give up so easily, you ask the host to check the reservation list again.
That would explain why you can’t get in the door, despite the fact that the place is empty.
Weeks later, you’ll realize that it also explains why the restaurant ended up closing and being replaced with a taqueria.
That’s the scenario you have with your application at this point.
There’s no way to get into the application because even if the user thinks they should be allowed in, there’s no record of them having access to the application.
For lack of a user store, the application is so exclusive that it’s completely unusable.
What you need is a user store—some place where usernames, passwords, and other data can be kept and retrieved from when making authentication decisions.
Fortunately, Spring Security is extremely flexible and is capable of authenticating users against virtually any data store.
But you can also create and plug in custom user store implementations.
Spring Security’s Java configuration makes it easy to configure one or more data store options.
We’ll start with the simplest user store: one that maintains its user store in memory.
For example, in the following listing, SecurityConfig overrides configure() to configure an in-memory user store with two users.
But you’ll also need some users in there, or else it’s as if you have no user store at all.
Therefore, you need to call the withUser() method to add a new user to the inmemory user store.
Listing 9.3 Configuring Spring Security to use an in-memory user store.
As you can see, the and() method is used to chain together multiple user configurations.
In addition to password(), roles(), and and(), there are several other methods for configuring user details for in-memory user stores.
Note that the roles() method is a shortcut for the authorities() methods.
Any values given to roles() are prefixed with ROLE_ and assigned as authorities to the user.
In effect, the following user configuration is equivalent to that in listing 9.3:
Although an in-memory user store is very useful for debugging and developer testing purposes, it’s probably not the most ideal choice for a production application.
For production-ready purposes, it’s usually better to maintain user data in a database of some sort.
It’s quite common for user data to be stored in a relational database, accessed via JDBC.
Specifies one or more authorities to grant to the user.
The only thing you must configure is a DataSource so that it’s able to access the relational database.
The DataSource is provided here via the magic of autowiring.
It expects that certain tables exist where user data will be kept.
More specifically, the following snippet of code from Spring Security’s internals shows the SQL queries that will be performed when looking up user details:
The first query retrieves a user’s username, password, and whether or not they’re enabled.
The next query looks up the user’s granted authorities for authorization purposes, and the final query looks up authorities granted to a user as a member of a group.
If you’re okay with defining and populating tables in your database that satisfy those queries, then there’s not much else for you to do.
But chances are your database doesn’t look anything like this, and you’ll want more control over the queries.
In that case, you can configure your own queries like this:
In this case, you’re only overriding the authentication and basic authorization queries.
When replacing the default SQL queries with those of your own design, it’s important to adhere to the basic contract of the queries.
All of them take the username as their only parameter.
The authentication query selects the username, password, and enabled status.
The authorities query selects zero or more rows containing the username and a granted authority.
And the group authorities query selects zero or more rows each with a group ID, group name, and an authority.
The only problem with that is that if the passwords are stored in plain text, they’re subject to the prying eyes of a hacker.
But if you encode the password in the database, then authentication will fail because it won’t match the plain text password submitted by the user.
To remedy this problem, you need to specify a password encoder by calling the passwordEncoder() method:
The passwordEncoder method accepts any implementation of Spring Security’s PasswordEncoder interface.
But you can always provide your own custom implementation if none of the out-of-the-box implementations meet your needs.
No matter which password encoder you use, it’s important to understand that the password in the database is never decoded.
Instead, the password that the user enters at login is encoded using the same algorithm and is then compared with the encoded password in the database.
Relational databases are just one storage option for user data.
Another very common choice is to keep user data in an LDAP repository.
The following configure() method shows a simple configuration for LDAP authentication:
By default, the base queries for both users and groups are empty, indicating that the search will be done from the root of the LDAP hierarchy.
But you can change that by specifying a query base:
The userSearchBase() method provides a base query for finding users.
Likewise, the groupSearchBase() specifies the base query for finding groups.
Rather than search from the root, this example specifies that users be searched for where the organization unit is people.
And groups should be searched for where the organizational unit is groups.
This involves sending the entered password to the LDAP directory and asking the server to compare the password against a user’s password attribute.
Because the comparison is done within the LDAP server, the actual password remains secret.
If you’d rather authenticate by doing a password comparison, you can declare so with the passwordCompare() method:
By default, the password given in the login form will be compared with the value of the userPassword attribute in the user’s LDAP entry.
In this example, you specify that the "passcode" attribute is what should be compared with the given password.
It’s nice that the actual password is kept secret on the server when doing server-side password comparison.
But the attempted password is still passed across the wire to the LDAP server and could be intercepted by a hacker.
To prevent that, you can specify an encryption strategy by calling the passwordEncoder() method.
This assumes that the passwords are also encrypted using MD5 in the LDAP server.
You’ve happily been configuring Spring to authenticate against an LDAP server, but where is that server?
By default, Spring Security’s LDAP authentication assumes that the LDAP server is listening on port 33389 on localhost.
But if your LDAP server is on another machine, you can use the contextSource() method to configure the location:
Instead of setting the URL to a remote LDAP server, you can specify the root suffix for the embedded server via the root() method:
When the LDAP server starts, it will attempt to load data from any LDIF files that it can find in the classpath.
Each record is composed of one or more lines, each containing a name:value pair.
If you’d rather that Spring not rummage through your classpath looking for just any LDIF files it can find, you can be more explicit about which LDIF file gets loaded by calling the ldif() method:
Here you specifically ask the LDAP server to load its content from the users.ldif file at the root of the classpath.
In case you’re curious, here’s an LDIF file that you could use to load the embedded LDAP server with user data:
Spring Security’s built-in user stores are convenient and cover the most common use cases.
But if your authentication needs are of the uncommon variety, you may need to create and configure a custom user-details service.
Suppose that you need to authenticate against users in a non-relational database such as Mongo or Neo4j.
In that case, you’ll need to implement a custom implementation of the UserDetailsService interface.
The following listing shows an implementation of UserDetailsService that looks up a user from a given implementation of SpitterRepository.
What’s interesting about SpitterUserService is that it has no idea how the user data is persisted.
The SpitterRepository it’s given could look up the Spitter from a relational database, from a document database, from a graph database, or it could just make it up.
SpitterUserService doesn’t know or care what underlying data storage is used.
It just fetches the Spitter object and uses it to create a User object.
But instead of using one of Spring’s provided user stores, it takes any implementation of UserDetailsService.
Another option worth considering is that you could change Spitter so that it implements UserDetailsService.
Earlier, in section 9.1.3, you saw an extremely simple Spring Security configuration and learned how it falls back to a default configuration where all requests require authentication.
Some may argue that too much security is better than too little.
But there’s also something to be said about applying the appropriate amount of security.
In any given application, not all requests should be secured equally.
Some requests may only be available to users with certain authorities and unavailable to those without those authorities.
For example, consider the requests served by the Spittr application.
Certainly, the home page is public and doesn’t need to be secured.
Likewise, since all Spittle objects are essentially public, the pages that display Spittles don’t require security.
Requests that create a Spittle, however, should only be performed by an authenticated user.
The key to fine-tuning security for each request is to override the configure (HttpSecurity) method.
The HttpSecurity object given to configure() can be used to configure several aspects of HTTP security.
The first call to antMatchers() specifies that requests whose path is /spitters/me should be authenticated.
The second call to antMatchers() is even more specific, saying that any HTTP POST request to /spittles must be authenticated.
Finally, a call to anyRequests() says that all other requests should be permitted, not requiring authentication or any authorities.
Although we’re not using it here, you could specify a path with a wildcard like this:
You could also specify multiple paths in a single call to antMatchers():
Whereas the antMatchers() method works with paths that may contain Ant-style wildcards, there’s also a regexMatchers() method that accepts regular expressions to define request paths.
For example, the following snippet uses a regular expression that’s equivalent to /spitters/** (Ant-style):
Aside from path selection, we’ve also used authenticated() and permitAll() to define how the paths should be secured.
The authenticated() method demands that the user have logged into the application to perform the request.
If the user isn’t authenticated, Spring Security’s filters will capture the request and redirect the user to the application’s login page.
Meanwhile, the permitAll() method allows the requests without any security demands.
In addition to authenticated() and permitAll(), there are other methods that can be used to define how a request should be secured.
Using methods from table 9.4, you can configure security to require more than just an authenticated user.
For example, you could change the previous configure() method to require that the user not only be authenticated, but also have ROLE_SPITTER authority:
Optionally, you can use the hasRole() method to have the ROLE_ prefix applied automatically:
Table 9.4 Configuration methods to define how a path is to be secured.
You can chain as many calls to antMatchers(), regexMatchers(), and anyRequest() as you need to fully establish the security rules around your web application.
You should know, however, that they’ll be applied in the order given.
For that reason, it’s important to configure the most specific request path patterns first and the least specific ones (such as anyRequest()) last.
If not, then the least specific paths will trump the more specific ones.
That is, you can use hasRole() to require a certain role, but you can’t also use hasIpAddress() to require a specific IP address on the same path.
Moreover, there’s no way to work in any conditions that aren’t defined by the methods in table 9.4
What if you wanted to restrict access to certain roles only on Tuesday?
In chapter 3, you saw how to use the Spring Expression Language (SpEL) as an advanced technique for wiring bean properties.
Using the access() method, you can also use SpEL as a means for declaring access requirements.
For example, here’s how you could use a SpEL expression to require ROLE_SPITTER access for the /spitter/me URL pattern:
This security constraint placed on /spitter/me is equivalent to the one we started with, except that now it uses SpEL to express the security rules.
The hasRole() expression evaluates to true if the current user has been granted the given authority.
What makes SpEL a more powerful option here is that hasRole() is only one of the security-specific expressions supported.
Table 9.5 lists all of the SpEL expressions available in Spring Security.
With Spring Security’s SpEL expressions at your disposal, you can do more than just limit access based on a user’s granted authorities.
For example, if you wanted to lock down the /spitter/me URLs to not only require ROLE_SPITTER, but to also only be allowed from a given IP address, you might call the access() method like this:
I’ll bet that you’re already dreaming up interesting security constraints based on SpEL.
But for now, let’s look at another way that Spring Security intercepts requests to enforce channel security.
It may not be a big deal to send a spittle message in the clear over HTTP.
But if you’re passing sensitive information such as passwords and credit card numbers across HTTP, then you’re asking for trouble.
Data is sent over HTTP unencrypted, leaving an open opportunity for a hacker to intercept the request and see information you don’t want them to see.
That’s why sensitive information should be sent encrypted over HTTPS.
All you have to do is add an s after the http in a URL and you’re set.
That’s true, but it places responsibility for using the HTTPS channel in the wrong place.
Just as it’s easy to make a page secure by adding an s, it’s just as easy to forget to add that s.
If you have several links in your app that require HTTPS, chances are good that you’ll forget to add an s or two.
On the other hand, you might overcorrect and use HTTPS in places where it’s unnecessary.
Although Spittr doesn’t ask for credit card numbers or social security numbers or anything terribly sensitive, users may want their registration information to be kept private.
Any time a request comes in for /spitter/form, Spring Security will see that it requires a secure channel (per the call to requiresSecure()) and automatically redirect the request to go over HTTPS.
Conversely, some pages don’t need to be sent over HTTPS.
The home page, for example, doesn’t carry any sensitive information and should be sent over HTTP.
You can declare that the home page always be sent over HTTP by using requiresInsecure() instead of requiresSecure:
If a request for / comes in over HTTPS, Spring Security will redirect the request to flow over the insecure HTTP.
In listing 9.5 you’re using antMatches(), but regexMatchers() is also available for selecting path patterns with regular expressions.
As you’ll recall, our SpittleController will create a new Spittle for a user when a POST request is submitted to /spittles.
Let’s say that you’re tempted by the offer of winning a new car and you click the button—you’ll submit the form to http://www.spittr.com/spittles.
If you’re already logged in to spittr.com, you’ll be broadcasting a message that tells everyone that you made a bad decision.
This is a simple example of a cross-site request forgery (CSRF)
Basically, a CSRF attack happens when one site tricks a user into submitting a request to another server,
Listing 9.5 The requiresChannel() method enforces HTTPS for select URLs.
Starting with Spring Security 3.2, CSRF protection is enabled by default.
In fact, unless you take steps to work with CSRF protection or disable it, you’ll probably have trouble getting the forms in your application to submit successfully.
Statechanging requests (for example, any request that is not GET, HEAD, OPTIONS, or TRACE) will be intercepted and checked for a CSRF token.
If the request doesn’t carry a CSRF token, or if the token doesn’t match the token on the server, the request will fail with a CsrfException.
This means that any forms in your application must submit a token in a _csrf field.
And that token must be the same as the one calculated and stored by the server so that it matches up when the form is submitted.
Fortunately, Spring Security makes this easy for you by putting the token into the request under the request attributes.
If you’re using JSP for page templates, you can do something very similar:
Even better, if you’re using Spring’s form-binding tag library, the <sf:form> tag will automatically add the hidden CSRF token tag for you.
Another way of dealing with CSRF is to not deal with it at all.
You can disable Spring Security’s CSRF protection by calling csrf().disable() in the configuration, as shown in the next listing.
Be warned that it’s generally not a good idea to disable CSRF protection.
If you do, you leave your application open to a CSRF attack.
Use the configuration in listing 9.6 only after careful deliberation.
Now that you’ve configured a user store and configured Spring Security to intercept requests, you should turn your attention to prompting the user for their credentials.
When you were still using the extremely simple Spring Security configuration in listing 9.1, you got a login page for free.
Notice that, as before, and() is called to chain together different configuration instructions.
If you link to /login in the application, or if the user navigates to a page that requires authentication, then the login page will be shown in the browser.
As you can see in figure 9.2, the page isn’t very exciting aesthetically, but it does the job it needs to do.
I’ll bet you’d prefer that your application’s login page look nicer than the default login page.
It’d be a shame to have such a plain login page ruin your otherwise beautifully designed website.
Let’s see how you can add a custom login page to your application.
Listing 9.7 The formLogin() method enables a basic login page.
Figure 9.2 The default login page is simple aesthetically, but fully functional.
The first step toward creating a custom login page is knowing what you need to include in the login form.
Look no further than the HTML source of the default login page to see what’s required:
The key thing to note is where the <form> submits to.
And make note of the username and password fields; you’ll need those same fields on your login page.
Finally, assuming that you’ve not disabled CSRF, you’ll need to be sure to include a _csrf field with the CSRF token.
The following listing shows a Thymeleaf template that provides a login page within the style of the Spittr application.
Listing 9.8 A custom login page for the Spittr application (as a Thymeleaf template)
Notice that the Thymeleaf template has both username and password fields, just like the default login page.
And since this is a Thymeleaf template, the hidden _csrf field will automatically be added to the form.
Form-based authentication is ideal for human users of an application.
But in chapter 16, you’ll see how to turn some of your web application’s pages into a RESTful API.
When the user of the application is another application, prompting for login with a form just won’t do.
When encountered by a web browser, it prompts the user with a plain modal dialog box.
But that’s just how it’s manifested in a web browser.
In reality, it’s an HTTP 401 response, indicating that a username and password must be presented with the request.
This makes it suitable as a means for REST clients to authenticate against the services they’re consuming.
Enabling HTTP Basic authentication is as simple as calling httpBasic() on the HttpSecurity object passed into configure()
Here’s a rather typical example of Spring Security configuration to enable HTTP Basic:
Notice that once again the and() method is used to chain together different configuration directives in configure()
Not much customization is available or even required with httpBasic()
So rather than dwell on the topic any further, let’s move on to see how to have a user automatically authenticated via remember-me functionality.
It’s important for an application to be able to authenticate users.
But from the user’s perspective, it’d be nice if the application didn’t always prompt them with a login every time they use it.
That’s why many websites offer remember-me functionality, so that you can log in once and then be remembered by the application when you come back to it later.
Spring Security makes it easy to add remember-me functionality to an application.
To turn on remember-me support, all you need to do is call rememberMe() on the HttpSecurity passed into configure():
Here, in addition to turning on remember-me functionality, a bit of special configuration has also been added.
By default, a remember-me token is stored in a cookie that’s valid for up to two weeks.
But this example specifies that the token should stay valid for up to four weeks (2,419,200 seconds)
By default, the private key is SpringSecured, but this example sets it to spitterKey to make it specific to the Spittr application.
Now that the remember-me functionality is enabled, you’ll need a way for users to indicate that they’d like the application to remember them.
For that, the login request will need to include a remember-me parameter.
A simple check box in the login form ought to do the job:
Just as important as being able to log in to an application is the ability to log out.
This is especially true if you’ve enabled remember-me; otherwise the user would be logged into the application forever.
Let’s see how you can add the ability to log out.
As it turns out, logout capability is already enabled by your configuration without you having to do anything else.
All you need to do is add a link that uses it.
Logout is implemented as a servlet filter that (by default) intercepts requests to /logout.
Therefore, adding logout to an application is as easy as adding the following link (shown here as a Thymeleaf snippet):
When the user clicks on the link, the request for /logout will be handled by Spring Security’s LogoutFilter.
The user will be logged out and any remember-me tokens cleared.
After the logout is complete, the user’s browser will be redirected to /login?logout to give the user an opportunity to log in again.
If you’d like to have the user redirected to some other page, such as the application’s home page, you can configure that in configure() like this:
In this case, the call to logoutSuccessUrl() indicates that the browser should be redirected to / after a successful logout.
So far you’ve seen how to secure web applications as requests are made.
The assumption has been that security would involve stopping a user from accessing a URL that they’re not authorized to use.
But it’s also a good idea to never show links that a user won’t be able to follow.
When rendering HTML to be served in the browser, you may want the view to reflect the security constraints and information.
Or you may want to conditionally render certain view elements, depending on what authorities have been granted to the user.
In chapter 6, we looked at two significant options for rendering views in a Spring MVC application: JSP and Thymeleaf.
It doesn’t matter which of these options you choose, there’s a way to work with security in the view.
Let’s see how to work Spring Security into our views, starting with Spring Security’s JSP tag library.
Spring Security’s JSP tag library is small and includes only three tags, listed in table 9.6
To use the JSP tag library, we’ll need to declare it in any JSP file where it will be used:
Once the tag library has been declared in the JSP file, you’re ready to use it.
Let’s look at each of the three JSP tags that come with Spring Security and see how they work.
The property attribute identifies a property of the user’s authentication object.
The properties available will vary depending on how the user was authenticated, but you can count on a few common properties being available, including those listed in table 9.7
In our example, the property being rendered is actually the nested username property of the principal property.
Table 9.6 Spring Security supports security in the view layer with a JSP tag library.
But if you’d rather assign it to a variable, then simply specify the name of the variable in the var attribute.
For example, here's how you could assign it to a property named loginId:
Let’s see how to conditionally render content depending on the user’s privileges.
There’s no point in showing a login form to a user who’s already logged in or in showing a personalized greeting to a user who’s not logged in.
For example, in the Spittr application you don’t want to show the form for adding a new spittle unless the user has the ROLE_SPITTER role.
But you have the full power of SpEL at your disposal when setting the access attribute, including the Spring Security-provided expressions listed in table 9.5
With these expressions available, you can cook up some interesting security constraints.
For example, imagine that the application has some administrative functions that are only available to the user whose username is “habuma”
Maybe you’d use the isAuthenticated() and principal expressions like this:
I’m sure you can dream up even more interesting expressions than that.
I’ll leave it up to your imagination to concoct more security constraints.
But one thing about the example that I dreamt up still bugs me.
Though I might want to restrict the administrative functions to “habuma”, perhaps doing it with a JSP tag isn’t ideal.
Sure, it’ll keep the link from being rendered in the view.
But nothing’s stopping anyone from manually entering the /admin URL in the browser’s address line.
Drawing on what you learned earlier in this chapter, that should be an easy thing to fix.
Adding a new call to the antMatchers() method in the security configuration will tighten security around the /admin URL:
The URL is secured and the link to the URL won’t appear unless the user is authorized to use it.
Is there any way to eliminate that duplication and still prevent the link to the administrative functions from being rendered unless the rule is met?
Unlike the access attribute where the security constraint is explicitly declared, the url attribute indirectly.
Since you’ve already declared security constraints for /admin in the Spring Security configuration, you can use the url attribute like this:
The expression was configured in one place (in the security configuration), but used in two places.
Spring Security’s JSP tag library comes in very handy, especially when it comes to conditionally rendering view elements to only those users who are allowed to see them.
But if you’ve chosen Thymeleaf instead of JSP for your views, then you’re not out of luck.
You’ve already seen how Thymeleaf’s Spring dialect will automatically add a hidden CSRF token field to your forms.
Much like Spring Security’s JSP tag library, Thymeleaf’s security dialect offers conditional rendering and the ability to render authentication details.
Table 9.8 lists the attributes provided by the security dialect.
In order to use the security dialect, you’ll need to make sure that the Thymeleaf Extras Spring Security module is in your application’s classpath.
Table 9.8 Thymeleaf’s security dialect offers attributes that mirror much of Spring Security’s tag library.
Similar to Spring Security’s <sec:authorize/> JSP tag when using the url attribute.
With the security dialect, you’re almost ready to start using its attributes in your Thymeleaf templates.
First, declare the security namespace in the templates where you’ll be using those attributes:
Here the standard Thymeleaf dialect is assigned to the th prefix as before, and the security dialect is assigned to the sec prefix.
Now you can use the Thymeleaf attributes however you see fit.
For example, suppose that you want to render text saying “Hello” to the user if the user is authenticated.
The following snippet from a Thymeleaf template will do the trick:
If that expression evaluates to true, then the body of the element will be rendered.
In this case, the expression is isAuthenticated(), so the body of the <div> tag will be rendered only if the user is authenticated.
With regard to the body, it says “Hello” to the authentication’s name property.
As you’ll recall, Spring Security’s <sec:authorize> JSP tag has a url attribute that causes its body to be conditionally rendered based on the authorizations associated with a given URL path.
With Thymeleaf, you can accomplish the same thing with the sec:authorize-url attribute.
For example, the following Thymeleaf snippet accomplishes the same thing you previously used the <sec:authorize> JSP tag and url attribute for:
Assuming that the user has authorization to access /admin, then a link to the admin page will be rendered; otherwise it won’t.
Spring Security provides a mechanism for securing your application that’s simple, flexible, and powerful.
Using a series of servlet filters, Spring Security can control access to web resources, including Spring MVC controllers.
But thanks to Spring Security’s Java configuration model, you don’t need to deal with those filters directly.
When it comes to authenticating users, Spring Security offers several options.
You saw how to configure authentication against an in-memory user store, a relational database, and LDAP directory servers.
And when your authentication needs don’t fit any of those options, you saw how to create and configure a custom user-details service.
Over the past few chapters, you’ve seen how Spring fits into the front end of an application.
Coming up in the next section, we’ll move a bit deeper down the stack and see how Spring plays a part in the back end.
That exploration will start in the next chapter with a look at Spring’s JDBC abstraction.
Although the web pages served by a web application are all your users ever see, the real work happens behind the scenes on the back end server where data is processed and persisted.
Part 3 will look at how Spring can help you work with data in the back end.
Relational databases have been the workhorse of enterprise applications for decades.
If JDBC is not your style, perhaps you’d rather work with an object-relational mapping (ORM) framework.
In addition, you’ll see how to work magic with Spring Data JPA, automatically generating repository implementations on the fly at runtime.
Security is an important aspect in the back end as well as the front end.
With the core of the Spring container now under your belt, it’s time to put it to work in real applications.
A perfect place to start is with a requirement of nearly any enterprise application: persisting data.
You have probably dealt with database access in an application in the past.
In practice, you’ll know that data access has many pitfalls.
You have to initialize your data-access framework, open connections, handle various exceptions, and close connections.
If you get any of this wrong, you could potentially corrupt or delete valuable company data.
In case you haven’t experienced the consequences of mishandled data access, it’s a Bad Thing.
Because we strive for Good Things, we turn to Spring.
Spring comes with a family of data-access frameworks that integrate with a variety of data-access technologies.
Whether you’re persisting your data via direct JDBC or an object-relational mapping (ORM) framework such as Hibernate, Spring removes the tedium of data access from your persistence code.
As you develop the persistence layer of the Spittr application, you’re faced with some choices.
You could use JDBC, Hibernate, the Java Persistence API (JPA), or any of a number of persistence frameworks.
Or you might consider one of the new breed of NoSQL databases (or schemaless databases, as I prefer to call them) that are popular these days.
No matter what choice you make, it’s good to know that there’s probably support for it in Spring.
In this chapter, we’ll focus on Spring’s support for JDBC.
But first, let’s lay some groundwork by getting familiar with Spring’s persistence philosophy.
From the previous chapters, you know that one of Spring’s goals is to allow you to develop applications following the sound object-oriented (OO) principle of coding to interfaces.
Like many applications, your Spittr application needs to read data from and write data to some kind of database.
To avoid scattering persistence logic across all components in the application, it’s good to factor database access into one or more components that are focused on that task.
Such components are commonly called data-access objects (DAOs) or repositories.
To avoid coupling the application to any particular data-access strategy, properly written repositories should expose their functionality through interfaces.
Figure 10.1 shows the proper approach to designing your data-access tier.
As you can see, the service objects access the repositories through interfaces.
First, it makes your service objects easily testable, because they’re not coupled to a specific data-access implementation.
In fact, you could create mock implementations of these data-access interfaces.
That would allow you to test your service object without ever having to connect to the database, which would significantly speed up your unit tests and rule out the chance of a test failure due to inconsistent data.
The chosen persistence approach is isolated to the repository, and only the.
Figure 10.1 Service objects don’t handle their own data access.
The repository’s interface keeps it loosely coupled to the service object.
This makes for a flexible application design and allows the chosen persistence framework to be swapped out with minimal impact on the rest of the application.
If the implementation details of the data-access tier were to leak into other parts of the application, the entire application would become coupled with the data-access tier, leading to a rigid application design.
I believe that interfaces are key to writing loosely coupled code and that they should be used at all layers of an application, not just at the data-access layer.
That said, it’s also important to note that though Spring encourages the use of interfaces, Spring doesn’t require them—you’re welcome to use Spring to wire a bean (repository or otherwise) directly into a property of another bean without an interface between them.
One way Spring helps you insulate your data-access tier from the rest of your application is by providing a consistent exception hierarchy that’s used across all of its supported persistence options.
There’s an old joke about a skydiver who’s blown off course and ends up landing in a tree, dangling above the ground.
After a while, someone walks by, and the skydiver asks where he is.
That story has been told several times, with the profession or nationality of the passerby different each time.
If you’ve ever written JDBC code (without Spring), you’re probably keenly aware that you can’t do anything with JDBC without being forced to catch SQLException.
SQLException means something went wrong while trying to access a database.
But there’s little about that exception that tells you what went wrong or how to deal with it.
Some common problems that might cause a SQLException to be thrown include these:
The big question surrounding SQLException is how it should be handled when it’s caught.
As it turns out, many of the problems that trigger a SQLException can’t be.
If the application can’t connect to the database, that usually means the application will be unable to continue.
Likewise, if there are errors in the query, little can be done about it at runtime.
If nothing can be done to recover from a SQLException, why are you forced to catch it?
Even if you have a plan for dealing with some SQLExceptions, you’ll have to catch the SQLException and dig around in its properties for more information about the nature of the problem.
That’s because SQLException is treated as a one-size-fits-all exception for problems related to data access.
Rather than have a different exception type for each possible problem, SQLException is the exception that’s thrown for all data-access problems.
Hibernate, for example, offers almost two dozen different exceptions, each targeting a specific data-access problem.
This makes it possible to write catch blocks for the exceptions that you want to deal with.
As stated before, we’d like to isolate the specifics of the persistence mechanism to the data-access layer.
If Hibernate-specific exceptions are being thrown, then the fact that you’re dealing with Hibernate will leak into the rest of the application.
Either that, or you’ll be forced to catch persistence platform exceptions and rethrow them as platformagnostic exceptions.
On one hand, JDBC’s exception hierarchy is too generic—it’s not much of a hierarchy at all.
On the other hand, Hibernate’s exception hierarchy is proprietary to Hibernate.
What we need is a hierarchy of data-access exceptions that are descriptive but not directly associated with a specific persistence framework.
SPRING’S PERSISTENCE PLATFORM–AGNOSTIC EXCEPTIONS Spring JDBC provides a hierarchy of data-access exceptions that solve both problems.
In contrast to JDBC, Spring provides several data-access exceptions, each descriptive of the problem for which they’re thrown.
Table 10.1 shows some of Spring’s data-access exceptions lined up against the exceptions offered by JDBC.
As you can see, Spring has an exception for virtually anything that could go wrong when reading from or writing to a database.
And the list of Spring’s data-access exceptions is more vast than what’s shown in table 10.1
I would have listed them all, but I didn’t want JDBC to get an inferiority complex.)
Even though Spring’s exception hierarchy is far richer than JDBC’s simple SQLException, it isn’t associated with any particular persistence solution.
This means you can count on Spring to throw a consistent set of exceptions, regardless of which persistence provider you choose.
This helps to keep your persistence choice confined to the data-access layer.
In other words, you don’t have to catch any of the data-access exceptions thrown from Spring (although you’re welcome to if you’d like)
Spring takes the stance that many exceptions are the result of problems that can’t be addressed in a catch block.
Instead of forcing developers to write catch blocks (which are often left empty), Spring promotes the use of unchecked exceptions.
This leaves the decision of whether or not to catch an exception in your hands.
To take advantage of Spring’s data-access exceptions, you must use one of Spring’s supported data-access templates.
Let’s look at how Spring templates can greatly simplify data access.
If so, you’ll surely agree that one of the most important parts of traveling is getting your luggage from point A to point B.
There are many steps to this process: When you arrive at the terminal, your first stop is at the counter to check your luggage.
Next, security scans it to ensure the safety of the flight.
Then it takes a ride on the luggage train on its way to being placed on the plane.
If you need to catch a connecting flight, your luggage needs to be moved, as well.
When you arrive at your final destination, the luggage has to be removed from the plane and placed on the carousel.
Finally, you go down to the baggage claim area and pick it up.
Even though there are many steps to this process, you’re actively involved in only a couple of them.
You’re involved only when you need to be; the rest is taken care of.
This mirrors a powerful design pattern: the template method pattern.
In the example, the process is moving luggage from departure city to arrival city.
The overall sequence of events for handling luggage occurs the same way every time: luggage is checked in, luggage is loaded onto the plane, and so forth.
Some steps of the process are fixed as well—they happen the same way every time.
When the plane arrives at its destination, every piece of luggage is unloaded one at a time and placed on a carousel to be taken to baggage claim.
For example, the handling of luggage starts with a passenger checking in the luggage at the counter.
This part of the process always has to happen at the beginning, so its sequence in the process is fixed.
Because each passenger’s luggage check-in is different, the implementation of this part of the process is determined by the passenger.
Different implementations of this interface define specific implementations of this portion of the process.
This is the same pattern that Spring applies to data access.
No matter what technology you’re using, certain data-access steps are required.
For example, you always need to obtain a connection to your data store and clean up resources when you’re done.
You query for different objects and update the data in different ways.
Spring separates the fixed and variable parts of the data-access process into two distinct classes: templates and callbacks.
Templates manage the fixed part of the process, whereas your custom data-access code is handled in callbacks.
As you can see, Spring’s template classes handle the fixed parts of data access—controlling transactions, managing resources, and handling exceptions.
In practice, this makes for an elegant framework, because all you have to worry about is your data-access logic.
Spring comes with several templates to choose from, depending on your persistence platform choice.
If you’re using straight JDBC, then you’ll want to use JdbcTemplate.
But if you favor one of the object-relational mapping frameworks, perhaps HibernateTemplate or JpaTemplate is more suitable.
Table 10.2 lists all of Spring’s data-access templates and their purposes.
Table 10.2 Spring comes with several data-access templates, each suitable for a different persistence mechanism.
Figure 10.2 Spring’s data-access template classes take responsibility for common data-access duties.
Spring provides support for several persistence frameworks, and there isn’t enough space to cover them all in this chapter.
Therefore, I’m going to focus on what I believe are the most beneficial persistence options and the ones you’ll most likely be using.
We’ll start with basic JDBC access in this chapter, because it’s the simplest way to read data from and write data to a database.
Then, in chapter 11, we’ll look at Hibernate and JPA, two of the most popular POJO-based ORM solutions.
We’ll wrap up our exploration of Spring persistence in chapter 12 by looking at how the Spring Data project brings the world of schemaless data to Spring.
Most of Spring’s persistence support options depend on a data source, so before you can get started with declaring templates and repositories, you need to configure Spring with a data source to be able to connect to the database.
Regardless of which form of Spring-supported data access you use, you’ll likely need to configure a reference to a data source.
Spring offers several options for configuring data-source beans in your Spring application, including these:
For production-ready applications, I recommend using a data source that draws its connections from a connection pool.
When possible, I prefer to retrieve the pooled data source from an application server via JNDI.
With that preference in mind, let’s start by looking at how to configure Spring to retrieve a data source from JNDI.
Spring applications are often deployed to run in a Java EE application server such as WebSphere or JBoss, or even a web container like Tomcat.
These servers allow you to configure data sources to be retrieved via JNDI.
The benefit of configuring data sources in this way is that they can be managed completely external to the application, allowing the application to ask for a data source when it’s ready to access the database.
Moreover, data sources managed in an application server are often pooled for greater performance and can be hot-swapped by system administrators.
With Spring, you can configure a reference to a data source that’s kept in JNDI and wire it into the classes that need it as if it were just another Spring bean.
The <jee:jndi-lookup> element from Spring’s jee namespace makes it possible to retrieve any object, including data sources, from JNDI and make it available as a Spring bean.
The jndi-name attribute is used to specify the name of the resource in JNDI.
If only the jndi-name property is set, then the data source will be looked up using the name given as is.
But if the application is running in a Java application server, you’ll want to set the resource-ref property to true so that the value given in jndi-name will be prepended with java:comp/env/
Clearly, the Java configuration for JNDI-fetched beans is more involved.
Many times, Java configuration is simpler than XML configuration, but this is one time when you might write more code in Java.
Even so, it’s easy to see how this Java configuration parallels the XML equivalent.
If you’re unable to retrieve a data source from JNDI, the next best thing is to configure a pooled data source directly in Spring.
Although Spring doesn’t provide a pooled data source, plenty of suitable ones are available, including the following open source options:
Or, if you prefer Java configuration, the pooled DataSource bean can be declared like this:
The first four properties are elemental to configuring a BasicDataSource.
The driverClassName property specifies the fully qualified name of the JDBC driver class.
Here you configure it with the JDBC driver for the H2 database.
The url property is where you set the complete JDBC URL for the database.
Finally, the username and password properties are used to authenticate when you’re connecting to the database.
In addition, you can use several properties to configure the data source pool.
Table 10.3 lists a few of the most useful pool-configuration properties of DBCP’s BasicDataSource.
In this case, you’ve configured the pool to start with five connections.
Should more connections be needed, BasicDataSource is allowed to create them, up to a maximum of 10 active connections.
The simplest data source you can configure in Spring is one that’s defined through a JDBC driver.
Configuring any of these data sources is similar to how you configured DBCP’s BasicDataSource.
The only significant difference with these data-source beans as compared to the pooling data-source beans is that because they don’t provide a connection pool, there are no pool configuration properties to set.
Although these data sources are great for small applications and running in development, you should seriously consider the implications of using them in a production application.
Because of these limitations, I strongly recommend using pooled data sources.
There’s one more data source I want to tell you about: the embedded database.
An embedded database runs as part of your application instead of as a separate database server that your application connects to.
Although it’s not very useful in production settings, an embedded database is a perfect choice for development and testing purposes.
That’s because it allows you to populate your database with test data that’s reset every time you restart your application or run your tests.
For example, the following listing shows how to use the jdbc namespace to configure an embedded H2 database that’s preloaded with a set of test data.
Be sure to have H2 in your application’s classpath.) Alternatively, you may set type to DERBY to use an embedded Apache Derby database.
The id attribute is set to dataSource, which will be the ID of the.
Listing 10.1 Configuring an embedded database using the jdbc namespace.
When you configure an embedded database in Java configuration, there isn’t the convenience of the jdbc namespace.
And instead of using the <jdbc:script> element to specify initialization SQL, you can call addScript()
You’ve seen a handful of different ways to configure data sources in Spring, and I’ll bet you’ve identified one or two of them that seem appropriate for your application.
In fact, you probably see a need for one of those data-source beans in one environment and a different one in another environment.
But you may want to use DBCP’s BasicDataSource in your QA environment.
And perhaps you need to use <jee:jndi-lookup> in your production deployment.
Spring’s bean-profiles feature that we discussed in chapter 3 is perfect here.
All you need to do is configure each of these data sources in different profiles, as shown next.
Listing 10.2 Spring profiles enabling selection of a data source at runtime.
Using profiles, the data source is chosen at runtime, based on which profile is active.
As configured in listing 10.2, the embedded database is created if and only if the development profile is active.
Similarly, the DBCP BasicDataSource is created if and only if the qa profile is active.
And the data source is retrieved from JNDI if and only if the production profile is active.
For the sake of completeness, the following listing shows the same profile-driven configuration using Spring XML configuration instead of Java configuration.
Now that you’ve established a connection to the database through a data source, you’re ready to access the database.
As I’ve already mentioned, Spring affords you several options for working with relational databases, including JDBC, Hibernate, and the Java Persistence API (JPA)
In the next section, you’ll see how to build the persistence layer of a Spring application using Spring’s support for JDBC.
But if Hibernate or JPA is more your style, feel free to jump ahead to the next chapter where those are the topics.
Despite this, a good number of applications write Java objects to a database the oldfashioned way: they earn it.
The tried-andtrue method for persisting data is with good old JDBC.
And why not? JDBC doesn’t require mastering another framework’s query language.
It’s built on top of SQL, which is the data-access language.
Plus, you can more finely tune the performance of your data access when you use JDBC than with practically any other technology.
And JDBC allows you to take advantage of your database’s proprietary features, where other frameworks may discourage or flat-out prohibit this.
What’s more, JDBC lets you work with data at a much lower level than the persistence frameworks.
You’re in full control of how your application reads and manipulates data.
This includes allowing you to access and manipulate individual columns in a database.
This fine-grained approach to data access comes in handy in applications, such as reporting applications, where it doesn’t make sense to organize the data into objects just to then unwind it back into raw data.
But all is not sunny in the world of JDBC.
With its power, flexibility, and other niceties also come some not-so-niceties.
Although JDBC gives you an API that works closely with your database, you’re responsible for handling everything related to accessing the database.
If you’ve ever written JDBC that inserts data into the database, the following code shouldn’t be too alien to you.
As far as JDBC operations go, this is about as simple as it gets.
So why does it take this many lines to do something so straightforward? Actually, it doesn’t.
But JDBC requires that you properly manage connections and statements and somehow handle the SQLException that may be thrown.
Speaking of that SQLException, not only is it not clear how you should handle it (because it’s not clear what went wrong), but you’re forced to catch it twice! You must catch it if something goes wrong while inserting a record, and you have to catch it.
Listing 10.4 Using JDBC to insert a row into a database.
Seems like a lot of work to handle something that usually can’t be handled programmatically.
Now look at the next listing, where you use traditional JDBC to update a row in the Spitter table in the database.
In fact, disregarding the SQL String and the line where the statement is created, they’re identical.
Again, that’s a lot of code to do something as simple as update a single row in a database.
Ideally, you’d only have to write the lines that are specific to the task at hand.
To round out our tour of conventional JDBC, let’s see how you might retrieve data from the database.
Listing 10.5 Using JDBC to update a row in a database.
That’s almost as verbose as the insert and update examples—maybe more.
By now you should see that much of JDBC code is boilerplate for creating connections and statements and handling exceptions.
With my point made, I’ll end the torture and not make you look at any more of this nasty code.
The fact is that all that JDBC boilerplate code is important.
Cleaning up resources and handling errors is what makes data access robust.
Listing 10.6 Using JDBC to query a row from a database.
So not only do you need this code, but you also need to make sure it’s correct.
This is all the more reason to let a framework deal with the boilerplate so you know that it’s written once and written right.
Spring’s JDBC framework will clean up your JDBC code by shouldering the burden of resource management and exception handling.
This leaves you free to write only the code necessary to move data to and from the database.
As I explained in the previous section, Spring abstracts away the boilerplate dataaccess code behind template classes.
For JDBC, Spring comes with three template classes to choose from:
JdbcTemplate—The most basic of Spring’s JDBC templates, this class provides simple access to a database through JDBC and indexed-parameter queries.
At one time, you had to weigh your choice of JDBC template carefully.
SimpleJdbcTemplate has been deprecated and its Java 5 features have been rolled into JdbcTemplate.
That leaves good ol’ JdbcTemplate as your go-to option for most JDBC work—that’s the option I’ll focus on in this section.
This makes it easy enough to configure a JdbcTemplate bean in Spring with the following @Bean method:
Now you can wire the jdbcTemplate bean into your repository and use it to access the database.
For example, suppose the Spitter repository is written to use JdbcTemplate:
And its constructor is annotated with @Inject so that when it’s created, it will be given a JdbcOperations object.
With a JdbcTemplate at your repository’s disposal, you can greatly simplify the addSpitter() method from listing 10.4
I think you’ll agree that this version of addSpitter() is significantly simpler.
There’s no more connection or statement-creation code—and no more exception-handling code.
Just because you don’t see a lot of boilerplate code doesn’t mean it’s not there.
When the update() method is called, JdbcTemplate gets a connection, creates a statement, and executes the insert SQL.
What you also don’t see is how the SQLException is handled.
Because Spring’s data-access exceptions are all runtime exceptions, you don’t have to catch them in the addSpitter() method.
Listing 10.8 shows a new version of findOne() that uses JdbcTemplate callbacks to query for a Spitter by ID and map the result set to a Spitter object.
This findOne() method uses JdbcTemplate’s queryForObject() method to query for a Spitter from the database.
The real magic happens in the SpitterRowMapper object, which implements the RowMapper interface.
For every row that results from the query, JdbcTemplate calls the mapRow() method of the RowMapper, passing in a ResultSet and an integer carrying the row number.
In SpitterRowMapper’s mapRow() method is the code that creates a Spitter object and populates it with values from the ResultSet.
Just like addSpitter(), the findOne() method is free of JDBC boilerplate code.
Methods that use JdbcTemplate are laser focused on retrieving a Spitter object from the database.
This means that if you’re developing your application using Java 8, you can express the RowMapper implementation with a lambda instead of with a concrete class implementation.
As you can see, the lambda is easier on the eyes than a full-blown RowMapper implementation, but it’s just as effective.
Java coerces the lambda into a RowMapper for the sake of satisfying the parameter it’s being passed into.
Alternatively, you can use Java 8 method references to define the mapping in a separate method:
In either event, you don’t have to explicitly implement the RowMapper interface.
You must provide a lambda or method that takes the same parameters and returns the same type as if you had implemented RowMapper.
This means you have to notice the order of the parameters in the query and list the values in the correct order when passing them to the update() method.
If you ever changed the SQL in such a way that the order of the parameters changed, you’d also need to change the order of the values.
Named parameters let you give each parameter in the SQL an explicit name and refer to the parameter by that name when binding values to the statement.
For example, suppose the SQL_INSERT_SPITTER query were defined as follows:
With named-parameter queries, the order of the bound values isn’t important.
If the query changes and the order of the parameters is no longer the same, you won’t have to change the binding code.
The first thing you’ll notice is that this version of addSpitter() is longer than the previous version.
Nevertheless, every line is focused on the goal of inserting a Spitter object into the database.
Some of the data-centric among you may even contend that data is the application.
With such significance placed on data, it’s important that you develop the data-access portion of your applications in a way that’s robust, simple, and clear.
But as defined in the specification, JDBC can be somewhat unwieldy.
Spring takes much of the pain out of working with JDBC, eliminating boilerplate code and simplifying JDBC exception handling, leaving you little more to deal with than writing the SQL that should be performed.
In this chapter, we looked at Spring’s support for data persistence.
We also looked at Spring’s template-based abstraction for JDBC, which greatly simplifies working with JDBC.
Coming up in the next chapter, we’ll continue our survey of Spring’s datapersistence support by looking at Spring’s facilities for the Java Persistence API.
When we were kids, riding a bike was fun, wasn’t it? We’d ride to school in the mornings.
When school let out, we’d cruise to our best friend’s house.
When it got late and our parents were yelling at us for staying out past dark, we’d peddle home for the night.
Then we grew up, and now we need more than a bike.
Sometimes we have to travel a long distance to work.
Groceries have to be hauled, and our kids need to get to soccer practice.
And if we live in Texas, air conditioning is a must! Our needs have outgrown our bikes.
It’s great for what it does, and for some jobs it works fine.
But as applications become more complex, so do our persistence requirements.
We need to be able to map object properties to database columns.
Lazy loading—As object graphs become more complex, you sometimes don’t want to fetch entire relationships immediately.
To use a typical example, suppose you’re selecting a collection of PurchaseOrder objects, and each of these objects contains a collection of LineItem objects.
If you’re only interested in PurchaseOrder attributes, it makes no sense to grab the LineItem data.
Lazy loading allows you to grab data only as it’s needed.
Eager fetching allows you to grab an entire object graph in one query.
In the cases where you know you need a PurchaseOrder object and its associated LineItems, eager fetching lets you get this from the database in one operation, saving you from costly round-trips.
Going back to the purchase order example, when an Order object is deleted, you also want to delete the associated LineItems from the database.
The general name for these services is object-relational mapping (ORM)
Using an ORM tool for your persistence layer can save you literally thousands of lines of code and hours of development time.
This lets you switch your focus from writing error-prone SQL code to addressing your application’s requirements.
Spring provides support for several persistence frameworks, including Hibernate, iBATIS, Java Data Objects (JDO), and the Java Persistence API (JPA)
As with Spring’s JDBC support, Spring’s support for ORM frameworks provides integration points to the frameworks as well as some additional services:
I don’t have enough space in this chapter to cover all the ORM frameworks that are supported by Spring.
But that’s okay, because Spring’s support for one ORM solution is similar to the next.
Once you get the hang of using one ORM framework with Spring, you’ll find it easy to switch to another.
In this chapter, we’ll look at how Spring integrates with two of the most commonly used ORM solutions: Hibernate and JPA.
You’ll also get your first look at the Spring Data project by looking at Spring Data JPA.
In doing so, you’ll not only learn how Spring Data JPA can take away a lot of the boilerplate code in your JPA repositories, but you’ll also have a foundation to build on in the next chapter when we look at using Spring Data for schemaless storage options.
Hibernate is an open source persistence framework that has gained significant popularity in the developer community.
It provides not only basic object-relational mapping but also all the other sophisticated features you’d expect from a full-featured ORM tool, such as caching, lazy loading, eager fetching, and distributed caching.
In this section, we’ll focus on how Spring integrates with Hibernate, without dwelling too much on the intricate details of using Hibernate.
The Session interface provides basic data-access functionality such as the ability to save, update, delete, and load objects from the database.
Through the Hibernate Session, an application’s repository performs all of its persistence needs.
The standard way to get a reference to a Hibernate Session object is through an implementation of Hibernate’s SessionFactory interface.
Among other things, SessionFactory is responsible for opening, closing, and managing Hibernate Sessions.
In Spring, the way to get a Hibernate SessionFactory is through one of Spring’s Hibernate session-factory beans.
As of version 3.1, Spring comes with three sessionfactory beans to choose from:
These session-factory beans are implementations of Spring’s FactoryBean interface that produce a Hibernate SessionFactory when wired into any property of type SessionFactory.
This makes it possible to configure your Hibernate session factory alongside the other beans in your application’s Spring context.
Choosing which of these session factory beans to use comes down to which version of Hibernate you’re using and whether you’ll be defining your object-to-database mapping in XML or using annotations.
The dataSource property is wired with a reference to a DataSource bean.
The mappingResources property lists one or more Hibernate mapping files that define the persistence strategy for the application.
It has many of the same properties and can be configured for either XML-based mapping or annotation-based mapping.
But instead of listing Hibernate mapping files, you can use the packagesToScan property to tell Spring to scan one or more packages, looking for domain classes that are annotated.
If you’d prefer, you may also explicitly list all of your application’s persistent classes by specifying a list of fully qualified class names in the annotatedClasses property:
The annotatedClasses property is fine for hand-picking a few domain classes.
But packagesToScan is more appropriate if you have a lot of domain classes and don’t want to list them all or if you want the freedom to add or remove domain classes without revisiting the Spring configuration.
With a Hibernate session factory bean declared in the Spring application context, you’re ready to start creating your repository classes.
In the early days of Spring and Hibernate, writing a repository class would involve working with Spring's HibernateTemplate.
HibernateTemplate would ensure that only one Hibernate session would be used per transaction.
The downside of this approach is that your repository implementation would be directly coupled to Spring.
The best practice now, however, is to take advantage of Hibernate contextual sessions and not use HibernateTemplate at all.
This can be done by wiring a Hibernate SessionFactory directly into your repository and using it to obtain a session, as shown in the following listing.
There are several things to take note of in listing 11.1
Then, in the currentSession() method, you use that SessionFactory to get the current transaction’s session.
First, @Repository is another one of Spring’s stereotype annotations that, among other things, are scanned by Spring component-scanning.
In addition to helping to reduce explicit configuration, @Repository serves another purpose.
Recall that one of the jobs of a template class is to catch platformspecific exceptions and rethrow them as one of Spring’s unified unchecked exceptions.
But if you’re using Hibernate contextual sessions and not a Hibernate template, how can the exception translation take place?
And you were able to develop it without directly depending on any Spring-specific classes (aside from the @Repository annotation)
That same template-less approach can be applied when developing a pure JPA-based repository.
Let’s take one more stab at developing a SpitterRepository implementation, this time using JPA.
The Java Persistence API (JPA) emerged out of the rubble of EJB 2’s entity beans as the next-generation Java persistence standard.
With the Spring 2.0 release came the premiere of Spring integration with JPA.
The irony is that many blame (or credit) Spring with the demise of EJB.
But now that Spring provides support for JPA, many developers are recommending JPA for persistence in Spring-based applications.
In fact, some say that Spring-JPA is the dream team for POJO development.
The first step toward using JPA with Spring is to configure an entity manager factory as a bean in the Spring application context.
This type of entity manager is most appropriate for use in standalone applications that don’t run in a Java EE container.
The application doesn’t interact with the entity manager factory at all.
Instead, entity managers are obtained directly through injection or from JNDI.
The container is responsible for configuring the entity manager factories.
This type of entity manager is most appropriate for use by a Java EE container that wants to maintain some control over JPA configuration beyond what’s specified in persistence.xml.
Both kinds of entity manager implement the same EntityManager interface.
The key difference isn’t in the EntityManager itself, but rather in how the EntityManager is created and managed.
What does this all mean for Spring developers wanting to use JPA? Not much.
In the container-managed scenario, Spring plays the role of the container.
Each flavor of entity manager factory is produced by a corresponding Spring factory bean:
This file must appear in the META-INF directory in the classpath.
The purpose of the persistence.xml file is to define one or more persistence units.
A persistence unit is a grouping of one or more persistent classes that correspond to a single data source.
In simple terms, persistence.xml enumerates one or more persistent classes along with any additional configuration such as data sources and XMLbased mapping files.
Here’s a typical example of a persistence.xml file as it pertains to the Spittr application:
Because so much configuration goes into a persistence.xml file, little configuration is required (or even possible) in Spring.
By specifying it in persistence.xml, JPA can look in this well-known location for persistence unit definitions.
Therefore, it seems silly to extract configuration information into persistence.xml.
For that reason, we’ll turn our attention to container-managed JPA.
Instead of configuring data-source details in persistence.xml, you can configure this information in the Spring application context.
Here you configured the dataSource property with a Spring-configured data source.
Although a data source may still be configured in persistence.xml, the data source specified through this property takes precedence.
You can use the jpaVendorAdapter property to provide specifics about the particular JPA implementation to use.
Spring comes with a handful of JPA vendor adapters to choose from:
Several properties are set on the vendor adapter, but the most important is the database property, where you specify the Hypersonic database as the database you’ll be using.
Other values supported for this property include those listed in table 11.1
Certain dynamic persistence features require that the class of persistent objects be modified with instrumentation to support the feature.
Objects whose properties are lazily loaded (they won’t be retrieved from the database until they’re accessed) must have their class instrumented with code that knows to retrieve unloaded data on access.
Others, such as JDO, perform class instrumentation at compile time.
Table 11.1 The Hibernate JPA vendor adapter supports several databases.
You can specify which database to use by setting its database property.
Which entity manager factory bean you choose will depend primarily on how you’ll use it.
The primary purpose of the persistence.xml file is to identify the entity classes in a persistence unit.
Therefore, there’s no need to declare them explicitly in persistence.xml.
Just like all of Spring’s other persistence integration options, Spring-JPA integration comes in template form with JpaTemplate.
Nevertheless, template-based JPA has been set aside in favor of a pure JPA approach.
This is analogous to the Hibernate contextual sessions you used in section 11.1.2
Because pure JPA is favored over template-based JPA, this section focuses on building Spring-free JPA repositories.
Aside from presenting a troubling codeduplication situation, it also means a new EntityManager is created every time one of.
Listing 11.2 A pure JPA repository that doesn’t use Spring templates.
Wouldn’t it be handy if you just had the EntityManager up front?
The problem is that an EntityManager isn’t thread-safe and generally shouldn’t be injected into a shared singleton bean like your repository.
But that doesn’t mean you can’t ask for an EntityManager anyway.
Although this is much more convenient, you’re probably wondering about the thread-safety issues of working with an injected EntityManager.
Instead of giving the repository a real EntityManager, it gives a proxy to a real EntityManager.
That real EntityManager either is one associated with the current transaction or, if one doesn’t exist, creates a new one.
Thus, you know that you’re always working with an entity manager in a thread-safe way.
Listing 11.3 Injecting a repository with a proxy to the EntityManager.
Transactional indicates that the persistence methods in this repository are involved in a transactional context.
Repository serves the same purpose here as it did when you developed the Hibernate contextual session version of the repository.
Note that exception translation, whether with JPA or Hibernate, isn’t mandatory.
But if you do use Spring’s exception translation, you’ll be unifying all of your data-access exceptions under Spring’s exception hierarchy, which will make it easier to swap out persistence mechanisms later.
And, on closer inspection, those methods start looking a bit boilerplate-ish.
In any reasonably-sized application, you’re likely to write that same method almost exactly the same way many times.
In fact, aside from the fact that it’s a Spitter that’s being persisted, I’ll bet you’ve written a similar method before.
The domain types will be different, but those methods are fairly common across all kinds of repositories.
Why keep writing the same persistence methods over and over again, just because you’re dealing with different domain types? Spring Data JPA brings an end to this boilerplate madness.
Rather than write the same repository implementations again and again, Spring Data lets you stop at writing the repository interface.
For instance, take a look at the following SpitterRepository interface.
But there’s a lot more here than meets the eye.
The key to writing a Spring Data JPA repository is to extend one of a handful of interfaces.
Here, SpitterRepository extends Spring Data JPA’s JpaRepository (I’ll mention a few of the other interfaces in a moment)
In doing so, JpaRepository is parameterized such that it knows this is a repository for persisting Spitter objects and that Spitters have an ID of type Long.
It also inherits 18 methods for performing common persistence operations, such as saving a Spitter, deleting a Spitter, and finding a Spitter by its ID.
At this point, you might be expecting that the next step is to write a class that implements SpitterRepository and its 18 methods.
If that were true, then this chapter would be about to take a tedious turn.
Fortunately, however, you won’t be writing any implementations of SpitterRepository.
To ask Spring Data to create an implementation of SpitterRepository, you need to add a single element to your Spring configuration.
The following listing shows the XML configuration needed to put Spring Data JPA into motion.
Listing 11.4 Creating a repository from an interface definition with Spring Data.
The <jpa:repositories> element holds all the magic of Spring Data JPA.
When it finds any interface extending Repository, it automatically (at application startup time) generates an implementation of that interface.
It’s important to understand that the repository implementation is generated at application startup time, as the Spring application context is being created.
Nor is it created at the time any of the interface’s methods are called.
Let’s see how to define a custom query method using Spring Data JPA.
One thing your SpitterRepository will need is a means of looking up a Spitter object given a username.
For example, let’s say you modify the SpitterRepository interface to look like this:
The new findByUsername() method is simple enough and should satisfy your requirement.
Now, how do you get Spring Data JPA to incorporate an implementation of that method?
Actually, nothing else needs to be done to implement findByUsername()
The method signature tells Spring Data JPA everything it needs to know in order to create an implementation for the method.
When creating the repository implementation, Spring Data will examine any methods in the repository interface, parse the method name, and attempt to understand the method’s purpose in the context of the persisted object.
In essence, Spring Data defines a sort of miniature domain-specific language (DSL) where persistence details are expressed in repository method signatures.
Spring Data knows that this method is intended to find Spitters, because you parameterized JpaRepository with Spitter.
The method name, findByUsername, makes it clear that this method should find Spitters by matching their username property with the username passed in as a parameter to the method.
Moreover, because the signature defines the method as returning a single Spitter and not a collection, it knows that it should look for only one Spitter whose username matches.
The findByUsername() method is simple enough, but Spring Data can handle even more interesting method names as well.
Repository methods are composed of a verb, an optional subject, the word By, and a predicate.
In the case of findByUsername(), the verb is find and the predicate is Username; the subject isn’t specified and is implied to be a Spitter.
As you can see, the verb is read, as opposed to find from the previous example.
Spring Data allows for four verbs in the method name: get, read, find, and count.
The get, read, and find verbs are synonymous; all three result in repository methods that query for data and return objects.
The count verb, on the other hand, returns a count of matching objects, rather than the objects themselves.
Its primary purpose is to allow you some flexibility in how you name the method.
The type of object being retrieved is determined by how you parameterize the JpaRepository interface, not the subject of the method name.
Figure 11.1 Repository methods are named following a pattern that helps Spring Data generate queries against the database.
If the subject starts with the word Distinct, then the generated query will be written to ensure a distinct result set.
The predicate is the most interesting part of the method name.
It specifies the properties that will constrain the result set.
Within the predicate, you’ll find one or more conditions that constrain the results.
Each condition must reference a property and may also specify a comparison operation.
If the comparison operator is left off, it’s implied to be an equals operation.
But you may choose any other comparison operations, including the following:
The values that the properties will be compared against are the parameters of the method.
When dealing with String properties, the condition may also include IgnoringCase or IgnoresCase to perform the comparison with no regard for whether the characters are uppercase or lowercase.
For example, to ignore case on the firstname and lastname properties, you can write the method signature like this:
Note that the parameter names are irrelevant, but they must be ordered to match up with the method name’s comparators.
Finally, you can sort the results by adding OrderBy at the end of the method name.
For example, you can sort the results in ascending order by the lastname property:
To sort by multiple properties, add them to the OrderBy class.
For example, this sorts by the lastname property in ascending order and then by the firstname property in descending order:
As you’ve seen already, the conditional parts are separated by either And or Or.
It would be impossible (or at least very difficult) to offer a definitive list of the kinds.
But here are a few more method signatures that adhere to the method-naming conventions:
This has been only a taste of the kinds of methods you can declare and have Spring Data JPA implement for you.
For now, just know that by carefully constructing a repository method signature using a mix of property names and keywords, you can make Spring Data JPA generate an implementation method to query for almost anything you can imagine.
Nevertheless, Spring Data’s mini-DSL has its limits, and sometimes it isn’t convenient or even possible to express the desired query in a method name.
When that happens, Spring Data has you covered with its @Query annotation.
Suppose you want to create a repository method to find all Spitters whose email address is a Gmail address.
One way to do this is to define a findByEmailLike() method and pass in %gmail.com any time you want to find Gmail users.
Unfortunately, this method name doesn’t adhere to Spring Data’s method-naming conventions.
When Spring Data attempts to generate an implementation for this.
In situations where the desired data can’t be adequately expressed in the method name, you can use the @Query annotation to provide Spring Data with the query that should be performed.
You only give the query, hinting to Spring Data JPA about how it should implement the method.
As you’ve seen here, @Query is useful when it’s difficult to express the query you want using the method-naming convention.
It can also be useful when, if you followed the naming convention, the method name would be incredibly long.
Now that’s a method name! I had to split it after the return type just to get it to fit in the margins of this book.
But there could be a real-world need to write a repository method to perform a query that could be defined using a long method name.
In that situation, you’d probably rather come up with a shorter method name and use @Query to specify how the method should query the database.
The @Query annotation is handy for adding custom query methods to a Spring Data JPA-enabled interface.
What if you need to mix in something more complex than can be handled in a simple query?
It’s likely that at some point you’ll want functionality in your repository that can’t be described with Spring Data’s method-naming conventions or even with a query given in the @Query annotation.
As awesome as Spring Data JPA is, it still has its limits, and you may need to write a repository method the old-fashioned way: by working with the EntityManager directly.
When that happens, do you give up on Spring Data JPA and go back to writing your repositories as you did in section 11.2.2?
When you need to do something that Spring Data JPA can’t do, you’ll have to work with JPA at a lower level than Spring Data JPA offers.
But the good news is, you don’t have to give up on Spring Data JPA completely.
You only need to work at the lower level for those methods that require it.
You can still let Spring Data JPA do the grunt work for the stuff it knows how to do.
When Spring Data JPA generates the implementation for a repository interface, it also looks for a class whose name is the same as the interface’s name postfixed with.
To illustrate, suppose you need a method in your SpitterRepository that updates all Spitters who have posted 10,000 or more Spittles, setting them to Elite status.
There’s no good way to declare such a method using Spring Data JPA’s methodnaming conventions or with @Query.
The most practical way to do it is using the following eliteSweep() method.
As you can see, the eliteStatus() method isn’t much different from any of the repository methods you created earlier in section 11.2.2
Spring Data JPA is still responsible for implementing that interface.
You should also make sure the eliteSweep() method is declared in the SpitterRepository interface.
The easy way to do that and avoid duplicating code is to change SpitterRepository so that it extends SpitterSweeper:
As I mentioned, Spring Data JPA associates the implementation class with the interface because the implementation’s name is based on the name of the interface.
Listing 11.6 Repository that promotes frequent Spitter users to Elite status.
Relational databases have been the go-to data store for several applications and for many years.
When working with JDBC and mapping objects to tables is too tedious, ORM options such as Hibernate and JPA enable a more declarative model for data persistence.
Although Spring doesn’t offer direct support for ORM, it does integrate with several popular ORM solutions, including Hibernate and the Java Persistence API.
In this chapter, we looked at how to use Hibernate’s contextual sessions in a Spring application such that your repositories contain little or no Spring-specific code.
You then got your first taste of Spring Data by seeing how to declare JPA repository interfaces while letting Spring Data JPA automatically generate implementations of those interfaces at runtime.
And when you need more out of those repository methods than Spring Data JPA can handle on its own, you can help it out with the @Query annotation and by writing custom repository method implementations.
But you have just dipped your toe into the Spring Data pool.
Coming up in the next chapter, we’ll dig deeper into Spring Data’s method-naming DSL and explore how Spring Data is good for more than just relational databases.
That’s right: you’ll see how Spring Data also supports the new contingent of NoSQL databases that have become popular in the past few years.
Others may think he was showing a bit of humor.
The reality, however, may be found in the fact that at the time his biography was published, he was cutting costs by using a quick-drying paint that was only available in black.
Paraphrasing Ford’s famous quote and applying it to database choice, we’ve been told for years that we can have any database we want, as long as it’s a relational database.
Relational databases have had a near-monopolistic hold on application development for a very long time.
But that hold is weakening now that some serious contenders have entered the database space.
The so-called “NoSQL” databases are making inroads into production applications everywhere as we recognize that there’s no one-size-fits-all database.
We now have a greater choice and can choose the best database for the problem we’re trying to solve.
Over the past couple of chapters, we’ve focused on relational databases, starting with Spring’s JDBC support and then object-relational mapping.
In the previous chapter, specifically, we looked at Spring Data JPA, one of several projects under the Spring Data umbrella project.
We saw how Spring Data JPA can make working with JPA more pleasant by automatically generating repository implementations at runtime.
This not only includes support for automatic repositories, but also template-based data access and mapping annotations.
In this chapter, we’re going to see how to write repositories that work with non-relational, NoSQL databases.
We’ll start with Spring Data MongoDB to see how to write repositories that deal with document-based data.
That is, rather than spread the data across multiple tables, nodes, or entities, it may make more sense to collect the information into denormalized structures (known as documents)
Although two or more of these documents may be related to each other, generally documents are standalone entities.
Databases that are finely tuned to work with documents in this way are known as document databases.
For example, suppose that you’re writing an application that captures a college student’s transcript.
You’ll need to be able to retrieve transcripts given a student’s name or perhaps search across the transcripts for some common properties.
But each student is evaluated individually, so it isn’t necessary for any two transcripts to be related to each other.
Although a relational database schema could be (and probably has been) designed to capture this transcript data, perhaps a document database is a better choice.
What document databases aren’t good for Knowing when to use a document database is important.
But it’s also important to know when document databases don’t make sense.
Document databases aren’t general-purpose databases and they have a very narrow set of problems that they address well.
Document databases aren’t well-tuned for storing data where there’s any significant degree of relationships.
A social network, for example, represents how different users of an application relate to each other and isn’t best kept in a document database.
Even though it’s not impossible to store relation-rich data in a document database, you’ll find more challenge than benefit in doing so.
MongoDB is one of the most popular open source document databases available.
We’ve already looked at how Spring Data JPA enabled automatic repository generation for JPA-based data access.
Spring Data MongoDB offers the same feature for MongoDBbased data access.
Before we can use any of these features, however, we’ll need to configure Spring Data MongoDB.
In order to effectively work with Spring Data MongoDB, you’re going to need a few essential beans in your Spring configuration.
First, you’ll need to configure a MongoClient bean to be able to access the MongoDB database.
You’ll also need a MongoTemplate bean to be able to perform template-based data access against the database.
Optionally, but desirably, you’ll want to enable Spring Data MongoDB’s automatic repository generation.
The following listing shows how to write a simple Spring Data MongoDB configuration class that addresses these needs.
The domain of the Spittr application isn’t a good fit for a document database.
In this chapter, we’ll look at MongoDB in the context of a purchase order system.
The first @Bean method uses MongoFactoryBean to declare a Mongo instance.
This bean will bridge Spring Data MongoDB to the database itself (not unlike what a DataSource does when working with a relational database)
It’s constructed giving it a reference to the Mongo instance created by the other bean method and the name of the database.
In a moment, you’ll see how to use MongoTemplate to query the database.
Even if you never use MongoTemplate directly, you’ll need this bean because the automatically generated repositories will use it under the covers.
This new configuration class is equivalent to the one in listing 12.1, albeit marginally simpler.
The most noticeable difference is that this configuration doesn’t directly declare a MongoTemplate bean, although one is implicitly created.
Instead, you override getDatabaseName() to provide the name of the database.
The mongo() method still creates an instance of MongoClient, but because it throws Exception, you can work with MongoClient directly without working with MongoFactoryBean.
That is, as long as the MongoDB server is running on localhost.
If your MongoDB server is running on a different server, you can specify that when you create MongoClient:
It’s also possible that your MongoDB server is listening on a port other than the default (27017)
In that case, you should also specify the port when creating MongoClient:
And if your MongoDB server is running in a production setting, I’d hope that you have authentication enabled.
In that case, you’ll need to provide your application’s credentials in order to access the database.
Accessing an authenticated MongoDB server is a bit more involved, as you can see in the next listing.
Listing 12.3 Creating a MongoClient to access an authenticated MongoDB server.
In order to access an authenticated MongoDB server, MongoClient must be instantiated with a list of MongoCredentials.
In listing 12.3 a single MongoCredential is created for that purpose.
In order to keep the credential details out of the configuration class, they’re resolved from the injected Environment.
For what it’s worth, Spring Data MongoDB can also be configured in XML.
As you should know by now, I favor the Java configuration option.
But if you’ve got a fondness for XML configuration, the following listing gives an example of how to configure Spring Data MongoDB using the mongo configuration namespace.
Now that Spring Data MongoDB has been configured, you’re almost ready to start using it to save and retrieve documents.
But first, you’ll need to map your Java domain types for document persistence using Spring Data MongoDB’s object-to-document mapping annotations.
When working with JPA, you had to map your Java entity types to relational tables and columns.
MongoDB, however, doesn’t come with its own object-to-document mapping annotations.
Spring Data MongoDB seized the opportunity to fill that gap with a handful of annotations that you can use to map your Java types to MongoDB documents.
You’ll use these two annotations often and on every Java type that will be stored as a document in the MongoDB database.
For example, the next listing shows how you might annotate an Order class to be persisted in MongoDB.
Document Identifies a domain object to be mapped to a MongoDB document.
DbRef Indicates that a field is intended to reference another document, possibly in another database.
Version Identifies a property to be used as a version field.
As you can see, Order is annotated with @Document, enabling it to be persisted using MongoTemplate, an automatically generated repository, or both.
Its id property is annotated with @Id to designate it as the ID of the document.
In addition, the customer property is annotated with @Field so that when the document is persisted, the customer property will be mapped to a field named client.
Unless they’re marked as transient, all fields of the Java object will be persisted as fields of the document.
And unless otherwise indicated with @Field, the document fields will have the same names as their Java property counterparts.
It’s clearly a collection of line items in this order.
In a traditional relational database setting, those items would probably be kept in a separate database table, referenced with a foreign key, and the items field might be annotated for JPA with @OneToMany.
As I said earlier, documents can be related to other documents, but that’s not what document databases are especially good at.
In the case of the relationship between a purchase order and its line items, the line items are merely a nested part of the same order document (as shown in figure 12.1)
Therefore, there’s no need for any annotations to designate the relationship.
In fact, the Item class itself isn’t annotated at all:
Related concepts (such as items of an order) are embedded in the toplevel document.
That’s because you’ll never persist an Item as an independent document.
It will always be a member of the Order document’s Item list and a nested element in that document.
Of course, you could annotate one of Item’s properties with @Field if you wanted to dictate how that field should be stored in the document.
It just wasn’t necessary to do so in this example.
Now we have a Java domain type annotated for MongoDB persistence.
Let’s see how you can use MongoTemplate to store a few of them.
All you need to do is inject it wherever it will be used:
Notice that here I’m injecting MongoTemplate into a property whose type is MongoOperations.
MongoOperations exposes several useful methods for working with a MongoDB document database.
It’d be impossible for us to discuss all of them here, but we can take a look at a few of the most commonly used operations, such as counting how many documents are in a document collection.
Using the injected MongoOperations, you get the order collection and then call count() to get a count:
Now let’s suppose you want to save a new order.
The first parameter to save() is the newly created Order; the second is the name of the document store to save it to.
You can also look up an order by its ID by calling findById():
More advanced queries require that you construct a Query object and pass it to the find() method.
In this case, the Criteria used to construct the Query only checks one field.
But it can also be used for even more interesting queries.
Perhaps you want to get all of Chuck’s orders that were placed over the web:
And, should you wish to remove a document, the remove() method is what you’re looking for:
As I’ve said, MongoOperations has several methods for working with document data.
I encourage you to examine the JavaDoc to discover what else you can do with MongoOperations.
Typically, you’d inject MongoOperations into a repository class of your own design and use its operations to implement the repository methods.
But if you don’t want to bother writing the repository yourself, then Spring Data MongoDB can automatically generate a repository implementation for you at runtime.
To understand how to create repositories with Spring Data MongoDB, let’s once again consider what you did in chapter 11 with Spring Data JPA.
In listing 11.4, you created an interface named SpitterRepository that extends JpaRepository.
In the same section, you also enabled Spring Data JPA repositories.
As a result, Spring Data JPA was able to automatically create an implementation of that interface, including several built-in methods and any methods you added that followed a naming convention.
Instead of extending JpaRepository, however, you’ll need to extend MongoRepository.
The OrderRepository interface in the following listing extends MongoRepository to provide basic CRUD operations for Order documents.
Because OrderRepository extends MongoRepository, it transitively extends the Repository marker interface.
As you’ll recall from our exploration of Spring Data JPA, any interface that extends Repository will have an implementation automatically generated at runtime.
In this case, however, instead of a JPA repository that interacts with a relational database, OrderRepository will be implemented to read and write data to a MongoDB document database.
Even though OrderRepository doesn’t define any methods of its own, it inherits several methods, including several useful methods for CRUD operations on Order documents.
Table 12.2 describes all of the methods that OrderRepository inherits.
The methods in table 12.2 refer to the generic types passed into and returned from the methods.
In section 11.3.1, you learned that Spring Data JPA supports a method-naming convention that helps Spring Data to automatically generate implementations for the methods that follow that convention.
As it turns out, the very same convention works with Spring Data MongoDB.
That means you can add custom methods to OrderRepository like this:
Table 12.2 By extending MongoRepository, a repository interface inherits several CRUD operations that are automatically implemented by Spring Data MongoDB.
Here you have four new methods, each one finding Order objects that match certain criteria.
One method finds a list of Order where the customer property is equal to the value passed into the method.
Another finds a list of Order where the customer property is like the value passed into the method.
The next finds Order objects whose customer and type properties are equal to the values passed in.
The final method is like the previous, except that the customer comparison is a like comparison instead of an equals comparison.
If you’d prefer, you can use get as the query verb:
Or if it suits you better, you can use read:
There’s also another special query verb for counting the objects that match:
As with Spring Data JPA, there’s a lot of flexibility in what can go in between the query verb and By.
For example, you could state what it is you’re finding:
It has nothing to do with what is being fetched.
If all you want is a single Order, you can simply return Order:
Here, the first Order that would’ve been found if it were a List is what will be returned.
If there isn’t a match, the method will return null.
Query works equally well with MongoDB as it does with JPA.
The only material difference is that for MongoDB, @Query takes a JSON query string instead of a JPA query.
The following method declaration in OrderRepository will give you what you need:
The JSON given to @Query is matched up against all Order documents, and any document that matches will be returned.
This indicates that the type property should be equal to the zeroth parameter to the.
For JPA, that involved creating an intermediary interface that declares the custom method(s), an implementation class for those custom methods, and changing the automatic repository interface to extend the intermediary interface.
The steps are the same for a Spring Data MongoDB repository.
Suppose that you need a method that finds all Order objects where the document’s type property matches a given value.
You could easily create such a method by giving it a signature of List<Order> findByType(String t)
But for the sake of this example, suppose that if the given type is NET, then it will query for Orders whose type is WEB.
This would be hard to do, even with the @Query annotation.
The following listing shows what the implementation might look like.
Listing 12.7 Mixing custom repository functionality into an automatic repository.
As you can see, the mixin implementation is injected with a MongoOperations (the interface that MongoTemplate implements)
The findOrdersByType() method uses the MongoOperations to query the database for documents matching the constructed query.
All that’s left is to change OrderRepository to extend the intermediary OrderOperations interface:
This is the same name as the OrderRepository interface, with an “Impl” suffix.
When Spring Data MongoDB generates the repository implementation, it will look for this class and mix it into the automatically generated implementation.
If you don’t care for the “Impl” suffix, you can configure Spring Data MongoDB to look for a class with a different suffix in its name.
Document databases such as MongoDB solve a certain class of problems.
But just as relational databases aren’t a one-size-fits-all solution, neither is MongoDB.
And there are certain problems that neither a relational database nor a document database is well-suited for.
Let’s have a look at how Spring Data supports Neo4j, a popular graph database.
Whereas document databases store data in coarse-grained documents, graph databases store data in several fine-grained nodes that are connected with each other through relationships.
A node in a graph database typically represents a concept in.
Relationships connect two nodes and may carry properties of their own.
At their simplest, graph databases are more general purpose than document databases, potentially being a schemaless alternative to relational databases.
But because data is structured as a graph, it’s possible to traverse relationships to discover things about your data that would be difficult or even impossible with other kinds of databases.
It provides annotations for mapping Java types to nodes and relationships, template-oriented Neo4j access, and automatic generation of repository implementations.
You’ll see how to use these features to work with Neo4j.
The following listing shows the basic Java configuration needed for Spring Data Neo4j.
Its basePackages is set so that it scans the orders.db package for interfaces that extend (directly or indirectly) the marker Repository interface.
With Neo4j, an embedded database shouldn’t be confused with an in-memory database.
Embedded” means that the database engine is running within the same JVM as a part of your application rather than as a separate server.
The data is still persisted to the filesystem (at /tmp/graphdb in this case)
In a production setting, however, it’s likely that you’ll want to secure the database server.
Here, the credentials are obtained via the injected Environment to avoid hard-coding them in the configuration class.
The <neo4j:config> element configures the details of how to access the database.
In this case, it configures Spring Data Neo4j to work with an embedded database.
Specifically, the storeDirectory attribute specifies the path in the filesystem where the data will be persisted.
The base-package attribute sets the package where the model classes are defined.
They’ll also need to be annotated as either node entities or relationship entities.
Node entities typically represent the things in your application, whereas relationship entities define how those things are related.
To see how a few of these annotations are used, let’s apply these annotations to our order/item example.
One way you can model the data is to designate an order as a node that’s related to one or more items.
To designate orders as nodes, you’ll need to annotate the Order class with @NodeEntity.
StartNode Declares a property as the start node of a relationship entity.
EndNode Declares a property as the end node of a relationship entity.
Fetch Declares a property on an entity to be eagerly loaded.
GraphId Declares a property as the ID field of an entity (the field must be a Long)
GraphTraversal Declares a property to automatically provide an iterable that’s built by following a graph traversal.
Query Declares a property to automatically provide an iterable that’s built by executing a given Cypher query.
QueryResult Declares a Java class or interface as being able to hold the results of a query.
RelationshipType Declares a field as the type of a relationship entity.
Listing 12.10 Order is annotated to be a node in the graph database.
GraphId private Long id; private String customer; private String type;
Unless they are transient, they’ll be properties on the node in the database.
The items property is annotated with @RelatedTo, indicating that an Order is related to a Set of Item.
It can be given any value, but it’s commonly given human-readable text that briefly describes the nature of the relationship.
Later you’ll use this label in queries to query across relationships.
As for the Item class itself, the following listing shows how it’s annotated for graph persistence.
GraphId private Long id; private String product; private double price; private int quantity;
As with Order, Item is annotated as @NodeEntity to designate it as a node.
It also has a Long property annotated to be the node’s graph ID with @GraphId.
Listing 12.11 Items are also represented as nodes in the graph database.
The relationship between Order and Item is simple in that it doesn’t carry any data of its own.
Therefore, the @RelatedTo annotation is sufficient to define the relationship.
Let’s reconsider how we’ve modeled this data to see how to work with more complex relationships.
In the current data model, we’ve combined the concepts of a line item and a product into the Item class.
When you think about it, however, an order is related to one or more products.
The relationship between an order and a product constitutes a line item of the order.
Figure 12.3 illustrates an alternative way to model the data in a graph.
In this new model, the quantity of products in the order is a property of the line item, and a product is a different concept.
But now that a line item must carry a quantity value, the relationship can’t be simple.
You’re going to need to define a class that represents a line item, such as LineItem in the next listing.
Figure 12.3 A relationship entity is a relationship that has properties of its own.
Again, all entities, both node entities and relationship entities, must have a graph ID and it must be of type Long.
What makes relationship entities special is that they connect two node entities.
In this case, the Order is the start node and the Product is the end node.
Finally, LineItem has a quantity property that will be persisted to the database when the relationship is created.
Now that the domain is annotated, you’re ready to start saving and reading nodes and relationships.
All you need to do is inject it wherever you need it.
For example, you might autowire it directly into a bean property:
Neo4jTemplate defines several dozen methods, including methods for saving nodes, deleting nodes, and creating relationships between nodes.
There’s not enough space to cover all of them, but let’s have a look at a few of the most commonly used methods that Neo4jTemplate provides.
One of the first and most basic things you might want to do with Neo4jTemplate is to save an object as a node.
Assuming that the object is annotated with @NodeEntity, you can use the save() method like this:
If you happen to know the object’s graph ID, you can fetch it using the findOne() method:
If there is no node with the given ID, then findOne() will throw a NotFoundException.
If you’d like to retrieve all objects of a given type, you can use the findAll()
The EndResult returned here is an Iterable, enabling it to be used in for-each looping and anywhere else an Iterable may be used.
If no such nodes exist, findAll() will return an empty Iterable.
If all you need to know is a count of how many objects of a given type are in the Neo4j database, you can call the count() method:
The delete() method can be used to delete an object:
As you might guess, it creates a relationship between two nodes.
For example, you could create a LineItem relationship between an Order node and a Product node:
Next, you specify a String value that describes the nature of the relationship.
The final parameter is a boolean that indicates whether or not duplicate relationships are allowed between the two node entities.
When you’re done, you call save() to save the relationship to the database.
But it requires that you write your own repository implementations that delegate to Neo4jTemplate.
Let’s see how Spring Data Neo4j can automatically generate repository implementations for you.
One of the most awesome things that most Spring Data projects do is automatically generate implementations for a repository interface.
Not to be left out, Spring Data Neo4j also supports automatic repository generation.
Just like the other Spring Data projects, Spring Data Neo4j triggers repository generation for interfaces that extend the Repository interface.
In this case, OrderRepository extends GraphRepository, which indirectly extends Repository.
Notice that GraphRepository is parameterized with Order, the type of entity that the repository works with.
Because Neo4j requires that graph IDs be of type Long, there’s no need to specify the ID type when extending GraphRepository.
Out of the box, you get several common CRUD operations, much like what JpaRepository and MongoRepository provide.
Table 12.4 describes the methods you get by extending GraphRepository.
Retrieves all entities where a given property matches the given value.
Retrieves all entities obtained by following a graph traversal starting at a given node.
There’s not enough space to cover all of these methods, but there are a few methods that you’ll get a lot of use out of.
For example, the following line saves a single Order entity:
When the entity is saved, the save() method returns the saved entity, which now should have its @GraphId-annotated property populated if it was null before.
You can look up a single entity by calling the findOne() method.
For example, this line will look up an Order whose graph ID is 4:
This will delete the given Order node from the database.
If you only have the graph ID, you can pass it to delete() instead of the node type itself:
If you want to do custom queries, you could use the query() method to execute an arbitrary Cypher query against the graph.
But that’s not much different than working with the query() method from Neo4jTemplate.
Instead, you can add your own query methods to OrderRepository.
It’d be awfully disappointing if Spring Data Neo4j didn’t offer the same capability.
As the next listing shows, there’s no need to be disappointed.
Listing 12.13 Defining query methods by following a naming convention.
One finds all Order nodes where the customer property is equal to the given String value.
The other method is similar, but in addition to matching the customer property, the Order nodes must also have a type property equal to the given type.
We’ve already discussed the naming convention for query methods, so there’s no need to dwell on it any further.
Refer to the previous chapter’s discussion of Spring Data JPA for a refresher on how to write these methods.
With Spring Data JPA, you used it to specify a JPA query for a repository method.
For example, suppose that you want to write the implementation of findSiAOrders() yourself, instead of relying on the @Query annotation.
You can start by defining an intermediary interface that carries the definition of the findSiAOrders() method:
Then you can change OrderRepository to extend OrderOperations in addition to GraphRepository:
The first step is to call the to() method on the Result to produce an EndResult<Order>
Graph databases such as Neo4j are wonderful for capturing data that’s represented well as nodes and relationships.
When you consider that the world we live in is made.
And, speaking personally, I’ll admit that I have a strong fondness for Neo4j.
Sometimes you only need to store a value somewhere and be able to retrieve it later with a key.
Let’s see how Spring Data enables key-value data persistence using the Redis key-value store.
Redis is a special kind of database known as a key-value store.
In fact, key-value stores share a lot in common with hash maps.
To call them persistent hash maps would not be too great of an oversimplification.
When you think about it, there aren’t too many kinds of queries that you can perform against a hash map ...
You can store a value at a particular key, and you can fetch the value for a particular key.
Consequently, Spring Data’s automatic repository support doesn’t make a lot of sense when applied to Redis.
On the other hand, Spring Data’s other key feature, template-oriented data access, can come in handy when working with Redis.
Spring Data Redis comes with a couple of template implementations for storing data to and fetching it from a Redis database.
But to create one of Spring Data Redis’s templates, you’ll need a Redis connection factory.
A Redis connection factory produces connections to a Redis database server.
Spring Data Redis comes with connection factories for four Redis client implementations:
I encourage you to do your own testing and benchmarking to determine which Redis client and connection factory fits your needs best.
From Spring Data Redis’s perspective, all of these connection factories are equally suitable.
Once you’ve made your choice, you can configure the connection factory as a bean in Spring.
Instantiating the connection factory via its default constructor results in a connection factory that creates its connections for localhost, port 6379, and with no password.
If your Redis server is running on a different host or port, you can set those properties when you create the connection factory:
Similarly, if your Redis server is configured to require authorization from clients, you can set the password by calling setPassword():
If you’ve made a different choice, then any of the other connection factories can be a drop-in replacement.
All of the Redis connection factories have setHostName(), setPort(), and setPassword() methods.
Now that you have a Redis connection factory, you’re ready to start working with Spring Data Redis’s templates.
As their names suggest, the Redis connection factories produce connections (as RedisConnection) to a Redis key-value store.
For example, you might obtain a connection and use it to store a greeting like this:
Likewise, you could retrieve that greeting value using a RedisConnection like this:
But do you really like working with arrays of bytes? As with other Spring Data projects, Spring Data Redis offers a higher-level data.
RedisTemplate is a class that greatly simplifies Redis data access, enabling you to persist keys and values of any type, not just byte arrays.
The first type is that of the key, and the second is that of the value.
In the RedisTemplate constructed here, Product objects will be stored as values assigned to String keys.
Most of the operations provided by RedisTemplate are available via the sub-APIs listed in table 12.5
Each one provides operations that work with entries based on whether the value is a simple value or a collection of values.
Across all of these sub-APIs, there are several dozen methods for saving and fetching data in Redis.
We don’t have space enough to cover them all, but we’ll look at a handful of the most common operations you’ll need.
Table 12.5 RedisTemplate offers much of its functionality via sub-APIs, which differentiate single values from collection values.
The following snippet of code will do that via opsForValue():
Similarly, if you wanted to fetch a product whose sku is 123456, you could use this snippet:
If no entry can be found with the given key, null will be returned.
For example, you can add a value to the end of a list entry like this:
This adds a Product to the end of the list stored at the key cart.
If a list doesn’t already exist at that key, one will be created.
Whereas the rightPush() method adds an element to the end of a list entry, leftPush() inserts a value at the beginning:
There are a number of ways you can fetch an item from a list.
You can pop an entry off of either end using leftPop() or rightPop():
Aside from fetching a value from the list, these two pop methods have the side effect of removing the popped items from the list.
If you’d rather simply retrieve the value (perhaps even from the middle of the list), you can use the range() method:
The range() method doesn’t remove any values from the list entry, but it does retrieve one or more values given the key and a range of indexes.
If the range exceeds the bounds of the list, then only the entries within those indexes will be returned.
If no entries fall within the indexes, an empty list will be returned.
The most basic thing you can do is add an item to a set entry:
Once you have a few set entries created and populated with values, you can perform interesting operations against those sets, including difference, intersection, and union.
And you can even fetch a random element from the set:
As sets don’t have indexes or any implicit ordering, you can’t pinpoint and fetch a single item from the set.
These sub-APIs mirror the other sub-APIs, but focus on a given key.
As an example of how these are used, let’s consider the case where you’re storing Product objects in a list entry whose key is cart.
In that scenario, suppose that you want to pop an item from the right end of the list and then add three new items to the end of the list.
Notice that the only time that the entry’s key is mentioned is when calling boundListOps()
When an entry is saved to the Redis key-value store, both the key and the value are serialized using a Redis serializer.
Spring Data Redis comes with several such serializers, including these:
All of these serializers implement the RedisSerializer interface, so if there’s not one to suit your needs, you can always create your own serializer.
These defaults are suitable for many cases, but you may find it helpful to plug in a different serializer.
For example, suppose that when using RedisTemplate, you want to serialize Product values to JSON with String keys.
Gone are the days when the only choice for data persistence was a relational database.
Now there are several different kinds of databases, each representing data in different forms and offering capabilities to suit a variety of domain models.
The Spring Data project enables developers to use these databases in their Spring applications and to use abstractions that are reasonably consistent across the various database choices.
In this chapter, we built on what you learned about Spring Data in the previous chapter when using JPA, applying it to the MongoDB document database and the Neo4j graph database.
Just like their JPA counterpart, the Spring Data MongoDB and Spring Data Neo4j projects both offer automatic generation of repositories based on interface definitions.
Additionally, you saw how to use the annotations provided by the Spring Data projects to map domain types to documents, nodes, and relationships.
Spring Data also enables data to be persisted to the Redis key-value store.
Key-value stores are significantly simpler and thus do not require support for automatic repositories or mapping annotations.
Nevertheless, Spring Data Redis offers two different template classes for working with the Redis key-value store.
No matter what kind of database you choose, fetching data from the database is a costly operation.
In fact, database queries are often the biggest performance bottlenecks in any application.
Now that you’ve seen how to store and fetch data from a variety of data sources, let’s look at how to avoid that bottleneck.
In the next chapter, you’ll see how to apply declarative caching to prevent unnecessary database fetches.
Have you ever had someone ask you a question and then, moments after you reply, ask you the same thing again? Often, I’m asked this type of question by my children:
In many ways, the components of the applications we write are the same way.
Stateless components tend to scale better, but they also tend to ask the same question over and over again.
Because they’re stateless, they discard any answer they were given once their current task is complete, and they have to ask the question again the next time that same answer is needed.
Sometimes it takes a little while to fetch or calculate the answer to the question being asked.
Maybe you must fetch data from the database, invoke a remote service, or perform a complex calculation.
If that answer isn’t likely to change frequently (or at all), then it’s wasteful to go through the same channel to fetch it again.
Moreover, doing so can and likely will have a negative impact on the performance of your application.
Instead of asking the same question over and over, only to arrive at the same answer each time, it makes sense to ask once and remember that answer when it’s needed later.
Caching is a way to store frequently needed information so that it’s readily available when needed.
Although Spring doesn’t implement a cache solution, it offers declarative support for caching that integrates with several popular caching implementations.
You’ll spend most of this chapter working with that form of declarative caching.
Then, in section 13.3, we’ll look at how to declare cache boundaries in XML.
Before you can start applying caching annotations in your beans, you must enable Spring’s support for annotation-driven caching.
If you’re using Java configuration, you can enable annotation-driven caching by adding @EnableCaching to one of your configuration classes.
They create an aspect with pointcuts that trigger off of Spring’s caching annotations.
Depending on the annotation used and the state of the cache, that aspect will fetch a value from the cache, add a value to the cache, or remove a value from the cache.
Cache managers are the heart of Spring’s cache abstraction, enabling integration with one of several popular caching implementations.
Its simplicity makes it a tempting choice for development, testing, or basic applications.
But because its cache storage is memory-based and thus tied to the lifecycle of the application, it’s probably not an ideal choice for larger production applications.
Let’s look at a few of the most commonly used cache managers.
Out of the box, Spring 3.1 comes with five cache-manager implementations:
Outside of the core Spring Framework, Spring Data offers two more cache managers:
As you can see, you have plenty of choices when it comes to selecting a cache manager for Spring’s cache abstraction.
Which one you select will depend on what underlying cache provider you want to use.
Each will provide your application with a different flavor of caching, and some are more production-ready than others.
Although the choice you make will have implications for how your data is cached, it will have no bearing on the way you declare caching rules in Spring.
You must select and configure a cache manager as a bean in your Spring application context.
The next listing shows how to configure it in Java.
This particular bit of injection can be confusing because both Spring and Ehcache define a CacheManager type.
So that you’ll have an Ehcache CacheManager to inject, you must also declare a CacheManager bean.
There’s more to Ehcache configuration than the beans you’ll configure in Spring.
Ehcache defines its own configuration schema for XML, and you’ll configure caching specifics in an XML file that adheres to that schema.
The contents of the ehcache.xml file vary from application to application, but you need to declare at least a minimal cache.
In your applications, you’ll likely want to take advantage of the rich set of configuration options afforded by Ehcache.
Consult Ehcache’s documentation at http://ehcache.org/documentation/configuration for details on how to fine-tune your Ehcache configuration.
Therefore, it isn’t surprising to learn that Redis, which is a key-value store, is perfectly suited to be a cache store.
So that Redis can be used to store cache entries for Spring’s caching abstraction, Spring Data Redis offers RedisCacheManager, an implementation of CacheManager.
RedisCacheManager works with a Redis server via a RedisTemplate to store cache entries in Redis.
You saw how to configure those beans in chapter 12
With a RedisTemplate in place, it’s a snap to configure a RedisCacheManager, as shown next.
As you can see, you construct a RedisCacheManager by passing an instance of a RedisTemplate as an argument to its constructor.
If you’re having trouble pinning down which cache manager to use, or if you have valid.
Listing 13.4 Configuring a cache manager that stores cache entries in a Redis server.
Now that you have a cache manager configured and caching enabled, you’re ready to start applying caching rules to your bean methods.
Let’s see how to use Spring’s caching annotations to define cache boundaries.
As mentioned earlier, Spring’s caching abstraction is largely built around aspects.
When you enable caching in Spring, an aspect is created that triggers off one or more of Spring’s caching annotations.
Table 13.1 Spring provides four annotations for declaring caching rules.
Cacheable Indicates that Spring should look in a cache for the method’s return value before invoking the method.
If the value is found, the cached value is returned.
If not, then the method is invoked and the return value is put in the cache.
CachePut Indicates that Spring should put the method’s return value in a cache.
The cache isn’t checked prior to method invocation, and the method is always invoked.
CacheEvict Indicates that Spring should evict one or more entries from a cache.
All the annotations in table 13.1 can be placed either on a method or on a class.
When placed on a single method, the caching behavior prescribed by the annotation applies only to that method.
If the annotation is placed at the class level, however, the caching behavior is applied to all methods in that class.
Cacheable looks for an entry in the cache first, preempting the method invocation if a matching entry is found.
If no matching entry is found, the method is invoked and the value returned is put in the cache.
CachePut, on the other hand, never checks for a matching value in the cache, always allows the target method to be invoked, and adds the returned value to the cache.
Once it’s initially saved, a Spittle isn’t likely to change.
If any particular Spittle is popular and is requested frequently, it’s a waste of time and resources to fetch it from the database repeatedly.
By annotating the findOne() method with @Cacheable, as shown in the following listing, you can make sure the Spittle is cached and avoid unnecessary trips to the database.
Caching A grouping annotation for applying multiples of the other caching annotations at once.
Table 13.1 Spring provides four annotations for declaring caching rules.
When findOne() is called, the caching aspect intercepts the call and looks for a previously returned value in the cache named spittleCache.
The cache key is the id parameter passed to the findOne() method.
If a value is found for that key, the found value will be returned and the method won’t be invoked.
On the other hand, if no value is found, then the method will be invoked and the returned value will be put in the cache, ready for the next time findOne() is called.
Any other implementation of SpittleRepository won’t have caching unless it’s also annotated with @Cacheable.
Therefore, you might consider placing the annotation on the method declaration in SpittleRepository instead of the implementation:
When you annotate the interface method, the @Cacheable annotation will be inherited by all implementations of SpittleRepository, and the same caching rules will be applied.
This offers a handy way to preload a cache before anyone comes asking.
For example, when a brand-new Spittle is saved via the save() method on SpittleRepository, there’s a high likelihood that it will soon be asked for.
It makes sense to toss the Spittle into the cache when save() is called, so it’s ready to go when someone looks for it by calling findOne()
To do that, you can annotate the save() method with @CachePut like this:
When save() is called, it does whatever it needs to do to save the Spittle.
Then the returned Spittle is placed in the spittleCache cache.
As I mentioned earlier, the default cache key is based on the parameters to the method.
Because the only parameter to save() is a Spittle, it’s used as the cache key.
Doesn’t it seem odd to place a Spittle in a cache where the key is the same Spittle?
Clearly, the default cache key isn’t what you want in this case.
You need the cache key to be the ID of the newly saved Spittle, not the Spittle itself.
So, you need to specify a key other than the default key.
Any valid SpEL expression will work, but you’ll likely want to use an expression that evaluates to a key relevant to the value being stored in the cache.
For this particular case, you need the key to be the ID of the saved Spittle.
The Spittle passed as a parameter to save() hasn’t been saved yet and therefore doesn’t have an ID.
You need the id property of the Spittle that is returned from save()
Fortunately, Spring exposes several pieces of metadata that come in handy when you’re writing SpEL expressions for caching.
For the save() method, you need the key to be the id property from the Spittle that is returned.
From that, you can reference the id property by setting the key attribute to #result.id:
Table 13.3 Spring offers several SpEL extensions specifically for defining cache rules.
With @CachePut specified this way, the cache isn’t considered going into the save() method.
But the Spittle that is returned will be put in the cache with a key equal to the Spittle’s id property.
But there may be cases where you’d rather have caching turned off.
Cacheable and @CachePut offer two attributes for conditional caching: unless and condition.
If the unless attribute’s SpEL expression evaluates to true, then the data returned from the cached method isn’t placed in the cache.
Similarly, if the condition attribute’s SpEL expression evaluates to false, then caching is effectively disabled for the method.
On the surface, it may seem that unless and condition accomplish the same thing.
The unless attribute can only prevent an object from being placed in the cache.
But the cache is still searched when the method is called, and if a match is found, it’s returned.
On the other hand, if condition’s expression evaluates to false, then caching is disabled for the duration of the method invocation.
The cache isn’t searched, nor is the return value placed in the cache.
As an example (albeit a contrived one), suppose you don’t want to cache any Spittle objects whose message property contains the text “NoCache”
To prevent such Spittles from being cached, you can set the unless attribute like this:
The SpEL expression given to unless considers the message property of the returned Spittle (identified in the expression as #result)
If it contains the text “NoCache”, then the expression evaluates to true and the Spittle isn’t placed in the cache.
Otherwise, the expression evaluates to false, the unless clause isn’t satisfied, and the Spittle is cached.
The unless attribute prevents values from being written to the cache.
That is, you may not want values added to the cache or fetched from the cache under certain conditions.
For instance, suppose you don’t want caching to be applied to any Spittle whose ID is less than 10
In this scenario, those Spittles are test entries you use for debugging purposes, and there’s no real value in caching them.
If findOne() is called with any value less than 10 as the parameter, the cache will not be searched, nor will the returned Spittle be placed in the cache.
It will be as if there is no @Cacheable annotation on the method.
As you’ve seen in these examples, the unless attribute expression can refer to the return value by referring to #result.
This is possible and useful because unless doesn’t start doing its job until a value is returned from the cached method.
On the other hand, condition has the job of disabling caching on the method.
Therefore, it can’t wait until the method has completed to decide if it needs to shut down caching.
This means its expression must be evaluated on the way into the method and that you can’t refer to the return value with #result.
Under what circumstances might you want to remove something from the cache? Any time a cached value is no longer valid, you should make sure it’s removed from the cache so that future cache hits won’t return stale or otherwise nonexistent data.
This makes the remove() method of SpittleRepository a perfect candidate for @CacheEvict:
Cacheable and @CachePut require a non-void return value, which is the item to place in the cache.
But because @CacheEvict is only removing items from the cache, it can be placed on any method, even a void one.
As shown here, a single entry is removed from the spittleCache cache when remove() is called.
The entry to be removed is the one whose key is equal to the value passed in as the spittleId parameter.
CacheEvict has several attributes, listed in table 13.4, that can influence its behavior beyond the defaults.
Spring’s caching annotations offer an elegant way to specify caching rules in your application code.
To close out this discussion on caching, let’s take a quick look at how to configure caching rules in XML.
You may be wondering why you’d ever want to declare caching in XML.
After all, the caching annotations we’ve looked at throughout this chapter are much more elegant.
You don’t feel comfortable putting Spring-specific annotations in your source code.
You want to apply caching to beans for which you don’t own the source code.
In either of those cases, it’s better (or necessary) to keep the caching configuration separate from the code whose data is being cached.
Because caching is an aspect-oriented activity, the cache namespace is paired with Spring’s aop namespace for declaring the pointcuts where caching should be applied.
To get started with XML-declared caching, you’ll need to create a Spring configuration XML file that includes the cache and aop namespaces:
If false (the default), the entries are removed after a successful method invocation.
The cache namespace defines the configuration elements for declaring caching in a Spring XML configuration file.
Table 13.5 lists all the elements offered by the cache namespace.
We’ve already discussed this style of caching, so there’s no need to dwell on it further.
The remaining elements in table 13.5 are for XML-based caching configuration.
The next listing shows how to use these elements to configure caching around the SpittleRepository bean, equivalent to what you did earlier in this chapter using caching annotations.
Table 13.5 Spring’s cache namespace offers elements for configuring caching rules in XML.
Listing 13.7 Declaring caching rules around SpittleRepository using XML elements.
This element matches the advice with a pointcut, thus establishing a complete aspect.
In this case, the aspect’s pointcut is triggered on the execution of any method of the SpittleRepository interface.
If such a method is called on any bean in the Spring application context, the aspect’s advice will be invoked.
The <cache:cacheable> elements each declare a method from the pointcut as being cacheable.
Specifically, the findRecent(), findOne(), and findBySpitterId() methods are all declared as cacheable, and their return values will be cached in the spittleCache cache.
It removes an element from the cache so that it won’t be found the next time someone looks for it.
Here, when you delete a Spittle from the cache by calling remove(), the entry whose key is the same as the ID passed in to remove() will be evicted from the cache.
It’s worth noting that the <cache:advice> element has a cache-manager attribute to specify the bean that serves as the cache manager.
But if your cache manager bean has a different ID (as might be the case if you declared multiple cache managers), you can specify which cache manager to use by setting the cache-manager attribute.
To remove that duplication, you can specify the cache name in the <cache:caching> annotation instead:
This optional attribute can be given a SpEL expression that, if it evaluates to true, prevents the return value from being cached.
If false, only the entry matching the key is removed.
The item to be removed is identified by the default key (based on the method’s parameter) or a key specified with a SpEL expression given to the key attribute.
Caching is a great way to keep your application code from having to derive, calculate, or retrieve the same answers over and over again for the same question.
When a method is initially invoked with a given set of parameters, the return value can be stored in a cache and retrieved from that cache later when the same method is called with the same parameters.
In many cases, looking up a value from a cache is a cheaper operation then looking it up otherwise (for example, performing a database query)
Therefore, caching can have a positive impact on application performance.
In this chapter, you’ve seen how to declare caching in a Spring application.
First you saw how to declare one or more of Spring’s cache managers.
We also looked at how to configure caching rules separate from the application code in XML.
Along the way, we discussed the fact that caching is an aspect-oriented activity.
This became apparent when you declared caching rules in XML: you had to bind your caching advice to a pointcut.
Spring also uses aspects when applying security rules to methods.
In the next chapter, you’ll see how to use Spring Security to enforce security on bean methods.
Before I leave my house or before I go to bed, one of the last things I do is make sure the doors to my house are locked.
Why? Because although the locks on my doors are a good form of security, the alarm system gives a second line of defense, should any burglar make it past the locks.
In chapter 9, you saw how to use Spring Security to secure the web layer of your application.
Web security is important, as it prevents users from accessing content that they’re not authorized to access.
Although there’s no reason to think that a user will be able to crack through your application’s security, a security hole at the web layer can sneak in rather easily.
Imagine, for instance, if a user makes a request for a page that they’re allowed to see, but due to a lack of developer diligence, the controller that handles that request calls a method that fetches data that the user isn’t allowed to see.
But security breaches are just as likely to arise from honest mistakes as they are from clever hacking.
By securing both the web layer of your application and the methods behind the scenes, you can be sure that no logic will be executed unless the user is authorized.
In this chapter, we’ll look at how you can secure bean methods using Spring Security.
In doing so, we’ll declare security rules that prevent a method from being executed unless the user for whom it is being executed has the authority to execute it.
We’ll start by looking at a couple of simple annotations that can be placed on methods to lock them away from unauthorized access.
The most commonly used approach to method-level security with Spring Security is to apply special security annotations to the methods you want secured.
This has several benefits, not the least of which is that the security rules for any given method are clearly visible when looking at the method in an editor.
Before the end of this chapter, you’ll have seen all of these annotations in action.
To get the ball rolling, let’s start by looking at the @Secured annotation, the simplest of the method-level security annotations offered by Spring Security.
When securedEnabled is true, a pointcut is created such that the Spring Security aspects will wrap bean methods that are annotated with @Secured.
For example, consider this addSpittle() method that’s been annotated with @Secured:
The @Secured annotation takes an array of String as an argument.
Each String value is an authorization, one of which is required to invoke the method.
If more than one value is passed into @Secured, then the authenticated user must be granted at least one of those authorities to gain access to the method.
These are unchecked exceptions, but ultimately someone will need to catch it and handle it.
If the secured method is invoked in the course of a web request, the exception will be automatically handled by Spring Security’s filters.
Otherwise, you’ll need to write the code to handle the exception.
One drawback of the @Secured annotation is that it’s a Spring-specific annotation.
If you’re more comfortable using annotations defined in Java standards, then perhaps you should consider using @RolesAllowed instead.
But using the standard @RolesAllowed annotation may have implications when used in the context of other frameworks or APIs that process that annotation.
Although here we’ve only enabled jsr250Enabled, it’s good to note that it’s not mutually exclusive with securedEnabled.
These two annotation styles can both be enabled at the same time.
They can restrict the invocation of a method based only on whether or not that user has been granted a specific privilege.
No other factors can play a part in the decision to allow the method to execute or not.
You saw in chapter 9, however, that SpEL expressions could be used to overcome a similar limitation when securing URLs.
Let’s see how you can use SpEL along with Spring Security’s pre- and postinvocation annotations to perform expression-based method security.
Sometimes security constraints depend on more than just whether a user has privileges or not.
Spring Security 3.0 introduced a handful of new annotations that use SpEL to enable even more interesting security constraints on methods.
Each of these annotations accepts a SpEL expression for its value parameter.
The expression can be any valid SpEL expression and may include any of the Spring Security extensions to SpEL listed in table 9.5
If the expression evaluates to true, then the security rule passes; otherwise, it fails.
The implications of a passing versus failing security rule differ depending on which annotation is in use.
We’ll look at specific examples of each of these in a moment.
Now that the pre/post annotations are enabled, you can start using them.
But their weakness is that they’re only able to make their decisions based on the user’s granted authorities.
PreAuthorize Restricts access to a method before invocation based on the result of evaluating an expression.
PostAuthorize Allows a method to be invoked, but throws a security exception if the expression evaluates to false.
PostFilter Allows a method to be invoked, but filters the results of that method based on an expression.
PreFilter Allows a method to be invoked, but filters input prior to entering the method.
Using expressions, you can allow or disallow access to a method using almost any conditions you can imagine.
PreAuthorize is evaluated before the method executes and prevents method execution unless the expression evaluates to true.
In contrast, @PostAuthorize waits until the method has returned before deciding whether or not to raise a security exception.
We’ll first look at preauthorization, as it’s the most commonly used of the expressiondriven security annotations.
After that, we’ll see how to secure access to methods after the method executes.
In fact, you could use @PreAuthorize to limit access based on the roles given to the authenticated user:
If the user has the ROLE_SPITTER role, then the method will be allowed to execute.
Otherwise, a security exception will be thrown and the method won’t execute.
But there’s a lot more to @PreAuthorize than is apparent in this simple example.
With SpEL expressions guiding access decisions, far more advanced security constraints can be written.
For example, suppose that the average Spittr user can only write spittles of 140 characters or less, but premium users are allowed unlimited spittle lengths.
The #spittle portion of the expression refers directly to the method parameter of the same name.
This enables Spring Security to examine the parameters passed to the method and use those parameters in its authorization decision making.
In this example, you dig into the Spittle’s text to make sure it doesn’t exceed the length allowed for standard Spittr users.
Or if the user is a premium user, then the length doesn’t matter.
Postauthorization typically involves making security decisions based on the object returned from the secured method.
This of course means that the method must be invoked and given a chance to produce a return value.
For example, suppose that you wanted to secure the getSpittleById() method so that it only authorizes access if the Spittle object returned belongs to the authenticated user.
There’s no way of knowing if a Spittle belongs to the current user until you’ve already fetched it.
If, after fetching the Spittle, it turns out to not belong to the current user, then a security exception should be thrown.
At that point it has the opportunity to consider the return value in its decisionmaking.
For example, to secure the getSpittleById() method as previously described, you can use @PostAuthorize like this:
For easy access to the object returned from the secured method, Spring Security provides the returnObject variable in SpEL.
Here you know that the returned object is a Spittle, so the expression digs into its spitter property and pulls the username property from that.
On the other side of the double-equal comparison, the expression digs into the built-in principal object to get its username property.
If the Spittle object has a Spitter whose username property is the same as the principal’s username, the Spittle will be returned to the caller.
That means that care should be taken to make sure that the method doesn’t have any side effects that would be undesirable if authorization fails.
PreAuthorize and @PostAuthorize are great if you’re using expressions to secure a method.
But sometimes restricting access to a method is too heavy-handed.
Sometimes it’s not the method that’s being secured, but rather the data being passed into or returned from that method.
This is a method that’s primarily intended to be used by an administrator to help moderate the content on the Spittr application.
But it could also be used by an individual user to see if any of their Spittles have been flagged as offensive.
It merely returns a list of offensive Spittles, no matter who they belong to.
That’s perfect for the administrative use of the method, but it falls short of limiting the list to those Spittles that belong to the current user.
But as I stated in the outset of this chapter, there’s always the possibility that the less restrictive version could be used in places where some restriction is needed.1
But instead of using that expression to restrict access to a method, @PostFilter evaluates that expression against each member of a collection being returned from the method, removing those members for whom the expression evaluates to false.
If the user makes it through that checkpoint, the method will execute and a List of Spittles will be returned.
But the @PostFilter annotation will filter that list, ensuring that the user only sees those Spittle objects that they’re allowed to see.
Specifically, administrators get to see all offensive Spittles, and non-administrators will only be given Spittles that belong to them.
The filterObject referenced in the expression refers to an individual element (which you know to be a Spittle) in the List returned from the method.
If that Spittle’s Spitter has a username that’s the same as the authenticated user (the principal.name in the expression) or if the user has the role of ROLE_ADMIN, then the element will end up in the filtered list.
This is a much less common technique, but it may come in handy on occasion.
For instance, suppose you have a list of Spittles that you want to delete as a batch.
To accomplish that, you might write a method with a signature that looks a little like this:
Seems simple enough, right? But what if you want to apply some security rules to it, such that the Spittles can only be deleted by the user who owns them or by an administrator.
In that case, you could write logic into the deleteSpittles() method to sift through each Spittle in the list and only delete those belonging to the current user (or all of them if the current user is an administrator)
While that would work, it means that you’re embedding security logic directly into the logic of the method.
And that security logic represents a separate (albeit related) concern from the concern of deleting Spittles.
What would be better is if the list only contained Spittles that were actually going to be deleted.
That would keep the logic for deleteSpittles() simpler and focused on the task of deleting Spittles.
Spring Security’s @PreFilter seems to be a perfect fit for this problem.
But instead of filtering the value returned from a method, @PreFilter filters those members of a collection going into the method.
But also, @PreFilter will ensure that the list being passed into deleteSpittles() will contain only Spittles that the current user has permission to delete.
The expression will be evaluated against each item in the collection, and only those items for whom the expression evaluates to true will remain in the list.
The targetObject variable is another Spring Security–provided value that represents the current list item to evaluate against.
At this point, you’ve seen how to use all four of Spring Security’s expression-driven annotations.
Expressions are a much more powerful way to define security constraints than just specifying an authority that must be granted to the user.
Even so, you should take care not to get too clever with the expressions.
Certainly you should avoid writing complex security expressions or trying to embed too much non-security business logic into the expressions.
Ultimately, expressions are just String values that are given to the annotations.
As such, they’re difficult to test and difficult to debug.
If you find yourself thinking that maybe your security expressions are getting out of hand, you might want to look into writing a custom permission evaluator to help simplify your SpEL expressions.
Let’s see how you can create and use a custom permission evaluator to simplify the expressions you’ve used for filtering.
But it’s not trivial either, and it doesn’t take much to imagine how you might keep growing that expression to accommodate other security rules.
Before long, the expression could become unwieldy, complex, and difficult to test.
What if you replaced that entire expression with a much simpler one that looks a little something like this:
The hasPermission() function is a Spring Security–provided extension to SpEL, and it represents an opportunity for you, the developer, to plug in whatever logic you want to perform when it’s evaluated.
All you need to do is write and register a custom permission evaluator.
Listing 14.1 A permission evaluator provides the logic behind hasPermission()
One of the hasPermission() methods takes an Object as the object to evaluate against in the second parameter.
The other hasPermission() is useful when only the ID of the target object is available, and it takes that ID as a Serializable in its second parameter.
As for the first hasPermission() method, it checks to see that the object being evaluated is a Spittle and that you’re checking for delete permission.
If so, it checks that the Spitter’s username is equal to the authenticated user’s name or that the current authentication has ROLE_ADMIN authority.
Once the permission evaluator is ready, you need to register it with Spring Security for it to back the hasPermission() operation in the expression given to @PostFilter.
To do that, you’ll need to replace the expression handler with one that’s configured to use your custom permission evaluator.
Method-level security is an important complement to Spring Security’s web-level security, which we discussed in chapter 9
For non-web applications, method-level security is the front line of defense.
When applied in a web application, method-level security backs up the security rules declared to secure web requests.
In this chapter, we looked at six annotations that can be placed on methods to declare security constraints.
Finally, we looked at how you can make your security rules easier to maintain, test, and debug by defining a custom expression evaluator that works behind the scenes of the hasPermission() function in SpEL.
Starting with the next chapter, we’ll switch gears from developing the back end of the application to using Spring to integrate with other applications.
Over the next several chapters, we’ll look at all kinds of integration techniques, including remoting, asynchronous messaging, REST, and even sending emails.
The first integration technique on tap will be working with Spring remoting, which we’ll explore in the next chapter.
These days, enterprise applications must coordinate with other systems to achieve their purpose.
In part 4, you’ll learn how to take your application beyond its own boundaries and integrate it with other applications and enterprise services.
You’ll learn how to transparently access remote services as though they’re any other object in your application.
In doing so, you’ll explore various remoting technologies, including RMI, Hessian/ Burlap, and SOAP web services with JAX-WS.
Increasingly, web applications are expected to be responsive and show near real-time data.
Wrapping up the book is a late but necessary addition to the table of contents.
You’ll see how Spring Boot takes away the chore of writing much of the boilerplate configuration that is typical in Spring applications and leaves you to focus on implementing business functionality.
Imagine for a moment that you’re stranded on a deserted island.
After all, who wouldn’t want some solitude on a beach, blissfully ignorant of the goings-on of the outside world?
But on a deserted island, it’s not pina coladas and sunbathing all the time.
Even if you enjoy the peaceful seclusion, it won’t be long before you’ll get hungry, bored, and lonely.
You can only live on coconuts and spear-caught fish for so long.
And if you don’t get in contact with another human soon, you may end up talking to a volleyball!
On the surface they might seem self-sufficient, but in reality, they probably collaborate with other systems, both within your organization and externally.
For example, consider a procurement system that needs to communicate with a vendor’s supply-chain system.
Maybe your company’s human resources system needs to integrate with the payroll system.
Or the payroll system may need to communicate with an external system that prints and mails paychecks.
No matter what the circumstances, your application will need to communicate with other systems to access services remotely.
Several remoting technologies are available to you as a Java developer, including these:
Regardless of which remoting technology you choose, Spring provides broad support for accessing and creating remote services with several different technologies.
In this chapter, you’ll learn how Spring both simplifies and complements these remoting services.
But first, let’s set the stage for this chapter with an overview of how remoting works in Spring.
Remoting is a conversation between a client application and a service.
On the client side, some functionality is required that isn’t within the scope of the application, so the application reaches out to another system that can provide the functionality.
The remote application exposes the functionality through a remote service.
Suppose you’d like to make some of the Spittr application’s functionality available as remote services for other applications to use.
Perhaps in addition to the existing browser-based user interface, you’d like to make a desktop or mobile front end for Spittr, as illustrated in figure 15.1
To support that, you’ll need to expose the basic functions of the SpitterService interface as a remote service.
The conversation between the other applications and Spittr begins with a remote procedure call (RPC) from the client applications.
On the surface, an RPC is similar to a call to a method on a local object.
Both are synchronous operations, blocking execution in the calling code until the called procedure is complete.
The difference is a matter of proximity, with an analogy to human communication.
If you’re at the proverbial water cooler at work discussing the outcome of the weekend’s football game, you’re conducting a local conversation—the conversation takes.
Likewise, a local method call is one where execution flow is exchanged between two blocks of code in the same application.
On the other hand, if you were to pick up the phone to call a client in another city, your conversation would be conducted remotely over the telephone network.
Similarly, during an RPC, execution flow is handed off from one application to another application, theoretically on a different machine in a remote location over the network.
Table 15.1 outlines each of these models and briefly discusses their usefulness in various situations.
Regardless of which remoting model you choose, you’ll find that a common theme runs through Spring’s support for each model.
This means that once you understand how to configure Spring to work with one of the models, you’ll have a modest learning curve if you decide to use a different model.
In all models, services can be configured into your application as Spring-managed beans.
This is accomplished using a proxy factory bean that enables you to wire remote services into properties of your other beans as if they were local objects.
Accessing/exposing Java-based services when network constraints such as firewalls aren’t a factor.
Hessian or Burlap Accessing/exposing Java-based services over HTTP when network constraints are a factor.
Figure 15.2 In Spring, remote services are proxied so that they can be wired into client code as if they were any other Spring bean.
The client makes calls to the proxy as if the proxy were providing the service functionality.
The proxy communicates with the remote service on behalf of the client.
It handles the details of connecting and making remote calls to the remote service.
Remote exceptions usually signal problems such as network or configuration issues that can’t be gracefully recovered from.
On the service side, you’re able to expose the functionality of any Spring-managed bean as a remote service using any of the models listed in table 15.1
Figure 15.3 illustrates how remote exporters expose bean methods as remote services.
Whether you’ll be developing code that consumes remote services, implements those services, or both, working with remote services in Spring is purely a matter of configuration.
You won’t have to write any Java code to support remoting.
Your service beans don’t have to be aware that they’re involved in an RPC (although any beans passed to or returned from remote calls may need to implement java.io .Serializable)
Let’s start our exploration of Spring’s remoting support by looking at RMI, the original remoting technology for Java.
If you’ve been working in Java for any length of time, you’ve no doubt heard of (and probably used) RMI.
Before RMI, the only remoting options available to Java programmers were CORBA (which at the time required the purchase of a third-party object request broker [ORB]) and handwritten socket programming.
But developing and accessing RMI services is tedious, involving several steps, both programmatic and manual.
Figure 15.3 Spring-managed beans can be exported as remote services using remote exporters.
Spring also provides a remote exporter that makes short work of converting your Spring-managed beans into RMI services.
For the Spittr application, I’ll show you how to wire an RMI service into a client application’s Spring application context.
But first, let’s see how to use the RMI exporter to publish the SpitterService implementation as an RMI service.
If you’ve ever created an RMI service, you know that it involves the following steps:
Write the service implementation class with methods that throw java.rmi .RemoteException.
Run the RMI compiler (rmic) to produce client stub and server skeleton classes.
Wow! That’s a lot of work just to publish a simple RMI service.
These exceptions usually indicate a fatal error that can’t be recovered from in a catch block, but you’re still expected to write boilerplate code that catches and handles those exceptions—even if there’s not much you can do to fix them.
Clearly a lot of code and manual work are involved in publishing an RMI service.
Is there anything Spring can do to make this situation less knotty?
Instead of writing RMI-specific classes with methods that throw RemoteException, you write a POJO that performs the functionality of your service.
The RMI service that you’ll create exposes the methods from the SpitterService interface.
As a reminder, the following listing shows what that interface looks like.
Listing 15.1 SpitterService: defines the service layer of the Spittr application.
As shown in figure 15.4, RmiServiceExporter works by wrapping the bean in an adapter class.
The simplest way to use RmiServiceExporter to expose SpitterServiceImpl as an RMI service is to configure it in Spring with the following @Bean method:
Here the spitterService bean is wired into the service property to indicate that the RmiServiceExporter is to export the bean as an RMI service.
And the serviceInterface property specifies the interface that the service implements.
By default, RmiServiceExporter attempts to bind to an RMI registry on port 1099 of the local machine.
If no RMI registry is found at that port, RmiServiceExporter will start one.
If you’d rather bind to an RMI registry at a different port or host, you can specify that with the registryPort and registryHost properties.
Figure 15.4 RmiServiceExporter turns POJOs into RMI services by wrapping them in a service adapter and binding the service adapter to the RMI registry.
That’s all you need to do to have Spring turn a bean into an RMI service.
Now that the Spitter service has been exposed as an RMI service, you can create alternative user interfaces or invite third parties to create new clients for Spittr that use the RMI service.
The developers of those clients will have an easy time connecting to the Spitter RMI service if they’re using Spring.
Let’s switch gears and see how to write a client of the Spitter RMI service.
Traditionally, RMI clients must use the RMI API’s Naming class to look up a service from the RMI registry.
For example, the following snippet of code might be used to retrieve the RMI Spitter service:
Although this snippet of code would certainly retrieve a reference to the RMI Spitter service, it presents two problems:
Any code that needs the Spitter service is responsible for retrieving the service itself.
That’s plumbing code and probably is not directly cohesive with the client’s functionality.
The exceptions thrown in the course of an RMI lookup are the kinds that typically signal a fatal and unrecoverable condition in the application.
To recover from this exception, the application will, at a minimum, need to be reconfigured and may have to be recompiled.
No try/catch block will be able to recover gracefully, so why should your code be forced to catch and handle it?
But perhaps more sinister is the fact that this code is in direct opposition to the principles of dependency injection (DI)
Because the client code is responsible for looking up the Spitter service and the service is an RMI service, there’s no opportunity to provide a different implementation of SpitterService from some other source.
Ideally, you should be able to inject a SpitterService object into any bean that needs one, instead of having the bean look up the service itself.
Using DI, any client of SpitterService can be ignorant of where that service comes from.
Here, the service is named SpitterService and is hosted on the local machine.
Meanwhile, the interface that the service provides is specified with the serviceInterface property.
The interaction between the client and the RMI proxy is illustrated in figure 15.5
Now that you’ve declared the RMI service as a Spring-managed bean, you can wire it as a dependency into another bean just as you would a regular non-remote bean.
For example, suppose the client needs to use the Spitter service to retrieve a list of Spittles for a given user.
You might use @Autowired to wire the service proxy into the client:
The client talks to the proxy through the service’s interface as if the remote service were a local POJO.
Then you can invoke methods on it as if it were a local bean:
What’s great about accessing an RMI service this way is that the client code doesn’t even know it’s dealing with an RMI service.
It’s given a SpitterService object via injection, without any concern for where it comes from.
In fact, who’s to say the client was even given an RMI-based implementation?
Furthermore, the proxy catches any RemoteExceptions that may be thrown by the service and rethrows them as unchecked exceptions that you may safely ignore.
This makes it possible to easily swap out the remote service bean with another implementation of the service—perhaps a different remote service, or maybe a mock implementation used when unit-testing the client code.
Even though the client code isn’t aware that the SpitterService it was given is a remote service, you may want to take care when you design the service’s interface.
Note that the client had to make two calls to the service: one to look up the Spitter by username, and another to retrieve the list of Spittle objects.
That’s two remote calls that are affected by network latency and that will impact the performance of the client.
Knowing that this is how the service will be used, it may be worthwhile to revisit the service’s interface to consolidate those two calls into a single method.
But if you’re working on the internet, you’ll probably run into trouble with RMI.
Even through RMI has support for tunneling over HTTP (which is usually allowed by firewalls), setting up RMI tunneling can be tricky.
That means both the client and the service must be written in Java.
And because RMI uses Java serialization, the types of the objects being sent across the network must have the exact same version of the Java runtime on both sides of the call.
These may or may not be issues for your application, but bear them in mind when choosing RMI for remoting.
Caucho Technology (the same company behind the Resin application server) has developed a remoting solution that addresses the limitations of RMI.
Actually, Caucho has come up with two solutions: Hessian and Burlap.
Let’s see how to use Hessian and Burlap to work with remote services in Spring.
Hessian and Burlap are two solutions provided by Caucho Technology that enable lightweight remote services over HTTP.
Each aims to simplify web services by keeping both its API and its communication protocols as simple as possible.
You may be wondering why Caucho has two solutions to the same problem.
Hessian and Burlap are two sides of the same coin, but each serves slightly different purposes.
Hessian, like RMI, uses binary messages to communicate between client and service.
Burlap is an XML-based remoting technology, which automatically makes it portable to any language that can parse XML.
And because it’s XML, it’s more easily humanreadable than Hessian’s binary format.
Unlike other XML-based remoting technologies (such as SOAP and XML-RPC), Burlap’s message structure is as simple as possible and doesn’t require an external definition language (such as WSDL or IDL)
How do you choose between Hessian and Burlap? For the most part, they’re identical.
The only difference is that Hessian messages are binary and Burlap messages are XML.
If human readability is important to you (for debugging purposes), or if your application will be communicating with a language for which there’s no Hessian implementation, Burlap’s XML messages may be preferable.
To demonstrate Hessian and Burlap services in Spring, let’s revisit the Spitter service example that we addressed with RMI in the previous section.
This time, we’ll look at how to solve the problem using Hessian and Burlap as the remoting models.
As before, suppose you want to expose the functionality of the SpitterServiceImpl class as a service—a Hessian service, this time.
Because Hessian services are already easy to implement, Spring doesn’t do much to simplify the Hessian model further.
But when used with Spring, a Hessian service can take full advantage of the Spring Framework in ways that a pure Hessian service can’t.
This includes using Spring AOP to advise a Hessian service with system-wide services, such as declarative transactions.
To expose the Spitter service bean as an RMI service, you had to configure an RmiServiceExporter bean in the Spring configuration.
Similarly, to expose the Spitter service as a Hessian service, you need to configure another exporter bean.
But, as shown in figure 15.6, how it pulls off this feat is different from how RmiServiceExporter exports POJOs as RMI services.
The serviceInterface is set to indicate that SpitterService is the interface the service implements.
With RMI, the serviceName property is used to register a service in the RMI registry.
Hessian doesn’t have a registry, and, therefore, there’s no need to name a Hessian service.
This means that in order to use exported Hessian services, you’ll need to perform two additional configuration steps:
Configure a Spring DispatcherServlet in web.xml, and deploy your application as a web application.
Configure a URL handler in your Spring configuration to dispatch Hessian service URLs to the appropriate Hessian service bean.
You first saw how to configure Spring’s DispatcherServlet and URL handlers in chapter 5, so these steps should be somewhat familiar by now.
Fortunately, you have one already configured in the Spittr application’s web.xml file.
But for the purposes of handling Hessian services, that DispatcherServlet needs a servlet mapping that catches *.service URLs:
Configured this way, any request whose URL ends with .service will be given to DispatcherServlet, which will in turn hand off the request to the Controller that’s mapped to the URL.
An alternative to Hessian’s binary protocol is Burlap’s XML-based protocol.
Let’s see how to export a service as a Burlap service.
As you can see, the only differences between this bean and its Hessian counterpart are the bean method and the exporter class.
Configuring a Burlap service is otherwise the same as configuring a Hessian service.
This includes the need to set up a URL handler and a DispatcherServlet.
Now let’s look at the other side of the conversation and consume the service that you published using Hessian (or Burlap)
In fact, it has no clue that it’s a remote service.
It only deals with the SpitterService interface—all the RMI details are contained in the configuration of the beans in Spring’s configuration.
The good news is that because of the client’s ignorance of the service’s implementation, switching from an RMI client to a Hessian client is extremely easy, requiring no changes to the client’s Java code.
The bad news is that if you love writing Java code, this section may be a letdown.
A Hessian-based Spitter service can be declared in the client code like this:
Just as with an RMI-based service, the serviceInterface property specifies the interface that the service implements.
Because Hessian is HTTP-based, it’s set to an HTTP URL here (determined in part by the URL mapping you defined earlier)
As it turns out, wiring a Burlap service into the client is equally uninteresting.
Although I’ve made light of how uninteresting the configuration differences are among RMI, Hessian, and Burlap, this tedium is a benefit.
It demonstrates that you can switch effortlessly between the various remoting technologies supported by Spring without having to learn a completely new model.
Once you’ve configured a reference to an RMI service, it’s short work to reconfigure it as a Hessian or Burlap service.
Because both Hessian and Burlap are based on HTTP, they don’t suffer from the same firewall issues as RMI.
But RMI has both Hessian and Burlap beat when it comes to serializing objects that are sent in RPC messages.
Whereas Hessian and Burlap both use a proprietary serialization mechanism, RMI uses Java’s own serialization mechanism.
If your data model is complex, the Hessian/Burlap serialization model may not be sufficient.
Let’s look at Spring’s HTTP invoker, which offers RPC over HTTP (like Hessian/Burlap) while at the same time using Java serialization of objects (like RMI)
The Spring team recognized a void between RMI services and HTTP-based services such as Hessian and Burlap.
On the one side, RMI uses Java’s standard object serialization but is difficult to use across firewalls.
The HTTP invoker is a new remoting model created as part of the Spring Framework to perform remoting across HTTP (to make the firewalls happy) and using Java’s serialization (to make programmers happy)
To get started with the HTTP invoker, let’s take another look at the Spitter service—this time implemented as an HTTP invoker service.
To export a bean as an RMI service, you used RmiServiceExporter.
It’s a Spring MVC controller that receives requests from a client through DispatcherServlet and translates those requests into method calls on the service implementation POJO.
Also as before, you need to make sure you map DispatcherServlet such that it handles requests with a *.service extension.
See the instructions in section 15.3.1 for details on how to set this mapping.
You’ve already seen how to consume remote services through RMI, Hessian, and Burlap.
Now let’s rework the Spitter client to use the service that you just exposed with HTTP invoker.
At the risk of sounding like a broken record, I must tell you that consuming an HTTP invoker-based service is much like what you’ve already seen with the other remote service proxies.
The serviceInterface property is still used to indicate the interface implemented by the Spitter service.
And the serviceUrl property is still used to indicate the location of the remote service.
Because HTTP invoker is HTTP-based, like Hessian and Burlap, the serviceUrl can contain the same URL as with the Hessian and Burlap versions of the bean.
This makes HTTP invoker services an appealing alternative to either RMI or Hessian/Burlap.
HttpInvoker has one significant limitation that you should keep in mind: it’s a remoting solution offered by the Spring Framework only.
This means both the client and the service must be Spring-enabled applications.
This also implies, at least for now, that both the client and the service must be Java-based.
And because Java serialization is being used, both sides must have the same version of the classes as well as the same version of the Java runtime (much like RMI)
But when it comes to ubiquitous remoting, none hold a candle to web services.
Next up, we’ll look at how Spring supports remoting through SOAP-based web services.
One of the most hyped TLAs (three-letter acronyms) in recent years is SOA (serviceoriented architecture)
But at the center of SOA is the idea that applications can and should be designed to lean on a common set of core services instead of reimplementing the same functionality for each application.
For example, a financial institution may have many applications, some of which need access to borrower account information.
Rather than build account-access logic into each application (much of which would be duplicated), the applications can all rely on a common service to retrieve the account information.
Java and web services have a long history together, and various options are available for working with web services in Java.
Many of those options integrate with Spring in some way.
Although it would be impossible for me to cover every Spring-enabled web service framework and toolkit in this book, Spring comes with some capable support for publishing and consuming SOAP web services using the Java API for XML Web Services (JAX-WS)
In this section, we’ll revisit the Spitter service example one more time.
This time, you’ll expose and consume the Spitter service as a web service using Spring’s JAX-WS support.
Let’s start by seeing what it takes to create a JAX-WS web service in Spring.
Earlier in this chapter, you created remote services using Spring’s service exporters.
These service exporters magically turn Spring-configured POJOs into remote services.
Now you probably expect me to show you how to create web services using a JAX-WS service exporter in this section.
But before you get there, you should know that it may not be the best choice in all situations.
The JAX-WS runtime that ships with Sun’s JDK 1.6 fits the bill, but other JAX-WS implementations, including the reference implementation of JAX-WS, may not.
If you’ll be deploying to a JAX-WS runtime that doesn’t support publishing to a specified address, you’ll have write your JAX-WS endpoints in a more conventional way.
That means the lifecycle of the endpoints will be managed by the JAX-WS runtime and not by Spring.
But that doesn’t mean they can’t be wired with beans from a Spring application context.
Just as with any other object in a sizable application, a JAX-WS endpoint will likely depend on other objects to do its work.
But if the endpoint’s lifecycle is managed by the JAX-WS runtime and not by Spring, it would seem to be impossible to wire Spring-managed beans into a JAX-WS–managed endpoint instance.
You annotate the spitterService property with @Autowired to indicate that it should be automatically injected with a bean from the Spring application context.
From there, this endpoint delegates to the injected SpitterService to do the real work.
But under the right circumstances, it’s possible to export a Spring-managed bean as a JAX-WS endpoint.
Instead, it publishes all beans that are annotated with JAX-WS annotations as JAX-WS services.
When it gets started, it digs through the Spring application context looking for beans that are annotated with @WebService.
When it finds one, it publishes the bean as a JAX-WS endpoint with a base address of http://localhost:8080/
As a full-fledged Spring bean, it qualifies for autowiring without extending a special support class.
But you’re in total control of the service URL, so if you’d like, you can set the base address to something else.
That includes the JAX-WS runtime that comes with Sun’s 1.6 JDK.
Publishing web services with Spring is different from the way you publish services in RMI, Hessian, Burlap, and the HTTP invoker.
But as you’ll soon see, consuming web services with Spring involves client-side proxies in much the same way that Springbased clients consume those other remoting technologies.
The proxy is created to implement the service’s interface (see figure 15.10)
The wsdlDocumentUrl property identifies the location of the remote web service’s definition file.
You can usually determine the values for the remaining three properties by looking at the service’s WSDL.
For illustration’s sake, suppose the WSDL for the Spitter service looked like this:
These proxies can then be wired into other beans as if they were local POJOs.
Although not likely, it’s possible for multiple services and/or ports to be defined in the service’s WSDL.
Finally, the namespaceUri property specifies the namespace of the service.
As with the port and service names, you can find the correct value for this property by looking in the WSDL.
It’s usually available in the targetNamespace attribute of the <wsdl:definitions> element.
But Spring provides remoting support that makes working with remote services as simple as working with regular JavaBeans.
On the client side, Spring provides proxy factory beans that enable you to configure remote services in your Spring application.
Regardless of whether you’re using RMI, Hessian, Burlap, Spring’s own HTTP invoker, or web services for remoting, you can wire remote services into your application as if they were POJOs.
Even though Spring hides many of the details of remote services, making them appear as though they’re local JavaBeans, you should bear in mind the consequences of remote services.
Remote services, by their nature, are typically less efficient than local services.
You should consider this when writing code that accesses remote services, limiting remote calls to avoid performance bottlenecks.
In this chapter, you saw how you can use Spring to expose and consume services based on basic remoting technologies.
Although these remoting options are useful in distributing applications, this was just a taste of what’s involved in working in a serviceoriented architecture (SOA)
We also looked at how to export beans as SOAP-based web services.
Although this is an easy way to develop web services, it may not be the best choice from an architectural standpoint.
In the next chapter, we’ll look at a different approach to building distributed applications by exposing portions of the application as RESTful resources.
As developers, we’re often focused on building great software to solve business.
Data is just the raw material that your software processes need to get their job done.
But if you were to ask most business people which is most valuable to them, data or software, they’d likely choose data.
Software is often replaceable, but the data gathered over the years can never be replaced.
Don’t you think it’s odd that, given the importance of data, the way we develop software often treats data as an afterthought? Take the remote services from the previous chapter as an example.
Those services were centered on actions and processes, not information and resources.
Whereas SOAP typically focused on actions and processing, REST’s concern is with the data being handled.
The good news is that Spring’s REST support builds on Spring MVC, so we’ve already covered much of what you’ll need for working with REST in Spring.
In this chapter, you’ll build on what you already know about Spring MVC to develop controllers that handle requests for RESTful resources.
But before we get too carried away, let’s examine what working with REST is all about.
I’ll wager that this isn’t the first time you’ve heard or read about REST.
There’s been a lot of talk about REST in recent years, and you’ll find that it’s fashionable in software development to speak ill of SOAP-based web services while promoting REST as an alternative.
Certainly, SOAP can be overkill for many applications, and REST brings a simpler alternative.
Moreover, many modern applications have mobile and rich JavaScript clients that consume REST APIs running on a server.
The problem is that not everybody has a solid grasp of what REST really is.
As a result, a lot of misinformation is floating about, and many things are labeled REST that don’t fit the true REST intent.
Before we can talk about how Spring supports REST, we need to establish a common understanding of what REST is all about.
On the contrary, REST has little to do with RPC.
Whereas RPC is service oriented and focused on actions and verbs, REST is resource oriented, emphasizing the things and nouns that comprise an application.
To understand what REST is all about, it helps to break down the acronym into its constituent parts:
State—When working with REST, you’re more concerned with the state of a resource than with the actions you can take against resources.
Transfer—REST involves transferring resource data, in some representational form, from one application to another.
There are no strict rules regarding RESTful URL structure, but the URL should identify a resource, not bark a command to the server.
That said, there are actions in REST, and they’re defined by HTTP methods.
These HTTP methods are often mapped to CRUD verbs as follows:
Even though this is the common mapping of HTTP methods to CRUD verbs, it’s not a strict requirement.
There are cases where PUT can be used to create a new resource and POST can be used to update a resource.
In fact, the non-idempotent nature of POST makes it a rogue method, capable of performing operations that don’t easily fit the semantics of the other HTTP methods.
Given this view of REST, I try to avoid terms such as REST service, RESTful web service, and anything similar that incorrectly gives prominence to actions.
Instead, I prefer to emphasize the resource-oriented nature of REST and speak of RESTful resources.
Spring has long had some of the ingredients needed for exposing REST resources.
Starting with version 3.0, however, Spring began adding enhancements to Spring MVC to provide first-class REST support.
Now, at version 4.0, Spring supports the creation of REST resources in the following ways:
Controllers can handle requests for all HTTP methods, including the four primary REST methods: GET, PUT, DELETE, and POST.
The @PathVariable annotation enables controllers to handle requests for parameterized URLs (URLs that have variable input as part of their path)
Resources can be represented in a variety of ways using Spring views and view resolvers, including View implementations for rendering model data as XML, JSON, Atom, and RSS.
Throughout this chapter, we’ll explore these features that make Spring more RESTful starting with how to produce REST resources using Spring MVC.
Then in section 16.4, we’ll switch to the client side of REST and see how to consume these resources.
Let’s start by looking at what goes into a RESTful Spring MVC controller.
One of the nice things about Spring’s support for REST is that you already know a lot about what goes into creating RESTful controllers.
What you learned in chapters 5–7 about creating web applications can now be used to expose resources in a REST API.
The following listing shows the beginnings of a new REST controller that will serve Spittle resources.
It’s a small start, but you’ll build on this controller throughout this chapter as you learn the ins and outs of Spring’s REST programming model.
Can you see how it serves a REST resource instead of just a web page?
Nothing about this controller, as it’s written, makes it a RESTful, resource-serving controller.
As you’ll recall, when a GET request comes in for /spittles, the spittles() method is called.
It looks up and returns a Spittle list retrieved from the injected SpittleRepository.
That list is placed into the model for a view to render.
For a browser-based web application, this probably means the model data is rendered to an HTML page.
In that case, HTML isn’t the appropriate representation of the data.
It’s how a client and a server communicate about a resource.
Any given resource can be represented in virtually any form.
If the consumer of the resource prefers JSON, then the resource can be presented in JSON format.
Or if the consumer has a fondness for angle brackets, the same resource can be presented in XML.
Meanwhile, a human user viewing the resource in a web browser will likely prefer seeing it in HTML (or possibly PDF, Excel, or some other human-readable form)
Certainly, if you’ll be presenting content to be consumed by a human, you should probably support HTML formatted resources.
Depending on the nature of the resource and the requirements of your application, you may even choose to present the resource as a PDF document or an Excel spreadsheet.
For non-human consumers, such as other applications or code that invokes your REST endpoints, the leading choices for resource representation are XML and JSON.
It’s easy enough to support both of these options using Spring, so there’s no need to make a choice.
With that said, I recommend that you at minimum support JSON.
It’s important to know that controllers usually don’t concern themselves with how resources are represented.
Controllers deal with resources in terms of the Java objects.
But it’s not until after the controller has finished its work that the resource is transformed into a form that best suits the client.
Spring offers two options to transform a resource’s Java representation into the representation that’s shipped to the client:
Content negotiation—A view is selected that can render the model into a representation to be served to the client.
Message conversion—A message converter transforms an object returned from the controller into a representation to be served to the client.
If the method doesn’t directly return a logical view name (if the method returns void, for example), the logical view name is derived from the request’s URL.
DispatcherServlet then passes the view name to a view resolver, asking it to help determine which view should render the results of the request.
In a human-facing web application, the view chosen is almost always rendered as HTML; view resolution is a one-dimensional activity.
If the view name matches a view, then that’s the view you go with.
When it comes to resolving view names into views that can produce resource representations, there’s an additional dimension to consider.
Not only does the view need to match the view name, but the view also needs to be chosen to suit the client.
If the client wants JSON data, then an HTML-rendering view won’t do—even if the view name matches.
A lot is going on in that simple bean declaration.
You start by figuring out what kind of content the client wants.
Shouldn’t the request’s Accept header give a clear indication of what representation should be sent to the client?
If the client in question is a web browser, there’s no guarantee that what the client wants is what the browser sends in the Accept header.
Web browsers typically only accept humanfriendly content types (such as text/html), and there’s no way (short of developeroriented browser plugins) to specify a different content type.
If the extension is .json, then the desired content type must be application/json.
If it’s .xml, then the client is asking for application/xml.
Of course, an .html extension indicates that the client wants the resource represented as HTML (text/html)
If the file extension doesn’t produce any usable clues for the media type, then the Accept header in the request is considered.
In that case, the Accept header’s value indicates the MIME type(s) that the client wants; there’s no need to look it up.
Instead, it delegates to other view resolvers, asking them to resolve the view.
Every view that’s resolved is added to a list of candidate views.
The first match found is the one that’s used to render the model.
Specify a default content type to fall back to if a content type can’t be derived from the request.
You should be able to easily map the new style of configuration to the old style if you’re working with an older version of Spring.
That’s because the bean name matches the logical view name.
The same controller method that serves human-facing HTML content can also serve JSON or XML to a non-human client.
Content negotiation is a convenient option when there’s a great deal of overlap between your human and non-human interfaces.
In practice, though, human-facing views rarely deal at the same level of detail as a REST API.
As a ViewResolver implementation, it only has an opportunity to determine how a resource is rendered to a client.
It has no say in what representations a controller can consume from the client.
When a client requests a list of Spittle objects in JSON, the client is probably expecting a response that looks something like this:
But because the model is a map of key-value pairs, the response looks more like this:
Although this isn’t a terrible thing, it may not be what your client is expecting.
Instead, I lean heavily toward using Spring’s message converters for producing resource representations.
Let’s see how you can employ Spring’s message converters in your controller methods.
Message conversion is a more direct way to transform data produced by a controller into a representation that’s served to a client.
When using message conversion, DispatcherServlet doesn’t bother with ferrying model data to a view.
In fact, there is no model, and there is no view.
There is only data produced by the controller and a resource representation produced when a message converter transforms that data.
Table 16.1 Spring provides several HTTP message converters that marshal resource representations to and from various Java types.
Registered if the Rome library is present on the classpath.
Reads from all media types (*/*), and writes as application/ octet-stream.
Registered if JAXB v2 libraries are present on the classpath.
Registered if the Jackson JSON library is present on the classpath.
Registered if the Jackson 2 JSON library is present on the classpath.
Registered if the Rome library is present on the classpath.
For example, suppose the client has indicated via the request’s Accept header that it can accept application/json.
Note that all but five of the HTTP message converters in table 16.1 are registered by default, so no Spring configuration is required to use them.
But you may need to add additional libraries to your application’s classpath to support them.
As you may have guessed, a slight twist to Spring MVC’s programming model is required to support message conversion.
Let’s tweak the controller from listing 16.1 so that it will use message conversion.
But if you’re going to employ message conversion, you need to tell Spring to skip the normal model/view flow and use a message converter instead.
There are a handful of ways to do this, but the simplest is to annotate the controller method with @ResponseBody.
Table 16.1 Spring provides several HTTP message converters that marshal resource representations to and from various Java types.
The @ResponseBody annotation tells Spring that you want to send the returned object as a resource to the client, converted into some representational form that the client can accept.
More specifically, DispatcherServlet considers the request’s Accept header and looks for a message converter that can give the client the representation it wants.
The message converter will convert the Spittle list returned from the controller into a JSON document that will be written to the body of the response.
Jackson uses reflection by default Be aware that by default, the Jackson JSON libraries use reflection in producing the JSON resource representation from the returned object.
But if you refactor the Java type by adding, removing, or renaming properties, then the produced JSON will be changed as well (which might break clients, depending on those properties)
You can, however, influence how the JSON is produced by applying Jackson’s mapping annotations on the Java type.
This gives you more control over what the resulting JSON looks like and prevents changes that could break your API and its clients.
I’ve added a produces attribute to declare that this method will only handle requests where JSON output is expected.
That is, this method will only handle requests whose Accept header includes application/json.
Any other kind of request, even if it’s a GET request whose URL matches the path specified, won’t be handled by this method.
Either it will be handled by some other handler method (if an appropriate one exists) or the client will be sent an HTTP 406 (Not Acceptable) response.
A REST API can also receive resource representations from the client.
It’d be inconvenient if your controller had to convert a JSON or XML representation sent from a client into an object it can use.
For example, suppose that you need a way for a client to submit a new Spittle to be saved.
You can write the controller method to handle such a request like this:
If you disregard the annotations, saveSpittle() is a fairly straightforward method.
But by applying the annotations, it becomes much more interesting and powerful.
The body of the POST request is expected to carry a resource representation for a Spittle.
Because the Spittle parameter is annotated with @RequestBody, Spring will look at the Content-Type header of the request and try to find a message converter that can convert the request body into a Spittle.
For example, if the client sent the Spittle data in a JSON representation, then the Content-Type header might be set to application/json.
In that case, DispatcherServlet will look for a message converter that can convert JSON into Java objects.
Notice that the @RequestMapping has a consumes attribute set to application/ json.
The consumes attribute works much like the produces attribute, only with regard to the request’s Content-Type header.
This tells Spring that this method will only handle POST requests to /spittles if the request’s Content-Type header is application/json.
Otherwise, it will be up to some other method (if a suitable one exists) to handle the request.
But if you’re writing a controller that has several methods, all of which should use message conversion, then those annotations get somewhat repetitive.
SpittleController, as defined thus far, can look like the next listing.
The key thing to notice in listing 16.3 is what’s not in the code.
But because the controller is annotated with @RestController, the objects returned from those methods will still go through message conversion to produce a resource representation for the client.
So far, you’ve seen how to use Spring MVC’s programming model to publish RESTful resources in the body of responses.
There are headers and status codes that can also provide useful information about the response to the client.
Let’s see how to populate response headers and set the status code when serving resources.
The @ResponseBody annotation is helpful in transforming a Java object returned from a controller to a resource representation to send to the client.
As it turns out, serving a resource’s representation to a client is only part of the story.
A good REST API does more than transfer resources between the client and server.
It also gives the client additional metadata to help the client understand the resource or know what has just taken place in the request.
For example, let’s start by adding a new handler method to SpittleController to serve a single Spittle:
That ID is passed in to the id parameter and used to look up a Spittle from the repository by calling findOne()
The Spittle returned from findOne() will be returned from the handler method, and message conversion will take care of producing a resource representation consumable by the client.
Or could it? What do you suppose will happen if there isn’t a Spittle whose ID matches the.
Meanwhile, the default HTTP status code carried on the response is 200 (OK), which means everything is fine.
The client asks for a Spittle, but it gets nothing.
It receives neither a Spittle nor any indication that anything is wrong.
It should be 404 (Not Found) to tell the client that what they asked for wasn’t found.
And it would be nice if the response body carried an error message instead of being empty.
Spring offers a few options for dealing with such scenarios:
This is another area where Spring offers a lot of flexibility, and there’s no one correct approach.
Instead of trying to nail down a single strategy for dealing with these kind of errors or trying to cover all possible scenarios, I’ll show you a couple of ways you could change spittleById() to handle the case where a Spittle can’t be found.
ResponseEntity is an object that carries metadata (such as headers and the status code) about a response in addition to the object to be converted to a resource representation.
Because ResponseEntity allows you to specify the response’s status code, it seems like a good choice for communicating an HTTP 404 error when the Spittle can’t be found.
Here’s a new version of spittleById() that returns a ResponseEntity:
As before, the ID from the path is used to retrieve a Spittle from the repository.
If one is found, the status is set to HttpStatus.OK (which was the default before)
Finally, a new ResponseEntity is created to carry the Spittle and the status code to the client.
There’s no need to annotate the method with @ResponseBody if it returns ResponseEntity.
This is a step in the right direction, for sure.
Now the client is given a proper status code if the Spittle it asks for can’t be found.
But the body of the response is still empty in that case.
You’d like for the body to carry additional error information.
First, define an Error object to carry the error information:
If the Spittle is found, it’s returned, wrapped in a ResponseEntity with a status code of 200 (OK)
On the other hand, if findOne() returns null, you construct an Error object and return it wrapped in a ResponseEntity with a status code of 404 (Not Found)
After all, the method works as you’d like it to.
First, it’s a bit more involved than when we started.
There’s a bit more logic involved, including a conditional statement.
And the fact that the method returns ResponseEntity<?> feels wrong.
The generic use of ResponseEntity leaves too much open for interpretation or mistake.
Error handlers deal with the ugly realities of what could go wrong, leaving the regular handler methods to blissfully focus on the happy path.
Let’s refactor some of the code to take advantage of an error handler.
The @ExceptionHandler annotation can be applied to controller methods to handle specific exceptions.
Now you can remove most of the error handling from the spittleById() method:
Aside from checking for a null return value, it’s completely focused on the successful case where the requested Spittle is found.
And you were able to get rid of the strange use of generics in the return type.
Knowing that the error handler method always returns an Error and always responds with an HTTP status code of 404 (Not Found), you can apply a similar cleanup process to spittleNotFound():
Because spittleNotFound() always returns an Error, the only reason to keep ResponseEntity around is so you can set the status code.
In order to set the response status code, you began using ResponseEntity.
But then you were able to use an exception handler and @ResponseStatus to eliminate the need for ResponseEntity and tighten up the code.
But there’s one more thing that ResponseEntity does well that can’t be done with other annotations or exception handlers.
In the case of the saveSpittle() method, you’re creating a new Spittle resource in the course of handling a POST request.
But as it’s currently written (refer to listing 16.3), you’re not accurately communicating that to the client.
After saveSpittle() handles the request, the server responds to the client with a representation of the Spittle in the body and an HTTP status code of 200 (OK)
That’s not a horrible thing, but it’s not entirely accurate.
Certainly, assuming that the request successfully creates the resource, the status can be thought of as OK.
But there’s more to be said than “OK.” Something was just created, and an HTTP status code communicates that to the client.
Applying what you’ve learned so far, that’s easy to fix.
All you need to do is annotate saveSpittle() with @ResponseStatus like this:
The client knows that something was created, but don’t you think it might be interested in knowing where the resource was created? After all, it’s a new resource, and a new URL is associated with it.
When creating a new resource, it’s considered good form to communicate the resource’s URL to the client in the Location header of the response.
Therefore, you need some way to populate the response headers.
The following listing shows a new version of saveSpittle() that returns a ResponseEntity to communicate that a new resource was created.
In this new version, an instance of HttpHeaders is created to carry the header values you want on the response.
Listing 16.4 Setting headers in the response when returning a ResponseEntity.
After calculating the URL of the newly created Spittle resource, the headers are used to create the ResponseEntity.
What’s more concerning, however, is that it calculates the Location header value using hard-coded values.
The localhost and 8080 portions of the URI are of particular concern, because those won’t be applicable if this application is deployed anywhere other than your local system.
It’s a builder class that lets you build up a UriComponents instance by specifying the various components of the URI (such as the host, port, path, and query) a piece at a time.
It obtains this foundational information from the request that the handler method is serving.
From there, the code builds up the rest of the UriComponents by setting the path.
Notice that the path is built up in two steps.
The first step calls path() to set it to / spittles/, the base path that the controller handles.
Then the saved Spittle ID is given in a second call to path()
As you may surmise, each call to path() builds on the previous calls.
After the path is completely set, the build() method is called to construct a UriComponents object.
From that, a call to toUri() gives the URI of the newly created Spittle resource.
Exposing resources in a REST API represents only one side of the conversation.
It does no good to publish an API if nobody comes along and uses it.
Commonly, mobile and JavaScript applications are the clients of a REST API, but there’s no reason a Spring application can’t consume those resources, too.
Let’s shift gears and see how to write Spring code that works for the client side of a RESTful interaction.
Writing code that interacts with a REST resource as a client can involve some tedium and boilerplate.
For example, let’s say you need to write a method to fetch someone’s Facebook profile from Facebook’s Graph API.
But the code to fetch the profile data is a bit more involved, as shown in the following listing.
As you can see, a lot goes into consuming a REST resource.
And I’m even cheating by using Apache HTTP Client to make the request and the Jackson JSON processor to parse the response.
What’s more, there are a few places along the way where an IOException could be thrown.
Because IOException is a checked exception, you’re forced to either catch it or throw it.
In this case, I’ve chosen to catch it and throw an unchecked RuntimeException in its place.
With so much boilerplate involved in resource consumption, you’d think it would be wise to encapsulate the common code and parameterize the variations.
But first, let’s take a high-level survey of all the REST operations that RestTemplate offers.
RestTemplate defines 36 methods for interacting with REST resources, and most of these methods map to HTTP methods.
With the exception of TRACE, RestTemplate has methods to cover all the HTTP verbs.
In addition, execute() and exchange() offer lower-level, general-purpose methods for using any of the HTTP methods.
Most of the operations in table 16.2 are overloaded into three method forms:
One that takes a java.net.URI as the URL specification with no support for parameterized URLs.
Once you get to know the 11 operations provided by RestTemplate and how each of the variant forms works, you’ll be well on your way to writing resource-consuming REST clients.
Let’s survey RestTemplate’s operations by looking at those that support the four primary HTTP methods: GET, PUT, DELETE, and POST.
You may have noticed that table 16.2 lists two kinds of methods for performing GET requests: getForObject() and getForEntity()
As described earlier, each of these methods is overloaded into three forms.
The signatures of the three getForObject() methods look like this:
Similarly, the signatures of the getForEntity() methods are as follows:
Except for the return type, the getForEntity() methods are mirror images of the getForObject() methods.
They both perform a GET request, retrieving a resource given a URL.
And they both map that resource to an instance of some type specified by the responseType parameter.
The only difference is that getForObject() returns an object of the type requested, whereas getForEntity() returns that object along with extra information about the response.
Then you’ll see how to get more information from a GET response by using the getForEntity() method.
The getForObject() method is a no-nonsense option for retrieving a resource.
You ask for a resource, and you receive that resource mapped to a Java type of your choosing.
Using RestTemplate, it’s reduced to a handful of lines (and could be even less if I didn’t have to wrap lines to fit within the margins of this book)
Then it invokes the getForObject() method to retrieve a Facebook profile.
In doing so, it asks for the result as a Profile object.
Upon receiving that Profile object, the method returns it to the caller.
One thing that’s absent here is any sort of JSON parsing or object mapping.
Under the covers, getForObject() converts the response body into an object for you.
What’s also missing from this method is any sort of exception handling.
That’s not because getForObject() couldn’t throw an exception, but because any exception it throws is unchecked.
You can catch it if you’d like—but you’re not forced by the compiler to catch it.
The getForEntity() methods work much the same as the getForObject() methods.
But where getForObject() returns only the resource (converted into a Java object by an HTTP message converter), getForEntity() returns that same object carried in a ResponseEntity.
The ResponseEntity also carries extra information about the response, such as the HTTP status code and response headers.
One thing you might want to do with a ResponseEntity is retrieve the value of one of the response headers.
For example, suppose that in addition to retrieving the resource, you want to know when that resource was last modified.
Assuming that the server provides that information in the LastModified header, you can use the getHeaders() method like this:
In addition to getLastModified(), HttpHeaders includes the following methods for retrieving header information:
For more general-purpose HTTP header access, HttpHeaders includes a get() method and a getFirst() method.
Both take a String argument that identifies the key of the desired header.
The get() method returns a list of String values—one for each value assigned to the header.
If you’re interested in the response’s HTTP status code, then you’ll want to call the getStatusCode() method.
Here, if the server responds with a status of 304, it indicates that the content on the server hasn’t been modified since the client previously requested it.
For performing PUT operations on a resource, RestTemplate offers a simple set of three put() methods.
As with all of RestTemplate’s methods, the put() method comes in three forms:
In its simplest form, the put() method takes a java.net.URI that identifies (and locates) the resource being sent to the server, and an object that’s the Java representation of that resource.
For example, here’s how you might use the URI-based version of put() to update a Spittle resource on the server:
Here, although the method signature is simple, the implication of using a java.net.URI argument is evident.
In order to create the URL for the Spittle object to be updated, you have to do String concatenation.
As you’ve already seen with getForObject() and getForEntity(), using one of the other String-based put() methods alleviates most of the discomfort associated with creating a URI.
These methods enable you to specify the URI as a template, plugging in values for the variable parts.
Here’s a new updateSpittle() method rewritten to use one of the String-based put() methods:
Optionally, you could pass in the template variables as a Map:
When you use a Map to send the template variables, the key of each entry in the Map corresponds to the placeholder variable of the same name in the URI template.
In all versions of put(), the second argument is the Java object that represents the resource being PUT to the server at the given URI.
RestTemplate uses one of the message converters from table 16.1 to convert the Spittle into a representation to send to the server in the request body.
The content type into which the object will be converted depends largely on the type being passed in to put()
Because you’re passing in a Spittle object, you need a message converter that can work with arbitrary objects.
When you don’t want a resource to be kept around on the server anymore, you’ll want to call RestTemplate’s delete() methods.
Much like the put() methods, the delete() methods have only three versions, whose signatures are as follows:
Hands down, the delete() methods are the simplest of all the RestTemplate methods.
The only thing you need to supply them with is the URI of the resource to be deleted.
For example, to get rid of a Spittle whose ID is given, you might call delete() like this:
That’s easy enough, but here again you rely on String concatenation to create a URI object.
Let’s turn to one of the simpler versions of delete() to avoid doing so:
Don’t you? Now that I’ve shown you the simplest set of RestTemplate methods, let’s look at.
RestTemplate’s most diverse set of methods—those that support HTTP POST requests.
Looking back at table 16.2, you see that RestTemplate comes with three different kinds of methods for sending POST requests.
When you multiply that by the three variants that each is overridden into, that’s a total of nine methods for POSTing data to the server.
The postForObject() and postForEntity() methods work with POST requests in a way that’s similar to how getForObject() and getForEntity() work for sending GET requests.
Let’s say that you’re using RestTemplate to POST a new Spitter object to the Spittr application’s REST API.
Because it’s a brand-new Spitter, the server doesn’t know about it (yet)
Therefore, it’s not officially a REST resource and doesn’t have a URL.
Also, the client won’t know the ID of the Spitter until it’s created on the server.
One way of POSTing a resource to the server is to use RestTemplate’s postForObject() method.
In all cases, the first parameter is the URL to which the resource should be POSTed, the second parameter is the object to post, and the third parameter is the Java type expected to be given in return.
In the case of the two versions that take the URL as a.
String, a fourth parameter identifies the URL variables (as either a variable arguments list or a Map)
When you POST new Spitter resources to the Spitter REST API, they should be posted to http://localhost:8080/spittr-api/spitters, where a POST-handling controller handler method is waiting to save the object.
Because this URL requires no URL variables, you can use any version of postForObject()
But in the interest of keeping it simple, let’s make the call like this:
In response, it receives a Spitter object and returns it to the caller.
As with the getForObject() methods, you may want to examine some of the metadata that comes back with the request.
Suppose that, in addition to receiving the Spitter resource in return, you’d also like to see the value of the Location header in the response.
Just like the getForEntity() method, postForEntity() returns a ResponseEntity<T> object.
From that object, you can call getBody() to get the resource object (a Spitter in this case)
And the getHeaders() method gives you an HttpHeaders from which you can access the various HTTP headers returned in the response.
Here, you’re calling getLocation() to retrieve the Location header as a java.net.URI.
The postForEntity() method is handy for receiving both the resource posted and any response headers.
But often you don’t need the resource to be sent back to you (after all, you sent it to the server in the first place)
If the value of the Location header is all you need to know, then it’s even easier to use RestTemplate’s postForLocation() method.
Like the other POST methods, postForLocation() sends a resource to the server in the body of a POST request.
But instead of responding with that same resource object, postForLocation() responds with the location of the newly created resource.
Here, you’re passing in the target URL as a String, along with the Spitter object to be POSTed (there are no URL variables in this case)
If, after creating the resource, the server responds with the new resource URL in the response’s Location header, then postForLocation() will return that URL as a String.
Up to this point, you’ve seen all manner of RestTemplate methods for GETting, PUTting, DELETEing, and POSTing resources.
Among those you saw two special methods, getForEntity() and postForEntity(), that give you the resulting resource wrapped in a RequestEntity from which you can retrieve response headers and status codes.
Being able to read headers from the response is useful.
But what if you want to set headers on the request sent to the server? That’s what RestTemplate’s exchange() methods are good for.
Like all the other methods in RestTemplate, exchange() is overloaded into three signature forms.
One takes a java.net.URI to identify the target URL, whereas the other two take the URL in String form with URL variables, as shown here:
The exchange() method also takes an HttpMethod parameter to indicate the HTTP verb that should be used.
Depending on the value given to this parameter, the exchange() method can perform the same jobs as any of the other RestTemplate methods.
For example, one way to retrieve a Spitter resource from the server is to use RestTemplate’s getForEntity() method like this:
As you can see in the next snippet of code, exchange() is also up to the task:
Used this way, the exchange() method is virtually identical to the previously used getForEntity()
Instead of passing null to exchange(), you pass in an HttpEntity created with the request headers you want.
Without specifying the headers, exchange() sends the GET request for a Spitter with the following headers:
It says it can accept several different XML content types as well as application/json.
That leaves a lot of room for the server to decide which format to send the resource back as.
Suppose you want to demand that the server send the response back as JSON.
In that case, you need to specify application/json as the only value in the Accept header.
Setting request headers is a simple matter of constructing the HttpEntity sent to exchange() with a MultiValueMap loaded with the desired headers:
Then you construct an HttpEntity (with a generic type of Object), passing the MultiValueMap as a constructor argument.
If this were a PUT or a POST request, you would also give the HttpEntity an object to send in the body of the request—but for a GET request, this isn’t necessary.
You should receive the Spitter object that you asked for.
Under the surface, the request is sent with the following headers:
And, assuming that the server can serialize the Spitter response into JSON, the response body should be represented in JSON format.
RESTful architecture uses web standards to integrate applications, keeping the interactions simple and natural.
Resources in a system are identified by URLs, manipulated with HTTP methods, and represented in one or more forms suitable for the client.
In this chapter, you’ve seen how to write Spring MVC controllers that respond to requests to manipulate RESTful resources.
By utilizing parameterized URL patterns and associating controller handler methods with specific HTTP methods, controllers can respond to GET, POST, PUT, and DELETE requests for the resources in an application.
In response to those requests, Spring can represent the data behind those resources in a format that’s best for the client.
Or a controller handler method can be annotated with @ResponseBody to completely bypass view resolution and have one of several message converters convert the returned value into a response for the client.
But Spring applications can also consume those APIs using RestTemplate.
The REST resources defined in this chapter are part of a public API.
That is, if you were to deploy them to an application somewhere on the internet, there’d be nothing stopping anyone from writing a client that uses them.
Coming up in the next chapter, you’ll start locking them down, as we look at ways to secure the REST resources so that only authorized clients are allowed to consume them.
You have just enough time to drive to the airport and catch your flight.
But before you pack up and head out, you need to be sure your boss and colleagues know the status of the work you’ve been doing so that on Monday they can pick up where you left off.
Unfortunately, some of your colleagues have already skipped out for the weekend, and your boss is tied up in a meeting.
You could call your boss’s cell phone—but it’s not necessary to interrupt him for a mere status report.
Maybe you could stick around and wait until he returns.
But it’s anyone’s guess how long the meeting will last, and you have a plane to catch.
Perhaps you could leave a sticky note on his monitor … next to a hundred other sticky notes it will blend in with.
The most practical way to communicate your status and still catch your plane is to send a quick email to your boss and your colleagues, detailing your progress and promising to send a postcard.
You don’t know where they are or when they’ll read.
If you injure yourself and need an ambulance, you’re probably going to pick up the phone—emailing the hospital just won’t do.
But often, sending a message is sufficient and offers some advantages over direct communication, such as letting you get on with your vacation.
A couple of chapters back, you saw how to use RMI, Hessian, Burlap, the HTTP invoker, and web services to enable communication between applications.
All of these communication mechanisms employ synchronous communication in which a client application directly contacts a remote service and waits for the remote procedure to complete before continuing.
Synchronous communication has its place, but it’s not the only style of interapplication communication available to developers.
Asynchronous messaging is a way of indirectly sending messages from one application to another without waiting for a response.
Asynchronous messaging has several advantages over synchronous messaging, as you’ll soon see.
With Spring, you have a few options for asynchronous messaging.
In this chapter, we’ll look at how to send and receive messages in Spring using both the Java Message Service (JMS) and the Advanced Message Queuing Protocol (AMQP)
In addition to basic sending and receiving of messages, we’ll look at Spring’s support for messagedriven POJOs: a way to receive messages that resembles EJB’s message-driven beans (MDBs)
Much like the remoting mechanisms and REST APIs we’ve covered so far in this part of the book, asynchronous messaging is all about applications communicating with one another.
But it differs from those other communication mechanisms in how information is transferred between systems.
As illustrated in figure 17.1, when the client invokes a remote method, the client must wait for the method to complete before moving on.
Even if the remote method doesn’t return anything to the client, the client is put on hold until the service is done.
Figure 17.1 When communicating synchronously, the client must wait for the operation to complete.
On the other hand, when messages are sent asynchronously, as shown in figure 17.2, the client doesn’t have to wait for the service to process the message or even for the message to be delivered.
The client sends its message and then moves along, assuming that the service will eventually receive and process the message.
We’ll take a closer look at these advantages in a moment, but first let’s examine how the messages are sent asynchronously.
Millions of times every day, people place letters, cards, and packages in the hands of postal workers, trusting that those items will reach the desired destinations.
The world’s too big for us to hand-deliver these things ourselves, so we rely on the postal system to handle them for us.
We address our items, place the necessary postage on them, and then drop them in the mail to be delivered without giving a second thought to how they might get where they’re going.
When Grandma’s birthday comes around, it would be inconvenient if we had to deliver a card directly to her.
Depending on where she lives, we’d have to set aside anywhere from a few hours to a few days to deliver a birthday card.
Fortunately, the postal service will deliver the card to her while we go about our lives.
When one application sends a message to another, there’s no direct link between the two applications.
Instead, the sending application places the message in the hands of a service that will ensure delivery to the receiving application.
There are two main actors in asynchronous messaging: message brokers and destinations.
When an application sends a message, it hands it off to a message broker.
The message broker ensures that the message is delivered to the specified destination, leaving the sender free to go about other business.
When you send a letter through the mail, it’s important to address it so that the postal service knows where it should be delivered.
Figure 17.2 Asynchronous communication is a no-wait form of communication.
Destinations are like mailboxes where the messages are placed until someone comes to pick them up.
But unlike mail addresses, which may indicate a specific person or street address, destinations are less specific.
Destinations are only concerned about where messages will be picked up—not who will pick them up.
Although different messaging systems may offer a variety of message-routing schemes, there are two common types of destinations: queues and topics.
Each of these is associated with a specific messaging model: either point-to-point (for queues) or publish/subscribe (for topics)
POINT-TO-POINT MESSAGING In the point-to-point model, each message has exactly one sender and one receiver, as illustrated in figure 17.3
When the message broker is given a message, it places the message in a queue.
When a receiver comes along and asks for the next message in the queue, the message is pulled from the queue and delivered to the receiver.
Because the message is removed from the queue as it’s delivered, it’s guaranteed that the message will be delivered to only one receiver.
Although each message in a message queue is delivered to only one receiver, this doesn’t imply that only one receiver is pulling messages from the queue.
It’s likely that several receivers are processing messages from the queue.
But they’ll each be given their own messages to process.
This is analogous to waiting in line at the bank.
As you wait, you may notice that multiple tellers are available to help you with your financial transaction.
When a teller finishes helping a customer, the teller calls for the next person in line.
When it’s your turn at the front of the line, you’re called to the counter and helped by one teller.
Another observation to be made at the bank is that when you get in line, you probably don’t know which teller will eventually help you.
You could count how many people are in line, match that with the number of available tellers, note which teller is fastest, and come up with a guess as to which teller will call you to their window.
But chances are you’ll be wrong and end up at a different teller’s window.
Likewise, with point-to-point messaging, if multiple receivers are listening to a queue, there’s no way of knowing which one will process a specific message.
This uncertainty is a good thing, because it enables an application to scale up message processing by adding another listener to the queue.
Figure 17.3 A message queue decouples a message sender from the message receiver.
Although a queue may have several receivers, each message is picked up by exactly one receiver.
PUBLISH-SUBSCRIBE MESSAGING In the publish/subscribe messaging model, messages are sent to a topic.
As with queues, many receivers may be listening to a topic.
But unlike with queues, where a message is delivered to exactly one receiver, all subscribers to a topic receive a copy of the message, as shown in figure 17.4
As you may have guessed from its name, the publish/subscribe message model is much like the model of a magazine publisher and its subscribers.
The magazine (a message) is published and sent to the postal service, and all subscribers receive their own copy.
The magazine analogy breaks down when you realize that the publisher has no idea who its subscribers are.
The publisher only knows that its message will be published to a particular topic—not who’s listening to that topic.
This also implies that the publisher has no idea how the message will be processed.
Now that we’ve covered the basics of asynchronous messaging, let’s see how it compares to synchronous RPC.
Even though it’s intuitive and simple to set up, synchronous communication imposes several limitations on the client of a remote service.
When a client invokes a method on a remote service, the client must wait for the remote method to complete before continuing.
If the client communicates frequently with the remote service or the remote service is slow to respond, this could negatively impact performance of the client application.
The client is coupled to the service through the service’s interface.
If the interface of the service changes, all of the service’s clients will need to change accordingly.
A client must be configured with the service’s network location so that it knows how to contact the service.
Figure 17.4 Like queues, topics decouple message senders from message receivers.
Unlike queues, a topic message may be delivered to many topic subscribers.
If the service becomes unavailable, the client is effectively crippled.
Although synchronous communication has its place, these shortcomings should be taken into account when deciding what communication mechanism is a best fit for your application’s needs.
If these constraints are a concern for you, you may want to consider how asynchronous communication addresses them.
The client drops off the message with the message broker and moves along, confident that the message will make it to the appropriate destination.
Because it doesn’t have to wait, the client is freed up to perform other activities.
With all this free time, the client’s performance can be dramatically improved.
This means the client isn’t fixed to a specific method signature.
Any queue or topic subscriber that can process the data sent by the client can process the message.
The client doesn’t need to be aware of any service specifics.
The implication is that clients aren’t resilient to changes in network topology.
If a service’s IP address changes or if it’s configured to listen on a different port, the client must be changed accordingly, or the client will be unable to access the service.
In contrast, messaging clients have no idea what service will process their messages or where the service is located.
The client only knows the queue or topic through which the messages will be sent.
As a result, it doesn’t matter where the service is located, as long as it can retrieve messages from the queue or topic.
In the point-to-point model, it’s possible to take advantage of location independence to create a cluster of services.
If the client is unaware of the service’s location, and if the service’s only requirement is that it must be able to access the message broker, there’s no reason multiple services can’t be configured to pull messages from the same queue.
If the service is overburdened and falling behind in its processing, all you need to do is start a few more instances of the service to listen to the same queue.
Location independence takes on another interesting side effect in the publish/ subscribe model.
Multiple services could all subscribe to a single topic, receiving duplicate copies of the same message.
For example, let’s say you have a set of services that together process a message that details the new hire of an employee.
One service might add the employee to the payroll system, another adds them to the HR portal, and yet another makes sure.
Each service works independently on the same data that they all received from a topic.
If the service were to go down or otherwise become unavailable, the client wouldn’t be able to proceed.
But when sending messages asynchronously, the client can rest assured that its messages will be delivered.
Even if the service is unavailable when a message is sent, the message will be stored until the service is available again.
Now that you have a feel for the basics of asynchronous messaging, let’s see it in action.
We’ll start by using JMS to send and receive messages.
The Java Message Service (JMS) is a Java standard that defines a common API for working with message brokers.
Before JMS, each message broker had a proprietary API, making an application’s messaging code less portable between brokers.
But with JMS, all compliant implementations can be worked with via a common interface in much the same way that JDBC has given database operations a common interface.
Spring supports JMS through a template-based abstraction known as JmsTemplate.
Using JmsTemplate, it’s easy to send messages across queues and topics from the producer side and also to receive those messages on the consumer side.
Spring also supports the notion of message-driven POJOs: simple Java objects that react to messages arriving on a queue or topic in an asynchronous fashion.
But before you can send and receive messages, you need a message broker ready to relay those messages between producers and consumers.
Let’s kick off our exploration of Spring JMS by setting up a message broker in Spring.
ActiveMQ is a great open source message broker and a wonderful option for asynchronous messaging with JMS.
As I’m writing this, the current version of ActiveMQ is 5.9.1
To get started with ActiveMQ, you’ll need to download the binary distribution from http://activemq.apache.org.
Once you’ve downloaded ActiveMQ, unzip it to your local hard drive.
This is the JAR file you’ll need to add to the application’s classpath to be able to use ActiveMQ’s API.
Under the bin directory, you’ll find subdirectories for various operating systems.
In those, you’ll find scripts that you can use to start ActiveMQ.
For example, to start ActiveMQ on OS X, run activemq start from the bin/macosx directory.
In moments, ActiveMQ will be ready and waiting to broker your messages.
In all cases, you’ll need a JMS connection factory to be able to send messages through the message broker.
Because you’re using ActiveMQ as your message broker, you’ll have to configure the JMS connection factory so that it knows how to connect to ActiveMQ.
That’s fine for development purposes, but it’s likely that your production ActiveMQ broker will be on a different host and/or port.
In that case, you can specify the broker URL with the brokerURL property:
Optionally, because you know you’re dealing with ActiveMQ, you can use ActiveMQ’s own Spring configuration namespace (available with all versions of ActiveMQ since version 4.1) to declare the connection factory.
First, be sure to declare the amq namespace in the Spring configuration XML file:
If you’re using a different message-broker implementation, there may or may not be a Spring configuration namespace available.
If not, you’ll need to wire the connection factory as a <bean>
Later in this chapter, you’ll use this connectionFactory bean a lot.
But for now, suffice it to say that brokerURL tells the connection factory where the message broker.
In this case, the URL given to brokerURL tells the connection factory to connect to ActiveMQ on the local machine at port 61616 (which is the port that ActiveMQ listens to by default)
The destination can be either a queue or a topic, depending on the needs of the application.
Regardless of whether you’re using a queue or a topic, you must configure the destination bean in Spring using a message broker–specific implementation class.
For example, the following <bean> declaration declares an ActiveMQ queue:
As with the connection factory, the ActiveMQ namespace offers an alternative way to declare queues and topics.
Or, if it’s a JMS topic that’s in order, use the <amq:topic>:
Either way, the physicalName attribute sets the name of the message channel.
At this point you’ve seen how to declare the essential components of working with JMS.
But first, let’s gain an appreciation for what JmsTemplate provides by looking at what JMS is like without JmsTemplate.
As you’ve seen, JMS gives Java developers a standard API for interacting with message brokers and for sending and receiving messages.
So there’s no reason to learn a proprietary messaging API for every message broker you deal with.
But although JMS offers a universal interface to all message brokers, its convenience comes at a cost.
Sending and receiving messages with JMS isn’t a simple matter of licking a stamp and placing it on an envelope.
As you’ll see, JMS demands that you also (figuratively) fuel the mail carrier’s truck.
Unfortunately, conventional JMS follows a similar model, as you’ll observe in the following listing.
Only a few of those lines actually send the message; the rest merely set the stage for sending the message.
It isn’t much better on the receiving end, as you can see in the next listing.
As in listing 17.1, that’s a lot of code to do something so darn simple.
If you take a lineby-line comparison, you’ll find that the listings are almost identical.
And if you were to look at a thousand other JMS examples, you’d find them all to be strikingly similar.
Some may retrieve their connection factories from JNDI, and some may use a topic instead of a queue.
A consequence of this boilerplate code is that you repeat yourself every time you work with JMS.
Worse still, you’ll find yourself repeating other developers’ JMS code.
You saw in chapter 10 how Spring’s JdbcTemplate handles runaway JDBC boilerplate.
Now let’s look at how Spring’s JmsTemplate can do the same thing for JMS boilerplate code.
JmsTemplate takes care of creating a connection, obtaining a session, and ultimately sending or receiving messages.
This leaves you to focus your development efforts on constructing the message to send or processing messages that are received.
What’s more, JmsTemplate can handle any clumsy JMSException that may be thrown along the way.
If a JMSException is thrown in the course of working with JmsTemplate, JmsTemplate will catch it and rethrow it as one of the unchecked subclasses of Spring’s own JmsException.
Table 17.1 Spring’s JmsTemplate catches standard JMSExceptions and rethrows them as unchecked subclasses of Spring’s own JmsException.
In fairness to the JMS API, JMSException does come with a rich and descriptive set of subclasses that give you a better sense of what went wrong.
Nevertheless, all these subclasses of JMSException are checked exceptions and thus must be caught.
JmsTemplate attends to that for you by catching each exception and rethrowing an appropriate unchecked subclass of JmsException.
To use JmsTemplate, you’ll need to declare it as a bean in the Spring configuration file.
Because JmsTemplate needs to know how to get connections to the message broker, you must set the connectionFactory property with a reference to the bean that implements JMS’s ConnectionFactory interface.
Here, you wire it with a reference to the connectionFactory bean that you declared earlier in section 17.2.1
Table 17.1 Spring’s JmsTemplate catches standard JMSExceptions and rethrows them as unchecked subclasses of Spring’s own JmsException.
That’s all you need to do to configure JmsTemplate—it’s ready to go.
You could build that feature directly into the application at the point where a spittle is added.
But figuring out whom to send alerts to and sending those alerts may take a while, which could hurt the perceived performance of the application.
When a new spittle is added, you want the application to be snappy and respond quickly.
Rather than taking the time to send a message the moment a spittle is added, it makes more sense to queue up that work and deal with it later, after the response has gone back to the user.
The time it takes to send a message to a message queue or a topic is negligible, especially compared to the time it may take to send alerts to other users.
To support sending spittle alerts asynchronously with the creation of spittles, let’s introduce AlertService to the Spittr application:
As you can see, AlertService is an interface that defines a single operation, sendSpittleAlert()
AlertServiceImpl, shown in listing 17.3, is an implementation of the AlertService interface that uses an injected JmsOperations (the interface that JmsTemplate implements) to send Spittle objects to a message queue to be processed at some later time.
The first parameter to JmsOperations’ send() method is the name of the JMS destination to which the message will be sent.
When the send() method is called, JmsTemplate deals with obtaining a JMS connection and session and sends the message on behalf of the sender (see figure 17.5)
The message is constructed using a MessageCreator, implemented here as an anonymous inner class.
In MessageCreator’s createMessage() method, you ask for an object message from the session, giving it the Spittle object from which to build the object message.
And that’s it! Note that the sendSpittleAlert() method is focused entirely on assembling and sending a message.
There’s no connection or session-management code; JmsTemplate handles all that for you.
And there’s no need to catch JMSException; JmsTemplate will catch any JMSException that’s thrown and then rethrow it as one of Spring’s unchecked exceptions from table 17.1
That form of send() comes in handy when you want to programmatically choose a destination.
But in the case of AlertServiceImpl, you’ll always be sending the spittle message to the same destination, so the benefits of that form of send() aren’t as clear.
Instead of explicitly specifying a destination each time you send a message, you can opt for wiring a default destination into JmsTemplate:
Figure 17.5 JmsTemplate deals with the complexities of sending a message on behalf of the sender.
But that’s only a name: it doesn’t say what kind of destination you’re dealing with.
If an existing queue or topic exists with that name, it will be used.
If not, then a new destination (usually a queue) will be created.
But if you want to be specific about what type of destination to create, you can instead wire in a reference to a queue or destination bean that you declared earlier:
Now the call to JmsOperations’ send() method can be simplified slightly by removing the first parameter:
This form of the send() method only takes a MessageCreator.
There’s no need to specify a destination, because the default destination is the one you want to send messages to.
Getting rid of the explicit destination in the call to send() made things a bit simpler.
But sending messages can be even easier if you take advantage of a message converter.
Unlike send(), the convertAndSend() method doesn’t take a MessageCreator as an argument.
That’s because convertAndSend() uses a built-in message converter to create the message for you.
When you use convertAndSend(), the sendSpittleAlert() method can be reduced to a single line in its body:
Just like magic, the Spittle is converted into a Message before it’s sent.
But as with any magic trick, JmsTemplate has a little something up its sleeve.
It uses an implementation of MessageConverter to do the dirty work of converting objects to Messages.
MessageConverter is a Spring-defined interface that has only two methods to be implemented:
Although this interface is simple enough to implement, you often won’t need to create a custom implementation.
Spring already offers a handful of implementations, such as those described in table 17.2
But you can override that by declaring the message converter as a bean and injecting it into JmsTemplate’s messageConverter property.
The various message converters may have additional configuration for finer-grained control of the conversion process.
Consult the JavaDoc for each message converter for more details on how to configure the finer details of these message converters.
In fact, it’s even easier to receive messages with JmsTemplate than it is to send them.
All you need to do is call JmsOperations’ receive() method, as shown in the following listing.
Table 17.2 Spring offers several message converters for common conversion tasks.
When the JmsOperations’ receive() method is called, it attempts to retrieve a message from the message broker.
If no message is available, receive() waits until a message becomes available.
Because you know that the spittle message was sent as an object message, it can be cast to ObjectMessage on arrival.
After that, you call getObject() to extract the Spittle object from the ObjectMessage and return it.
The one gotcha is that you have to do something about the JMSException that may be thrown.
As I already mentioned, JmsTemplate is good about handling any checked JMSExceptions that are thrown and then rethrowing them as Spring unchecked JmsExceptions.
But that’s only applicable when you call one of JmsTemplate’s methods.
JmsTemplate can’t do much about the JMSException that may be thrown by the call to ObjectMessage’s getObject() method.
Therefore, you must either catch that JMSException or declare that the method throws it.
In keeping with Spring’s philosophy of avoiding checked exceptions, you don’t want to let the JMSException escape this method, so you’ll catch it instead.
This is effectively the same thing JmsTemplate does for you in other cases.
You’ve seen how message converters can convert objects to Messages in convertAndSend()
Figure 17.6 Receiving messages from a topic or queue using JmsTemplate is as simple as calling the receive() method.
Now there’s no need to cast the Message to ObjectMessage, retrieve the Spittle by calling getObject(), or muck about with the checked JMSException.
This means the receiver must wait patiently for the message to arrive, because those methods will block until a message is available (or until a timeout condition occurs)
Doesn’t it seem odd to synchronously consume a message that was asynchronously sent?
Let’s see how to receive messages asynchronously using components that react to messages rather than wait on them.
During one summer in college, I had the privilege of working at Yellowstone National Park.
I didn’t have a high-profile job like being a park ranger or the guy who turns Old Faithful on and off.
Instead, I held a position in housekeeping at Old Faithful Inn, changing sheets, cleaning bathrooms, and vacuuming floors.
Not glamorous, but at least I was working in one of the most beautiful places on Earth.
Every day after work, I’d head over to the local post office to see if I had any mail.
I was away from home for several weeks, so it was nice to receive a letter or card from my friends back at school.
I didn’t have my own post box, so I’d walk up and ask the man sitting on the stool behind the counter if I had received any mail.
You see, the man behind the counter was approximately 195 years old.
And like most people that age, he had a difficult time getting around.
He’d drag his keister off the stool, slowly scoot his feet across the floor, and then disappear behind a partition.
After a few moments, he’d emerge, shuffle his way back to the counter, and lift himself back up onto the stool.
JmsTemplate’s receive() method is a lot like that aged postal employee.
When you call receive(), it goes away and looks for a message in the queue or topic and doesn’t return until a message arrives or until the timeout has passed.
Meanwhile, your application is sitting there doing nothing, waiting to see if there’s a message.
Wouldn’t it be better if your application could go about its business and be notified when a message arrives?
One of the highlights of the EJB 2 specification was the inclusion of the messagedriven bean (MDB)
In other words, MDBs react to messages in a JMS destination as events and respond to those events.
This is in contrast to synchronous message receivers, which block until a message is available.
Even many of EJB’s most rabid detractors would concede that MDBs were an elegant way of handling messages.
In doing so, they also had to implement a few EJB lifecycle callback methods.
With the EJB 3 specification, MDBs were cleaned up to have a slightly more POJO feel to them.
In this section, you’ll learn how Spring supports asynchronous message consumption using message-driven POJOs (we’ll call them MDPs, for short)
And although it’s not strictly required, it’s recommended that the MDB implement the MessageListener interface.
For a moment, try to imagine a simpler world where message-driven components don’t have to implement the MessageListener interface.
Okay, maybe the demands placed on an MDB by the EJB 3 specification aren’t that arduous.
Ideally, you’d like the alert handler to be capable of handling messages, but not coded as if it knows that’s what it will be doing.
Spring offers the ability for a method on a POJO to handle messages from a JMS queue or topic.
Listing 17.5 Spring MDP that asynchronously receives and processes messages.
Although changing the color of the sky and training birds to sing are out of the scope of Spring, listing 17.5 shows that the dream world I described is much closer to reality.
It can nevertheless handle messages just like its EJB cousin.
Spring’s jms namespace provides everything you need to do that.
Here you have a message listener that’s contained in a message-listener container.
A message-listener container is a special bean that watches a JMS destination, waiting for a message to arrive.
Once a message arrives, the bean retrieves the message and passes it on to any message listeners that are interested.
To configure the message-listener container and message listener in Spring, you use two elements from Spring’s jms namespace.
Here its connectionFactory attribute is configured with a reference to the connectionFactory that’s to be used by each of the child <jms:listener>s as they listen for messages.
In this case, the connectionfactory attribute could have been left off, because it defaults to connectionFactory.
The <jms:listener> element is used to identify a bean and a method that should handle incoming messages.
For the purposes of handling spittle alert messages, the ref element refers to your spittleHandler bean.
When a message arrives, it’s forwarded to a message listener (such as a message-driven POJO)
It’s also worth noting that if the bean identified by the ref attribute implements MessageListener, then there’s no need to specify the method attribute.
Chapter 15 explored several of Spring’s options for exposing bean methods as remote services and for making calls on those services from clients.
In this chapter, you’ve seen how to send messages between applications over message queues and topics.
Now we’ll bring those two concepts together and cover how to make remote calls that use JMS as a transport.
As you’ll see, these two options are similar, but each has advantages and disadvantages.
I’ll show you both approaches and let you decide which works best for you.
Let’s start by looking at how to work with Spring’s support for JMS-backed services.
As you’ll recall from chapter 15, Spring provides several options for exporting beans as remote services.
But Spring has one more service exporter that we didn’t talk about in chapter 15
Don’t concern yourself too much with the inner details of the sendSpittleAlert() method at this point.
We’ll talk more about how to send emails with Spring later, in chapter 20
The important thing to notice is that AlertServiceImpl is a simple POJO and has nothing that indicates it will be used to handle JMS messages.
As you can see, AlertServiceImpl is annotated with @Component so that it will be automatically discovered and registered as a bean in the Spring application context with an ID of alertService.
This bean’s properties describe what the exported service should look like.
The service property is wired to refer to the alertService bean, which is the implementation of the remote service.
Meanwhile, the serviceInterface property is set to the fully qualified class name of the interface that the service provides.
The exporter’s properties don’t describe the specifics of how the service will be carried over JMS.
The JMS listener container is given the connection factory so that it can know how to connect to the message broker.
Meanwhile, the <jms:listener> declaration is given the destination on which the remote message will be carried.
It hides the details of accessing a remote service behind a convenient interface, through which the client interacts with the service.
The serviceInterface specifies that the proxy should be exposed through the AlertService interface.
But JMS isn’t the only messaging choice available to Java and Spring developers.
In the past few years, the Advanced Message Queuing Protocol (AMQP) has been getting a lot of attention.
As it turns out, Spring has support for sending messages with AMQP, as you’ll see next.
You may be wondering why you need another messaging specification.
As it turns out, AMQP offers several advantages over JMS.
First, AMQP defines a wire-level protocol for messaging, whereas JMS defines an API specification.
JMS’s API specification ensures that all JMS implementations can be used through a common API but doesn’t mandate that messages sent by one JMS implementation can be consumed by a different JMS implementation.
AMQP’s wire-level protocol, on the other hand, specifies the format that messages will take when en route between the producer and consumer.
If you read this to mean that AMQP goes beyond the Java language and platform, then you’re catching on quickly.
Another significant advantage of AMQP over JMS is that AMQP has a much more flexible and transparent messaging model.
With JMS, there are only two messaging models to choose from: point-to-point and publish/subscribe.
Both of those models are certainly possible with AMQP, but AMQP enables you to route messages in a number of ways, and it does this by decoupling the message producer from the queue(s) in which the messages will be placed.
Spring AMQP is an extension to the Spring Framework that enables AMQP-style messaging in Spring applications.
As you’ll see, Spring AMQP provides an API that makes working with AMQP remarkably similar to Spring’s JMS abstraction.
That means much of what you learned earlier in this chapter for JMS can be used to help you understand how to send and receive messages with Spring AMQP.
You’ll see how to work with Spring AMQP soon enough.
But before we dig deep into how to send and receive AMQP messages in Spring, let’s take a quick look at what makes AMQP tick.
To understand the AMQP messaging model, it may help to briefly recall the JMS messaging model.
In JMS, there are just three primary participants: the message producer, the message consumer(s), and a channel (either a queue or a topic) to carry the message between producers and consumers.
In JMS, the channel helps to decouple the producer from the consumer, but both are still coupled to the channel.
A producer publishes messages to a specific queue or topic, and the consumer receives those message from a specific queue or topic.
The channel has the double duty of relaying messages and determining how those messages will be routed; queues route using a point-to-point algorithm, and topics route in publish/subscribe fashion.
In contrast, AMQP producers don’t publish directly to a queue.
Instead, AMQP introduces a new level of indirection between the producer and any queues that will carry the message: the exchange.
As you can see, a message producer publishes a message to an exchange.
The exchange, which is bound to one or more queues, routes the message to the queue(s)
Figure 17.8 In AMQP, message producers are decoupled from message queues by an exchange that handles message routing.
What’s not apparent from figure 17.8 is that the exchange isn’t a pass-through mechanism to a queue.
Depending on an exchange’s algorithm, it may consider the message’s routing key and/or arguments and compare those with the routing key and arguments of the binding between the exchange and a queue.
A routing key can be loosely thought of as the To address in an email, specifying the intended recipient.) If the algorithm is satisfied with the comparison, the message will be routed to the queue.
If not, then it won’t be routed to the queue.
The four standard types of AMQP exchanges are as follows:
Direct—A message will be routed to a queue if its routing key is a direct match for the routing key of the binding.
Topic—A message will be routed to a queue if its routing key is a wildcard match for the routing key of the binding.
Headers—A message will be routed to a queue if the headers and values in its table of arguments match those in the binding’s table of arguments.
A special header named x-match can specify whether all values must match or if any can match.
Fanout—A message will be routed to all queues that are bound to the exchange, regardless of the routing key or headers/values in the table of arguments.
Fortunately, when it comes to sending and receiving messages, the routing algorithm(s) in play have little impact on how you develop the message producers and consumers.
Put simply, producers publish to an exchange with a routing key; consumers retrieve from a queue.
This has been a quick overview of the basics of AMQP messaging—you should have just enough understanding to start sending and receiving messages using Spring AMQP.
But I encourage you to dig deeper into AMQP by reading the specification and other materials at www.amqp.org or by reading RabbitMQ in Action by Alvaro Videla and Jason J.W.
Now let’s step away from the abstract discussion of AMQP so you can get your hands dirty writing code that sends and receives messages using Spring AMQP.
You’ll start by seeing some of the common Spring AMQP configuration needed for both producers and consumers.
And I haven’t even mentioned that it’s possible to bind exchanges to other exchanges to create a nested hierarchy of routing.
When you first started working with Spring’s JMS abstraction, you began by configuring a connection factory.
Similarly, working with Spring AMQP starts with configuring a connection factory.
But instead of configuring a JMS connection factory, you need to configure an AMQP connection factory.
The easiest way to configure a RabbitMQ connection factory is to use the rabbit configuration namespace provided by Spring AMQP.
To use it, you need to be sure the schema is declared in your Spring configuration XML:
Although it’s optional, in this case I’ve decided to declare the rabbit namespace as the primary namespace in the configuration and demote the beans namespace to being a secondary namespace.
That’s because I anticipate declaring more rabbits than beans in this configuration and would rather prefix the few bean elements with beans: and leave the rabbit elements prefix-less.
The rabbit namespace includes several elements for configuring RabbitMQ in Spring.
In its simplest form, you can configure a RabbitMQ connection factory with no attributes:
What is RabbitMQ? RabbitMQ is a popular open source message broker that implements AMQP.
Spring AMQP comes ready with RabbitMQ support, including a RabbitMQ connection factory, template, and Spring configuration namespace.
You’ll need to install RabbitMQ before you can send and receive messages with it.
They vary depending on what OS you’re running, so I’ll leave it to you to follow the instructions appropriate for your environment.
This will work, but it leaves the resulting connection factory bean without a usable bean ID, which makes it hard to wire the connection factory into any other bean that needs it.
Therefore, you’ll probably want to give it a bean ID with the id attribute:
By default, the connection factory will assume that the RabbitMQ server is listening on localhost at post 5672 and that the username and password are both guest.
Those are reasonable defaults for development, but you’ll probably want to change those for production.
You use placeholders to specify the values so that the configuration can be managed outside of the Spring configuration (most likely in a properties file)
In addition to the connection factory, there are a few more configuration elements that you may want to consider using.
Let’s see how to configure Spring AMQP to lazily create queues, exchanges, and bindings.
One way of declaring queues, exchanges, and bindings is via a variety of methods on the RabbitMQ Channel interface.
Fortunately, the rabbit namespace includes several elements to help declare queues, exchanges, and the bindings that tie them together.
Table 17.3 Spring AMQP’s rabbit namespace includes several elements for lazily creating queues, exchanges, and the bindings between them.
That’s because there’s a default direct exchange with no name, and all queues are bound to that exchange with a routing key that’s the same as the queue’s name.
With this simple configuration, you could send messages to the no-name exchange and specify a routing key of spittle .alert.queue to have messages routed to the queue.
More interesting routing, however, will require that you declare one or more exchanges and bind them to queues.
For example, to have a message routed to multiple queues with no regard for the routing key, you can configure a fanout exchange and several queues like this:
Using the elements in table 17.3, there are countless ways to configure routing in RabbitMQ.
But I don’t have countless pages to describe them all to you, so in the interest of keeping this discussion on track, I’ll leave routing creativity as an exercise for you and move on to discussing how to send messages.
As its name implies, the RabbitMQ connection factory is used to create connections with RabbitMQ.
If you want to send messages via RabbitMQ, you could inject the connectionFactory bean into your AlertServiceImpl class, use it to create a.
Table 17.3 Spring AMQP’s rabbit namespace includes several elements for lazily creating queues, exchanges, and the bindings between them.
Connection, use that Connection to create a Channel, and use that Channel to publish a message to an exchange.
But that would be a lot of work and would involve a lot of boilerplate coding on.
It should be no surprise that Spring AMQP provides RabbitTemplate to eliminate boilerplate associated with sending and receiving messages with RabbitMQ.
The simplest configuration for RabbitTemplate can be done using the <template> element from the rabbit configuration namespace as follows:
Now all you need to do to send a message is inject the template bean into AlertServiceImpl and use it to send a Spittle.
The following listing shows a new version of AlertServiceImpl that uses RabbitTemplate instead of JmsTemplate to send a Spittle alert.
As you can see, the sendSpittleAlert() method now calls the convertAndSend() method on the injected RabbitTemplate.
It passes in three parameters: the name of the exchange, the routing key, and the object to be sent.
Notice that what’s not specified is how the message will be routed, what queues it will be sent on, or any consumers that are expected to receive the message.
RabbitTemplate has several overloaded versions of convertAndSend() to simplify its use.
For example, using one of the overloaded convertAndSend() methods, you can leave out the exchange name when calling convertAndSend():
Or, with another, you can leave out both the exchange name and routing key if you want:
When the exchange name or the exchange name and routing key are left out of the parameter list, RabbitTemplate uses its default exchange name and routing key.
As you have configured the template, the default exchange name is blank (or the default no-name exchange) and the default routing key is also blank.
But you can configure different defaults using the exchange and routing-key attributes on the <template> element:
No matter what you set the defaults to, you’re always able to override them when calling convertAndSend() by explicitly specifying them as parameters.
You might be interested in considering one of RabbitTemplate’s other methods for sending messages.
As with convertAndSend(), the send() method is overloaded to not require the exchange name and/or routing key.
The trick to using the send() methods is constructing a Message object to send.
In the Hello World example, you construct a Message instance by giving it the string’s byte array.
That’s easy enough for String values but can get more complicated when the message payload is a complex object.
For that reason, convertAndSend() exists to automatically convert an object to a Message.
It does this with the assistance of a message converter.
Spring AMQP provides a few other message converters that you might find useful, including some for working with JSON and XML data.
Now that you’ve sent a message, let’s shift to the other side of the conversation and see how to retrieve the message.
As you’ll recall, Spring’s JMS support offers two ways to fetch a message from a queue: synchronously via JmsTemplate and asynchronously with message-driven POJOs.
Spring AMQP offers similar options for retrieving messages sent over AMQP.
Because you already have a RabbitTemplate handy, let’s first look at how to use it to synchronously fetch a message from a queue.
The simplest ones are the receive() methods, which are the consumer-side analogues to RabbitTemplate’s send() methods.
Using the receive() methods, you can fetch a Message object from the queue:
Or, if you prefer, you can configure a default queue for receiving messages by setting the queue attribute when configuring the template:
This enables you to call the receive() method without any arguments to receive from the default queue:
Once you have a Message object, you’ll probably need to convert the array of bytes in its body property to whatever object you want.
Just as it was tricky to convert domain objects into Messages for sending, it’s messy to convert received Messages to domain objects.
Or you can leave the queue name out of the call parameters to fall back on the template’s default queue name:
That leaves it up to you to manage any polling and threading necessary to monitor the queue.
Instead of synchronously polling and waiting for messages to arrive, Spring AMQP offers message-driven POJO support that’s reminiscent of the same feature in Spring JMS.
Let’s see how to consume messages with message-driven AMQP POJOs.
You can get away with reusing the same POJO because nothing about it is dependent on JMS or AMQP.
It’s just a POJO and is ready to process a Spittle regardless of what messaging mechanism it’s carried over.
But again, you already did this when you were working with JMS-based MDPs.
You did this for JMS-based MDPs, but there is a slight difference in the configuration for AMQP-based MDPs:
Do you see the difference? I’ll agree that it’s not obvious.
These elements, however, come from the rabbit namespace instead of the JMS namespace.
In case you’re wondering, yes: the queue-names attribute name indicates plurality.
Here you only specify a single queue to listen on, but you can list as many queue names as you want, separated with commas.
Another way of specifying the queues to listen on is to reference the queue beans you declared with the <queue> element.
Again, this attribute can take a comma-separated list of queue IDs.
This, of course, requires that you declare the queues with IDs.
For example, here’s the alert queue redeclared, this time with an ID:
Note that the id attribute is used to assign a bean ID for the queue in the Spring application context.
The name attribute specifies the queue’s name in the RabbitMQ broker.
Indirect communication results in applications that are loosely coupled with respect to one another and thus reduces the impact of any one system going down.
Additionally, because messages are forwarded to their recipients, there’s no need for a sender to wait for a response.
In many circumstances, this can be a boost to application performance and scalability.
Although JMS provides a standard API for all Java applications wishing to participate in asynchronous communication, it can be cumbersome to use.
Spring eliminates the need for JMS boilerplate code and exception-handling code and makes asynchronous messaging easier to use.
In this chapter, you’ve seen several ways that Spring can help establish asynchronous communication between two applications by way of message brokers and JMS.
Spring’s JMS template eliminates the boilerplate that’s commonly required by the traditional JMS programming model.
And Spring-enabled message-driven beans make it possible to declare bean methods that react to messages that arrive in a queue or topic.
We also looked at using Spring’s JMS invoker to provide message-based RPC with Spring beans.
You’ve seen how to use asynchronous communication between applications in this chapter.
Coming up in the next chapter, we’ll continue this theme by looking at how to enable asynchronous communication between a browser-based client and a server using WebSocket.
In the previous chapter, you saw ways to send messages between applications using JMS and AMQP.
Asynchronous messaging is a common form of communication between applications.
But when one of those applications is running in a web browser, something a little different is needed.
WebSocket is a protocol providing full-duplex communication across a single socket.
It enables, among other things, asynchronous messaging between a web browser and a server.
Being full-duplex means that the server can send messages to the browser as well as the browser sending messages to the server.
SockJS support to cope with the lack of WebSocket support in browsers, servers, and proxies.
In this chapter, you’ll learn how to achieve asynchronous communication between a server and a browser-based application using Spring’s WebSocket features.
We’ll start by looking at how to work with Spring’s low-level WebSocket API.
In its simplest form, a WebSocket is just a communication channel between two applications.
An application on one end of the WebSocket sends a message, and the other end handles that message.
Because it’s full-duplex, either end can send messages and either end can handle messages.
WebSocket communication can be used between any kinds of applications, but the most common use of WebSocket is to facilitate communication between a server and a browser-based application.
A JavaScript client in the browser opens a connection to the server, and the server sends updates to the browser on that connection.
This is generally more efficient and more natural than the historically common alternative of polling the server for updates.
To demonstrate Spring’s low-level WebSocket API, let’s write a simple WebSocket example where a JavaScript-based client plays a never-ending game of Marco Polo with the server.
To handle messages in Spring with low-level WebSocket support, you must write a class that implements WebSocketHandler:
As you can see, the WebSocketHandler interface requires that you implement five methods.
Figure 18.1 A WebSocket is a full-duplex communication channel between two applications.
Instead, it leaves it up to you to decide which methods you want to override.
These three methods are merely specializations of the handleMessage() method, each tuned to a specific kind of message.
When a text message comes in, that message is logged and, after a simulated 2-second delay, another text message is sent back on the same connection.
This means that MarcoHandler will also handle binary and pong messages, but will do nothing with those messages.
Listing 18.1 MarcoHandler handles text messages sent via a WebSocket.
Regardless of whether you handle text messages, binary messages, or both, you might also be interested in handling the establishment and closing of connections.
In this example, the connection events are only logged, but these methods could be useful for setup and teardown of any resources used during the life of the connection.
Notice that these methods both start with the word “after.” That means that these methods are only able to react to those events after the event occurs and can’t change the outcome.
Now that you have a message handler class, you must configure it so that Spring will dispatch messages to it.
Listing 18.2 Enabling WebSocket and mapping a message handler in Java configuration.
In this case, you register the MarcoHandler (declared as a bean) and associate it with the /marco path.
Alternatively, if you’d rather configure Spring in XML, you can take advantage of the websocket namespace, as follows.
Whether you use Java or XML configuration, that’s the only configuration you’ll need.
Now we can turn our attention to the client that will send a “Marco!” text message.
The following listing shows some JavaScript that opens a native WebSocket and uses it to volley messages to the server.
Listing 18.3 The websocket namespace enables XML configuration for WebSockets.
The first thing that the code in listing 18.4 does is create an instance of WebSocket.
By creating a WebSocket instance, it effectively opens the WebSocket to the URL it’s given.
In this case, the URL is prefixed with “ws://”, indicating a basic WebSocket connection.
If it were a secure WebSocket connection, the protocol prefix would have been “wss://”
Once the WebSocket instance is created, the next several lines set up the WebSocket with event-handling functions.
The onopen event is given a function that calls sayMarco() to send the “Marco!” message on the WebSocket.
When the client receives the message from the server, the onmessage event will result in another “Marco!” message being sent to the server.
And it goes on and on like that until the connection is closed.
It’s not shown in listing 18.4, but a call to sock.close() will put an end to the madness.
The server could also close the connection, or the browser could navigate away from the page, and the connection will be closed.
In any case, once the connection goes down, the onclose event will be fired.
Here, that occasion will be marked with a simple message to the console log.
At this point, you’ve written everything that goes into enabling Spring’s low-level WebSocket support, including a handler class that receives and sends messages and a simple JavaScript client to do the same in the browser.
If you were to build the code and deploy it to a servlet container, it might even work.
Did you sense some pessimism in my choice of the word “might”? That’s because I can’t guarantee that it will work.
In fact, there’s a really good chance that it won’t work.
Even if we do everything correctly, the odds are stacked against us.
Let’s look at what will prevent WebSocket code from working and take steps to improve our chances.
Even though it was standardized by the end of 2011, it still doesn’t have consistent support in web browsers and application servers.
Firefox and Chrome have had full support for WebSocket for quite a while, but other browsers have only recently started to support WebSocket.
Here’s a brief list of the minimum versions of several popular browsers that support WebSocket:
Unfortunately, many web surfers don’t recognize or understand the features of new web browsers and are slow to upgrade.
Moreover, many corporations standardize on a specific version of a browser, making it hard (or impossible) for their employees to use anything newer.
Given those circumstances, it’s very likely that your application’s audience will not be able to use your application if it employs WebSocket.
It’s the same song, second verse, when it comes to server-side support for WebSocket.
GlassFish has had some form of WebSocket support for a couple of years, but many other application servers have only just started supporting WebSocket in their most recent versions.
For example, I had to test the previous example using a release candidate build of Tomcat 8
Even if the browser and application server versions align and WebSocket is supported on both ends, there might be trouble in the middle.
They’re not capable or not configured (yet) to allow WebSocket communication.
I realize that I’ve painted a rather bleak picture of the current WebSocket landscape.
But don’t let a little thing like lack of support stop you from trying to use WebSocket.
When it doesn’t, all you need is a fallback plan.
SockJS is a WebSocket emulator that mirrors the WebSocket API as closely as possible on the surface, but under the covers is clever enough to choose another form of communication when WebSocket isn’t available.
SockJS will always favor WebSocket first, but if WebSocket isn’t an option, it will determine the best available option from the following:
The good news is that you don’t need to fully understand all of those options to be able to use SockJS.
SockJS lets you develop to a consistent programming model as if WebSocket support were ubiquitous, and it handles the fallback plans under the covers.
For example, to enable SockJS communication on the server side, you can simply ask for it in the Spring configuration.
To use SockJS on the client, you’ll need to be sure to load the SockJS client library.
The exact way you do that depends largely on whether you’re using a JavaScript module loader (such as require.js or curl.js) or are simply loading your JavaScript libraries with a <script> tag.
The simplest way to load the SockJS client library is to load it from the SockJS CDN with a <script> tag like this:
Aside from loading the SockJS client library, there are only two lines from listing 18.4 that must be changed to use SockJS:
The first change you can make is to the URL.
SockJS deals in URLs with the http:// or https:// scheme instead of ws:// and wss://
Even so, you can use relative URLs, keeping you from having to derive the fully qualified URL.
The key change you must make, however, is to create an instance of SockJS instead of WebSocket.
Because SockJS mimics WebSocket as closely as possible, the rest of the code from listing 18.4 can remain the same.
The same onopen, onmessage, and onclose event-handler functions will still respond to their respective events.
And the same send() function will still send “Marco!” to the server.
You didn’t change too many lines of code, and yet you’ve made a huge difference in how the client-server messaging works.
You can be reasonably confident that WebSocket-like communication will work between the browser and the server, even if WebSocket isn’t supported by the browser, server, or any proxy that sits in the middle.
WebSocket enables browser-server communication, and SockJS offers fallback communication when WebSocket isn’t supported.
But in either case, this form of communication is too low-level for practical use.
Let’s see how you can layer STOMP (Simple Text Oriented Messaging Protocol) on top of WebSocket to add proper messaging semantics to browser-server communication.
If I were to suggest that you write a web application, you’d probably already have a good idea of the base technologies and frameworks you might use, even before we discussed requirements.
Even for a simple Hello World web application, you might be thinking of writing a Spring MVC controller to handle a request and a JSP or Thymeleaf template for the response.
At the very least, you might create a static HTML page and let the web server deal with serving it to any web browser that requests it.
Now let’s suppose I suggested we pretend that HTTP doesn’t exist and that you write a web application using nothing but TCP sockets.
Certainly, it would be possible to pull off this feat, but you’d need to devise your own wire protocol that both the client and server could agree upon to facilitate effective communication.
Thankfully, the HTTP protocol addresses the minute details of how a web browser makes a request and how a web server responds to that request.
As a result, most developers never write code that deals with low-level TCP socket communication.
Working directly with WebSocket (or SockJS) is a lot like developing a web application using only TCP sockets.
Without a higher-level wire protocol, it’s up to you to define the semantics of the messages being sent between applications.
And you’d need to be sure that both ends of the connection agreed on those semantics.
Fortunately, you don’t have to work with raw WebSocket connections.
Just as HTTP layers a request-response model on top of TCP sockets, STOMP layers a frame-based wire format to define messaging semantics on top of WebSocket.
At a quick glance, STOMP message frames look very similar in structure to HTTP requests.
Much like HTTP requests and responses, STOMP frames are comprised of a command, one or more headers, and a payload.
In this simple example, the STOMP command is SEND, indicating that something is being sent.
It’s followed by two headers: one indicates the destination where the message should be sent, and the other communicates the size of the payload.
Following a blank line, the frame concludes with the payload; in this case, a JSON message.
The destination header is probably the most interesting thing about the STOMP frame.
It’s a clue that STOMP is a messaging protocol, very much like JMS or AMQP.
Messages are published to destinations that may, in fact, be backed by real message brokers.
On the other end, message handlers can listen to those destinations to receive the messages sent.
In the context of WebSocket communication, a browser-based JavaScript application may publish a message to a destination that’s handled by a server-side component.
A server-side component may publish a message to a destination to be received by the JavaScript client.
Spring provides for STOMP-based messaging with a programming model based on Spring MVC.
As you’ll see, handling STOMP messages in a Spring MVC controller isn’t much different from handling HTTP requests.
But first, you must configure Spring to enable STOMP-based messaging.
Spring’s web messaging is built around a message broker, so there’s more to configure than just telling Spring that you’d like to handle messages.
You must also configure a message broker and some basic destination details.
The following listing shows the basic Java configuration required to enable brokerbased web messaging.
This indicates that this configuration class is not only configuring WebSocket, but it’s configuring broker-based STOMP messaging.
This path is distinct from any destination path that you might send or receive messages from.
It’s the endpoint that a client would connect to before subscribing to or publishing to a destination path.
If you don’t override it, you’ll get a simple in-memory message broker configured to handle messages prefixed with /topic.
But in this example, you override it so that the message broker is.
In addition, any messages destined for the application will be prefixed with /app.
When a message arrives, the destination prefix will determine how the message is handled.
In figure 18.2 the application destinations are prefixed with /app and the broker destinations are prefixed with either /topic or /queue.
Although it mimics a STOMP message broker, it only supports a subset of STOMP commands.
And because it’s memory-based, it’s not suitable for clusters where each node would be managing its own broker and set of messages.
For a production application, you’ll probably want to back your WebSocket messaging with a real STOMP-enabled broker, such as RabbitMQ or ActiveMQ.
Such brokers will offer more scalable and robust messaging, not to mention the complete set of STOMP commands.
You’ll need to be sure to set up your broker for STOMP according to their documentation.
Depending on which STOMP broker you choose, you may be limited in your choices for the destination prefix.
RabbitMQ, for instance, only allows destinations of type /temp-queue, /exchange, /topic, /queue, /amq/queue, and /replyqueue/
Consult your broker’s documentation for supported destination types and their purposes.
Any messages whose destination begins with /app will be routed to an @MessageMapping method and not published to a broker queue or topic.
Figure 18.3 illustrates how the broker relay fits into Spring’s STOMP message handling.
As you can see, the key difference is that rather than mimicking a STOMP broker’s functionality, the broker relay hands messages off to a real message broker for handling.
If your STOMP broker is on another server or is configured with different client credentials, you can configure those details when enabling the STOMP broker relay:
Figure 18.3 The STOMP broker relay delegates to a real message broker for handling STOMP messages.
This bit of configuration adjusts the server, port, and credentials.
For instance, if you only need to change the relay host, you can call setRelayHost() and leave out the other setter methods in the configuration.
Now Spring is configured and ready to handle STOMP messages.
RequestMapping, the star annotation in Spring MVC, maps HTTP requests to methods that will process those requests.
That same programming model extends to serving RESTful resources as you saw in chapter 16
Nevertheless, Spring offers a programming model that’s very similar to Spring MVC for handling STOMP messages.
A method annotated with @MessageMapping can handle messages as they arrive at a specified destination.
For example, consider the simple controller class in the following listing.
At first glance, this looks like any other Spring MVC controller class.
It’s annotated with @Controller, so it will be picked up and registered as a bean by componentscanning.
And it has a handler method, just like any @Controller class would have.
But the handler method is a little different than those we’ve looked at before.
This signifies that handleShout() should handle any messages that arrive at the specified destination.
In this case, the destination is /app/marco (the "/app" prefix is implied as it is the prefix we configured as the application destination prefix)
Because handleShout() accepts a Shout parameter, the payload of the STOMP message will be converted into a Shout using one of Spring’s message converters.
The Shout class is just a simple one-property JavaBean that carries a message:
Instead, Spring 4.0 offers only a few message converters as part of its messaging API.
Table 18.1 describes the message converters that might come into play when handling STOMP messages.
Table 18.1 Spring can convert message payloads to Java types using one of a few message converters.
By default, Jackson will use reflection to map JSON properties to Java object properties.
Although it’s unnecessary in this example, you can influence how the conversion takes place by annotating the Java type with Jackson annotations.
This may seem odd, knowing that outgoing messages tend to go to broker destinations prefixed with /topic or /queue.
Clients subscribe to those destinations and probably won’t subscribe to destinations prefixed with /app.
If the clients are subscribing to /topic and /queue destinations, there’s no way that an @SubscribeMapping method can handle those subscriptions.
The primary use case for @SubscribeMapping is to implement a request-reply pattern.
In the request-reply pattern, the client subscribes to a destination expecting a one-time response at that destination.
The Shout object is then converted into a message and sent back to the client at the same destination to which the client subscribed.
If you’re thinking that this request-reply pattern isn’t much different than an HTTP GET request-response pattern, then you’re mostly correct.
The key difference, however, is that where an HTTP GET request is synchronous, a subscription request-reply is asynchronous, allowing the client to deal with the reply whenever it’s available and not have to wait for it.
Now all you need is a client to send those messages.
The following listing shows some JavaScript client code that might connect to the /marcopolo endpoint and send a “Marco!” message.
As with our previous JavaScript client example, this one starts by creating an instance of SockJS for a given URL.
The URL in this case references the STOMP endpoint configured in listing 18.5 (not including the application’s context path, /stomp)
What’s different here, however, is that you never use SockJS directly.
Instead you construct an instance of the STOMP client by calling Stomp.over(sock)
This effectively wraps SockJS to send STOMP messages over the WebSocket connection.
Next, you use the STOMP client to connect to and, assuming that the connection succeeds, send a message with a JSON payload to the destination named /marco.
The second parameter passed to send() is a map of headers to be included in the STOMP frame; although in this case you’re not contributing any headers and the map is empty.
Now you have a client that sends a message to the server, and a handler method on the server ready to process it.
But you may have noticed that it’s a bit one-sided.
Let’s give the server a voice and see how to send messages to the client.
So far, the client is doing all of the message sending and the server is forced to listen for those messages.
While that’s a valid use of WebSocket and STOMP, it’s not the use case that you probably think of when you think of WebSocket.
WebSocket is often viewed as a way that a server can send data to the browser without being in response to an HTTP request.
How can you communicate with the browser-based client using Spring and WebSocket/STOMP?
Spring offers two ways to send data to a client:
You already know about some methods to handle messages and subscriptions, so we’ll first look at how to send messages to the client as a side-effect of those methods.
Listing 18.7 Messages can be sent from JavaScript using the STOMP library.
Its job is to simply handle a message, not reply to the client.
Even so, if you want to send a message in response to receiving a message, all you need to do is return something other than void.
In this new version of handleShout(), a new Shout object is returned.
By simply returning an object, a handler method can also be a sender method.
By default, the frame will be published to the same destination that triggered the handler method, but with /topic as the prefix.
In the case of handleShout(), that means that the returned Shout object will be written to the payload of a STOMP frame and published to the /topic/marco destination.
But you can override the destination by annotating the method with @SendTo:
With this @SendTo annotation in place, the message will be published to /topic/shout.
Any application that’s subscribed to that topic (such as the client), will receive that message.
The handleShout() method now sends a message in response to having received a message.
For example, you could send a Shout message when the client subscribes by adding this method to the controller:
The Shout object it returns will be converted and sent back to the client.
What’s different with @SubscribeMapping is that the Shout message is sent directly to the client without going through the broker.
If you annotate the method with @SendTo, the message will be sent to the destination specified, going through the broker.
To put this into practice, let’s revisit the Spittr application’s home page to offer a live Spittle feed.
As it is currently written, the controller handling the home page request fetches the most recent list of Spittles and places them into the model to be rendered into the user’s browser.
Although this works fine, it doesn’t offer a live feed of Spittle updates.
If the user wants to see an updated Spittle feed, they’ll have to refresh the page in their browser.
Rather than force the user to refresh the page, you can have the home page subscribe to a STOMP topic to receive a live feed of Spittle updates as they’re created.
Within the home page, you need to add the following JavaScript chunk:
As in previous examples, you’re creating an instance of SockJS and then an instance of Stomp over that SockJS instance.
After connecting to the STOMP broker, you subscribe to /topic/spittlefeed and designate the handleSpittle() function to handle the Spittle updates as they arrive.
The handleSpittle() function parses the incoming message’s body into a proper JavaScript object and then uses the Handlebars library to render the Spittle data into HTML prepended to the list.
The Handlebars template is defined in a separate <script> tag as follows:
Therefore, there’s no need to create a new instance here.
The broadcastSpittle() method is where the Spittle message is sent.
Spittle into a message and send it to the /topic/spittlefeed topic.
If the convertAndSend() method seems familiar, that’s because it mimics the methods of the same name offered by both JmsTemplate and RabbitTemplate.
When you publish a message to a STOMP topic with convertAndSend() or as a result of a handler method, any client subscribed to that topic will receive the message.
For a situation where you want to keep all clients up to date with a live Spittle feed, that’s perfect.
But sometimes you might want to send a message to a specific user and not to all clients.
Up to this point, the messages you’ve sent and received were between a client (in a web browser) and the server.
The user of that client hasn’t been taken into account.
Similarly, if you don’t know who the user is, then any messages sent will go to all clients that have subscribed to the topic that the message is carried on; there’s no way to send that message to a specific user.
If you know who the user is, however, it becomes possible to deal with messages associated with a user, not just those associated with a client.
The good news is that you already know how to identify the user.
Using the same authentication mechanism applied in chapter 9, you can use Spring Security to authenticate the user and work with user-targeted messages.
There are three ways to take advantage of an authenticated user when messaging with Spring and STOMP:
Let’s start by looking at the first two ways, both of which enable a controller’s messagehandling methods to work with user messages.
By simply asking for a Principal as a parameter to a handler method, the handler method can know who the user is and use that information to focus its work on that user’s data.
In addition, a handler method can be annotated with @SendToUser to indicate that its return value should be sent in a message to the authenticated user’s client (and to that client only)
To demonstrate, let’s write a controller method that creates a new Spittle object from an incoming message and sends a reply indicating that the Spittle has been.
If this use-case sounds familiar, it’s because you already implemented this as a REST endpoint in chapter 16
But REST requests are synchronous by nature, and the client must wait while the server processes them.
By posting the Spittle as a STOMP message, you can take full advantage of the asynchronous nature of STOMP messaging.
Consider the following handleSpittle() method, which handles an incoming message and saves it as a Spittle:
As you can see, handleSpittle() accepts both a Principal object as well as a SpittleForm object.
It uses those to create an instance of Spittle and then uses the SpittleRepository to save it.
Finally, it returns a new Notification indicating that the Spittle was saved.
Of course, what happens inside the method isn’t nearly as interesting as what’s going on outside.
Because this method is annotated with @MessageMapping, it will be invoked whenever a message arrives on the /app/spittle destination.
The SpittleForm will be created from that message and, assuming that the user is authenticated, the Principal will also be derived from headers in the STOMP frame.
The big thing to pay attention to, however, is where the returned Notification goes.
On the surface, /queue/ notifications doesn’t appear to be specific to a given user.
To understand how Spring will publish the message, let’s step back a bit and see how a client would subscribe to the destination that this controller method publishes a Notification to.
Consider this line of JavaScript that subscribes to a user-specific destination:
Internally, destinations that are prefixed with /user are handled in a special way.
In the case of a subscription, it derives the target destination by removing the /user prefix and adding a suffix that’s based on the user’s session.
As it turns out, the client subscribed to that destination, so the client will receive the Notification message.
The @SendToUser annotation and a Principal parameter are very useful when working within a controller method.
But in listing 18.8 you saw how to send messages from anywhere in an application using a messaging template.
To demonstrate, let’s add a feature to the Spittr application that notifies a user when some other user posts a Spittle that mentions them.
When handling a message, something could go wrong and an exception could be thrown.
Due to the asynchronous nature of STOMP messaging, the sender may never know that anything went wrong.
Aside from being logged by Spring, the exception could be lost with no recourse or opportunity to recover.
In Spring MVC, if an exception occurs during request handling, an @ExceptionHandler method will be given an opportunity to deal with the exception.
For example, consider this method that handles exceptions thrown from messagehandling methods:
But you can declare a specific exception type that it should handle as a parameter:
Or you can specify several exception types to be handled as an array parameter:
Although it only logs that an error occurred, this method could do much more.
Here, if a SpittleException is thrown, that exception will be logged and then returned.
WebSocket is an exciting way to send messages between applications, especially when one of those applications is running within a web browser.
It’s critical for writing highly interactive web applications that seamlessly transfer data to and from the server.
Spring’s WebSocket support includes a low-level API that lets you work with raw WebSocket connections.
Unfortunately, WebSocket support is not ubiquitous among web browsers, servers, and proxies.
Therefore, Spring also supports SockJS, a protocol that falls back to alternative communication schemes when WebSocket doesn’t work.
Spring also offers a higher-level programming model for handling WebSocket messages using the STOMP wire-level protocol.
In this higher-level model, STOMP messages are handled in Spring MVC controllers, similarly to how HTTP messages are handled.
In the past couple of chapters, you’ve seen a few ways to send messages asynchronously between applications.
But there’s another kind of asynchronous messaging that Spring can do.
In the next chapter, you’ll see how to use Spring to send emails.
It’s no secret that email has become a common form of communication, displacing many traditional means of communication such as postal mail, telephone calls, and, to some degree, face-to-face communication.
Email offers many of the same asynchronous benefits as the messaging options we discussed in chapter 17, only with humans as the senders and receivers.
As soon as you click Send in your email client, you can move on to some other task, knowing that the recipient will eventually receive and (hopefully) read your email.
Perhaps it’s an email confirmation of an order that a user placed on an eCommerce site, or maybe it’s an automated notification of an activity involving someone’s bank account.
Whatever the subject, it’s likely that you’ll develop applications that need to send email messages.
In chapter 17, you used Spring’s messaging support to asynchronously queue up jobs to send spittle alerts to other Spittr application users.
But you left that task unfinished, because no email messages were sent.
Let’s finish what you started by looking at how Spring abstracts the problem of sending email, and then use that abstraction to send spittle alert email messages.
At the heart of Spring’s email abstraction is the MailSender interface.
As its name implies, and as illustrated in figure 19.1, a MailSender implementation sends email by connecting with an email server.
Before you can send email messages from your Spring application, you must wire JavaMailSenderImpl as a bean in the Spring application context.
In its simplest form, JavaMailSenderImpl can be configured as a bean with only a few lines in an @Bean method:
The host property is optional (it defaults to the host of the underlying JavaMail session), but you’ll probably want to set it.
It specifies the hostname for the mail server that will be used to send the email.
Here it’s configured by fetching the value from the injected Environment so that you can manage the mail-server configuration outside of Spring (for example, in a properties file)
By default, JavaMailSenderImpl assumes that the mail server is listening on port 25 (the standard SMTP port)
If your mail server is listening on a different port, specify the correct port number using the port property.
Figure 19.1 Spring’s MailSender interface is the primary component of Spring’s email abstraction API.
Likewise, if the mail server requires authentication, you’ll want to set values for the username and password properties:
Thus far, JavaMailSenderImpl has been configured to create its own mail session.
If so, it doesn’t make much sense to configure JavaMailSenderImpl with the full server details.
Instead, you can configure it to use the MailSession you have ready to use from JNDI.
You’ve also seen how to retrieve objects from JNDI using Spring’s <jee:jndi-lookup> element.
You can use <jee:jndi-lookup> to create a bean that references a mail session in JNDI:
With the mail session bean configured, you can now wire it into the mailSender bean like this:
Now the mail session is completely configured and managed in JNDI.
JavaMailSenderImpl can focus on sending email messages and not worry about the details of how to connect with the mail server.
With the mail sender configured, it’s time to wire it into the bean that will use it.
This class has a mailSender property that’s annotated with @Autowired:
With the mailSender bean wired in, you’re ready to construct and send email messages.
Because you want to send email to a Spitter user to alert them about new spittles that their friends may have written, you’ll need a method that, given an email address and a Spittle object, will send that email message.
This mail-message object, as its name implies, is perfect for sending no-nonsense email messages.
The sender and recipient are specified via the setFrom() and setTo() methods on the email message.
After you set the subject with setSubject(), the virtual “envelope” has been addressed.
All that’s left is to call setText() to set the message’s content.
The last step is to pass the message to the mail sender’s send() method, and the email is on its way.
Now you’ve configured a mail sender and used it to send a simple email message.
And as you’ve seen, working with Spring’s email abstraction is easy.
We could call it good at this point and move on to the next chapter.
But then you’d miss out on the fun stuff in Spring’s email abstraction.
Let’s kick it up a notch and see how to add attachments and create rich email messages.
Plaintext email messages are fine for simple things like asking your friends over to watch the big game.
But they’re less than ideal when you need to send photos or documents.
And they’re ineffective for capturing the recipient’s attention, as in marketing email.
You have the option of adding attachments and even dressing up the body of the message with HTML.
Then you’ll go a step further and make your email messages look good with HTML.
The trick to sending email with attachments is to create multipart messages—email messages composed of multiple parts, one of which is the body and the other parts being the attachments.
To send multipart email messages, you need to create a Multipurpose Internet Mail Extensions (MIME) message.
It seems that all you need to do is give it To and From addresses, a subject, some text, and an attachment.
Although that’s true, it’s not as straightforward as you might think.
To use MimeMessageHelper, instantiate an instance of it, passing in the MimeMessage to its constructor:
The second parameter to the constructor, a Boolean true as shown here, indicates that this is to be a multipart message.
From the MimeMessageHelper instance, you’re ready to assemble your email message.
The only major difference is that you’ll provide the email specifics through methods on the helper instead of on the message itself:
The only thing needed before you can send the message is to add the attachment: in this case, a coupon image.
To do that, you’ll need to load the image as a resource and then pass that resource in as you call the helper’s addAttachment() method:
Here, you’re using Spring’s FileSystemResource to load coupon.png from within the application’s classpath.
The first parameter is the name to be given to the attachment in the message.
The multipart email message has been constructed, and you’re ready to send it.
Adding attachments is only one thing you can do with multipart email messages.
In addition, by specifying that the body of the message is HTML, you can produce polished email messages that look much nicer than flat text.
Let’s see how to send attractive-looking email using Spring’s MimeMessageHelper.
Sending rich email isn’t much different than sending plaintext email messages.
The key is to set the message’s text as HTML.
Doing that is as simple as passing in an HTML string to the helper’s setText() method and true as the second parameter:
The second parameter indicates that the text passed in to the first parameter is HTML, so that the message part’s content type will be set accordingly.
Note that the HTML passed in has an <img> tag to display the Spittr application’s logo as part of the message.
The src attribute could be set to a standard http: URL to pull the Spittr logo from the web.
But here, you embed the logo image in the email message.
The value cid:spitterLogo indicates that there will be an image in one of the message’s parts identified as spitterLogo.
Adding the embedded image to the message is much like adding an attachment.
Instead of calling the helper’s addAttachment() method, you call the addInline() method:
The second parameter is the resource reference for the image, created here using Spring’s ClassPathResource to retrieve the image from the application’s classpath.
Aside from the slightly different call to setText() and the use of the addInline() method, sending email with rich content is much like sending a plaintext message with attachments.
And now you’re sending email messages with rich content and embedded images! You could stop here and call your email code complete.
But it bugs me that the email’s body is created by using string concatenation to construct an HTML message.
The problem with constructing an email message using string concatenation is that it’s not clear what the resulting message will look like.
It’s hard enough to mentally parse HTML markup to imagine how it might appear when rendered.
But mixing up that HTML in Java code compounds the issue.
Moreover, it might be nice to extract the email layout into a template that a graphic designer (who probably has an aversion to Java code) can produce.
What you need is a way to express the email layout in something close to what the resulting HTML will look like, and then transform that template into a String to be passed into the setText() method on the message helper.
When it comes to transforming templates into strings, there are several templating options to choose from, including Apache Velocity and Thymeleaf.
Let’s look at how to create rich email messages using each of these options, starting with Velocity.
Velocity has been around for quite a while and has been used for all kinds of things, including code generation and as an alternative to JSP.
It can also be used to format rich email messages, as you’ll do here.
In this case, you’re configuring it to load Velocity templates from the classpath (see the Velocity documentation for more details on how to configure Velocity)
Next, you can use the velocityEngine property to transform a Velocity template into a String to send as your email text.
In preparation for processing the template, you start by creating a Map to hold the model data used by the template.
All that’s left to be done in the Java code is to hand off the merged email text to the message helper’s setText() method:
Figure 19.2 gives a sample of the kind of email message it might produce.
Looking at the figure, I see a lot of opportunity to dress up the template so the message looks much nicer.
But, as they say, I’ll leave that as an exercise for the reader.
Figure 19.2 A Velocity template and some embedded images can dress up an otherwise ho-hum email message.
Velocity has been used for years as the templating engine of choice for many tasks.
But as you saw in chapter 6, a new templating option is becoming popular.
Let’s see how you can use Thymeleaf to construct spittle email messages.
As we discussed in chapter 6, Thymeleaf is an attractive templating engine for HTML because it enables you to create WYSIWYG templates.
Unlike JSP and Velocity, Thymeleaf templates don’t contain any special tag libraries or unusual markup.
This makes it easy for template designers to use any HTML tools they like in their work without worrying about a tool’s inability to deal with special markup.
When you convert an email template to a Thymeleaf template, the WYSIWYG nature of Thymeleaf is apparent:
Using Thymeleaf to generate and send HTML email messages is similar to what you did with Velocity:
The first thing to do is create a Thymeleaf Context instance and populate it with model data.
This is analogous to populating a Map with model data, as you did with Velocity.
Then you ask Thymeleaf to process your template, merging the model data in the context into the template by calling the process() method on the Thymeleaf engine.
Finally, you set the resulting text on the message using the message helper and send the message using the mail sender.
But where does the Thymeleaf engine (represented by the thymeleaf variable) come from?
As you left it in chapter 6, it’s only configured to resolve templates from the servlet context.
Your email templates will need to be resolved from the classpath.
Note, though, that the prefix property is set to mail/, indicating that it expects to find Thymeleaf templates in the mail directory rooted at the classpath root.
Also, because you’ll now have two template resolvers, you need to indicate which one takes precedence, using the order property.
But now you have two template resolvers, so you must inject them as members of a Set into the templateResolvers (plural) property.
Spring builds on the email capabilities provided in Java, abstracting JavaMail for simpler use and configuration in a Spring application.
In this chapter, you’ve seen how to use Spring’s email abstraction to send simple email messages, and you’ve taken it further by sending rich messages that contain attachments and that are formatted with HTML.
We also looked at using templating engines like Velocity and Thymeleaf to generate rich email text without resorting to creating HTML via string concatenation.
Coming up in the next chapter, you’ll see how to add management and notification capabilities to your Spring beans using Java Management Extensions (JMX)
Spring’s support for DI is a great way to configure bean properties in an application.
But once the application has been deployed and is running, DI alone can’t do much to help you change that configuration.
Suppose you want to dig into a running application and change its configuration on the fly.
Originally available as a separate extension to Java, JMX is now a standard part of the Java 5 distribution.
The key component of an application that’s instrumented for management with JMX is the managed bean (MBean)
An MBean is a JavaBean that exposes certain methods that define the management interface.
Standard MBeans—MBeans whose management interface is determined by reflection on a fixed Java interface that’s implemented by the bean class.
Dynamic MBeans—MBeans whose management interface is determined at runtime by invoking methods of the DynamicMBean interface.
Because the management interface isn’t defined by a static interface, it can vary at runtime.
Open MBeans—A special kind of dynamic MBean whose attributes and operations are limited to primitive types, class wrappers for primitive types, and any type that can be decomposed into primitives or primitive wrappers.
Model MBeans—A special kind of dynamic MBean that bridges a management interface to the managed resource.
Model MBeans aren’t written as much as they are declared.
They’re typically produced by a factory that uses some metainformation to assemble the management interface.
Spring’s JMX module enables you to export Spring beans as model MBeans so that you can see inside your application and tweak the configuration—even while the application is running.
Let’s see how to JMX-enable your Spring application so that you can manage the beans in the Spring application context.
There are several ways you can use JMX to manage the beans in the Spittr application.
In the interest of keeping things simple, let’s start by making a modest change to SpittleController as it appeared in listing 5.10
Now, rather than commit to that decision at build time with a hard-coded value, you’re going to use JMX to leave the decision open to change at runtime.
The new spittlesPerPage property is the first step toward enabling that.
But on its own, the spittlesPerPage property can’t enable external configuration of the number of spittles displayed on the page.
It’s just a property on a bean, like any other property.
What you need to do next is expose the SpittleController bean as an MBean.
Then the spittlesPerPage property will be exposed as the MBean’s managed attribute, and you’ll be able to change its value at runtime.
Spring’s MBeanExporter is the key to JMX-ifying beans in Spring.
MBeanExporter is a bean that exports one or more Spring-managed beans as model MBeans in an.
An MBean server (sometimes called an MBean agent) is a container where MBeans live and through which the MBeans are accessed.
As illustrated in figure 20.1, exporting Spring beans as JMX MBeans makes it possible for a JMX-based management tool such as JConsole or VisualVM to peer inside a running application to view the beans’ properties and invoke their methods.
The following @Bean method declares an MBeanExporter in Spring to export the spittleController bean as a model MBean:
In its most straightforward form, MBeanExporter can be configured through its beans property by injecting a Map of one or more beans that you’d like to expose as model MBeans in JMX.
The value of entry is a reference to the Spring-managed bean that’s to be exported.
Here, you’re exporting the spittleController bean so that its properties can be managed at runtime through JMX.
Figure 20.1 Spring’s MBeanExporter exports the properties and methods of Spring beans as JMX attributes and operations in an MBean server.
From there, a JMX management tool such as JConsole can look inside the running application.
With the MBeanExporter in place, the spittleController bean is exported as a model MBean to the MBean server for management under the name SpittleController.
Figure 20.2 shows how the SpittleController MBean appears when viewed through JConsole.
As you can see on the left side of figure 20.2, all public members of the SpittleController are exported as MBean operations and attributes.
All you really want to do is configure the spittlesPerPage property.
You don’t need to invoke the spittles() method or muck about with any other part of SpittleController.
Thus, you need a way to select which attributes and operations are available.
To gain finer control over an MBean’s attributes and operations, Spring offers a few options, including the following:
Figure 20.2 SpittleController exported as an MBean and seen through the eyes of JConsole.
Let’s try each of these options to see which best suits the SpittleController MBean.
You’ll start by selecting the bean methods to expose by name.
An MBean info assembler is the key to constraining which operations and attributes are exported in an MBean.
This assembler is given a list of names of methods to export as MBean operations.
For the SpittleController bean, you want to export spittlesPerPage as a managed attribute.
Those are the methods that will be exposed as the MBean’s managed operations.
From whence the MBean server? As configured, MBeanExporter assumes that it’s running in an application server (such as Tomcat) or some other context that provides an MBean server.
But if your Spring application will be running standalone or in a container that doesn’t provide an MBean server, you’ll want to configure an MBean server in the Spring context.
Knowing this, you can wire it into MBeanExporter’s server property to specify which MBean server an MBean should be exposed through.
To put the assembler into action, you need to wire it into the MBeanExporter:
Figure 20.3 After specifying which methods are exported in the SpittleController MBean, the spittles() method is no longer a managed operation.
But can you imagine what would happen if you were to export several Spring beans as MBeans? After a while, the list of method names given to the assembler would be huge.
And there’s also a possibility that you may want to export a method from one bean while another bean has a same-named method that you don’t want to export.
Clearly, in terms of Spring configuration, the method-name approach doesn’t scale well when exporting multiple MBeans.
Let’s see if using interfaces to expose MBean operations and attributes is any better.
It’s similar to the method name–based assemblers, except that instead of listing method names to be exported, you list interfaces that define the methods to be exported.
Again, these accessor methods will indirectly export the spittlesPerPage property as a managed attribute.
To use this assembler, I just need to use the following assembler bean instead of the method name–based assemblers from before:
The interface is there for the sake of the exporter, but you don’t need to implement it directly in any of your code.
SpittleController probably should implement the interface, though, if for no other reason than to enforce a consistent contract between the MBean and the implementation class.
This goes a long way toward keeping the Spring configuration tidy even when exporting multiple MBeans.
Ultimately, those managed operations must be declared somewhere, whether in Spring configuration or in an interface.
Moreover, the declaration of the managed operations represents a duplication in code: method names declared in an interface or Spring context and method names in the implementation.
This duplication exists for no other reason than to satisfy the MBeanExporter.
One of the things that Java annotations are good at is helping to eliminate such duplication.
Let’s see how to annotate a Spring-managed bean so that it can be exported as an MBean.
I could show you how to use that assembler, but I won’t.
That’s because wiring it up manually is burdensome and not worth the trouble just to be able to use annotations.
This handy element wires up an MBean exporter and all the appropriate assemblers to turn on annotation-driven MBeans in Spring.
All you have to do is use it instead of the MBeanExporter bean that you’ve been using:
For example, the following listing shows how to alter SpittleController to be exported as an MBean using annotations.
The @ManagedResource annotation is applied at the class level to indicate that this bean should be exported as an MBean.
The accessor methods for the spittlesPerPage property are both annotated with @ManagedAttribute to indicate that it should be exposed as a managed attribute.
Note that it’s not strictly necessary to annotate both accessor methods.
This exposes those methods through JMX, but it doesn’t expose the spittlesPerPage property as a managed attribute.
That’s because methods annotated with @ManagedOperation are treated strictly as methods and not as JavaBean accessors when it comes to exposing MBean functionality.
So far you’ve seen how to publish an MBean into an MBean server using several approaches.
In all cases, you’ve given the MBean an object name that’s made up of a management domain name and a key-value pair.
Assuming that there’s not already an MBean published with the name you’ve given your MBean, you should have no trouble publishing your MBean.
There are three ways to handle an MBean name collision via the registrationPolicy property:
The registrationPolicy property accepts a value from the RegistrationPolicy enum representing one of the three collision-handling behaviors available.
Now that you’ve registered your MBeans using MBeanExporter, you need a way to access them for management.
As you’ve seen already, you can use tools like JConsole.
But a tool such as JConsole doesn’t lend itself to programmatic management of MBeans.
How can you manipulate MBeans in one application from within another application? Fortunately, there’s another way to access MBeans as remote objects.
Let’s explore how Spring’s support for remote MBeans enables you to access your MBeans in a standard way through a remote interface.
Although the original JMX specification referred to remote management of applications through MBeans, it didn’t define the actual remoting protocol or API.
Consequently, it fell to JMX vendors to define their own, often proprietary, remoting solutions for JMX.
This specification defines a standard for JMX remoting, which at a minimum requires an RMI binding and optionally the JMX Messaging Protocol (JMXMP)
In this section, you’ll see how Spring enables remote MBeans.
You’ll start by configuring Spring to export the SpittleController MBean as a remote MBean.
Then you’ll see how to use Spring to manipulate that MBean remotely.
But you’re not limited to exporting MBeans using only JMXMP.
Depending on the JMX implementation, you may have several remoting protocol options to choose from, including Remote Method Invocation (RMI), SOAP, Hessian/ Burlap, and even Internet InterORB Protocol (IIOP)
For example, if you want to use RMI for MBean remoting, you’d set serviceUrl like this:
That means you also need an RMI registry running and listening at that port.
As you’ll recall from chapter 15, RmiServiceExporter can start an RMI registry automatically for you.
And that’s it! Now your MBeans are available through RMI.
But there’s little point in doing this if nobody will ever access the MBeans over RMI.
Let’s turn our attention to the client side of JMX remoting and see how to wire up a remote MBean in the Spring context of a JMX client.
For example, say that you’d like to know how many MBeans are registered in the remote MBean server.
You can also query the remote server for the names of all the MBeans using the queryNames() method:
The two parameters passed to queryNames() are used to refine the results.
Passing in null for both parameters indicates that you’re asking for the names of all the registered MBeans.
Querying the remote MBean server for bean counts and names is fun, but doesn’t get much work done.
The real value of accessing an MBean server remotely is found in accessing attributes and invoking operations on the MBeans that are registered in the remote server.
For accessing MBean attributes, you’ll want to use the getAttribute() and setAttribute() methods.
For example, to retrieve the value of an MBean attribute, you’d call the getAttribute() method like so:
Similarly, you can change the value of an MBean attribute using the setAttribute() method:
If you’d like to invoke an MBean’s operation, the invoke() method is what you’re looking for.
This isn’t nearly as intuitive as a normal method invocation would be.
For a more direct approach, you need to proxy the remote MBean.
The objectName property specifies the object name of the remote MBean that’s to be proxied locally.
Here it’s referring to the SpittleController MBean that you exported earlier.
Finally, the proxyInterface property specifies the interface that will be implemented by the proxy.
The proxy’s client can then interact with the remote MBean as if it were a locally configured POJO.
You’ve seen several ways that you can communicate with MBeans, and you can now view and tweak your Spring bean configuration while the application is running.
You’ve talked to the MBeans, but the MBeans haven’t been able to get a word in edgewise.
It’s time for you to hear what they have to say by listening for notifications.
Querying an MBean for information is only one way of keeping an eye on the state of an application.
But it’s not the most efficient way to be informed of significant events within the application.
For example, suppose the Spittr application were to keep a count of how many spittles have been posted.
And suppose you want to know every time the count has increased by one million spittles (the one millionth spittle, the two millionth, the three millionth, and so on)
One way to handle this would be to write some code that periodically queried the database, counting the number of spittles.
But the process that performed that query would keep itself and the database busy as it constantly checked for the spittle count.
Instead of repeatedly querying the database to get that information, a better approach may be to have an MBean notify you when the momentous occasion takes place.
Any bean-turned-MBean that wishes to send notifications should implement this interface.
Figure 20.5 JMX notifications enable MBeans to communicate proactively with the outside world.
Let’s set up a notification listener to listen to and react to the notification.
With JMX, you can open a window into the inner workings of your application.
In this chapter, you saw how to configure Spring to automatically export Spring beans as JMX MBeans so that their details can be viewed and manipulated through JMX-ready management tools.
You also learned how to create and use remote MBeans for times when those MBeans and tools are distant from each other.
Finally, you saw how to use Spring to publish and listen for JMX notifications.
By now you’ve probably noticed that the number of remaining pages in this book is dwindling fast.
But before we conclude, we have one more quick stop to make.
In the next chapter, we’ll look at Spring Boot, an exciting new way to build Spring applications with little or no explicit configuration.
I recall the first few days of my first calculus course where we learned about derivatives of functions.
We performed some rather hairy computations using limits to arrive at the derivatives of several functions.
Even though the functions were simple, the work involved in calculating the derivatives was nightmarish.
After several homework assignments, study groups, and an exam, most everyone in the class was able to do the work.
Applying a simple formula made quick work of calculating derivatives (if you’ve ever taken calculus, you’ll know what.
With this newfound trick, we were able to compute derivatives for dozens of functions in the time it would’ve previously taken for a single function.
The instructor replied that the hard way helped us appreciate the derivatives for what they mean, told us it built character, and said something about putting hair on our chests.
Now that we’ve gone through an entire book on Spring, I find myself in the same position as that calculus instructor.
Although Spring’s chief benefit is to make Java development easy, this chapter will show you how Spring Boot can make it even easier.
Spring Boot is arguably the most exciting thing to happen to Spring since the Spring Framework was first created.
It layers a completely new development model on top of Spring, taking away much of the tedium of developing applications with Spring.
We’ll get started with an overview of the tricks that Spring Boot employs to simplify Spring.
Before this chapter concludes, you’ll have developed a complete (albeit simple) application using Spring Boot.
Spring Boot is an exciting (dare I say “game-changing”?) new project in the Spring family.
It offers four main features that will change the way you develop Spring applications:
Spring Boot starters—Spring Boot starters aggregate common groupings of dependencies into single dependencies that can be added to a project’s Maven or Gradle build.
Command-line interface (CLI)—Spring Boot’s CLI takes advantage of the Groovy programming language along with autoconfiguration to further simplify Spring application development.
Throughout this chapter, you’ll build a small application using all of these features of Spring Boot.
But first, let’s take a quick look at each to get a better feel for how they contribute to a simpler Spring programming model.
The ambitious baker will mix flour, eggs, sugar, baking powder, salt, butter, vanilla, and milk into a batter.
Or you can buy a prepackaged box of cake mix that includes most of the ingredients you’ll need and only mix in a few wet ingredients like water, eggs, and vegetable oil.
Much as a prepackaged cake mix aggregates many of the ingredients of a cake recipe into a single ingredient, Spring Boot starters aggregate the various dependencies of an application into a single dependency.
To illustrate, let’s suppose you’re starting a new Spring project from scratch.
This will be a web project, so you’ll need Spring MVC.
There will also be a REST API, exposing resources as JSON, so you’ll need the Jackson JSON library in your build.
Because your application will use JDBC to store and fetch data from a relational database, you’ll want to be sure to include Spring’s JDBC module (for JdbcTemplate) and Spring’s transaction module (for declarative transaction support)
As for the database itself, the H2 database will do fine.
And, oh yeah, you want to use Thymeleaf for Spring MVC views.
If you’re building your project with Gradle, you’ll need (at least) the following.
For the sake of brevity, I won’t bother showing you what this list of dependencies would look like in a Maven pom.xml file.) Even so, a lot of work went into creating this list, and more will go into maintaining it.
How can you know if these dependencies will play well together? As the application grows and evolves, dependency management will become even more challenging.
But if you’re using the prepackaged dependencies from Spring Boot starters, the Gradle dependency list can be a little shorter:
As you can see, Spring Boot’s web and JDBC starters replaced several of the finergrained dependencies.
You still need to include the H2 and Thymeleaf dependencies, but the other dependencies are rolled up into the starter dependencies.
Aside from making the dependency list shorter, you can feel confident that the versions of dependencies provided by the starters are compatible with each other.
The web and JDBC starters are just two of the starters that Spring Boot has to offer.
Table 21.1 lists all of the starters available at the time I was writing this chapter.
Table 21.1 Spring Boot starter dependencies aggregate commonly needed dependency groupings into single project dependencies.
Table 21.1 Spring Boot starter dependencies aggregate commonly needed dependency groupings into single project dependencies.
If you were to look under the covers of these starter dependencies, you’d realize that there’s not much mystery to how the starters work.
Taking advantage of Maven’s and Gradle’s transitive dependency resolution, the starters declare several dependencies in their own pom.xml file.
When you add one of these starter dependencies to your Maven or Gradle build, the starter’s dependencies are resolved transitively.
A single starter could transitively pull in dozens of other dependencies.
The mobile starter, for instance, references the web starter, which in turn references the Tomcat starter.
Table 21.1 Spring Boot starter dependencies aggregate commonly needed dependency groupings into single project dependencies.
Whereas Spring Boot starters cut down the size of your build’s dependency list, Spring Boot autoconfiguration cuts down on the amount of Spring configuration.
It does this by considering other factors in your application and making assumptions about what Spring configuration you’ll need.
With Spring Boot autoconfiguration, however, all you need to do is add Thymeleaf to the project’s classpath.
When Spring Boot detects that Thymeleaf is on the classpath, it will assume that you want to use Thymeleaf for Spring MVC views and will automatically configure those three beans.
For instance, all you need to do to use Spring MVC in your Spring Boot application is to add the web starter as a dependency in the build.
When you add the web starter to your project’s build, it will transitively pull in Spring MVC dependencies.
When Spring Boot’s web autoconfiguration detects Spring MVC in the classpath, it will automatically configure several beans to support Spring MVC, including view resolvers, resource handlers, and message converters (among others)
All that’s left for you to do is write the controller classes to handle the requests.
The Spring Boot CLI takes the magic provided by Spring Boot starters and autoconfiguration and spices it up a little with Groovy.
It reduces the Spring development process to the point where you can run one or more Groovy scripts through a CLI and see it run.
In the course of running the application, the CLI will also automatically import Spring types and resolve dependencies.
One of the most interesting examples used to illustrate Spring Boot CLI is contained in the following Groovy script:
Believe it or not, that is a complete (albeit simple) Spring application that can be executed through the Spring Boot CLI.
You can paste it into your Twitter client and tweet it to your friends.
Eliminate the unnecessary whitespace and you get this 64-character one-liner:
This version is so brief that you can paste it twice into a single tweet on Twitter.
But it’s still a complete and runnable (if feature-poor) Spring application.
If you have the Spring Boot CLI installed, you can run it with the following command line:
Although it’s fun to show off a tweetable example of Spring Boot CLI’s capabilities, there’s much more to it than meets the eye.
In section 21.3 we’ll look at how you can build a more complete application with Groovy and the CLI.
The Spring Boot Actuator brings a handful of useful features to a Spring Boot project, including.
All of these features are useful, but the management endpoints are the most immediately useful and interesting features of the Actuator.
In section 21.4 we’ll look at a few examples of how Spring Boot’s Actuator opens a window into the inner workings of your application.
Now that you’ve had a glimpse of each of the four main features of Spring Boot, let’s put them to work and build a small but complete application.
Throughout the rest of this chapter, I aim to show you how to build complete, realworld applications using Spring Boot.
Of course, the qualities that define a “realworld” application are subject to debate and would likely exceed the space and scope of this chapter.
Therefore, rather than build a real-world application here, we’ll scale it back a little and develop something a little less real-world, but representative of the kinds of bigger applications you might build with Spring Boot.
It will allow a user to enter contact information (name, phone number, email address) and to list all of the contacts that the user has previously entered.
You have the choice of building your application with either Maven or Gradle.
I prefer Gradle, but I’ll show you what’s needed for Maven in case that’s your preference.
The dependencies block is empty to start, but we’ll fill it in with dependencies along the way.
Notice that the build includes a buildscript dependency on the Spring Boot Gradle plugin.
As you’ll see later, this will help produce an executable uber-JAR file that contains all of the application’s dependencies.
Alternatively, if you prefer Maven, the following listing shows the complete pom.xml file.
Listing 21.1 The Gradle build file for the Contacts application.
Listing 21.2 The Maven build file for the Contacts application.
Similar to the Gradle build, this Maven pom.xml file makes use of the Spring Boot Maven plugin.
This plugin is the Maven counterpart to the Gradle plugin and enables the build to produce an executable uber-JAR file.
Also notice that unlike the Gradle build, this Maven build has a parent project.
By basing your project’s Maven build on the Spring Boot starter parent, you get the benefit of Maven dependency management, and you won’t have to explicitly declare version numbers for many of your project dependencies.
Following the standard project structure for Maven- and Gradle-based projects, the project will be structured like this when you’re finished:
Don’t worry about those missing Java files and other resource files.
You’ll create those over the next few sections as we develop the Contacts application.
In fact, we’ll start right now by developing the web layer of the application.
Since you’re going to develop the web layer of the application with Spring MVC, you’re going to need to add Spring MVC as a dependency in your build.
As we’ve already discussed, Spring Boot’s web starter is the one-stop-shop for adding everything needed for Spring MVC to a build.
If you’re using Maven to do the build, those dependencies will look like this:
Note that because the Spring Boot parent project specifies the version for the web starter dependency, there’s no need to explicitly specify it in the project’s build.gradle or pom.xml.
With the web starter dependency in place, all of the dependencies you’ll need to work with Spring MVC will be available to your project.
Now you’re ready to write a controller class for the application.
The controller will be relatively simple, presenting a contact form for an HTTP GET request and processing the form submission for a POST request.
It won’t do any of the real work itself, but will delegate to a ContactRepository (which you’ll create soon) for persisting contacts.
Listing 21.3 ContactController handles basic web requests for the Contacts application.
The first thing you should notice about ContactController is that it’s a typical Spring MVC controller.
Although Spring Boot gets involved when it comes to managing build dependencies and minimizing Spring configuration, the programming model is the same when it comes to writing much of your application logic.
In this case, ContactController follows the typical pattern for a Spring MVC controller that displays and handles form submission.
The home() method uses the injected ContactRepository to retrieve a list of all Contact objects, placing them into the model before handing the request off to the home view.
That view will render the list of contacts along with a form to add a new Contact.
The submit() method will handle the POST request resulting from the form submission, save the Contact, and redirect to the home page.
And because ContactController is annotated with @Controller, it’s subject to component scanning.
Therefore, you won’t have to explicitly configure it as a bean in the Spring application context.
As for the Contact model type, it’s just a simple POJO with a handful of properties and accessor methods, as shown in the following listing.
All that’s left is to create a Thymeleaf template that defines the home view.
Traditionally, Java web applications use JSP as the view-layer technology.
But as we discussed in chapter 6, there’s a new kid in town.
Thymeleaf’s natural templates are much more pleasant to work with than JSP, and they make it possible for you to write your templates as HTML.
Because of that, we’re going to use Thymeleaf to define the home view for the Contacts application.
First, you need to add Thymeleaf to your project’s build.
If you’re using Maven, this is the dependency you’ll need:
Keep in mind that by simply adding Thymeleaf to the project’s classpath, you’re setting Spring Boot autoconfiguration in motion.
When the application is run, Spring Boot will detect that Thymeleaf is in the classpath and will automatically configure the view resolver, template resolver, and template engine beans necessary to use Thymeleaf with Spring MVC.
Therefore, there’s no explicit Spring configuration required to use Thymeleaf in your application.
Aside from adding the Thymeleaf dependency to the build, the only thing you need to do is define the view template.
Listing 21.5 shows home.html, a Thymeleaf template that defines the home view.
It has two parts: a form and then a list of contacts.
The form will POST data back to the submit() method of ContactController to create a new Contact.
The list cycles through the list of Contact objects in the model.
In order for this template to be used, you need to be careful to name and place it correctly in your project.
Because the logical view name returned from the home() method in ContactController is home, the template file should be named home.html.
There’s only one loose end that needs to be tied up with regard to this Thymeleaf template.
The HTML it produces will reference a stylesheet named style.css.
Therefore, you need to add that stylesheet to the project.
Listing 21.5 The home view renders a form to create new contacts and to list contacts.
Normally, stylesheets and images are things that I avoid discussing in the context of writing Spring applications.
Certainly, those kind of artifacts go a long way toward making any application (including Spring applications) more aesthetically pleasing to a user.
But static artifacts aren’t critical to the discussion of writing server-side Spring code.
In the case of Spring Boot, however, it’s worth mentioning how Spring Boot deals with static content.
When Spring Boot’s web autoconfiguration is automatically configuring beans for Spring MVC, those beans include a resource handler that maps /** to several resource locations.
Those resource locations include (relative to the root of the classpath) the following:
In a conventional Maven/Gradle-built application, you’d typically put static content at src/main/webapp so that it would be placed at the root of the WAR file that the build produces.
When building a WAR file with Spring Boot, that’s still an option.
But you also have the option of placing static content at one of the four locations mapped to the resource handler.
So, in order to satisfy the Thymeleaf template’s reference to /style.css, you need to create a file named style.css at one of the following locations:
I tend to put static content in /public, but each of those four choices works equally well.
Although the content of style.css isn’t relevant to our discussion, here’s a simple stylesheet that will give your application a slightly cleaner look:
Believe it or not, you’re more than halfway finished building your simple Contacts application! The web layer is completely finished.
Now you need to create the ContactRepository to handle persistence of Contact objects.
You have a lot of options when it comes to working with databases in Spring.
You could use JPA or Hibernate to map objects to tables and columns in a relational database.
Or you could abandon the relational database model altogether and use a different kind of database, such as Mongo or Neo4j.
For the purposes of the Contacts application, a relational database is a fine choice.
We’ll use the H2 database and JDBC (using Spring’s JdbcTemplate) to keep things simple.
These choices naturally lead to the necessity of adding a few dependencies to the build.
The JDBC starter dependency will pull in everything you need to work with Spring’s JdbcTemplate.
In Gradle, the following two lines in the dependencies block will do the trick:
With these two dependencies in the build, you can now write your repository class.
ContactRepository in the following listing works with an injected JdbcTemplate to read and write Contact objects from the database.
Listing 21.6 ContactRepository  saves and fetches Contacts from the database.
It looks no different from how it might look in a traditional Spring application.
There’s nothing about its implementation that suggests that it’s part of a Spring Boot–enabled application.
The findAll() method uses the injected JdbcTemplate to fetch Contact objects from the database.
The save() method uses JdbcTemplate to save a new Contact object.
And because ContactRepository is annotated with @Repository, it will automatically be picked up by component-scanning and created as a bean in the Spring application context.
Once again, Spring Boot handles all of the Spring configuration for you.
There’s no way that Spring Boot can guess what the contacts should look like.
So you’ll need to define a schema, such as this:
Now you just need some way to load this create table SQL and execute it against the H2 database.
If you name this SQL file as schema.sql and place it at the root of the classpath (that is, in src/main/resources in the Maven or Gradle project), it will be found and loaded when the application starts up.
The Contacts application is rather simple, but it does qualify as a realistic Spring application.
It has a web layer defined by a Spring MVC controller and a Thymeleaf template.
And it has a persistence layer defined by a repository and Spring’s JdbcTemplate.
At this point you’ve written all of the application code necessary for the Contacts application.
One thing you haven’t written, however, is any form of configuration.
You haven’t yet written any Spring configuration, nor have you configured DispatcherServlet in a web.xml file or servlet initializer class.
Would you believe me if I said that you don’t have to write any configuration? That can’t be right.
After all, according to Spring’s critics, Spring is all about configuration.
Certainly there’s an XML file or Java configuration class we’ve overlooked.
Generally speaking, Spring Boot’s autoconfiguration feature eliminates most or all of the configuration.
Therefore, it’s entirely possible to write an entire Spring application and not write a single line of configuration code.
Of course, autoconfiguration doesn’t cover all scenarios, so a typical Spring Boot application will still include some configuration.
For the Contacts application specifically, there’s no need for any configuration.
Spring’s autoconfiguration took care of all of your configuration needs.
You do, however, need a special class that bootstraps the Spring Boot application.
The Application class in listing 21.7 is a typical example of a Spring Boot bootstrap class.
Listing 21.7 A simple bootstrapper class to initiate Spring Boot autoconfiguration.
Okay, I’ll admit that Application has a tiny bit of configuration.
But that’s it! There’s no more configuration in the Contacts application than those two lines.
What’s especially interesting about Application is that it has a main() method.
As you’ll see in a moment, Spring Boot applications can be run in a unique way, and the main() method here makes that possible.
Within the main() method, there’s a single line that tells Spring Boot (via the SpringApplication class) to run using the configuration in Application itself and any arguments that were given on the command line.
If you’re a Maven fan, you’ll need to build the project like this:
After running the Maven build, you’ll find the build artifact in the target folder.
Traditionally, this would mean deploying the application WAR file to a servlet container such as Tomcat or WebSphere.
But you don’t even have a WAR file—the build gives you a JAR file.
You can run it from the command line like this (referencing the Gradle-built JAR file):
After only a few seconds, the application should start up and be ready to go.
Point your browser at http://localhost:8080 and you should be ready to start entering contacts.
After entering a few contacts, your browser might look a little something like figure 21.1
You’re probably thinking that this isn’t how you should run a web application.
It’s neat and convenient to be able to run it from the command line like this, but that’s not reality.
Where you work, web applications are deployed as WAR files to a web container.
The deployment police at your company won’t like it if you don’t give them a WAR file.
Even though running the application from the command line is a valid option, even for production applications, I understand that you probably need to work within the parameters of your company’s deployment procedures.
Fortunately, you won’t need to abandon the simplicity of Spring Boot if it’s a WAR file that’s required.
All that’s needed is a small tweak to the build.
In the Gradle build, you’ll need to add the following line to apply the “war” plugin:
In the case of a Maven-built project, it’s even easier.
That WAR file is deployable to any web container that supports Servlet 3.0
What’s more, you can still run the application from the command line like this:
As you can see, Spring Boot goes a long way to make developing Spring applications in Java as simple as possible.
Spring Boot starters simplify project build dependencies, and autoconfiguration eliminates the need for most explicit Spring configuration.
But as you’ll see next, if you add Groovy to the mix, it gets even easier.
The syntax allows for shortcuts such as leaving off semicolons and the public keyword.
Also, the properties of a Groovy class don’t require setter and getter methods as in Java.
And that’s without mentioning the other features of Groovy that eliminate much of the ceremony that goes into Java coding.
If you’re willing to write your application code in Groovy and run it through Spring Boot’s CLI, then Spring Boot can take advantage of Groovy’s simplicity to further simplify Spring development.
To illustrate this point, let’s rewrite the Contacts application in Groovy.
Why not? There were only a few small Java classes in the original version of the application, so there’s not much to rewrite in Groovy.
You can reuse the same Thymeleaf template and schema.sql file.
And if my claims about Groovy simplifying Spring further are true, then rewriting the application won’t be a big deal.
Along the way, you can get rid of a few files, too.
The Spring Boot CLI is its own bootstrapper, so you won’t need the Application class you created before.
The Maven and Gradle build files can go away too, since you’ll be running uncompiled Groovy files through the CLI.
And without Maven and Gradle, the entire project structure can be flattened.
The new project structure will look a little like this:
Although the schema.sql, style.css, and home.html files will remain unchanged, you’ll need to convert the three Java classes to Groovy.
As mentioned before, Groovy doesn’t have nearly as much ceremony built into the language as Java.
This means that you can write Groovy code without things like.
Taking advantage of Groovy’s relaxed syntax (as well as some Spring Boot magic), you can rewrite the ContactController class in Groovy, as shown in listing 21.8
As you can see, this version of ContactController is much simpler than its Java counterpart.
By ditching all of the things that Groovy doesn’t need, ContactController is shorter and arguably easier to read.
You may have noticed that there are no import lines, as is typical in a Java class.
Groovy imports a number of packages and classes by default, including the following:
Thanks to these default imports, the List class doesn’t need to be imported by ContactController.
It’s in the java.util package, so it’s among the default imports.
Listing 21.8 ContactController is simpler in Groovy than in Java.
Later when you run the application, the Spring Boot CLI will try to compile these Groovy classes using the Groovy compiler.
But the Spring Boot CLI doesn’t give up that easily.
This is where the CLI takes autoconfiguration to a whole new level.
The CLI will recognize that the failures were due to missing Spring types, and it will take two steps to fix that problem.
It will first fetch the Spring Boot web starter dependency and transitively all of its dependencies and add them to the classpath.
That’s right, it will download and add JARs to the classpath.) Then it will add the necessary packages to the Groovy compiler’s list of default imports and try to compile the code again.
And you won’t need to resolve the Spring libraries manually or by using Maven or Gradle.
Now let’s take a step back and consider what’s going on here.
With the web starter’s dependencies also being added transitively to the classpath, Spring Boot’s autoconfiguration will kick in and automatically configure the beans necessary to support Spring MVC.
But again, all you had to do was use those types.
Although it knows how to resolve many Spring dependencies and automatically add imports for many Spring types (as well as a handful of other libraries), it won’t automatically resolve and import everything.
The choice to use Thymeleaf templates, for example, is an opt-in choice.
So you must explicitly ask for it with an @Grab annotation in the code.
Note that for many dependencies, it's unnecessary to specify the group ID or version number.
Spring Boot plugs itself into the dependency resolution behind @Grab and fills in the missing group ID and version for you.
Also, by adding the @Grab annotation and asking for Thymeleaf, you triggered autoconfiguration to configure the beans necessary to support Thymeleaf templates in Spring MVC.
Although it has little to do with Spring Boot, it’s worth showing the Contact class in Groovy for the sake of a complete example:
As you can see, Contact is also much simpler without semicolons, accessor methods, and modifiers like public and private.
Spring Boot had absolutely no part in simplifying the Contact class.
Now let’s see how to simplify the repository class with Spring Boot CLI and Groovy.
All of the Groovy and Spring Boot CLI tricks you applied to ContactController can also be applied to ContactRepository.
The following listing shows the new Groovy version of ContactRepository.
Aside from the obvious improvements from Groovy syntax, this new ContactRepository class takes advantage of Spring Boot CLI’s auto-import feature to automatically import JdbcTemplate and RowMapper.
Moreover, the JDBC starter dependency is automatically resolved when the CLI sees that you’re using those types.
There are only a couple of things that the CLI’s auto-import and auto-resolution couldn’t help you with.
As you can see, you still had to import ResultSet.
You’ve converted all of the Java classes to Groovy and took advantage of Spring Boot magic along the way.
Listing 21.9 When written in Groovy, ContactRepository is much more succinct.
After compiling the Java application, you had two choices for running it.
You could either run it as an executable JAR or WAR file from the command line, or you could deploy a WAR file to a servlet container.
As you might guess from its name, running applications through the Spring Boot CLI is a way to run the application from the command line.
But with the CLI, there’s no need to build the application into a JAR or WAR file first.
You can run the application directly by passing the Groovy source code through the CLI.
If you’d rather install Spring Boot manually, you can download it using the instructions at http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/
Once you have the CLI installed, you can check the installation and which version you’re using with the following command line:
Assuming everything installs well, you’re ready to run the Contacts application.
For example, if your application only has a single Groovy class, you can run it like this:
This runs a single Groovy class named Hello.groovy through the CLI.
If your application has several Groovy class files, you can run them using wildcards.
Or, if those Groovy class files are in one or more subdirectories, you can use Ant-style wildcards to recursively seek for Groovy classes:
Because the Contacts application has three Groovy classes to be read, and because they’re all at the project root, either of the last two options will work.
After running the application, you should be able to point your browser to http://localhost:8080 and see essentially the same Contacts application that you created earlier.
At this point, you’ve created a Spring Boot application twice: once in Java and another time in Groovy.
In both cases, Spring Boot applied a great deal of magic to minimize the boilerplate configuration and build dependencies.
Spring Boot has one more trick up its sleeves, though.
Let’s see how you can use the Spring Boot Actuator to introduce management endpoints to a web application.
The main thing that the Spring Boot Actuator does is add several helpful management endpoints to a Spring Boot-based application.
To enable the actuator, you simply add the actuator starter dependency to your project.
If you’re writing your application in Groovy and running through the Spring Boot CLI, you can add the actuator starter with @Grab, like this:
If you’re building a Java application using Gradle, you can add the following dependency to the dependencies block in build.gradle:
Or in your project’s Maven pom.xml file, you can add the following <dependency>:
After adding the Spring Boot Actuator, you can rebuild and restart your application and then point your browser to any of those management endpoints for more information.
For example, if you want to see all of the beans that are in the Spring application context, you can make a request for http://localhost:8080/beans.
Using the curl command-line tool, the result might look something like this (reformatted and abridged for readability):
From this, you can see that there’s a bean whose ID is contactController that depends on another bean named contactRepository.
Because I abridged the output, there are dozens of other beans not shown that you’d otherwise see in the JSON produced from the /beans endpoint.
This offers some insight into the otherwise mysterious outcome of autowiring and autoconfiguration.
Another endpoint that lends some insight into how Spring Boot’s autoconfiguration works is the /autoconfig endpoint.
The JSON produced by this endpoint lays bare the decisions that Spring Boot made when autoconfiguring beans.
For example, here’s the abridged (and reformatted) JSON received from the /autoconfig endpoint when fetched from the Contacts application:
As you can see, the report has two sections: one for negative matches and one for positive matches.
The negative matches section shown here indicates that the AOP and Spring Batch autoconfiguration weren’t applied because the requisite classes weren’t found on the classpath.
You can also see that the default template resolver, view resolver, and template engine beans will be autoconfigured unless you have already explicitly configured those beans.
Moreover, the default view resolver bean will only be autoconfigured if the Servlet class is found on the classpath.
The /beans and /autoconfig endpoints are just two examples of the kind of insight that Spring Boot’s Actuator makes available.
There isn’t enough space in this chapter to discuss all of the endpoints in detail, but I encourage you to try them out for yourself to see what the Actuator can tell you about your application.
Spring Boot is an exciting new addition to the Spring family of projects.
Where Spring aims to make Java development simpler, Spring Boot aims to make Spring itself simpler.
Spring Boot employs two main tricks to eliminate boilerplate configuration in a Spring project: Spring Boot starters and automatic configuration.
A single Spring Boot starter dependency can replace several common dependencies in a Maven or Gradle build.
For example, adding only Spring Boot’s web starter as a dependency in a project pulls in Spring’s web and Spring MVC modules as well as the Jackson 2 databind module.
Automatic configuration takes full advantage of Spring 4.0’s conditional configuration feature to automatically configure certain Spring beans to enable a certain feature.
For example, Spring Boot can detect that Thymeleaf is in the application classpath and automatically configure the beans required to enable Thymeleaf templates as Spring MVC views.
Spring Boot’s command-line interface (CLI) further simplifies Spring projects with Groovy.
By simply referencing a Spring component in Groovy code, you can trigger the CLI to automatically add the necessary starter dependency (which may, in turn, trigger automatic configuration)
Moreover, many Spring types don’t require explicit import statements in Groovy code run via the Spring Boot CLI.
Finally, the Spring Boot Actuator adds some common management features to a Spring Boot–developed web application, including insight into thread dumps, web request history, and the beans in the Spring application context.
After reading this chapter, you may be wondering why I saved such a helpful topic like Spring Boot until the end of the book.
You might even be thinking that had I introduced Spring Boot earlier in the book, that much of what you learned would’ve been even easier.
Indeed, Spring Boot layers a very compelling programming model on top of Spring, and once you’ve used it, it’s hard to imagine writing a Spring application without it.
I could say that by saving Spring Boot for last, my intentions were to give you a deeper appreciation for Spring (and perhaps build character and sprout hair on your chest)
While that could be true, the real reason is that most of this book had already been written by the time Spring Boot came along.
So I slid it in at the only place I could without shuffling the entire book: at the end.
Who knows? Maybe the next edition of this book will start off using Spring Boot.
Whether you’re just discovering Spring or you want to absorb the new features, there’s no better way to master Spring than with this book.
You’ll move between short snippets and an ongoing example as you learn to build simple and effi  cient JEE applications.
Author Craig Walls has a special knack for crisp and entertaining examples that zoom in on the features and techniques you really need.
He’s a popular author and a frequent speaker at user groups and conferences.
Aft er ten years, this is still the clearest and most comprehensive introduction to the core concepts of the.
Spring in Action brief contents contents preface acknowledgments about this book Roadmap Code conventions and downloads Author Online About the author About the cover illustration.
