O’Reilly books may be purchased for educational, business, or sales promotional use.
Java EE 7 Essentials, the image of glassfish, and related trade dress are trademarks of O’Reilly Media, Inc.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and O’Reilly Media, Inc., was aware of a trademark claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of this book, the publisher and author assume no responsibility for errors or omissions, or for damages resulting from the use of the information contained herein.
To Aditya and Mihir, your stories and games are invaluable to me.
As Java EE platform specification lead, I’ve been guiding the path of Java EE since its introduction in 1999
Arun has been a key member of the Java EE team from the beginning.
The Java EE platform has evolved significantly over the last 13 years.
Java EE 7 is the latest release continuing this theme of focusing on developer productivity.
Arun has been involved in several different areas of Java EE, but the common thread of his involvement has been understanding real developers and real applications.
His background with Java EE, and his current role as technology evangelist for Java EE, make him uniquely qualified to introduce developers to the latest Java EE technology.
In this book, Arun surveys all the key technologies of the latest version of Java EE, giving developers a taste for these many new capabilities, and showing just how easy it is to write Java EE applications.
Arun expands on his popular Java EE 6 Pocket Guide to cover more technologies in more depth.
Particular attention is paid to technologies new to Java EE 7, and to new features of existing technologies.
Developers with some Java EE experience, as well as developers new to Java EE, will find this a very helpful overview of Java EE 7
Each chapter covers a Java EE technology in just enough depth to help you understand what the technology does, what it’s best used for, and how to get started using it.
While it’s not a complete tutorial, an experienced developer will find that it provides just the right level of detail to understand the technology.
The chapters are full of short code fragments that developers will appreciate.
After describing the key technologies of Java EE, in the last chapter of the book, Arun pulls it all together with a hands-on lab that walks you through the process of developing a real application that uses most of these technologies.
There’s nothing like seeing the code for a running application to show you how these technologies actually work in practice.
Java EE is a rich platform that we’ve been developing over many years.
It can be daunting to sort through all the old and new versions of technologies to find the best way to write Java EE applications.
We’ve made it much easier to write Java EE applications in recent years, but sometimes that message doesn’t come through when reading our many Java EE specifications.
Arun’s years of experience in working with application developers, teaching hands-on labs, and evangelizing Java EE put him in a unique position to provide all the key information at just the right depth.
This book is a great way for developers to get an overview of the Java EE platform, and especially the new features in Java EE 7
This book is directed toward readers who want to get a quick overview of the platform and to keep coming back to review the basics.
This book provides an overview of the key specifications in the Java EE 7 platform (one specification per chapter)
This book is by no means intended to be an exhaustive guide or tutorial that explains each and every concept of different specifications.
However, the main concepts from the different specifications are explained using simple code samples.
No prior knowledge of earlier versions of the platform is required, but you’ll need some basic understanding of Java to understand the code.
A significant part of this book is derived from Java EE 6 Pocket Guide (O’Reilly)
New chapters have been added to cover the new technologies in the platform.
New sections have been added or existing sections updated to reflect the changes in the platform.
If you have read the Java EE 6 Pocket Guide, then you can read this book at a much faster pace; otherwise, you can read this book from beginning to end.
Alternatively, you can read specific chapters based upon your interest.
I also provide self-paced instructions on how to build an end-to-end application using most of the technologies described.
This allows developers to understand the design patterns they can apply to build a real-life application using Java EE 7
Conventions Used in This Book The following typographical conventions are used in this book: Italic.
Indicates new terms, URLs, email addresses, filenames, and file extensions.
Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.
Constant width italic Shows text that should be replaced with user-supplied values or by values determined by context.
Using Code Examples Supplemental material (code examples, exercises, etc.) is available for download at http://oreil.ly/javaee7-files.
This book is here to help you get your job done.
In general, if this book includes code examples, you may use the code in your programs and documentation.
You do not need to contact us for permission unless you’re reproducing a significant portion of the code.
For example, writing a program that uses several chunks of code from this book does not require permission.
Selling or distributing a CD-ROM of examples from O’Reilly books does require permission.
Answering a question by citing this book and quoting example code does not require permission.
Incorporating a significant amount of example code from this book into your product’s documentation does require permission.
An attribution usually includes the title, author, publisher, and ISBN.
Technology professionals, software developers, web designers, and business and creative professionals use Safari Books Online as their primary resource for research, problem solving, learning, and certification training.
Safari Books Online offers a range of product mixes and pricing programs for organizations, government agencies, and individuals.
Subscribers have access to thousands of books, training videos, and prepublication manuscripts in one fully searchable database from publishers like O’Reilly Media, Prentice Hall Professional, Addison-Wesley.
For more information about Safari Books Online, please visit us online.
How to Contact Us Please address comments and questions concerning this book to the publisher:
We have a web page for this book, where we list errata, examples, and any additional information.
For more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.
Acknowledgments This book would not have been possible without support from a multitude of people.
First and foremost, many thanks to O’Reilly for trusting in me and providing an opportunity to write this book.
Their team provided excellent support throughout the editing, reviewing, proofreading, and publishing process.
At O’Reilly, Meghan Blanchette provided excellent editorial help throughout all the stages, helping with interim reviews, providing feedback on styling, arranging technical reviews, and connecting me with the rest of the team when required.
Rachel Monaghan and Kara Ebrahim helped with copyediting and making sure to provide the finishing touches.
And thanks to the rest of the O’Reilly team with whom I did not interact directly, but who were helping in many other ways.
Their vast experience and knowledge showed in the depth of their comments.
I am grateful for the numerous discussions with developers around the world that helped me understand the technology better.
Thanks to my colleagues at Oracle and the different JSR specification leads for explaining the intended use cases of different technologies.
And thanks to everybody else in my life, who provided much-needed breaks from book writing.
Introduction The Java Platform, Enterprise Edition (Java EE), provides a standards-based platform for developing web and enterprise applications.
These applications are typically designed as multitier applications, with a frontend tier consisting of a web framework, a middle tier providing security and transactions, and a backend tier providing connectivity to a database or a legacy system.
These applications should be responsive and capable of scaling to accommodate the growth in user demand.
The Java EE platform defines APIs for different components in each tier, and also provides some additional services such as naming, injection, and resource management that span across the platform.
These components are deployed in containers that provide runtime support.
Containers provide a federated view of the underlying Java EE APIs to the application components.
Java EE application components never interact directly with other Java EE application components.
They use the protocols and methods of the container for interacting with each other and with platform services.
Interposing a container between the application components and the Java EE services allows the container to transparently inject the services required by the component, such as declarative transaction management, security checks, resource pooling, and state management.
This container-based model and abstraction of resource access allows the platform to offload the developer from common infrastructure tasks.
Each component of the platform is defined in a separate specification that also describes the API, javadocs, and expected runtime behavior.
The WebSocket protocol, developed as part of the collection of technologies that make up HTML5, brings a new level of ease of development and network efficiency to modern, interactive web applications.
It provides a two-way, full-duplex communication channel between a client and a server over a single TCP (transmission control protocol) channel.
Java EE 7 defines a new standard API to develop and deploy WebSocket clients and endpoints.
Until now, developers were required to bundle third-party libraries for JSON processing.
Java EE 7 defines a new portable API to parse, generate, transform, and query JSON using a Streaming API or Object Model API.
JavaServer Faces (JSF) introduces pass-through attributes and elements that allow near-total control over the user experience of each individual element in the view.
This allows HTML5-friendly markup to be easily embedded in a page.
JMSContext provides the unified functionality of Connection and Session objects.
In addition, several JMS interfaces implement Autocloseable and thus are automatically closed after use.
Finally, correct error handling, runtime exceptions instead of checked exceptions, method chaining on JMSProducer, and simplified message sending are further examples of features that the JMS API has simplified.
Without the Client API (introduced in JAX-RS 2), developers are required to use basic HttpUrlConnection APIs and write all the surrounding code.
The Contexts and Dependency Injection (CDI) specification is now a core component model, and is enabled by default.
This makes the platform a lot more cohesive and integrated.
Transactional annotation brings transactional semantics to POJOs (plain old Java objects), outside of an EJB (Enterprise JavaBean)
Bean Validation allows automatic validation of method arguments and results using interceptors.
Less boilerplate text, more defaults, and a cohesive integrated platform together boost developers’ productivity when building applications using the latest version of the platform.
Enterprise demands Batch Applications for the Java Platform is a new functionality in the platform and very important for enterprise customers.
It allows developers to easily define noninteractive, bulk-oriented, long-running jobs in an item- or task-oriented way.
Concurrency Utilities for Java EE, another functionality new to the platform, is an extension of the Java SE Concurrency Utilities API, for use in the Java EE containermanaged environment so that the proper container-managed runtime context can be made available for the execution of these tasks.
This functionality in the platform allows the developer to leverage the standard APIs and reduces the dependency on third-party frameworks.
The JCP process defines three key deliverables for any JSR: Specification.
A formal document that describes the proposed component and its features.
The RI helps to ensure that the proposed specifications can be implemented in a binary form and provides constant feedback to the specification process.
Technology Compliance Kit (TCK) A set of tests that verify that the RI is in compliance with the specification.
Java EE 7 consists of the platform specification that defines requirements across the platform.
It also consists of the following component specifications: Web technologies.
The different components work together to provide an integrated stack, as shown in Figure 1-1
Different components can be logically divided into three tiers: backend tier, middle tier, and web tier.
This is only a logical representation, and the components can be restricted to a different tier based upon the application’s requirements.
Managed Beans and EJB provide a simplified programming model using POJOs to use the basic services.
CDI, Interceptors, and Common Annotations provide concepts that are applicable to a wide variety of components, such as type-safe dependency injection, addressing cross-cutting concerns using interceptors, and a common set of annotations.
Concurrency Utilities can be used to run tasks in a managed thread.
Web Fragments allow automatic registration of thirdparty web frameworks in a very natural way.
WebSocket allows the setup of a bidirectional, full-duplex communication channel over a single TCP connection.
Bean Validation provides a standard means to declare constraints and validate them across different technologies.
It is also available in a Web Profile distribution and can be downloaded from http://glassfish.org.
The application server is easy to use (ZIP installer and NetBeans/ Eclipse/IntelliJ integration), lightweight (downloads starting at 37 MB, small disk/ memory footprint), and modular (OSGi-based, containers start on demand)
The TCK is available to all Java EE licensees for testing their respective implementations.
What’s New in Java EE 7 Some new specifications have been added to improve the functionality and richness of the platform.
Several existing component specifications were revised to make them simpler and easier to use.
The main features of the new specifications are described as follows: Java API for WebSocket.
Enables a WebSocket client and server endpoint to be defined declaratively via annotations on a POJO, or programmatically via interface implementation.
Provides server-specific configuration, such as mapping that identifies a WebSocket endpoint in the URI space of the container, subprotocols supported by the endpoint, and extensions required by the applications.
Java API for JSON Processing • The streaming API provides a way to parse and generate JSON in a streaming.
The Object Model API creates a random-access, tree-like structure that represents the JSON data in memory.
Features the Batch Programming Model using interfaces, abstract classes, and.
The main features of the updated specifications are described as follows: Java API for RESTful Web Services.
Offers a new Client API that can be used to access web resources and provides integration with JAX-RS providers.
Defines Message Filters and Entity Interceptors as extension points to customize the request/response processing on the client and server side.
Java Message Service • Several changes have been made to make the API simpler and easier to use.
New methods have been added to create a session without the need to supply redundant arguments.
A message producer can now specify that a message must not be delivered until after a specified time interval.
New send methods have been added to allow an application to send messages asynchronously.
Expression Language • Expression Language (EL) is a specification of its own.
In addition to the usual arithmetic and comparison operators, new operators.
This will help define how EJB features beyond EJB Lite can be officially added to a product that does not support full Java EE Profile.
An option has been added to disable passivation of stateful session beans.
Servlets • Defines a standard mechanism to upgrade existing HTTP connection to a different protocol using HttpUpgradeHandler.
JavaServer Faces • Faces Flow provides an encapsulation of related views/pages with applicationdefined entry and exit points.
Resource Library Contracts enable developers to apply facelet templates to an.
HTML5-friendly markup allows near-total control over the user experience of.
Stateless Views mean developers no longer have to save the UIComponent state.
This allows applications with JavaScript components to manage the state instead of JSF doing it for them.
Unsynchronized Persistence Contexts mean a persistence context does not have to be enlisted in a transaction.
Interceptors • Associating interceptors using InterceptorBinding is now part of this specification, instead of CDI.
Priority ranges can be dedicated for ordering interceptors using interceptor.
Contexts and Dependency Injection • Allows for automatic enabling of CDI for beans with a scope annotation, and.
Supports global ordering and enabling of interceptors, decorators, and alternatives using the @Priority annotation.
Adds the @Vetoed annotation, allowing easy programmatic disabling of classes.
Bean Validation • Validation constraints can be applied to the parameters and return values of.
The targeted group can be altered when validation cascading is happening.
TransactionScoped is a new CDI scope that defines bean instances whose life cycle is scoped to the currently active JTA transaction.
Servlets are defined as JSR 340, and the complete specification can be downloaded.
A servlet is a web component hosted in a servlet container and generates dynamic content.
The web clients interact with a servlet using a request/response pattern.
The servlet container is responsible for the life cycle of the servlet, receives requests and sends responses, and performs any other encoding/decoding required as part of that.
The fully qualified class name is the default servlet name, and may be overridden using the name attribute of the annotation.
Typically the developer is concerned with overriding the doGet and doPost methods.
The following code shows a servlet handling the GET request:
The request parameters; HTTP headers; different parts of the path such as host, port, and context; and much more information is available from HttpServletRe quest.
The HTTP cookies can be sent and retrieved as well.
This code shows how an HTTP GET request received by a servlet displays a simple response to the client:
Request parameters may be passed in GET and POST requests.
In a GET request, these parameters are passed in the query string as name/value pairs.
Here is a sample URL to invoke the servlet explained earlier with request parameters:
In a POST request, the request parameters can also be passed in the posted data that is encoded in the body of the request.
Initialization parameters, also known as init params, may be defined on a servlet to store startup and configuration information.
As explained earlier, @WebInitParam is used to specify init params for a servlet:
Typically, database connections are initialized in init and released in destroy.
You can also define a servlet using the servlet and servlet-mapping elements in the deployment descriptor of the web application, web.xml.
The annotations cover most of the common cases, so web.xml is not required in those cases.
But some cases, such as ordering of servlets, can only be done using web.xml.
If the metadata-complete element in web.xml is true, then the annotations in the class are not processed:
The values defined in the deployment descriptor override the values defined using annotations.
A servlet is packaged in a web application in a .war file.
Multiple servlets may be packaged together, and they all share a servlet context.
The ServletContext provides detail about the execution environment of the servlets and is used to communicate with the container—for example, by reading a resource packaged in the web application, writing to a logfile, or dispatching a request.
A servlet can send an HTTP cookie, named JSESSIONID, to the client for session tracking.
This cookie may be marked as HttpOnly, which ensures that the cookie is not exposed to client-side scripting code, and thus helps mitigate certains kinds of crosssite scripting attacks:
Alternatively, URL rewriting may be used by the servlet as a basis for session tracking.
The HttpSession interface can be used to view and manipulate information about a session such as the session identifier and creation time, and to bind objects to the session.
A servlet may forward a request to another servlet if further processing is required.
The former can accept a relative path, whereas the latter can accept a path relative to the current context only:
In this code, bank is another servlet deployed in the same context.
It can then be used to obtain a RequestDispatcher, which can dispatch requests in that context.
This sends a temporary redirect response to the client, and the client issues a new request to the specified URL.
Note that in this case, the original request object is not available to the redirected URL.
The redirect may also be marginally slower because it entails two requests from the client, whereas forward is performed within the container:
Note that this URL could be on a different host/port and may be relative or absolute to the container.
Servlet Filters A servlet filter may be used to update the request and response payload and header information from and to the servlet.
It is important to realize that filters do not create the response—they only modify or adapt the requests and responses.
Authentication, logging, data compression, and encryption are some typical use cases for filters.
The filters are packaged along with a servlet and act upon the dynamic or static content.
You can associate filters with a servlet or with a group of servlets and static content by specifying a URL pattern.
In the code shown, the LoggingFilter is applied to all the servlets and static content pages in the web application.
The @WebInitParam may be used to specify initialization parameters here as well.
A filter and the target servlet always execute in the same invocation thread.
The addFilter method returns ServletRegis tration.Dynamic, which can then be used to add mapping for URL patterns, set initialization parameters, and handle other configuration items:
These listeners are classes that implement an interface that supports event notifications for state changes in these objects.
Each class is annotated with @WebListener, declared in web.xml, or registered via one of the ServletCon text.addListener methods.
A typical example of these listeners is where an additional servlet is registered programmatically without an explicit need for the programmer to do so, or a database connection is initialized and restored back at the application level.
There may be multiple listener classes listening to each event type, and they may be specified in the order in which the container invokes the listener beans for each event type.
The listeners are notified in the reverse order during application shutdown.
There is also AsyncListener, which is used to manage async events such as completed, timed out, or an error.
Asynchronous Support Server resources are valuable and should be used conservatively.
Consider a servlet that has to wait for a JDBC connection to be available from the pool, receiving a JMS message or reading a resource from the filesystem.
This is where the server can be asynchronously processed such that the control (or thread) is returned to the container to perform other tasks while waiting for the long-running process to complete.
The request processing continues in the same thread after the response from the long-running process is returned, or may be dispatched to a new resource from within the long-running process.
A typical use case for a long-running process is a chat application.
The asynchronous behavior needs to be explicitly enabled on a servlet.
You achieve this by adding the asyncSupported attribute on @WebServlet:
You can then start the asynchronous processing in a separate thread using the startA sync method on the request.
This method returns AsyncContext, which represents the execution context of the asynchronous request.
The container completes the invocation of the asynchronous request in the latter case.
In this code, the request is put into asynchronous mode.
AsyncListener is registered to listen for events when the request processing is complete, has timed out, or resulted in an error.
A request may be dispatched from an asynchronous servlet to synchronous, but the other way around is illegal.
The asynchronous behavior is available in the servlet filter as well.
Nonblocking I/O Servlet 3.0 allowed asynchronous request processing but only permitted traditional I/O, which restricted the scalability of your applications.
In a typical application, Serv letInputStream is read in a while loop:
If the incoming data is blocking or streamed slower than the server can read, then the server thread is waiting for that data.
Nonblocking I/O allows developers to read data as it becomes available or write data when it’s possible to do so.
This increases not only the scalability of the Web Container but also the number of connections that can be handled simultaneously.
Servlet 3.1 achieves nonblocking I/O by introducing two new interfaces: ReadListen er and WriteListener.
These listeners have callback methods that are invoked when the content is available to be read or can be written without blocking.
Invoking setXXXListener methods indicates that nonblocking I/O is used instead of traditional.
The onDataAvailable callback method is called whenever data can be read without blocking.
The onAllDataRead callback method is invoked whenever data for the current request is completely read.
In this code, the onDataAvailable callback is invoked whenever data can be read without blocking.
The onWritePossible callback method is called whenever data can be written without blocking.
The onError callback is invoked if there is an error processing the response.
Web Fragments A web fragment is part or all of the web.xml file included in a library or framework JAR’s META-INF directory.
If this framework is bundled in the WEB-INF/lib directory, the container will pick up and configure the framework without requiring the developer to do it explicitly.
It can include almost all of the elements that can be specified in web.xml.
However, the top-level element must be web-fragment and the corresponding file must be called webfragment.xml.
The developer can specify the order in which the resources specified in web.xml and web-fragment.xml need to be loaded.
The two orders are mutually exclusive, and absolute ordering overrides relative.
The absolute ordering contains one or more <name> elements specifying the name of the resources and the order in which they need to be loaded.
Specifying <others/> allows for the other resources not named in the ordering to be loaded:
In this code, the resources specified in web.xml are loaded first and followed by MyServ let and MyFilter.
This code will require the container to load the resource MyFilter after the resource MyServlet (defined elsewhere) is loaded.
If web.xml has metadata-complete set to true, then the web-fragment.xml file is not processed.
The web.xml file has the highest precedence when resolving conflicts between web.xml and web-fragment.xml.
Security Servlets are typically accessed over the Internet, and thus having a security requirement is common.
You can specify the servlet security model, including roles, access control, and authentication requirements, using annotations or in web.xml.
ServletSecurity is used to specify security constraints on the servlet implementation class for all methods or a specific doXXX method.
The container will enforce that the corresponding doXXX messages can be invoked by users in the specified roles:
The roles are mapped to security principals or groups in the container.
This deployment descriptor requires that only the GET method at the /account/* URL is protected.
This method can only be accessed by a user in the manager role with a requirement for content integrity.
In this code, all HTTP methods at the /account/* URL are protected.
In this code fragment, only the HTTP GET method is protected and all other HTTP protocols methods such as POST and PUT are uncovered.
In this code, only the HTTP GET method is not protected and all other HTTP protocol methods are protected.
If an annotation is specified on both the class and the method level, the one specified on the method overrides the one specified on the class.
This allows you to specify security constraints at a higher level than a particular role.
The login form must contain fields for entering a username and a password.
The HttpServletRequest also provides programmatic security with the login, log out, and authenticate methods.
The login method validates the provided username and password in the password validation realm (specific to a container) configured for the ServletContext.
This ensures that the getUserPrincipal, getRemoteUser, and getAuthType methods return valid values.
The login method can be used as a replacement for form-based login.
The authenticate method uses the container login mechanism configured for the ServletContext to authenticate the user making this request.
The resource path is specified as a string with a leading “/.” This path is resolved relative to the root of the context or relative to the META-INF/resources directory of the JAR files bundled in the WEB-INF/lib directory:
Normally, if stylesheets and image directories need to be accessed in the servlet, you need to manually extract them in the root of the web application.
Servlet 3.0 allows the library to package the resources in the META-INF/resources directory:
In this case, the resources need not be extracted in the root of the application and can be accessed directly instead.
This allows resources from third-party JARs bundled in META-INF/resources to be accessed directly instead of manually extracted.
The application always looks for resources in the root before scanning through the JARs bundled in the WEB-INF/lib directory.
The order in which it scans JAR files in the WEBINF/lib directory is undefined.
Error Mapping An HTTP error code or an exception thrown by a serlvet can be mapped to a resource bundled with the application to customize the appearance of content when a servlet generates an error.
This allows fine-grained mapping of errors from your web application to custom pages.
Adding the preceding fragment to web.xml will display the /error-404.jsp page to a client attempting to access a nonexistent resource.
You can easily implement this mapping for other HTTP status codes as well by adding other <error-page> elements.
The <exception-type> element is used to map an exception thrown by a servlet to a resource in the web application:
You can easily implement this mapping for other exceptions as well by adding other <error-page> elements.
The <error-page> declaration must be unique for each class name and HTTP status code.
The location attribute is used to specify the directory location where the files are stored.
The getParts method provides a Collection of parts for this multipart request.
In this code, the form is POSTed to FileUploadServlet with encoding multipart/formdata.
The capabilities and nature of the application-layer communication after the protocol change are entirely dependent upon the new protocol chosen.
After an upgrade is negotiated between the client and the server, the subsequent requests use the newly chosen protocol for message exchanges.
A typical example is how the WebSocket protocol is upgraded from HTTP, as described in the Opening Handshake section of RFC 6455
However, the servlet container itself does not have any knowledge about the upgraded protocol.
Data reading or writing between the servlet container and the HttpUpgradeHandler is in byte streams.
The decision to upgrade is made in the Servlet.service method.
The request looks for the Upgrade header and makes a decision based upon its value.
In this case, the connection is upgraded if the Upgrade header is equal to echo.
The upgrade method is called on HttpServ letRequest by passing an instance of HttpUpgradeHandler.
The servlet filters only process the initial HTTP request and response.
JavaServer Faces (JSF) is defined as JSR 344, and the complete specification can be downloaded.
JavaServer Faces is a server-side user interface (UI) framework for Java-based web applications.
This allows a two-way migration of application data with the UI.
Handle page navigation in response to UI events and model interactions.
Provide a simple model for wiring client-generated events to server-side application.
A set of web pages in which the UI components are laid out.
One set of beans binds components to a server-side model.
An optional set of custom objects such as converters and listeners, created by the.
Facelets Facelets is the view declaration language (aka view handler) for JSF.
It is the replacement for JSP, which is now retained only for backward compatibility.
New features introduced in version 2 of the JSF specification, such as composite components and Ajax, are only exposed to page authors using facelets.
In this code, an XML prologue is followed by a document type declaration (DTD)
An XML namespace is declared for the tag library used in the web page.
Facelets HTML tags (those beginning with h:) and regular HTML tags are used to add components.
Table 3-1 shows the standard set of tag libraries supported by Facelets.
By convention, web pages built with XHTML have a .xhtml extension.
This allows two-way data binding between the backing beans and the UI:
It’s important to add @Named on a CDI bean to enable its injection in an EL.
Specifying this annotation on a bean binds it with the current view.
This is a stateless session bean and has a business method that returns a list of customer names.
In this code, the list of customer names returned is displayed in a table.
Notice how the getCustomerNames method is available as a property in the EL.
In addition, Facelets provides a powerful templating system that allows you to provide a consistent look and feel across multiple pages in a web application.
A base page, called a template, is created via Facelets templating tags.
This page defines a default structure for the page, including placeholders for the content that will be defined in the pages.
A template client page uses the template and provides actual content for the placeholders defined in the template.
Table 3-2 lists some of the common tags used in the template and template client pages.
If the template attribute is used, the children of this tag define the template layout.
A matching ui:define tag in the template client page replaces the content.
Any component or content fragment outside this tag is ignored.
In this code, the page defines the structure using <div> and CSS (not shown here)
In this code, ui:insert with top and bottom names is not defined, so those sections are used from the template page.
There is a ui:define element with a name matching the ui:insert element in the template, so the contents are replaced.
Resource Handling JSF defines a standard way of handling resources, such as images, CSS, or JavaScript files.
These resources are required by a component to be rendered properly.
The resources may also be localized, versioned, and collected into libraries.
In this code, header.jpg is bundled in the standard resources directory.
If a resource is bundled in a library corp (a folder at the location where resources are packaged), then you can access it using the library attribute:
In this code, myScript.js is a JavaScript resource packaged in the scripts directory in the standard resources directory.
The ResourceHandler API provides a programmatic way to serve these resources as well.
Composite Components Using features of Facelets and resource handling, JSF defines a composite component as a component that consists of one or more JSF components defined in a Facelets markup file.
This allows you to create a reusable component from an arbitrary region of a page.
The composite component is defined in the defining page and used in the using page.
Future versions of the JSF specification may relax the requirement to specify metadata, as it can be derived from the implementation itself.
You can define a composite component using JSF 1.2 as well, but it requires a much deeper understanding of the JSF life cycle and also authoring multiple files.
JSF2 really simplifies the authoring of composite components using just an XHTML file.
This code renders a table with two rows and three columns, as shown in Figure 3-1
The first column displays a prompt for the field to be entered; the second column displays an input text box where the data can be entered; and the third column (which is empty to begin with) is for displaying a message for the corresponding field.
The first row binds the input value to the User.name field, and the second row binds the input value to the User.password field.
There is also a command button, and clicking the button invokes the register method of the UserService bean.
If this login form is to be displayed in multiple pages, then instead of repeating this code everywhere, it is beneficial to convert this fragment into a composite component.
This requires the code fragment to be copied to an .xhtml file, and the file itself is copied in a library in the standard resources directory.
If the fragment shown earlier is copied to login.xhtml in the resources/mycomp directory, the defining page looks like:
In this code, cc:interface defines metadata that describes the characteristics of the component, such as supported attributes, facets, and attach points for event listeners.
The tag name is the filename without the .xhtml suffix in the using page:
In this code, all the parameters are explicitly specified in cc:interface for clarity.
The third parameter has a targets attribute referring to ccForm:loginButton.
This is required so that the button within the form can be explicitly referenced.
It is defined as a methodsignature and describes the signature of the method.
The user, password, and actionListener are then passed as required attributes in the using page:
Now the using page can pass different backing beans, and different business methods can be invoked when the submit button is clicked.
Follows the Don’t Repeat Yourself (DRY) design pattern and allows you to keep code that can be repeated at multiple places in a single file.
Allows developers to author new components without any Java code or XML configuration.
Application developers don’t necessarily need to know the details of the life cycle, but it helps those who need to know information such as when validations, conversions, and events are usually handled and what they can do to change how and when they are handled.
A JSF page is represented by a tree of UI components, called a view.
When a client makes a request for the page, the life cycle starts.
During the life cycle, the JavaServer Faces implementation must build the view while considering the state saved from a previous submission of the page.
When the client submits a page, the JavaServer Faces implementation must perform several tasks, such as validating the data input of components in the view, converting input data to types specified on the server side, and binding data to the backing beans.
The JavaServer Faces implementation performs all these tasks as a series of steps in the life cycle.
The different components of the application go through the following well-defined request processing life-cycle phases:
Restore view Restores and creates a server-side component tree to represent the UI information from a client.
If the request is made to a URL for the first time, then a new View object is created and rendered to the client.
This view is also stored in the current FacesContext instance.
If the view state is already found in FacesContext, then it is restored and displayed.
Any custom converters, validators, renderers, if attached for the UI components, are restored in this phase.
If the UI component values are directly mapped to the property defined in a managed bean, then the value for the property is restored and it is associated with the view.
Most of the work is handled by the ViewHandler.re storeView method.
Apply request values This phase updates the server-side components with request parameters, headers, cookies, and so on from the client.
The outcome of this phase may either end in the process validations phase or the render response phase.
If any of the conversions or the validations fail, then the current processing is terminated and the control directly goes to the render response for rendering the conversion or the validation errors to the client.
Process validations This phase will process any validations and data type conversions configured for UIComponents.
If any conversion or validation error happens here, then the current process is terminated and the control is directed to the render response phase for reporting any errors.
Update model values Reaching this phase means that the request values are syntactically valid.
The values from UIComponents are synchronized with the model objects, which are usually backing beans.
Setting the request value to the model object may also result in events being queued and fired.
All the listeners that are registered for the UIComponents are invoked.
For example, all action components, like the command button or the hyperlink, have default action listeners that are invoked in this phase.
Render response Renders the response back to the client application.
Ajax JSF provides native support for adding Ajax capabilities to web pages.
It allows partial view processing, where only some components from the view are used for processing the response.
It also enables partial page rendering, where selective components from the page, as opposed to the complete page, are rendered.
Programmatic Ajax integration is enabled through the resource handling mechanism.
This resource contains the JavaScript API that facilitates Ajax interaction with JSF pages.
You can make it available in pages using the outputScript tag:
Two input text fields accept the username and password, and the third output field displays the status (whether the user is logged in or not)
The form has prependId set to false to ensure that the id of each element is preserved as mentioned in the form.
Otherwise, JSF prepends the form’s id to the id of its children.
The command button has an actionListener identifying the method in the backing bean to be invoked when the button is clicked.
This request is made on the command button’s on click event.
The ability to process only part of the view (name and password elements in this case) is referred to as partial view processing.
Similarly, rendering only part of the output page (the status element in this case) is referred to as partial output rendering.
Table 3-3 lists the possible values of the render attribute.
The execute attribute takes a similar set of values, but the default value for the execute attribute is @this.
This tag may be nested within a single component (enabling Ajax for a single component), or it may be “wrapped” around multiple components (enabling Ajax for many components)
In this code, we use f:ajax to specify the list of input elements using the execute attribute, and the output elements to be rendered using the render attribute.
By default, if f:ajax is nested within a single component and no event is specified, the asynchronous request is fired based upon the default event for the parent component (the on click event in the case of a command button)
A delay attribute may be specified on the f:ajax tag.
If multiple requests are issued before the delay time elapses, then only the most recent request is sent and all others are discarded.
The default value is 300 milliseconds, but you could also specify the special value of none to disable this mechanism.
This listener method is invoked for the default event for the child elements (the value Change event for h:inputText, in this case)
You can specify additional Ajax functionality on the child elements using a nested f:ajax.
View parameters can be used to map URL parameters in GET requests to an EL.
You can do so by adding the following fragment to a Facelets page:
This is achieved by way of a nested f:convert er and f:validator, just like with any h:inputText, and can be done as shown:
You specify the desired Facelets page instead of manually constructing the URL:
Server and Client Extension Points Converters, validators, and listeners are server-side attached objects that add more functionality to the components on a page.
Behaviors are client-side extension points that can enhance a component’s rendered content with behavior-defined scripts.
A converter converts the data entered in a component from one format to another (e.g., string to number)
In this code, the text entered in the text box will be converted to an integer if possible.
An error message is thrown if the text cannot be converted.
In this code, the methods getAsObject and getAsString perform object-to-string and string-to-object conversions between model data objects and a string representation of those objects that is suitable for rendering.
The POJO implements the Converter interface and is also marked with @FacesConverter.
This converter can then be used in a JSF page:
The value attribute of @FacesConverter must match the value of the converterId attribute here.
A validator is used to validate data that is received from the input components.
An error message is thrown if the length is outside the specified range.
In this code, the method validate returns if the value is successfully validated.
The value attribute of @FacesValidator must match the value of the id attribute of f:validator here.
Other than placing annotation constraints on the bean, no additional work is required by the developer.
Any error message because of constraint violation is automatically converted to a FacesMessage and displayed to the end user.
The event can be a change of value, a click of a button, a click on a link, or something else.
A listener can be a method in a managed bean or a class by itself.
In this code, the nameUpdated method in the User bean is called when the associated form is submitted.
Unlike converters, validators, and listeners, a behavior enhances the client-side functionality of a component by declaratively attaching scripts to it.
Client-side behavior also allows you to perform clientside validation and client-side logging, show tooltips, and other similar functionality.
You can define custom behaviors by extending ClientBehaviorBase and marking with @FacesBehavior.
Validating Data In addition to using built-in and creating custom JSF validators, you can specify constraints defined on a backing bean using Bean Validation.
Consider a simple web application that has one page with several text fields inside of a form:
Assume that every text field is bound to a managed bean property that has at least one Bean Validation constraint annotation attached to it:
The validate method of this Validator is called for the user-specified validation constraints during the process validations phase.
This message is then displayed to the user as other validator messages are handled.
Implicit navigation rules look for the outcome of an action (e.g., a click on a link or a button)
If a Facelets page matching the action outcome is found, that page is then rendered:
In this code, clicking the button will render the page login.xhtml in the same directory.
In this code, the page navigation from index.xhtml to login.xhtml only occurs if the user is a premium customer.
This feature borrows core concepts from ADF Task Flows, Spring Web Flow, and Apache MyFaces CODI to provide a modular approach for defining control flow in an application and standardizes them as part of JSF 2.2
Faces Flow provides an encapsulation of related pages and corresponding backing beans as a module.
This module has well-defined entry and exit points assigned by the application developer.
Usually the objects in a faces flow are designed to allow the user to.
An application thus becomes a collection of flows instead of just views.
Imagine a multipage shopping cart with one page for selecting the items, a second page for choosing shipping options, a third page for entering credit card details, and a fourth page for confirming the order.
You can use managed beans to capture the data, session scope variables to pass information between pages, button clicks to invoke the business logic in backing EJBs, and (conditional) navigation rules to go from one page to another.
This flow of sequence will typically be part of a bigger application.
This application, typically with several pages, is one large flow and everything has global visibility with no logical partitioning.
The flow of pages or views cannot be encapsulated as a logical unit and thus cannot be reused—that is, incorporated into another bigger application or flow easily.
The same flow cannot be opened in multiple windows because session scoped variables are used to pass information between pages.
A session-based scope is more than a request scope, but becomes invalid after the browser is closed.
We require a scope of something in between that can span multiple pages per the application logic.
The only way to invoke application logic is to tie it to a UI component activated by the user in a page.
The application is broken into a series of modular flows that can call one another.
The flow of pages can be packaged as a module that can be reused within the same.
Shared memory scope (for example, flow scope) enables data to be passed between.
A new CDI scope, @FlowScoped, can be specified on a bean.
Business logic can be invoked from anywhere in the page based upon the flow.
The flow of application is no longer restricted to flow between pages but instead is defined as flow between “nodes.” There are five different types of nodes:
Method call Invoke application logic from the flow graph via an EL.
Switch Navigation decisions in the flow graph based on Boolean EL.
Flow call Call another flow with parameters and receive return values.
These nodes define the entry and exit points of a flow.
The newly introduced CDI scope @FlowScoped defines the scope of a bean in the specified flow.
In this code, the bean has two flow-scoped variables: address and creditCard.
You can define flows declaratively using <flow-definition>, or programmatically using the fluent FlowBuilder API.
Flows can be packaged in JAR files or in directories.
MyFlow1Definition defines the entry and exit points of a flow, inbound parameter.
In this code: — Flow is defined programmatically via the CDI producer.
A FlowBuilder instance is injected as a parameter via the @FlowBuilderPara meter and is used to define the flow.
The returnNode method is used to define an exit point from the flow.
In this case, the flow is directed to /index for the action goHome.
A named outbound parameter and its value are set via the outboundParameter method.
Every View Declaration Language file, defined by an .xhtml page, in that directory is a view node of that flow.
The start node of the flow is the view whose name is the same as the name of the flow.
Navigation among any of the views in the directory is considered to be within the flow.
Navigation to a view outside of that directory is considered to be an exit of the flow.
It defines the entry and exit points of a flow, inbound parameter name and value coming from another flow, outbound parameter name and value for another flow, and navigation to other nodes:
In this case, the flow is directed to /index for the action goHome.
The WEB-INF directory will contain other resources required by the pages, such as backing beans.
Facelets allows you to create templates using XHTML and CSS that can then be used to provide a consistent look and feel across different pages of an application.
A configurable set of views in the application will be able to declare themselves as template-clients of any template in the resource library contract.
All contracts reside in the contracts directory of the WAR.
All templates and resources for a contract are in their own directory.
For example, the preceding structure has two defined contracts, blue and red.
Each contract has a template.xhtml file, a CSS, and an image.
In the template, it is recommended that you refer to the stylesheets using h:outputStylesheet so that they are resolved appropriately.
The template.xhtml file has <ui:insert> tags called as declared insertion points.
CSS, images, and other resources bundled in the directory are declared resources.
The declared template, declared insertion points, and declared resources together.
A template client needs to know the value of all three in order to use the contract.
The client pages will use the contract by referring to the template:
A contract is applied based upon the URL pattern invoked.
The contracts can be packaged in the META-INF/contracts entry of a JAR file.
Each contract in the JAR file must have a marker file.
The contents of the contracts directory from our application can be packaged in the META-INF/contracts entry of a JAR file, say layout.jar.
This JAR can then be packaged into WEB-INF/lib, and the declared templates can be used in the application:
You can use a new layout.jar file, providing a similar set of declared insertion points and resources (likely with a different CSS), to change the look and feel of the application.
You can change the template of the page dynamically as well by enclosing the template client page ui:composition in an f:view:
The value of this EL is populated from the radio button in the form inside ui:de fine.
Clicking on the Apply command button will apply the chosen template to this page.
These attributes include the type attribute for input elements, which supports values such as email, url, tel, number, range, and date:
This code fragment allows the browser to check whether the entered text is in email format.
In addition, custom data attributes, also known as data-* attributes, can be defined to store custom data private to the page or application.
Every HTML element may have any number of custom data attributes specified, with any value:
This code fragment introduces data-length as a custom data attribute.
These attributes are not rendered but can be read by JavaScript.
The set of available attributes supported by a JSF component is determined by the combination of the UIComponent and Renderer for that tag.
In some cases, the value of the attribute is interpreted by the UIComponent or Renderer (for example, the columns attribute of h:panelGrid), and in others, the value is passed straight through to the user agent (for example, the lang attribute of h:input Text)
The passthrough attributes can be specified in three different ways:
In this code, p is the shortname for the namespace.
In this code, a type attribute of value email is marked as a passthrough attribute.
This mechanism can be applied to any JSF component and is not restricted to just HTML5 elements.
Component Tags JSF 2 defines a variety of component tags.
These component tags are rendered as an HTML element via the HTML RenderKit Renderer.
The form must have multipart/ form-data as the value of enctype.
This is a standard MIME type that should be used for submitting forms that contain files, non-ASCII data, and binary data.
The file is uploaded when the Upload button is clicked.
This code is similar to that previously shown with the following differences:
The <textarea> outside h:form is a placeholder for displaying the status of the file upload.
This tag invokes the statusUpdate method defined separately in JavaScript:
This code prints the event source and name as the Ajax request goes through the JSF Ajax life cycle and receives the standard life-cycle events.
RESTful Web Services are defined as JSR 339, and the complete specification can be downloaded.
Web services designed using REST are called RESTful web services, and their main principles are:
Everything can be identified as a resource, and each resource can be uniquely identified by a URI.
A resource can be represented in multiple formats, defined by a media type.
The media type will provide enough information on how the requested format needs to be generated.
Standard methods are defined for the client and server to negotiate on the content type of the resource.
Use standard HTTP methods to interact with the resource: GET to retrieve a resource, POST to create a resource, PUT to update a resource, and DELETE to remove a resource.
All the associated state required by the server is passed by the client in each invocation.
Java API for RESTful web services (JAX-RS) defines a standard annotation-driven API that helps developers build a RESTful web service in Java and invoke it.
The standard principles of REST, such as identifying a resource as a URI, a well-defined set of methods to access the resource, and multiple representation formats of a resource, can be easily marked in a POJO via annotations.
Resources A simple RESTful web service can be defined as a resource using @Path:
OrderResource is a POJO class and is published as a RESTful resource at the or ders path when we add the class-level @Path annotation.
The Order class is marked with the @XmlRootElement annotation, allowing a conversion between Java and XML.
The getAll resource method, which provides a list of all orders, is invoked when we access this resource using the HTTP GET method; we identify it by specifying the @GET annotation on the method.
The curly braces around oid identify it as a template parameter and bind its value at runtime to the id parameter of the getOrder resource method.
The @PathParam can also be used to bind template parameters to a resource class field.
Typically, a RESTful resource is bundled in a .war file along with other classes and resources.
The Application class and @ApplicationPath annotation are used to specify the base path for all the RESTful resources in the packaged archive.
The Application class also provides additional metadata about the application.
Let’s say this POJO is packaged in the store.war file, deployed at localhost:8080, and the Application class is defined:
You can access a list of all the orders by issuing a GET request to: http://localhost:8080/store/webresources/orders.
You can obtain a specific order by issuing a GET request to: http://localhost:8080/store/webresources/orders/1
Here, the value 1 will be passed to getOrder’s method parameter id.
The resource method will locate the order with the correct order number and return back the Or der class.
The @XmlRootElement annotation ensures that an automatic mapping from Java to XML occurs following JAXB mapping and an XML representation of the resource is returned.
A URI may pass HTTP query parameters using name/value pairs.
You can map these to resource method parameters or fields using the @QueryParam annotation.
If the resource method getAll is updated such that the returned results start from a specific order number, the number of orders returned can also be specified:
By default, a resource method is required to wait and produce a response before returning to the JAX-RS implementation, which then returns control to the client.
It achieves this by first suspending the client connection and later resuming when the response is available:
The getAll method is marked to produce an asynchronous response.
We identify this by injecting a method parameter of the class AsyncResponse using the new annotation @Suspended.
This method returns immediately after forking a new thread, likely using Manage dExecutorService as defined by Concurrency Utilities for Java EE.
The new thread executes the long-running operation and resumes the connection by calling resume when the response is ready.
In this code, the onComplete method is invoked when the request processing is finished, after a response is processed and is sent back to the client, or when an unmapped throwable has been propagated to the hosting I/O container.
In this code, the onDisconnect method is invoked in case the container detects that the remote client connection associated with the asynchronous response has been disconnected.
The @FormParam annotation binds the value of an HTML form parameter to a resource method parameter or a field.
The name attribute in the HTML form and the value of the @FormParam annotation are exactly the same to ensure the binding.
Clicking the submit button in this form will return the XML representation of the created Order.
A Re sponse object may be used to create a custom response.
The content method parameter will have the value New Order.
The content method parameter will have the value New Order.
The HEAD and OPTIONS methods receive automated support from JAX-RS.
The HTTP HEAD method is identical to GET except that no response body is returned.
This method is typically used to obtain metainformation about the resource without requesting the body.
The set of HTTP headers in response to a HEAD request is identical to the information sent in response to a GET request.
The @HEAD annotation is used to mark a method serving HEAD requests:
This method is often used for testing hypertext links for validity, accessibility, and recent modification.
A HEAD request to this resource may be issued as:
The HTTP OPTIONS method requests the communication options available on the request/response identified by the URI.
If no method is designated with @OPTIONS, the JAX-RS runtime generates an automatic response using the annotations on the matching resource class and methods.
An OPTIONS request to this resource may be issued as: curl -i -X OPTIONS http://localhost:8080/store/webresources/orders/1
The HTTP Allow response header provides information about the HTTP operations permitted.
The Content-Type header is used to specify the media type of the body, if any is included.
In addition to the standard set of methods supported with corresponding annotations, HttpMethod may be used to build extensions such as WebDAV.
Multiple Resource Representations By default, a RESTful resource is published or consumed with the */* MIME type.
These annotations may be specified on the resource class or a resource method.
The annotation specified on the method overrides any on the resource class.
The resource method can generate an XML or JSON representation of Order.
The exact return type of the response is determined by the HTTP Accept header in the request.
The following resource method will be dispatched if the HTTP Accept header specifies any application MIME type such as application/xml, application/json, or any other media type:
Here is an example of how multiple MIME types may be consumed by a resource method:
The resource method invoked is determined by the HTTP Content-Type header of the request.
A representation with a qs value of 0.000 will never be chosen.
A representation with no qs parameter value is given a qs factor of 1.0:
You can define a mapping between a custom representation and a corresponding Java type by implementing the MessageBodyReader and MessageBodyWriter interfaces and annotating with @Provider.
Binding a Request to a Resource By default, a new resource is created for each request to access a resource.
The resource method parameters, fields, or bean properties are bound by way of xxxParam annotations added during object creation time.
This code binds the value of the "JSESSIONID" cookie to the resource method parameter sessionid.
FormParam binds the value of a form parameter contained within a request entity body.
You can obtain more details about the application deployment context and the context of individual requests using the @Context annotation.
Here is an updated resource definition where more details about the request context are displayed before the method is invoked:
HttpHeaders provides access to HTTP header information either as a Map or as.
Note that @HeaderParam can also be used to bind an HTTP header to a resource method parameter, field, or bean property.
Request provides a helper to request processing and is typically used with Re sponse to dynamically build the response.
SecurityContext provides access to security-related information about the current request.
Providers supplies information about runtime lookup of provider instances based on a set of search criteria.
Entity Providers JAX-RS defines entity providers that supply mapping services between on-the-wire representations and their associated Java types.
These are specified as method parameters and return types of resource methods.
Applications may provide their own mapping to custom types using the Mes.
This allows us to extend the JAXRS runtime easily to support our own custom entity providers.
The MessageBodyReader interface defines the contract for a provider that supports the conversion of a stream to a Java type.
Conversely, the MessageBodyWriter interface defines the contract for a provider that supports the conversion of a Java type to a stream.
If we do not specify @XmlRootElement on OrderResource, then we need to define the mapping between XML to Java and vice versa.
Java API for XML Processing can be used to define the mapping between the Java type to XML and vice versa.
Similarly, Java API for JSON Processing can be used to define the two-way mapping between Java and JSON:
The method is using the Streaming API defined by Java API for JSON Processing to write Order o to the underlying OutputStream out for the HTTP entity.
The implementation class needs to be marked with @Provider to make it discoverable by the JAX-RS runtime on the server side.
The providers need to be explicitly registered on the client side.
Produces ensures that this entity provider will only support the specified media type:
This method is using the Streaming API defined by Java API for JSON Processing to read Order o from the InputStream in for the HTTP entity.
The implementation class needs to be marked with @Provider to make it discoverable by the JAX-RS runtime.
The providers need to be explicitly registered on the client side.
Consumes ensures that this entity provider will only support the specified media type.
Client API JAX-RS 2 adds a new Client API that can be used to access web resources and provides integration with JAX-RS providers.
Without this API, users must use a low-level HttpUrlConnection to access the REST endpoint:
This code uses the fluent builder pattern and works as follows:
It is used to obtain an instance of Client that uses method chaining to build and execute client requests in order to consume the responses returned.
Clients are heavyweight objects that manage the client-side communication infrastructure.
Initialization as well as disposal of a Client instance may be a rather expensive operation.
It is therefore recommended that you construct only a small number of Client instances in the application.
We create WebTarget by specifying the URI of the web resource.
We then use these targets to prepare client request invocation by resolving the URI template, using the resolveTemplate method for different names.
We can specify additional query or matrix parameters here using the queryParam and matrixParam methods, respectively.
We build the client request by invoking the request method.
We invoke the HTTP GET method by calling the get method.
The fluency of the API hides its complexity, but a better understanding of the flow allows us to write better code.
In this code, a new message entity is created with the specified media type, a POST request is created, and a response of type Order is expected.
There are other variations of the Entity.entity method that would allow us to manipulate the request.
The Entity class defines variants of the most popular media types.
It also allows us to POST an HTML form using the form method.
We can make an HTTP DELETE request by identifying the resource with the URI and using the delete method:
In this code, the call to get after async is called returns immediately without blocking the caller’s thread.
The response is a Future instance that can be used to monitor or cancel asynchronous invocation or retrieve results.
Optionally, InvocationCallback can be registered to receive the events from the asynchronous invocation processing:
The completed method is called on successful completion of invocation, and the response data is made available in the parameter o.
The failed method is called when the invocation is failed for any reason, and the parameter t contains failure details.
A more generic client request can be prepared and executed at a later time.
This enables a separation of concerns between the creator and the submitter:
These requests are then executed at a later time via the invoke method and the result retrieved.
In the first case, a more generic Response is returned, which can then be used to extract the result and other metadata about it.
In the second case, an Order instance is returned because of the type specified before.
In this code, we submit the Invocations for asynchronous execution using the sub mit method.
After waiting for some time, we can obtain the first result by calling the get method on the returned Future.
In the first case, we need to extract the exact result by calling the readEntity method.
In the second case, an Order response is returned directly because of the type specified during the submit invocation.
The application can supply checked or exception mapping to an instance of the Response class.
Let’s say the application throws the following exception if an order is not found:
This ensures that the client receives a formatted response instead of just the exception being propagated from the resource.
Filters and Entity Interceptors JAX-RS 2 defines extension points to customize the request/response processing on both the client and server side.
These are used to extend an implementation in order to provide capabilities such as logging, confidentiality, and authentication.
The two kinds of extension points are: filters and entity interceptors.
Filters are mainly used to modify or process incoming and outgoing request or response headers.
Entity interceptors are mainly concerned with marshaling and unmarshaling of HTTP message bodies.
Filters can be configured on the client and server, giving us four extension points for filters, defined by four interfaces:
The client-side or server-side filters may be implemented by the same class or different classes:
This code shows a simple client-side filter that will log the headers sent as part of the request and received in the response message.
A server-side filter that will log the headers received as part of the request and sent in the response message can be implemented similarly:
In this code, the filter is a provider class and thus must be marked with @Provider.
If the filter is not marked with @Provider, it needs to be explicitly registered in the Application class:
A prematch filter is applied globally on all resources before the resource is matched with the incoming HTTP request.
A pre-match filter is typically used to update the HTTP method in the request and is capable of altering the matching algorithm.
A post-match filter is applied after the resource method has been matched.
You can convert any Contain erRequestFilter to a pre-match filter by adding the @PreMatching annotation.
On the server side, the filters can be registered in four different ways:
Globally bound to all resources and all methods in them By default, if no annotation is specified on the filter, then it is globally bound—that is, it all applies to methods on all resources in an application.
Globally bound to all resources and methods via the meta-annotation @NameBinding The annotation may be specified on the Application class and then the filter becomes globally enabled on all methods for all resources:
This annotation then needs to be specified on the filter implementation and the resource class and/or method:
If the annotation is specified on a resource, then the filter is applied to all methods of the resource.
If the annotation is specified on a specific resource method, then the filter is applied only when that particular method is invoked.
This feature is marked with @Provider and is thus automatically discovered by the JAX-RS runtime.
Multiple filters may be implemented at each extension point and arranged in filter chains.
Filters in a chain are sorted based on their priorities and are executed in order.
The Priorities class defines built-in priorities for security, decoders/encoders, and more.
These rules ensure that response filters are executed in reverse order of request filters.
Filters are executed without method invocation wrapping (i.e., filters execute in their own silos and do not directly invoke the next filter in the chain)
The JAX-RS runtime decides whether to invoke the next filter or not.
Entity interceptors are mainly concerned with marshaling and unmarshaling of HTTP message bodies.
WriterInterceptor operates on the outbound request on the client side and on the outbound response on the server side:
ReaderInterceptor operates on the outbound response on the client side and on the inbound request on the server side:
As with filters, there is an interceptor chain for each kind of entity interceptor.
Entity interceptors in a chain are sorted based on their priorities and are executed in order.
The priorities are sorted in ascending order; the lower the number, the higher the priority.
Filters and entity interceptors may be specified on a client and resource.
Figure 4-1 shows the invocation sequence on both client and server.
Validation of Resources Bean Validation 1.1 allows declarative validation of resources.
The constraints can be specified in any location in which the JAX-RS binding annotations are allowed, with the exception of constructors and property setters:
These fields cannot be null and must be at least one character.
You can specify cross-field and cross-property constraints by declaring annotations on the class:
You can map request entity bodies to resource method parameters and validate them by specifying the constraint on the resource method parameter:
Alternatively, if the request entity is mapped to a bean that is decorated with constraint annotations already, then @Valid can be used to trigger the validation:
JAX-RS constraint validations are carried out in the Default validation group only.
SOAP-Based Web Services are defined as JSR 224, and the complete specification can be downloaded.
The SOAP specification defines an envelope that represents the contents of a SOAP message and encoding rules for data types.
It also defines how SOAP messages may be sent over different transport protocols, such as exchanging messages as the payload of HTTP POST.
The SOAP protocol provides a way to communicate among applications running on different operating systems, with different technologies, and different programming languages.
Java API for XML-Based Web Services (JAX-WS) hides the complexity of the SOAP protocol and provides a simple API for development and deployment of web service endpoints and clients.
The developer writes a web service endpoint as a Java class.
The JAX-WS runtime publishes the web service and its capabilities using Web Services Description Language (WSDL)
Tools provided by a JAX-WS implementation, such as wscompile by the JAX-WS Reference Implementation, are used to generate a proxy to the service and invoke methods on it from the client code.
The JAX-WS runtime converts the API calls to and from SOAP messages and sends them over HTTP, as shown in Figure 5-1
In addition to sending SOAP messages over HTTP, JAX-WS provides XML-over-HTTP protocol binding and is extensible to other protocols and transports.
The XML-overHTTP binding use case is better served by JAX-RS and will not be discussed here.
The JAX-WS specification defines mapping from WSDL 1.1 to Java.
This mapping defines how different WSDL constructs such as wsdl:service, wsdl:portType, and wsdl:operation are mapped to Java.
This mapping is used when web service interfaces for clients and endpoints are generated from a WSDL 1.1 description.
Java to WSDL 1.1 mapping is also defined by this specification.
This mapping defines how Java packages, classes, interfaces, methods, parameters, and other parts of a web service endpoint are mapped to WSDL 1.1 constructs.
This mapping is used when web service endpoints are generated from existing Java interfaces.
This allows a JAX-WS endpoint to be invoked by a client on another operating system written in another programming language and vice versa.
JAX-WS also facilitates, using a nonstandard programming model, the publishing and invoking of a web service that uses WS-* specifications such as WS-Security, WS-Secure Conversation, and WS-Reliable Messaging.
Some of these specifications are already implemented in the JAX-WS implementation bundled as part of GlassFish.
However, this particular usage of JAX-WS will not be discussed here.
Web Service Endpoints You can convert a POJO to a SOAP-based web service endpoint by adding the @WebSer vice annotation:
All public methods of the class are exposed as web service operations.
Even though the name contains the word interface, an interface is not required for building a JAX-WS endpoint.
This approach of starting with a POJO is also called the code-first approach.
There are reasonable defaults for wsdl:service name, wsdl:portType name, wsdl:port name, and other elements in the generated WSDL.
The @WebMethod annotation can be used on each method to override the corresponding default values:
Specifying this annotation overrides the default name of the wsdl:operation matching this method.
Additionally, if any method is annotated with @WebMethod, all other methods of the class are implicitly not available at the SEI endpoint.
If there are multiple methods in the POJO and a particular method needs to be excluded from the web service description, the exclude attribute can be used:
The mapping of Java programming language types to and from XML definitions is delegated to JAXB.
It follows the default Java-to-XML and XML-to-Java mapping for each method parameter and return type.
The usual JAXB annotations can be used to customize the mapping to the generated schema:
In this code, @XmlRootElement allows the Item class to be converted to XML and vice versa.
By default, the generated WSDL uses the document/literal style of binding.
You can change this by specifying the @SOAPBinding annotation on the class:
If this exception is thrown in the business method on the server side, it is propagated to the client side.
If the exception is declared as an unchecked exception, it is mapped to SOAPFaultException on the client side.
The @WebFault annotation may be used to customize the mapping of wsdl:fault in the generated WSDL.
By default, a message follows the request/response design pattern where a response is received for each request.
A method may follow the fire-and-forget design pattern by specifying the @Oneway annotation on it so that a request can be sent from the message.
Such a method must have a void return type and must not throw any checked exceptions:
A WebServiceContext may be injected in an endpoint implementation class: @Resource WebServiceContext context;
This provides information about message context (via the getMessageContext method) and security information (via the getUserPrincipal and isUserInRole methods) relative to a request being served.
Instead of just the mapped Java types, the complete protocol message or protocol message payload is available as Source, DataSource, or SOAPMessage at the endpoint.
The response message also needs to be prepared using these APIs.
In this code, the SOAP body payload is available as a Source.
WebServiceProvider is used to associate the class with a wsdl:service and a wsdl:port element in the WSDL document.
Table 5-2 describes the attributes that can be used to provide additional information about the mapping.
By default, only the message payload (i.e., the SOAP body in the case of the SOAP protocol) is received at the endpoint and sent in a response.
The ServiceMode annotation can be used to override this if the provider endpoint wishes to send and receive the entire protocol message:
In this code, the complete SOAP message is received and sent from the endpoint.
The runtime catches the exception thrown by a Provider endpoint and converts it to a protocol-specific exception (e.g., SOAPFaultException for the SOAP protocol)
Endpoint-Based Endpoints An Endpoint-based endpoint offers a lightweight alternative for creating and publishing an endpoint.
This is a convenient way of deploying a JAX-WS-based web service endpoint from Java SE applications.
In this code, a POJO annotated with @WebService is used as the endpoint implementation.
The address of the endpoint is passed as an argument to Endpoint.publish.
This method call publishes the endpoint and starts accepting incoming requests.
The endpoint implementation can be a Provider-based endpoint as well.
A mapped WSDL is automatically generated by the underlying runtime in this case.
You can publish a contract-first endpoint by packaging the WSDL and specifying the wsdl:port and wsdl:service as part of the configuration:
An Executor may be set on the endpoint to gain better control over the threads used to dispatch incoming requests:
EndpointContext allows multiple endpoints in an application to share any information.
Web Service Client The contract between the web service endpoint and a client is defined through WSDL.
As with an SEI-based web service endpoint, you can easily generate a high-level web service client by importing the WSDL.
Such tools follow the WSDL-to-Java mapping defined by the JAX-WS specification and generate the corresponding classes.
Table 5-3 describes the mapped Java artifact names generated for some of the WSDL elements.
You can generate a new instance of the proxy by calling one of the getPort methods on the generated Service class:
Table 5-4 describes the properties that may be set on the provider.
Typically, a generated client has an endpoint address preconfigured based upon the value of the soap:address element in the WSDL.
Dispatch-Based Dynamic Client A Dispatch-based endpoint provides a dynamic alternative to the generated proxybased client.
Instead of just the mapped Java types, the complete protocol message or protocol message payload is prepared by way of XML APIs.
In this code, we create a Service by specifying the fully qualified QName, a port is created from the service, a Dispatch<Source> is created, and the web service endpoint is invoked.
The business method invoked on the service endpoint is dispatched based upon the received SOAP message.
A pregenerated Service object, generated by a tool following WSDL-to-Java mapping, may be used to create the Dispatch client as well.
In this code, jaxbContext is the JAXBContext used to marshal and unmarshal messages or message payloads.
The Response object can then be used to query (via the isDone method), cancel (via the cancel method), or obtain the results from (via get methods) the method invocation.
You can convert the asynchronous invocation into a blocking request by invoking re sponse.get right after obtaining the response object.
A new class, MyAsyncHandler, registers a callback class that receives control when the response is received from the endpoint.
The response can be used to check if the web.
The handleResponse method of the callback is used to process the response received.
Handlers Handlers are well-defined extension points that perform additional processing of the request and response messages.
Logical handlers are protocol-agnostic and cannot change any protocol-specific parts of a message (such as headers)
Logical handlers act only on the payload of the message.
Protocol handler Protocol handlers are specific to a protocol and may access or change the protocolspecific aspects of a message.
In this code, the handler has implemented the handleMessage, handleFault, and close methods.
The handleMessage method is called for inbound and outbound message processing, and the handleFault method is invoked for fault processing.
Message and handleFault messages return true to continue further processing, and false to block processing.
MessageContext provides a context about the message that is currently being processed by the handler instance.
It provides a predefined set of properties that can be used to communicate among different handlers.
In this code, jaxbObject is obtained as the payload, updated, and then sent back explicitly as the payload on the message.
In this code, the handler has implemented the handleMessage, handleFault, close, and getHeaders methods.
The getHeaders method returns the set of SOAP headers processed by this handler instance.
The handlers within a handler chain are invoked each time a message is sent or received.
Inbound messages are processed by handlers prior to dispatching a request to the service endpoint or returning a response.
Outbound messages are processed by handlers after a request is sent from the client or a response is returned from the service endpoint.
During runtime, the handler chain is reordered such that logical handlers are executed before the SOAP handlers on an outbound message and SOAP handlers are executed before logical handlers on an inbound message.
The sequence of logical and SOAP handlers during a request and response is shown in Figure 5-2
The format is easy for humans and machines to read and write.
A JSON structure can be built as either of the following:
A collection of name/value pairs, generally realized as dictionary, hash table, or associative array.
An ordered list of values, generally realized as an array, list, or sequence.
The following example shows the JSON representation of an object that describes a movie:
The first name is name with a string value for the movie name, the second name is actors with an array value for the actors in the movie, and the third name is year with a number value for the year the movie was released.
Currently, Java applications use different implementation libraries to produce/consume JSON.
Java API for JSON Processing will provide a standard API to parse and generate JSON so that the applications that use the API are smaller and portable.
Produce/consume JSON text in a streaming fashion (similar to StAX API for XML) • Build a Java object model for JSON text (similar to DOM API for XML)
Binding of JSON text to Java objects is outside the scope of this API.
Streaming API The Streaming API provides a way to parse and generate JSON text in a streaming fashion.
The API provides an event-based parser and allows an application developer to ask for the next event (i.e., pull the event), rather than handling the event in a callback.
This gives a developer more procedural control over processing of the JSON.
Parser events can be processed or discarded, or the next event may be generated.
The streaming model is adequate for local processing where only specific parts of the JSON structure need to be accessed, and random access to other parts of the data is not required.
The streaming API is a low-level API designed to process large amounts of JSON data efficiently.
Other JSON frameworks (such as JSON binding) can be implemented with this API.
The streaming API is similar to the StAX API for XML and consists of the interfaces JsonParser for consuming JSON and JsonGenerator for producing JSON.
Json Parser provides forward, read-only access to JSON data using the pull parsing programming model.
In this model, the application code controls the thread and calls methods in the parser interface to move the parser forward or to obtain JSON data from the current state of the parser.
This code shows how to create a parser from an InputStream obtained from a new FileInputStream.
This code shows how to create a parser from a StringReader.
The factory can be configured with the specified map of provider-specific configuration properties.
Any unsupported configuration properties specified in the map are ignored.
In this case, null properties are passed during the creation of the parser factory.
The pull-parsing programming model is used to to parse the JSON.
The next method returns the event for the next parsing state, which could be any of the following types:
The events generated for a nested structure are shown in bold:
Producing JSON Using the Streaming API The Streaming API provides a way to generate well-formed JSON to a stream by writing one event at a time.
JsonGenerator contains writeXXX methods to write name/value pairs in JSON objects and values in JSON arrays:
The factory can be configured with the specified map of provider-specific configuration properties.
Any unsupported configuration properties specified in the map are ignored.
In this case, null properties are passed during the creation of the generator factory.
An empty object, with no name/value pairs, is created and written to the configured output stream.
An object is started when the writeStartObject method is called, and ended with the writeEnd method.
JsonGenerator may be configured to write to a Writer as well.
A name/value pair is written via the write method, which takes a name as the first parameter and a value as the second parameter.
The value can be BigDecimal, BigIn teger, boolean, double, int, long, String, and JsonValue.
A new array is started when the writeStartArray method is called and ended when the writeEnd method is called.
An object within an array is written via the writeStar tObject and writeEnd methods.
Each element of the array is written via the write method, which can take values of the type BigDecimal, BigInteger, boolean, double, int, long, String, and JsonValue.
These JSON structures are represented as object models via the Java types JsonObject and JsonArray.
JsonObject provides a Map view to access the unordered collection of zero or more name/value pairs from the model.
Similarly, JsonArray provides a List view to access the ordered sequence of zero or more values from the model.
This programming model is most flexible and enables processing that requires random access to the complete contents of the tree.
However, it is often not as efficient as the streaming model and requires more memory.
The Object Model API is similar to the DOM API for XML and uses builder patterns to create these object models.
It consists of the interfaces JsonReader (for consuming JSON) and JsonObjectBuilder and JsonArrayBuilder (for producing JSON)
Consuming JSON Using the Object Model API JsonReader contains methods to read JSON data using the object model from an input source.
This code shows how to create a new parser from an InputStream obtained from a new FileInputStream.
This code shows how to create a parser from a StringReader.
The factory can be configured with the specified map of provider-specific configuration properties.
Any unsupported configuration properties specified in the map are ignored.
In this case, null properties are passed during the creation of the reader factory.
In this code, a JsonReader is initialized via StringReader, which reads the empty JSON object.
In this code, the getString method returns the string value for the specific key in the object.
Other getXXX methods can be used to access the value based upon the data type.
In this code, calling the readArray method returns an instance of the JsonArray interface.
This interface has convenience methods to get boolean, integer, and String values at a specific index.
Similarly, JsonArrayBuilder can be used to create models that represent JSON arrays where the resulting model is of type JsonArray:
In this code, a JsonObjectBuilder is used to create an empty object.
The factory can be configured with the specified map of provider-specific configuration properties.
Any unsupported configuration properties specified in the map are ignored.
In this case, null properties are passed during the creation of the reader factory.
In this code, a new JsonWriter instance is created and configured to write to Sys tem.out.
The previously created jsonObject is then written when the writeObject method is called.
JsonWriter may be configured to write to a Writer as well.
A name/value pair is written via the add method, which takes a name as the first parameter and a value as the second parameter.
Specifying the value as JsonObjectBuilder and JsonArrayBuilder allows us to create nested objects and arrays.
You write an object within an array by calling the add method and creating a new object using the JsonObjectBuild er method.
Each element of the array is written via the add method, which can take values of the type BigDeci mal, BigInteger, boolean, double, int, long, String, JsonValue, JsonObjectBuild er, and JsonArrayBuilder.
The Java API for WebSocket is defined as JSR 356, and the complete specification can be downloaded.
WebSocket provides a full-duplex and bidirectional communication protocol over a single TCP connection.
Full-duplex means a client and server can send messages independent of each other.
Bidirectional means a client can send a message to the server and vice versa.
The protocol defines an opening handshake and basic message framing, layered over TCP.
The API enables web pages to use the WebSocket protocol for twoway communication with the remote host.
Unlike HTTP, there is no need to create a new TCP connection and send a message chock-full of headers for every exchange between client and server.
There are no predefined message exchange patterns of request/response or one-way between client and server.
These need to be explicitly defined over the basic protocol.
The communication between client and server is pretty symmetric, but there are two differences:
A client initiates a connection to a server that is listening for a WebSocket request.
Other than these two differences, the client and server behave symmetrically after the opening handshake.
After a successful handshake, clients and servers transfer data back and forth in conceptual units referred to as messages.
On the wire, a message is composed of one or more frames.
Java API for WebSocket defines a standard API for building WebSocket applications and will provide support for:
ServerEndpoint decorates the class as a WebSocket endpoint published at the URI mentioned as a value of the annotation.
The annotation can have the attributes specified in Table 7-1
OnMessage decorates a Java method that receives the incoming WebSocket message.
The text and binary messages contain the payload generated by the application.
A pong message is a WebSocket control message and is generally not dealt with at the application layer.
The method can have the following parameters: — Each method can process text, binary, or pong messages.
If the method is handling text messages: — Use a String to receive the whole text message:
Use a Java primitive or class equivalent to receive the whole message converted to that type:
The Boolean parameter is true if the part received is the last part, and false otherwise.
Use byte[] and a boolean pair, or ByteBuffer and a boolean pair, to receive the message in parts:
The Boolean parameter is true if the part received is the last part, and false otherwise.
If the method is handling pong messages: — Use PongMessage to receive the pong message:
PathParam is used to annotate the room method parameter on a server endpoint where a URI template has been used in the path mapping of the ServerEnd point annotation.
The method parameter may be of type String, any Java primitive type, or any boxed version thereof.
If a client URI matches the URI template, but the requested path parameter cannot be decoded, then the WebSocket’s error handler will be called.
Session indicates a conversation between two WebSocket endpoints and represents the other end of the connection.
In this case, a response to the client may be returned:
Such a message is consumed at the endpoint without returning a response.
The method may have String, ByteBuffer, byte[], any Java primitive or class equivalent, and any other class for which there is an encoder as the return value.
If a return type is specified, then a response is returned to the client.
The maxMessageSize attribute may be used to define the maximum size of the message in bytes that this method will be able to process:
In this code, if a message of more than 6 bytes is received, then an error is reported and the connection is closed.
You can receive the exact error code and message by intercepting the life-cycle callback using @OnClose.
The default value is -1 to indicate that there is no maximum.
The maxMessageSize attribute only applies when the annotation is used to process whole messages, not to those methods that process messages in parts or use a stream or reader parameter to handle the incoming message.
Encoders provide a way to convert custom Java objects into WebSocket messages and can be specified via the encoders attribute.
Decoders provide a way to convert WebSocket messages to custom Java objects and can be specified via the decoders attribute.
An optional configurator attribute can be used to specify a custom configuration class for configuring new instances of this endpoint:
This abstract class offers several methods to configure the endpoint, such as providing custom configuration algorithms and intercepting the opening handshake.
The modifyHandshake method is called when a handshake response resulting from a well-defined handshake request is prepared.
HandshakeRequest provides information about the WebSocket defined HTTP GET request for the opening handshake.
This class provides access to data such as the list of HTTP headers that came with the request or the HttpSession that the handshake request was part of.
HandshakeResponse identifies the HTTP handshake response prepared by the container.
The configurator attribute is used to specify the custom configurator class as part of @ServerEndpoint.
OnOpen can be used to decorate a method to be called when a new connection from a peer is received.
Similarly, @OnClose can be used to decorate a method to be called when a connection is closed from the peer.
OnError may be used to decorate a method to be called when an error is received.
The open method is called when a new connection is established with this endpoint.
The parameter s provides more details about other end of the connection.
The close method is called when the connection is terminated.
The parameter c provides more details about why a WebSocket connection was closed.
The error method is called when there is an error in the connection.
For endpoints deployed in the Java EE platform, full dependency injection support as described in the CDI specification is available.
Field, method, and constructor injection is available in all WebSocket endpoint classes.
Interceptors may be enabled for these classes using the standard mechanism:
In this code, the User bean is injected using the standard injection mechanism.
The WebSocket annotation behaviors are not passed down the Java class inheritance hierarchy.
They apply only to the Java class on which they are marked.
In this code, the ChatServer class is identified as a WebSocket endpoint; however, CustomChatServer is not.
If it needs to be recognized as a WebSocket endpoint, then it must be explicitly marked with a class-level @ServerEndpoint annotation.
Subclasses of an annotated endpoint may not use method-level WebSocket annotations unless they themselves use a class-level WebSocket annotation.
Subclasses that override methods annotated with WebSocket method annotations do not obtain WebSocket callbacks unless those subclass methods themselves are marked with a method-level WebSocket annotation.
Programmatic Server Endpoint You can create a WebSocket server endpoint by extending the Endpoint class.
In this code, the onOpen method is called when a new connection is initiated.
Endpoint Config identifies the configuration object used to configure this endpoint.
Multiple MessageHandlers may be registered in this method to process incoming text, binary, and pong messages.
However, only one MessageHandler per text, binary, or pong message may be registered per Endpoint:
The onMessage method of the handler is invoked when the message is received.
The parameter s is bound to the payload of the message.
The onMessage method of the handler is invoked when the message is received.
The parameter b is bound to the payload of the message.
The onMessage method of the handler is invoked when the message is received.
The parameter p is bound to the payload of the message.
Although not required, a response can be sent to the other end of the connection synchronously:
In the first variation, a callback handler SendHandler is registered.
The onResult method of the registered handler is called once the message has been transmitted.
The parameter sr indicates whether the message was sent successfully, and if not, it carries an exception to indicate what the problem was.
The returned Future object is used to track the progress of the transmission.
Errors in transmission are wrapped in the Execu tionException thrown when the Future object is queried.
The Endpoint.onClose and onError methods can be overridden to invoke other lifecycle callbacks:
In the onClose method, the c parameter provides more details about why the WebSocket connection was closed.
Likewise, the t parameter provides more details about the error received.
The Boolean parameter is true if the part received is the last part, and false otherwise.
This interface provides methods to specify the WebSocket endpoints within an archive that must be deployed:
The URI of the endpoint is specified here as well.
The modifyHandshake method is used to intercept the opening handshake.
Serv erEndpointConfig is the endpoint configuration object used to configure this.
HandshakeRequest provides information about the WebSocket-defined HTTP GET request for the opening handshake.
This class provides access to data such as the list of HTTP headers that came with the request or the HttpSession that the handshake request was part of.
HandshakeResponse identifies the HTTP handshake response prepared by the container.
For endpoints deployed in the Java EE platform, full dependency injection support as described in the CDI specification is available.
Field, method, and constructor injection is available in all WebSocket endpoint classes.
Interceptors may be enabled for these classes via the standard mechanism:
In this code, the MyBean bean is injected via the standard injection mechanism.
Annotated Client Endpoint You can convert a POJO to a WebSocket client endpoint by using @ClientEndpoint:
The @ClientEndpoint decorates the class as a WebSocket client endpoint.
The annotation can have the attributes described in Table 7-2
The open method is called when a new connection is established with this endpoint.
The parameter s provides more details about the other end of the connection.
The close method is called when the connection is terminated.
The parameter c provides more details about why a WebSocket connection was closed.
The error method is called when there is an error in the connection.
A new outbound message from the client to the endpoint can be sent during the connection initiation—for example, in the open method:
An inbound message from the endpoint can be received in any Java method decorated with @OnMessage:
The processMessage method is invoked when a message is received from the endpoint.
The message parameter is bound to the payload of the message.
The session parameter provides more details about the other end of the.
ContainerProvider uses the ServiceLoader mechanism to load an implementation of ContainerProvider and provide a new instance of WebSocketContainer.
WebSocketContainer allows us to initiate a WebSocket handshake with the endpoint.
The client connects to the endpoint by invoking the connectToServer method and providing the decorated client class and the URI of the endpoint.
This method blocks until the connection is established, or throws an error if either the connection could not be made or there was a problem with the supplied endpoint class.
You can use an optional configurator attribute to specify a custom configuration class for configuring new instances of this endpoint:
This abstract class provides two methods to configure the client endpoint: beforeRequest and afterResponse.
The beforeRequest method is called after the handshake request that will be used to initiate the connection to the.
The afterRes ponse method is called after a handshake response is received from the server as a result of a handshake interaction it initiated.
The headers parameter is a mutable map of handshake request headers the implementation is about to send to start the handshake interaction.
The configurator attribute is used to specify the custom configurator class as part of @ClientEndpoint.
As for annotation-based server endpoints, the WebSocket annotation behaviors are not passed down the Java class inheritance hierarchy.
They apply only to the Java class on which they are marked.
Subclasses of an annotated endpoint may not use method-level WebSocket annotations unless they themselves use a class-level WebSocket annotation.
Subclasses that override methods annotated with WebSocket method annotations do not obtain WebSocket callbacks unless those subclass methods themselves are marked with a method-level WebSocket annotation.
Programmatic Client Endpoint You can also create a WebSocket client endpoint by extending the Endpoint class.
In this code, the onOpen method is called when a new connection is initiated.
Endpoint Config identifies the configuration object used to configure this endpoint.
This endpoint is configured via multiple MessageHandlers, as for the interface-based server endpoint.
The programmatic client endpoint can connect to the endpoint via ContainerProvider:
ContainerProvider uses the ServiceLoader mechanism to load an implementation of ContainerProvider and provide a new instance of WebSocketContainer.
WebSocketContainer allows us to initiate a WebSocket handshake with the endpoint.
The client connects to the endpoint by invoking the connectToServer method and providing the programmatic client endpoint and the URI of the endpoint as parameters.
This method blocks until the connection is established, or throws an error if either the connection could not be made or there was a problem with the supplied endpoint class.
You use the default configuration of the client endpoint by passing null as the second parameter.
This abstract class provides two methods to configure the client endpoint: beforeRequest and afterResponse.
The beforeRequest method is called after the handshake request that will be used to initiate the connection to the server is formulated, but before any part of the request is sent.
The afterResponse method is called after a handshake response is received from the server as a result of a handshake interaction it initiated.
For endpoints deployed in the Java EE platform, full dependency injection support as described in the CDI specification is available.
Field, method, and constructor injection is available in all WebSocket endpoint classes.
Interceptors may be enabled for these classes via the standard mechanism:
In this code, the MyBean bean is injected using the standard injection mechanism.
The API allows us to connect to a WebSocket endpoint by specifying the URL and an optional list of subprotocols:
We invoke the WebSocket constructor by specifying the URI where the endpoint is published.
The ws:// protocol scheme defines the URL to be a WebSocket endpoint.
The wss:// scheme may be used to initiate a secure connection.
WebSocket endpoint is hosted at localhost host and port 8080
You can specify an optional array of subprotocols in the constructor; the default.
An established WebSocket connection is available in the JavaScript websocket.
The API defines event handlers that are invoked for different life-cycle methods:
The onopen event handler is called when a new connection is initiated.
The onerror event handler is called when an error is received during the.
The onclose event handler is called when the connection is terminated:
This code reads the value entered in a text field called myField, creates a binary array buffer of the length specified in that field, and sends it as a binary message to the WebSocket endpoint.
The binaryType attribute can be set to blob or arraybuffer to send different types of binary data.
Any message exchange patterns, such as request-response, need to be explicitly built at the application level.
Encoders and Decoders Applications can receive and send a payload in raw text and binary format.
This code shows how a String payload is decoded to MyMessage type.
The decode method decodes the String parameter into an object of type MyMessage, and the will Decode method returns true if the string can be decoded into the object of type MyMes sage.
Standard javax.json.* APIs are used to generate the JSON representation from a string:
This code defines how a MyMessage type is encoded to a String, and the encode method encodes the message parameter into a String.
You can specify the encoders and decoders on an annotated endpoint using the encod ers and decoders attributes of @ServerEndpoint:
The first encoder that matches the given type is used.
The first decoder where the willDecode method returns true is used.
In this code, the Encoder and Decoder list is initialized in the constructor and sets the encoder and decoder implementation using the encoders and decoders methods.
You can specify the encoders and decoders on a client endpoint using the encoders and decoders attributes of @ClientEndpoint:
The client endpoint sends a message using sendObject instead of sendString.
In this code, the Encoder and Decoder list is initialized with the encoder and decoder implementations.
The encoders and decoders methods on ClientEndpointCon fig.Builder can be used to set the encoders and decoders.
Integration with Java EE Security A WebSocket mapped to a given ws:// URI is protected in the deployment descriptor with a listing to an http:// URI with same hostname, port, and path since this is the URL of its opening handshake.
The authentication and authorization of the WebSocket endpoint builds on the servlet-defined security mechanism.
A WebSocket that requires authentication must rely on the opening handshake request that seeks to initiate a connection to be previously authenticated.
Typically, this will be performed by an HTTP authentication (perhaps basic or form-based) in the web application containing the WebSocket prior to the opening handshake to the WebSocket.
Accordingly, WebSocket developers may assign an authentication scheme, user-rolebased access, and a transport guarantee to their WebSocket endpoints.
All HTTP GET requests require basic authentication defined by BASIC in <authmethod>
Invoking any page in the application will prompt the user to enter a username and password.
The entered credentials must match one of the users in the group g1
Any subsequent requests, including the WebSocket opening handshake, will occur in the authenticated request.
If a client sends an unauthenticated opening handshake request for a WebSocket that is protected by the security mechanism, a 401 (Unauthorized) response to the opening handshake request is returned and the WebSocket connection is not initialized.
A transport guarantee of NONE allows unencrypted ws:// connections to the WebSocket.
A transport guarantee of CONFIDENTIAL only allows access to the WebSocket over an encrypted (wss://) connection.
Enterprise JavaBeans (EJB) is defined as JSR 345, and the complete specification can be downloaded.
Enterprise JavaBeans are used for the development and deployment of componentbased distributed applications that are scalable, transactional, and secure.
An EJB typically contains the business logic that operates on the enterprise’s data.
The service information, such as transaction and security attributes, may be specified in the form of metadata annotations, or separately in an XML deployment descriptor.
A bean instance is managed at runtime by a container.
The bean is accessed on the client and is mediated by the container in which it is deployed.
The client can also be on the server in the form of a managed bean, a CDI bean, or a servlet of some sort.
In any case, the EJB container provides all the plumbing required for an enterprise application.
This allows the application developer to focus on the business logic and not worry about lowlevel transaction and state management details, remoting, concurrency, multithreading, connection pooling, or other complex low-level APIs.
It is strongly recommended to use the Java Persistence API for all the persistence and object/relational mapping functionality.
Stateful Session Beans A stateful session bean contains conversational state for a specific client.
The state is stored in the session bean instance’s field values, its associated interceptors and their.
You can define a simple stateful session bean by using @Stateful: package org.sample;
That’s all it takes to convert a POJO to a stateful session bean.
All public methods of the bean may be invoked by a client.
A client may remove a stateful session bean by invoking the remove method.
Calling this method will result in the container calling the method marked with the @PreDestroy annotation.
Removing a stateful session bean means that the instance state specific to that client is gone.
This style of bean declaration is called as a no-interface view.
Such a bean is only locally accessible to clients packaged in the same archive.
If the bean needs to be remotely accessible, it must define a separate business interface annotated with @Remote:
Now the bean is injected via the interface: @Inject Cart cart;
A client of this stateful session bean can access this bean: @Inject Cart cart;
The bean class must implement the interface or the interface must be designated as a local or remote business interface of the bean by means of the Local or Remote annotation or in the deployment descriptor.
In this code, if Cart and Payment have no annotations of their own, then they are exposed as local views of the bean.
In this code, the bean Bean only exposes one remote interface, Cart.
The PostConstruct and PreDestroy lifecycle callback methods are available for stateful session beans.
An EJB container may decide to passivate a stateful session bean to some form of secondary storage and then activate it again.
The container takes care of saving and restoring the state of the bean.
However, if there are nonserializable objects such as open sockets or JDBC connections, they need to be explicitly closed and restored as part of that process.
For example, a stateful session bean may contain nonserializable attributes, which would lead to runtime exceptions during passivation, or passivation and acivation of such instances may cause degradation of an application performance:
In this code, the stateful EJB will not be passivated.
The @PrePassivate life-cycle callback method is invoked to clean up resources before the bean is passivated, and the PostActivate callback method is invoked to restore the resources.
Stateless Session Beans A stateless session bean does not contain any conversational state for a specific client.
All instances of a stateless bean are equivalent, so the container can choose to delegate a client-invoked method to any available instance.
Since stateless session beans do not contain any state, they don’t need to be passivated.
You can define a simple stateless session bean by using @Stateless:
That’s all it takes to convert a POJO to a stateless session bean.
All public methods of the bean may be invoked by a client.
This style of bean declaration is called as a no-interface view.
Such a bean is only locally accessible to clients packaged in the same archive.
If the bean needs to be remotely accessible, it must define a separate business interface annotated with @Remote:
Now the bean is injected via the interface: @EJB Account account;
The PostConstruct and PreDestroy life-cycle callbacks are supported for stateless session beans.
The PostConstruct callback method is invoked after the no-args constructor is invoked and all the dependencies have been injected, and before the first business method is invoked on the bean.
This method is typically where all the resources required for the bean are initialized.
The PreDestroy life-cycle callback is called before the instance is removed by the container.
This method is where all the resources acquired during PostConstruct are released.
As stateless beans do not store any state, the container can pool the instances, and all of them are treated equally from a client’s perspective.
Any instance of the bean can be used to service the client’s request.
Singleton Session Beans A singleton session bean is a session bean component that is instantiated once per application and provides easy access to shared state.
If the container is distributed over multiple virtual machines, each application will have one instance of the singleton for each JVM.
A singleton session bean is explicitly designed to be shared and supports concurrency.
The container is responsible for when to initialize a singleton bean instance.
However, you can optionally mark the bean for eager initialization by annotating it with @Startup:
The container now initializes all such startup-time singletons, executing the code marked in @PostConstruct, before the application becomes available and any client request is serviced.
The container ensures that Foo bean is initialized before Bar bean.
A singleton bean supports PostConstruct and PreDestroy life-cycle callback methods.
By default, a singleton bean is marked for container-managed concurrency, but alternatively may be marked for beanmanaged concurrency.
Container-managed concurrency is based on method-level locking metadata where each method is associated with either a Read (shared) or Write (exclusive) lock.
A Write lock waits for the processing of one invocation to complete before allowing the next invocation to proceed.
By default, a Write lock is associated with each method of the bean.
These annotations may be specified on the class, a business method of the class, or both.
A value specified on a method overrides a value specified on the bean.
Bean-managed concurrency requires the developer to manage concurrency using Java language–level synchronization primitives such as synchronized and volatile.
Life-Cycle Event Callbacks Life-cycle callback interceptor methods may be defined for session beans and messagedriven beans.
An AroundConstruct life-cycle callback interceptor method may be defined on an interceptor class only.
All other interceptor methods can be defined on an interceptor class and/or directly on the bean class.
The AroundConstruct callback annotation designates an interceptor method that receives a callback when the target class constructor is invoked.
This callback interceptor method may be defined only on interceptor classes and/or superclasses of interceptor classes and cannot be defined on the target class.
The PostConstruct annotation is used on a method that needs to be executed after dependency injection is done to perform any initialization and before the first business method invocation on the bean instance.
The method annotated with PostConstruct is invoked even if the class does not request any resources to be injected.
In this code, the bean’s default constructor is called first, then AnotherBean is injected, and finally the setupResources method is called before any of the business methods can be called.
This life-cycle callback interceptor method for different types of session beans occurs in the following transaction contexts:
For a stateless session bean, it executes in an unspecified transaction context.
For a stateful session bean, it executes in a transaction context determined by the life-cycle callback method’s transaction attribute.
For a singleton session bean, it executes in a transaction context determined by the bean’s transaction management type and any applicable transaction attribute.
The PreDestroy annotation is used on methods as a callback notification to signal that the instance is in the process of being removed by the container.
The method annotated with PreDestroy is typically used to release resources that it has been holding:
In this code, the cleanupResources method is called before the instance is removed by the container.
This life-cycle callback interceptor method for different types of session beans occurs in the following transaction contexts:
For a stateless session bean, it executes in an unspecified transaction context.
For a stateful session bean, it executes in a transaction context determined by.
For a singleton session bean, it executes in a transaction context determined.
The PrePassivate annotation can only be used on a stateful session bean.
This annotation designates a method to receive a callback before a stateful session bean is passivated:
These methods are ignored for stateless or singleton session beans.
This life-cycle callback interceptor method executes in a transaction context determined by the life-cycle callback method’s transaction attribute.
The PostActivate annotation can only be used on a stateful session bean.
This annotation designates a method to receive a callback after a stateful session bean is activated:
These methods are ignored for stateless or singleton session beans.
This life-cycle callback interceptor method executes in a transaction context determined by the life-cycle callback method’s transaction attribute.
Life-cycle callback interceptor methods may throw system runtime exceptions, but not application exceptions.
Message-Driven Beans A message-driven bean (MDB) is a container-managed bean that is used to process messages asynchronously.
An MDB can implement any messaging type, but is most commonly used to process Java Message Service (JMS) messages.
These beans are stateless and are invoked by the container when a JMS message arrives at the destination.
A session bean can receive a JMS message synchronously, but a message-driven bean can receive a message asynchronously.
In this code, @MessageDriven defines the bean to be a message-driven bean.
The map pedName attribute specifies the JNDI name of the JMS destination from which the bean will consume the message.
The bean must implement the MessageListener interface, which provides only one method, onMessage.
This code shows how a text message is received by the onMessage method and how the message body can be retrieved and displayed:
Even though a message-driven bean cannot be invoked directly by a session bean, it can still invoke other session beans.
Table 8-1 defines the standard set of configuration properties that are supported.
A single message-driven bean can process messages from multiple clients concurrently.
Just like stateless session beans, the container can pool the instances and allocate enough.
A message is delivered to a message-driven bean within a transaction context, so all operations within the onMessage method are part of a single transaction.
The transaction context is propagated to the other methods invoked from within onMessage.
This provides access to the runtime message-driven context that is associated with the instance for its lifetime:
A bean that implements a no-method interface exposes as message listener methods all public methods of the bean class and of any superclasses except the java.lang.Ob ject.
This feature cannot be used today but provides an extension point that allows the MDBs to provide additional functionality in the future.
Portable Global JNDI Names A session bean can be packaged in an ejb-jar file or within a web application module (.war)
An optional EJB deployment descriptor, ejb-jar.xml, providing additional information about the deployment may be packaged in an ejb-jar or .war file.
A local or no-interface bean packaged in the .war file is accessible only to other components within the same .war file, but a bean marked with @Remote is remotely accessible independent of its packaging.
The ejb-jar file may be deployed by itself or packaged within an .ear file.
The beans packaged in this ejb-jar can be accessed remotely.
If the bean exposes only one client interface (or alternatively has only a no-interface view), the bean is also exposed with an additional JNDI name using the following syntax:
The stateless session bean is also available through the java:app and java:module namespaces.
If the AccountSessionBean is packaged in bank.war, then the following JNDI entries are exposed:
Transactions A bean may use programmatic transaction in the bean code, which is called a beanmanaged transaction.
Alternatively, a declarative transaction may be used in which the transactions are managed automatically by the container; this is called a containermanaged transaction.
The @TransactionManage ment annotation is used to declare whether the session bean or message-driven bean uses a bean-managed or container-managed transaction.
The value of this annotation is either CONTAINER (the default) or BEAN.
Container-managed transaction is the default and does not require you to specify any additional annotations on the class.
The EJB container implements all the low-level transaction protocols, such as the two-phase commit protocol between a transaction manager and a database system or messaging provider, to honor the transactional semantics.
The changes to the underlying resources are all committed or rolled back.
A stateless session bean using a container-managed transaction can use @Transactio nAttribute to specify transaction attributes on the bean class or the method.
There are no additional annotations specified on the bean class or the method.
If the client calls with a transaction context, then it behaves as REQUIRED.
Otherwise, the container starts a new transaction before delegating a call to the business method and attempts to commit the transaction when the business process has completed.
REQUIRES_NEW The container always starts a new transaction context before delegating a call to the business method and attempts to commit the transaction when the business process has completed.
If the client calls with a transaction context, then the suspended transaction is resumed after the new transaction has committed.
If the client calls without a transaction context, then it behaves as NOT_SUPPORTED.
NOT_SUPPORTED If the client calls with a transaction context, then the container suspends and resumes the association of the transaction context before and after the business method is invoked.
If the client calls without a transaction context, then no new transaction context is created.
If the client calls without a transaction context, then it behaves as NOT_SUPPORTED.
The values specified in the deployment descriptor override or supplement the transaction attributes specified in the annotation.
Only the NOT_SUPPORTED and REQUIRED transaction attributes may be used for messagedriven beans.
A JMS message is delivered to its final destination after the transaction is committed, so the client will not receive the reply within the same transaction.
Asynchronous Invocation Each method of a session bean is invoked synchronously (i.e., the client is blocked until the server-side processing is complete and the result returned)
A session bean may tag a method for asynchronous invocation, and a client can then invoke that method asynchronously.
This returns control to the client before the container dispatches the instance to a bean.
The asynchronous operations must have a return type of void or Future<V>
The methods with a void return type are used for a fire-and-forget pattern.
The other version allows the client to retrieve a result value, check for exceptions, or attempt to cancel any in-progress invocations.
The @Asynchronous annotation is used to mark a specific method (method level) or all methods (class level) of the bean as asynchronous.
Here is an example of a stateless session bean that is tagged as asynchronous at the class level:
The method signature returns Future<Integer> and the return type is AsyncResult(In teger)
AsyncResult is a new class introduced in EJB 3.1 that wraps the result of an asynchronous method as a Future object.
Behind the scenes, the value is retrieved and sent to the client.
Adding any new methods to this class will automatically make them asynchronous as well.
This session bean can be injected and invoked in any Java EE component: @EJB MyAsyncBean asyncBean;
The client transaction context does not propagate to the asynchronous business method.
This means that the semantics of the REQUIRED transaction attribute on an asynchronous method are exactly the same as REQUIRES_NEW.
The client security principal propagates to the asynchronous business method.
This means the security context propagation behaves the same way for synchronous and asynchronous method execution.
Timers The EJB Timer Service is a container-managed service that allows callbacks to be scheduled for time-based events.
These events are scheduled according to a calendar-based schedule at a specific time, after a specific elapsed duration, or at specific recurring intervals.
The first way to execute time-based methods is by marking any method of the bean with @Schedule:
In this code, the printTime method is called every 10th second of every minute of every hour.
Schedule also takes year and month fields, with a default value of * indicating to execute this method each month of all years.
The EJB container reads the @Schedule annotations and automatically creates timers.
Note that there is no need for an @Startup annotation here, as life-cycle callback methods are not required.
Each redeploy of the application will automatically delete and recreate all the schedule-based timers.
You can easily create the single-action timer by specifying fixed values for each field:
Timers are not for real time, as the container interleaves the calls to a timeout callback method with the calls to the business methods and the life-cycle callback methods of the bean.
So the timed-out method may not be invoked at exactly the time specified at timer creation.
The Timer Service allows for programmatic creation and cancellation of timers.
You can create programmatic timers using the createXXX methods on TimerService.
The method to be invoked at the scheduled time may be the ejbTimeout method from TimedObject:
The initTimer method is a life-cycle callback method that cleans up any previously created timers and then creates a new timer that triggers every 10th second.
The ejbTi meout method, implemented from the TimedObject interface, is invoked every time the timeout occurs.
The timer parameter in this method can be used to cancel the timer, get information on when the next timeout will occur, get information about the timer itself, and gather other relevant data.
Note that the timers are created in the life-cycle callback methods, thus ensuring that they are ready before any business method on the bean is invoked.
These include both the programmatically created timers and the automatically created timers.
The fourth way to create timers is by tagging a method for execution on a timer expiration using ejb-jar.xml.
You can convert the method timeout into a timer method by adding the following fragment to ejb-jar.xml:
Timers can be created in stateless session beans, singleton session beans, and messagedriven beans, but not stateful session beans.
This functionality may be added to a future version of the specification.
The timer-based events can only be scheduled in stateless session beans and singleton session beans.
Embeddable API The Embeddable EJB API allows client code and its corresponding enterprise beans to run within the same JVM and class loader.
The client uses the bootstrapping API from the javax.ejb package to start the container and identify the set of enterprise bean components for execution.
This provides better support for testing, offline processing, and executing EJB components within a Java SE environment.
The following sample code shows how to write a test case that starts the embeddable EJB container, looks up the loaded EJB using the Portable Global JNDI Name, and invokes a method on it:
The embeddable EJB container uses the JVM classpath to scan for the EJB modules to be loaded.
The client can override this behavior during setup by specifying an alternative set of target modules:
This code will load only the bar EJB module in the embeddable container.
Table 8-4 explains the properties that may be used to configure the EJB container.
String Fully qualified name of the embeddable container provider class to be used for this application.
If included in the classpath, specified as String or String[]
If not in the classpath, specified as File or File[] where each object refers to an ejb-jar or exploded ejb-jar directory.
As explained earlier, the Web Profile offers a reasonably complete stack composed of standard APIs, and is capable out-of-the-box of addressing a wide variety of web applications.
The applications targeted toward web profiles will want to use transactions, security, and other functionality defined in the EJB specification.
No new functionality is defined as part of EJB Lite; it is merely a proper subset of the full functionality.
This allows the EJB API to be used in applications that may have much smaller installation and runtime footprints than a typical full Java EE implementation.
Local asynchronous session bean invocations and the nonpersistent EJB Timer Service are new additions in EJB 3.2 Lite.
A full Java EE–compliant application server is required to implement the complete set of functionality.
Contexts and Dependency Injection (CDI) is defined as JSR 346, and the complete specification can be downloaded.
A bean specifies only the type and semantics of other beans it depends upon, without a string name and using the type information available in the Java object model.
The injection request need not be aware of the actual life cycle, concrete implementation, threading model, or other clients of the bean.
The bean so injected has a well-defined life cycle and is bound to life-cycle contexts.
The injected bean is also called a contextual instance because it is always injected in a context.
Almost any POJO can be injected as a CDI bean.
This includes EJBs, JNDI resources, entity classes, and persistence units and contexts.
Even the objects that were earlier created by a factory method can now be easily injected.
Specifically, CDI allows EJB components to be used as JSF managed beans, thus bridging the gap between the transactional and the web tier.
It is also integrated with Unified Expression Language (UEL), allowing any contextual object to be used directly within a JSF or JSP page.
Discovery of Beans Bean classes are deployed in bean archives.
A bean archive has the bean discovery modes listed in Table 9-1
A bean archive that does not contain beans.xml but contains one or more bean classes with a bean-defining annotation, or one or more session beans, is considered an implicit bean archive.
A bean with a declared scope type is said to have a bean-defining annotation.
An explicit bean archive is an archive that contains a beans.xml file with any of the following conditions:
A sample beans.xml file contains the starting and ending beans tag, with namespaces and attributes.
An explicit bean archive has a bean discovery mode of all.
A bean archive that contains a beans.xml file with version 1.1 (or later) must specify the bean-discovey-mode attribute.
If it exists in the archive, then it must be present in the following locations:
Package names can be excluded if a system property is not defined for a particular name or a system property is not defined with a particular value:
You can prevent a bean from injection by adding this annotation:
In this code, the SimpleGreeting bean is not considered for injection.
All beans in a package may be prevented from injection:
Java EE components, such as stateless EJBs or JAX-RS resource endpoints, can be marked with @Vetoed to prevent them from being considered beans.
Injection Points You can inject a bean at a field, method, or constructor using @Inject.
The following code shows a Greeting interface, a POJO SimpleGreeting as its implementation, and the injection of the interface as a field in GreetingService:
Inject specifies the injection point, Greeting specifies what needs to be injected, and greeting is the variable that gets the injection.
A bean may define one or more methods as targets of injection as well: Greeting greeting;
Finally, a bean can have at most one constructor marked with @Inject: Greeting greeting;
This constructor may have any number of parameters, and all of them are injection points.
A constructor marked with @Inject need not have public access.
This allows a bean with constructor injection to be immutable.
All methods of the bean annotated with @Inject (the call order is not portable,
Qualifier and Alternative Qualifier allows you to uniquely specify a bean to be injected among its multiple implementations.
This removes any direct dependency to any particular implementation of the interface.
Default Default qualifier on all beans without an explicit qualifier, except @Named.
Using the SimpleGreeting and FancyGreeting implementations defined earlier, the injection points are explained as follows:
The use of @Named as an injection point qualifier is not recommended, except in the case of integration with legacy code that uses string-based names to identify beans.
The beans marked with @Alternative are unavailable for injection, lookup, or EL resolution.
We need to explicitly enable them in beans.xml using <alternatives>:
Now the following injection will give an error about unresolved dependency: @Inject Greeting greeting;
We can resolve this error by explicitly enabling one of the beans in beans.xml:
Alternative allows us to package multiple implementations of a bean with the same qualifiers in the .war file and selectively enable them by changing the deployment descriptor based upon the environment.
For example, this can allow you to target separate beans for injection in development, testing, and production environments by enabling the classes in beans.xml.
The producer methods provide runtime polymorphism where the concrete type of the bean to be injected may vary at runtime, the injected object may not even be a bean, and objects may require custom initialization.
Here is an example that shows how List<String> can be made available as a target for injection:
In this code, the getGreetings method can populate List<String> from a Data Source or by invoking some other external operation.
By default, a bean is injected in @Dependent scope, but we can change it by explicitly specifying the required scope.
The following code shows how a Connection bean is available for injection in request scope:
Here is another example of how PersistenceContext may be exposed as a type-safe bean.
Similarly, JMS factories and destinations can be injected in a type-safe way.
Some objects that are made available for injection via @Produces may require explicit destruction.
For example, the JMS factories and destinations need to be closed.
Here is a code example that shows how the Connection produced earlier may be closed:
Interceptors Interceptors are used to implement cross-cutting concerns, such as logging, auditing, and security, from the business logic.
The specification is not entirely new, as the concept already existed in the EJB 3.0 specification.
However, it is now abstracted at a higher level so that it can be more generically applied to a broader set of specifications in the platform.
Interceptors do what their name implies—they intercept invocations and life-cycle events on an associated target class.
Basically, an interceptor is a class whose methods are invoked when business methods on a target class are invoked, life-cycle events such as methods that create/
The CDI specification defines a type-safe mechanism for associating interceptors to beans using interceptor bindings.
We need to define an interceptor binding type in order to intercept a business method.
Target defines the program element to which this interceptor can be applied.
In this case, the annotation @Logging can be applied to a method or a type (class, interface, or enum)
AroundInvoke indicates that this interceptor method interposes on business methods.
Only one method of an interceptor may be marked with this annotation.
InvocationContext provides context information about the intercepted invocation and operations and can be used to control the behavior of the invocation chain.
Name of the business method invoked and the parameters passed to it can be retrieved from the context.
You can define multiple interceptors using the same interceptor binding.
They need to be explicitly enabled and ordered via the @Priority annotation, along with a priority value on the interceptor class:
If more than one interceptor has the same priority, the relative order of these interceptor is undefined.
The values in Table 9-4 define the following interceptor ranges to order interceptors for a specific interposed method or event in the interceptor chain.
Interceptors defined by the Java EE Platform specifications that are to be executed at the beginning of the interceptor chain.
Interceptors defined by extension libraries that are intended to be executed later in the interceptor chain.
PLATFORM_AFTER Interceptors defined by the Java EE Platform specifications that are to be executed at the end of the interceptor chain.
Note that the actual interceptor implementation class is mentioned here.
Defining interceptor bindings provides one level of indirection but removes the dependency from the actual interceptor implementation class.
It also allows you to vary the actual interceptor implementation based upon the deployment environment as well, and to provide a central ordering of interceptors for that archive.
The interceptors are invoked in the order in which they are specified inside the <interceptors> element.
An interceptor that adds basic transactional behavior to a managed bean may be defined thusly:
UserTransaction is injected in the interceptor and is then used to start and commit the transaction in the interceptor method.
MyTransactional can now be specified on any managed bean or a method thereof to indicate the transactional behavior.
The decorator class may be abstract, as it may not be implementing all methods of the bean.
A decorator class has a delegate injection point that is an injection point for the same type as the bean it decorates.
The delegate injection point follows the normal rules for injection and therefore must be an injected field, initializer method parameter, or bean constructor method parameter:
This delegate injection point specifies that the decorator is bound to all beans that implement Greeting.
A delegate injection point may specify qualifiers, and the decorator is then bound to beans with the same qualifiers.
By default, all decorators are disabled and need to be explicitly enabled and ordered via the @Priority annotation, along with a priority value on the decorator class:
The order of more than one decorator with the same priority is undefined.
A decorator enabled via the @Priority annotation is enabled for the entire application.
Just like interceptors, this allows you to specify a central ordering of decorators for that archive and vary the set of decorators based upon the deployment environment.
The priority value ranges for decorators were defined previously in Table 9-4
In this case, the decorator is enabled for the bean archive that contains beans.xml.
The order of the decorator declarations using <class> determines the decorator ordering.
Decorators that occur earlier in the list are called first.
Decorators enabled via @Priority are called before decorators enabled via beans.xml.
In order of execution, the interceptors for a method are called before the decorators that apply to the method.
Scopes and Contexts A bean is said to be in a scope and is associated with a context.
The associated context manages the life cycle and visibility of all beans in that scope.
A bean is created once per scope and then reused.
When a bean is requested in a particular scope, a new instance is created if it does not exist already.
The runtime makes sure the bean in the right scope is created, if required; the client does not have to be scope-aware.
This provides loose coupling between the client and the bean to be injected.
There are four predefined scopes and one default scope, as shown in Table 9-5
The bean is available during a single request and destroyed when the request is complete.
The bean is shared between all requests that occur in the same HTTP session, holds state throughout the session, and is destroyed when the HTTP session times out or is invalidated.
The bean is created when the application is started, holds state throughout the application, and is destroyed when the application is shut down.
ConversationScoped A bean is scoped to a conversation and is of two types: transient or long-running.
By default, a bean in this scope is transient, is created with a JSF request, and is destroyed at the end of the request.
A transient conversation can be converted to a long-running one via Conversa tion.begin.
All long-running conversations are scoped to a particular HTTP servlet session and may be propagated to other JSF requests.
Multiple parallel conversations can run within a session, each uniquely identified by a string-valued identifier that is either set by the application or generated by the container.
This allows multiple tabs in a browser to hold state corresponding to a conversation, unike session cookies, which are shared across tabs.
This is the default scope of the bean that does not explicitly declare a scope.
A contextual reference to the bean is not a direct reference to the bean (unless it is in @Dependent scope)
This client proxy is responsible for ensuring that the bean instance that receives a method invocation is the instance that is associated with the current context.
This allows you to invoke the bean in the current context instead of using a stale reference.
If the bean is in @Dependent scope, then the client holds a direct reference to its instance.
A new instance of the bean is bound to the life cycle of the newly created object.
A bean in @Dependent scope is never shared between multiple injection points.
If an @Dependent-scoped bean is used in an EL expression, then an instance of the bean is created for each EL expression.
Stereotypes A stereotype encapsulates architectural patterns or common metadata for beans that produce recurring roles in a central place.
It encapsulates scope, interceptor bindings, qualifiers, and other properties of the role.
In this code, an interceptor binding defined earlier, @Transactional, is used to define the stereotype.
A single interceptor binding defines this stereotype instead of the interceptor binding.
However, it allows you to update the stereotype definition later with other scopes, qualifiers, and properties, and those values are then automatically applied on the bean.
The metadata defined by the stereotype is now applicable on the bean.
Specifying this stereotype on a bean marks it to have @RequestScoped unless the bean explicitly specifies the scope.
Adding @Alternative to the stereotype definition marks all the target beans to be alternatives.
Stereotypes can be stacked together to create new stereotypes as well.
This stereotype provides a default name for the bean and marks it @RequestScoped.
Adding this stereotype on a bean will enable it to pass values from a JSF view to a controller, say, an EJB.
Events Events provide an annotation-based event model based upon the observer pattern.
The event object, typically a POJO, carries state from producer to consumer.
The producer and the observer are completely decoupled from each other and only communicate using the state.
In this code, Customer is carrying the state of the event.
The observer bean’s method signature has to match the exact set of qualifiers in order to receive the events fired by this bean:
Qualifiers with parameters and multiple qualifiers may be specified to further narrow the scope of an observer bean.
By default, an existing instance of the bean or a new instance of the bean is created in the current context to deliver the event.
This behavior can be altered so that the event is delivered only if the bean already exists in the current scope:
Transactional observer methods receive their event notifications during the before completion or after completion phases of the transaction in which the event was fired.
Trans actionPhase identifies the kind of transactional observer methods, as defined in Table 9-6
BEFORE_COMPLETION Observers are called during the before completion phase of the transaction.
AFTER_COMPLETION Observers are called during the after completion phase of the transaction.
AFTER_FAILURE Observers are called during the after completion phase of the transaction, only when the transaction fails.
AFTER_SUCCESS Observers are called during the after completion phase of the transaction, only when the transaction succeeds.
For example, the following observer method will be called after the transaction has successfully completed:
Portable Extensions CDI exposes an Service Provider Interface (SPI) allowing portable extensions to extend the functionality of the container easily.
This extension prints the list of annotations on a bean packaged in a web application.
This file contains the fully qualified name of the class implementing the extension:
The bean can listen to a variety of container life-cycle events, as listed in Table 9-7
BeforeShutdown After all requests are finished processing and all contexts destroyed.
ProcessProducer For each producer method or field of each enabled bean.
Each of these events allows a portable extension to integrate with the container initialization.
BeanManager provides operations for obtaining contextual references for beans, along with many other operations of use to portable extensions.
It can be injected into the observer methods as follows:
Built-in Beans A Java EE or embeddable EJB container must provide the following built-in beans, all of which have the qualifer @Default:
In this code, a UserTransaction instance is injected in a bean-managed transaction EJB.
The injected instance can be used to start and commit/roll back the transaction.
In this code, a Principal instance is injected in an EJB.
The injected instance can be used to check the security principal name.
A servlet container must provide the following built-in beans, all of which have the qualifer @Default:
The setupResources method is where any resources required during business method execution can be acquired, and the cleanupResources method is where those resources are closed or released.
The life-cycle callback methods are invoked after the no-args constructor.
Concurrency Utilities for Java EE are defined as JSR 236, and the complete specification can be downloaded.
Concurrency Utilities for Java EE provides a simple, standardized API for using concurrency from application components without compromising container integrity while still preserving the Java EE platform’s fundamental benefits.
This is because all application code is run on a thread managed by the container, and each container typically expects all access to container-supplied objects to occur on the same thread.
This allows the container to manage the resources and provide centralized administration.
Further, using resources in a nonmanaged way is discouraged, because it can potentially undermine the enterprise features that the platform is designed to provide, such as availability, security, reliability, and scalability.
Application developers familiar with this API can leverage existing libraries and usage patterns with little modification.
This will allow you to add concurrency design principles to existing Java EE applications using existing design patterns.
The unit of work that needs to be executed concurently is called a task.
The call method is called to compute the result of the task, and throws an exception.
There are two differences between a task implementing Callable and Runnable:
A Callable task can return a result, whereas a Runnable task does not.
A Callable task can throw checked exceptions, whereas a Runnable task cannot.
Each task runs within the application component context that submitted the task.
It is possible that the task could be running beyond the life cycle of the submitting component, such as when the component is destroyed.
The submit method submits a Runnable or Callable task and returns a Future representing that task:
In this code, a Collection of Callable<Product> is created and submitted via invokeAll.
The invokeAll method has another variation where the timeout can be specified.
In this code, a Collection of Callable<Product> is created and submitted via invokeAny.
The result of one task that has completed successfully is returned.
The invokeAny method has another variation where the timeout can be specified.
This ensures that a task will execute at most one time.
The security context of the calling thread is propagated to the called thread.
Each task can implement the ManagedTask interface to provide identity information about the task, get notification of life-cycle events of the task, or provide additional execution properties.
The run method is implemented from the Runnable interface, and all other methods are implemented from the Managed TaskListener interface.
All listeners run without an explicit transaction (they do not enlist in the application component’s transaction)
The submit, execute, invokeAll, and invokeAny methods behave as in ManagedExecu torService.
ScheduledFuture<?> schedule(Runnable command, Trigger trigger) creates and executes a task based on a Trigger.
This code will schedule the task after five seconds of initial delay.
The returned ScheduledFuture can be used to check the status of the task, cancel the execution, and retrieve the result.
ScheduledFuture<V> schedule(Runnable command, long delay, TimeUnit unit) creates and executes a one-shot action that becomes enabled after the given delay.
This code will schedule the task after five seconds of initial delay.
The returned ScheduledFuture can be used to check the status of the task, cancel the execution, and retrieve the result.
This code will schedule the task after an initial delay of two seconds and then every three seconds after that.
If any execution of the task encounters an exception, subsequent executions are suppressed.
If any execution of this task takes longer than its period, then subsequent executions may start late, but will not concurrently execute.
Otherwise, the task will only terminate via cancellation or termination of the executor.
The returned ScheduledFuture can be used to check the status of the task, cancel the execution, and retrieve the result.
This code will schedule the task after an initial delay of two seconds and then every three seconds after that.
A new task is started only after the previous task has terminated successfully.
If any execution of the task encounters an exception, subsequent executions are suppressed.
Otherwise, the task will only terminate via cancellation or termination of the executor.
You can create new threads from this factory using newThread(Runnable r)
The container context information is propagated to the thread’s Runnable.
Naming context, class loader, and security context information is propagated to the thread.
Dynamic Contextual Objects Application component container contexts, such as classloading, namespace, and security, can be associated with an object instance via ContextService.
The object becomes a contextual object, and whenever a method on the contextual object is invoked, the method executes with the thread context of the associated application component instance.
The JNDI naming context, classloader, and security context is propagated to the proxied object.
Proxy methods suspend any transactional context on the thread and allow components to manually control global transaction demarcation boundaries.
The User Transaction instance can be used if a transaction is required within the proxy object.
You can obtain an instance of ContextService with the JNDI lookup using resource environment references.
Contextual object proxies will run as an extension of the application component instance that created the proxy and may interact with Java EE container resources.
A contextual instance of a Runnable executed with Java SE ExecutorService can be created as:
You create the contextual proxy of a Runnable task by calling the createContex tualProxy method.
If the object instance supports multiple interfaces, then you can specify the interfaces for which the contextual proxy needs to be created as follows:
MyRunnableWork is the object to be proxied and implements the Runnable and MyWork interfaces.
You create the contextual proxy by passing both the interfaces, and the return type is Object.
You can invoke methods on a non-Runnable interface by casting to the MyWork interface.
You can submit a proxied instance to the ExecutorService by casting to the Runn able interface.
Bean Validation is defined as JSR 349, and the complete specification can be downloaded.
Bean Validation provides a class-level constraint declaration and validation facility for Java applications.
The constraints can be declared in the form of annotations placed on a field, property, method parameter, or class.
Specifying a constraint on an interface ensures the constraint is enforced on classes implementing the interface.
Similarly, all classes inheriting from a superclass inherit the validation behavior as well.
Constraints declared on an interface or superclass are validated along with any constraints defined on the implementing or overriding class.
The descriptors override and extend the metadata defined via annotations.
The specification also includes a constraint metadata repository and the capability to query it.
This is primarily targeted toward tool development as well as integration with other frameworks and libraries.
Built-in Constraints Bean Validation offers a built-in set of constraint definitions that can be used on beans.
Multiple constraints can be specified on a bean to ensure different validation requirements are met.
These constraints can also be used for composing other constraints.
Annotated element must be null and can be applied to any type: @Null String httpErrorCode;
The httpErrorCode field captures the HTTP status code from a RESTful endpoint.
Annotated element must not be null and can be applied to any type: @NotNull String name;
Specifying @NotNull will trigger a validation error if the instance variable is assigned a null value.
The annotated element must be true and can be applied to boolean or Boolean types only:
The annotated element must be false and can be applied to boolean or Boolean types only:
Min, @DecimalMin The annotated element must be a number whose value is higher or equal to the specified minimum.
Max, @DecimalMax The annotated element must be a number whose value is lower or equal to the specified maximum.
The annotated element size must be between the specified boundaries.
The length of the string is used for validation critieria.
The List.size method is used for validation in this case.
The annotated element must be a number within the accepted range.
The annotated element must be a date in the past.
The present time is defined as the current time according to the virtual machine.
The annotated element must be a date in the future.
The present time is defined as the current time according to the virtual machine.
You can make this field more meaningful by adding the @Size constraint:
Each constraint declaration can also override the message, group, and payload fields.
This is the default value and discovers the target when no ambiguity is present.
It implies the annotated element if it is not specified on a method or a constructor.
If specified on a method or constructor with no parameter, it implies RETURN_VALUE.
If specified on a method with no return value, then it implies PARAMETERS.
If there is ambiguity, then either RETURN_VALUE or PARAMETERS is required.
Applies to the return value of a method or constructor.
Defining a Custom Constraint Custom constraints designed to meet specific validation criteria can be defined by the combination of a constraint annotation and a list of custom validation implementations.
Target indicates that this constraint can be declared on types, methods, fields, constructors, and method parameters.
It also creates a link with its constraint validation implementation, defined by the attribute validated By.
Multiple validator implementations may be specified as an array of classes.
By default, each violation of a composing annotation raises an individual error report.
All the error reports are collected together, and each violation is reported.
In this case, the error report from the composed annotation is generated instead.
By default, the value is an empty array and belongs to the Default group.
A default value of the parameter, Country.US, is also specified.
The constraint validator implementation class implements the ConstraintValida tor interface.
This requires defining multiple constraint validator implementations, one each for a specific type.
The initialize method initializes any resources or data structures used for validation.
This code initializes the array of valid zip codes for a specific country.
The values of the country attribute and other attributes are available from the con straintAnnotation parameter.
This method is guaranteed to be called before any use of this instance for validation.
The method returns true if the constraint is valid, and false otherwise.
This code returns true if the zip code exists in the array of valid zip codes.
If a bean X contains a field of type Y, by default, the validation of type X does not trigger the validation of type Y.
However, annotating the field of type Y with @Valid will be cascaded along with the validation of X.
If field Y is an interface or an abstract class, then the validation constraints applied at runtime are from the actual implementing class or subtype.
Any Iterable fields and properties may also be decorated with @Valid to ensure all elements of the iterator are validated.
Valid is applied recursively, so each element of the iterator is validated as well:
In this code, the list of order items is recursively validated along with the orderId field, because @Valid has been specified on items.
If @Valid is not specified, only the order Id field is validated when the bean is validated.
In this code, the ZipCode constraint is applied to method parameters only (i.e., zip parameter in this case)
Validation Groups By default, all constraints are defined in the Default validation group.
Also by default, all validation constraints are executed and in no particular order.
A constraint may be defined in an explicitly created validation group in order to perform partial validation of the bean or control the order in which constraints are evaluated.
In this code, zip will be validated only when the ZipCodeGroup validation group is targeted for validation.
By default, the Default validation group is not included if an explicit set of groups is specified:
You can define a new group that consists of Default and ZipCodeGroup:
This new validation group can now be specified as part of the constraint, and is semantically equivalent to specifying two groups separately:
Partial validation of a bean may be required when validation of certain fields is optional or resource intensive.
For example, entering data in a multipage HTML form requires only the field values entered in each page to be validated.
Validating previously validated fields will be redundant, and validating fields that do not yet have a value assigned will.
You can achieve partial validation by creating a validation group for each page:
The fully qualified class name of the validation group needs to be specified in the validationGroups attribute of f:validateBean.
GroupSequence is used to define a sequence of groups in which the groups must be validated.
In this code, Simple and Complex are validation groups that are specified on simple and complex validators of a bean.
The definitions of simple and complex will depend upon the business domain, of course.
If one of the groups from the sequence generates a constraint violation, the subsequent groups are not processed.
Specifying @GroupSequence on a class changes the default validation group for that class.
Method and Constructor Constraint Bean Validaton 1.1 allows us to specify constraints on arbitrary methods and constructors, and/or the parameters of a POJO by directly adding constraint annotations.
In the former case, all the parameters or the return value is constrained.
This allows us to describe and validate the contract by ensuring that the preconditions must be met by the caller before the method or constructor may be invoked.
This also ensures that the postconditions are guaranteed to the caller after a method or constructor invocation returns.
This enables a programming style known as Programming by Contract (PbC)
Checks are expressed declaratively and don’t have to be performed manually, which results in less code to write, read, and maintain.
The pre- and postconditions applying for a method or constructor don’t have to be expressed again in the documentation, since any of its annotations will automatically be included in the generated JavaDoc.
This reduces redundancies, thus avoiding efforts and inconsistencies between implementation and documentation.
You can specify the constraints using either actual Java annotations or an XML constraint mapping file:
AddressBook is a POJO with two methods, addNames and getName.
Method getNames takes a parameter, dob, that cannot be null and must be in the past.
Annotating the methods or constructors with parameter or return value constraints does not automatically enforce these constraints.
The declared constraints need to be explicitly triggered via a method interceptor or a similar mechanism.
In Java EE, typically you achieve this by using CDI interceptors or dynamic proxies.
Meeting all the constraints ensures that the method or constructor is called if the caller has satisified the preconditions and returns to the caller if the postconditions are guaranteed.
Cross-parameter constraints can be declared on a method and allow you to express constraints based on the value of several method parameters:
This method retrieves the list of names born between startDob and endDob.
Valida teDates is a cross-parameter constraint that checks that the startDob is before end Dob.
It is often useful to combine constraints directly placed on individual parameters and cross-parameter constraints.
Some constraints can target the return value as well as its array of parameters.
They are known to be both generic and cross-parameter constraints.
NON_GETTER_METHODS All methods except the ones following the JavaBeans getter pattern.
The Java Transaction API (JTA) is defined as JSR 907, and the complete specification can be downloaded.
The JTA specifies local interfaces between a transaction manager and the parties involved in a distributed transaction system: the application, the resource manager, and the application server.
The API defines a high-level interface, annotation, and scope to demarcate transaction boundaries in a transactional application.
User-Managed Transactions The UserTransaction interface enables the application to control transaction boundaries programmatically.
This interface is typically used in EJBs with bean-managed transactions (BMT)
The begin method starts a global transaction and associates the transaction with the calling thread.
The commit method completes the transaction associated with the current thread.
All statements within begin and commit execute in the transaction scope:
When the commit method completes, the thread is no longer associated with a transaction.
When the rollback method completes, the thread is no longer associated with a transaction.
You can change the timeout value associated with the transaction started by the current thread with the begin method:
In this code, the transaction timeout is set to three seconds.
If the value is zero, the transaction service restores the default value.
It enables an application to declaratively control transaction boundaries on CDI-managed beans, as well as classes defined as managed beans, such as servlets, JAX-RS resource classes, and JAX-WS service endpoints.
The annotation can be specified at both the class and method level, where method-level annotations override those at the class level:
In this code, only the myMethod2 method is executed in a transaction context.
This support is provided via an implementation of CDI interceptors that conduct the necessary suspending, resuming, etc.
Life-cycle methods are invoked in an unspecified transaction context unless the method is annotated explicitly with @Transactional.
The TxType element of the annotation provides the semantic equivalent of the transaction attributes in EJB (see Table 12-1)
The managed bean method execution must then continue inside this transaction context.
REQUIRES_NEW The interceptor must begin a new JTA transaction, the managed bean method execution must then continue inside this transaction context, and the transaction must be completed by the interceptor.
The current transaction context must be suspended, a new JTA transaction will begin, the managed bean method execution must then continue inside this transaction context, the transaction must be completed, and the previously suspended transaction must be resumed.
The managed bean method execution will then continue under that context.
The managed bean method execution must then continue inside this transaction context.
NOT_SUPPORTED The managed bean method execution must then continue outside a transaction context.
The current transaction context must be suspended, the managed bean method execution must then continue outside a transaction context, and the previously suspended transaction must be resumed by the interceptor that suspended it after the method execution has completed.
By default, checked exceptions do not result in the transactional interceptor marking the transaction for rollback, and instances of RuntimeException and its subclasses do.
The rollbackOn element can be set to indicate exceptions that must cause the interceptor to mark the transaction for rollback:
This code will override behavior for checked exceptions, causing the transaction to be marked for rollback for all checked exceptions.
The dontRollbackOn element can be set to indicate exceptions that must not cause the interceptor to mark the transaction for rollback:
When a class is specified for either of these elements, the designated behavior applies to subclasses of that class as well.
It defines a bean instance whose life cycle is scoped to the currently active JTA transaction.
If multiple instances of such a bean are injected within a transaction, the underlying CDI proxy refers to the same instance, ensuring that only one instance of the bean is injected.
The object with this annotation will be associated with the current active JTA transaction when the object is used.
The way in which the JTA transaction is begun and completed (for example, via UserTransaction, Transactional interceptor, etc.) is of no consequence.
The Java Persistence API (JPA) is defined as JSR 338, and the complete specification can be downloaded.
A database table, typically with multiple columns, stores the persistent state of an application.
Multiple rows are stored in the database table to capture different states.
A single column or combination of columns may define the uniqueness of each row using primary key constraint.
Typically, an application accesses and stores data to multiple tables.
These tables generally have relationships defined among them using foreign key constraint.
It defines syntax to capture primary and foreign key constraints and how these rows can be created, read, updated, and deleted using these POJOs.
Transactions, caching, validation, and other similar capabilities required by an application accessing a database are also defined by JPA.
Entities A POJO with a no-arg public constructor is used to define the mapping with one or more relational database tables.
Each such class is annotated with @Entity, and the instance variables that follow JavaBeans-style properties represent the persistent state of the entity.
The mapping between the table column and the field name is derived following reasonable defaults and can be overridden by annotations.
For example, the table name is the same as the class name, and the column names are the same as the persistent field names.
This class has a no-arg constructor by default, as no other constructors are defined.
The entity’s persistent state is defined by four fields; the identity is defined by the.
A composite primary key may also be defined where the primary key corresponds to one or more fields of the entity class.
The class implements a Serializable interface, and that allows it to be passed by value through a remote interface.
Address is a POJO class that does not have a persistent identity of its own and exclusively belongs to the Student class.
This allows the database structure to be more naturally mapped in Java.
The @ElementCollection annotation signifies that a student’s courses are listed in.
By default, you derive the table name by combining the name of the owning class, the string “_,” and the field name.
The persistent fields or properties of an entity may be of the following types:
An entity may inherit from a superclass that provides persistent entity state and mapping information, but which itself may or may not be an entity.
An entity superclass is abstract and cannot be directly instantiated but can be used to create polymorphic queries.
The @MappedSuperclass annotation is used to designate a nonentity superclass and captures state and mapping information that is common to multiple entity classes.
Such a class has no separate table defined for it, so the mappings will only apply to its subclasses.
An entity may inherit from a superclass that provides inheritance of behavior only.
A unidirectional relationship requires the owning side to specify the annotation.
A bidirectional relationship also requires the nonowning side to refer to its owning side by use of the mappedBy element of the OneToOne, OneToMany, or ManyToMa ny annotation.
The FetchType.EAGER annotation may be specified on an entity to eagerly load the data from the database.
The FetchType.LAZY annotation may be specified as a hint that the data should be fetched lazily when it is first accessed.
The entities may display a collection of elements and entity relationships as java.util.Map collections.
The map key may be the primary key or a persistent field or property of the entity.
MapKey is used to specify the key for the association.
For example, all the Courses by a Student can be modeled as:
In this code, specifying @MapKey on the Map indicates that the map key is the primary key as well.
The map key can be a basic type, an embeddable class, or an entity.
If a persistent field or property other than the primary key is used as a map key, then it is expected to have a uniqueness constraint associated with it.
In this case, @MapKeyColumn is used to specify the mapping for the key column of the map:
In this code, Map represents all the Courses taken by a Student in a year.
MapKeyClass can be used to specify the map key for the association.
If the value is a basic type or embeddable class, then @ElementCollection is used to specify the mapping.
Each entity has a unique instance for any persistent entity identity within the context.
Within the persistence context, the entity instances and their life cycles are managed by the entity manager.
A container-managed entity manager is obtained by the application directly through dependency injection:
In this code, we assign a JNDI name to the entity manager and then look it up using InitialContext.
The persistence context is propagated across multiple transactions for a containermanaged entity manager, and the container is responsible for managing the life cycle of the entity manager.
A new isolated persistence context is created when a new entity manager is requested, and the application is responsible for managing the life cycle of the entity manager.
A container-managed entity manager is typically used in a Java EE environment.
An entity manager and persistence context are not required to be threadsafe.
This requires an entity manager to be obtained from an entity manager factory in Java EE components that are not required to be threadsafe, such as servlets.
The entity managers, together with their configuration information, the set of entities managed by the entity managers, and metadata that specifies mapping of the classes to the database, are packaged together as a persistence unit.
A persistence unit is defined by a persistence.xml file and is contained within an ejb-jar, .war, .ear, or applicationclient JAR.
Multiple persistence units may be defined within a persistence.xml file.
The transaction-type attribute’s value of JTA signifies that a JTA data source is.
The jta-data-source element defines the global JNDI name of the JTA data source.
In a Java EE environment, this ensures that all the database configuration information, such as host, port, username, and password, are specified in the container, and just the JTA data source name is used in the application.
The <properties> element is used to specify both standard and vendor-specific properties.
In both cases, the default data source will be provisioned and available to the application.
By default, a container-managed persistence context is scoped to a single transaction, and entities are detached at the end of a transaction.
For stateful session beans, the persistence context may be marked to span multiple transactions and is called an extended persistence context.
The entities stay managed across multiple transactions in this case.
Such a context is automatically joined to the current JTA transaction, and updates made to the persistence context are propagated to the resource manager (i.e., stored in the database)
Such a persistence context is not enlisted in any JTA transaction unless explicitly joined to that transaction by the application:
The persistence context remains joined to the transaction until the transaction commits or rolls back.
The persistence context remains unsynchronized after that and explicitly needs to join a transaction in the new scope.
The application can invoke the persist, merge, remove, and refresh entity life-cycle operations on an unsynchronized persistence context.
After joining the transaction, any changes in persistence context may be flushed to the database either explicitly by application via flush or by the provider.
It may or may not involve generation of a proper database schema depending upon the credentials and authorization of the user.
This is also useful in environments that require provisioning a database on demand (e.g., in a cloud)
This feature will allow your JPA domain object model to be directly generated in a database.
The generated schema may need to be tuned for the actual production environment.
This use case is supported by allowing the schema generation to occur into DDL scripts, which can then be further tuned by a DBA.
Table 13-1 lists the set of properties in persistence.xml or specified during EntityMana gerFactory creation that control the behavior of schema generation.
Specifies the action to be taken by the persistence provider.
If this property is not specified, no schema generation actions must be taken on the database.
Specifies which scripts are to be generated by the persistence provider.
A script will only be generated if the script target is specified.
If this property is not specified, no scripts will be generated.
Specifies whether the creation or deletion of database artifacts is to occur on the basis of the object/relational mapping metadata, DDL script, or a combination of the two.
Specifies whether the persistence provider needs to create schema in addition to creating database objects such as tables, sequences, constraints, etc.
Need to be specified only if scripts are to be generated.
Specifies locations from which DDL scripts are to be read.
Needed if scripts are to be generated and no connection to the target database is supplied.
An application that requires database tables to be dropped and created via the scripts bundled in the META-INF directory of the application can have the following persistence.xml:
For example, the table name is defaulted from the entity name and the.
However, annotations may be used to override or customize the values:
This entity is generated in the database with the following attributes:
The id field is mapped to the ID column as the primary key.
The name is mapped to the NAME column with a default VARCHAR(255)
ManyToOne is mapped to the DEPT_ID foreign key column and can be customized.
In addition to these properties, a couple of new annotations are added to JPA 2.1
An index for the primary key is generated by default in a database.
This new annotation will allow you to define additional indexes, over a single or multiple columns, for better performance.
In this case, the generated table will have a default index on the primary key.
In addition, two new indexes are defined on the NAME column (default ascending) and the foreign key that maps to the department in descending order.
This is used to define a foreign key constraint or to otherwise override or disable the persistence provider’s default foreign key definition.
In this entity, the employee’s manager is mapped by the MANAGER_ID column in the MANAGER table.
Create, Read, Update, and Delete Entities An entity goes through create, read, update, and delete (CRUD) operations during its life cycle.
A create operation means a new entity is created and persisted in the database.
A read operation means querying for an entity from the database based upon selection criteria.
An update operation means updating the state of an existing entity in the database.
And a delete operation means removing an entity from the database.
Typically, an entity is created once, read and updated a few times, and deleted once.
The Java Persistence Query Language is a string-based typed query language used to define queries over entities and their persistent state.
The query language uses a SQL-like syntax and uses the abstract persistence schema of entities as its data model.
This portable query language syntax is translated into SQL queries that are executed over the database schema where the entities are mapped.
The query statements can be used to select, update, or delete rows from the database.
Criteria API The Criteria API is an object-based, type-safe API and operates on a metamodel of the entities.
Typically, the static metamodel classes are generated by way of an annotation processor, and model the persistent state and relationships of the entities.
In JPA 2, the Criteria API allowed only querying the entities.
Native SQL statement Create a native SQL query specific to a database.
A new entity can be persisted in the database with an entity manager:
In this code, em is an entity manager obtained as explained earlier.
The entity is persisted to the database at the transaction commit.
A simple JPQL statement to query all the Student entities and retrieve the results looks like:
NamedQuery and @NamedQueries are used to define a mapping between a static JPQL query statement and a symbolic name.
The usual WHERE, GROUP BY, HAVING, and ORDER BY clauses may be specified in the JPQL statements to restrict the results returned by the query.
The KEY, VALUE, and ENTRY operators may be applied where map-valued associations or collections are returned.
Typically, a persistence provider will precompile the static named queries.
You can define a dynamic JPQL query by directly passing the query string to the corresponding createQuery methods:
Dynamic queries can also be constructed via the type-safe Criteria API.
Here is a code sample that explains how to use the Criteria API to query the list of Students:
The Criteria API is very useful in building dynamic queries at runtime—for example, an elaborate search page in an application that searches for content based on input fields.
Using the Critiera API, instead of JPQL, would eliminate the need for string concatenation operations to build the query.
The static @NamedQuery may be more appropriate for simple use cases.
In a complex query where SELECT, FROM, WHERE, and other clauses are defined at runtime, the dynamic JPQL may be more error prone, typically because of string concatenation.
The type-safe Criteria API offers a more robust way of dealing with such queries.
All the clauses can be easily specified in a type-safe manner, providing the advantages of compile-time validation of queries.
The JPA2 metamodel classes capture the metamodel of the persistent state and relationships of the managed classes of a persistence unit.
This abstract persistence schema is then used to author the type-safe queries via the Criteria API.
The canonical metamodel classes can be generated statically by way of an annotation processor following the rules defined by the specification.
The good thing is that no extra configuration is required to generate these metamodel classes.
To remove an existing entity, you need to find it and then call the EntityManager.re move method:
Removing an entity removes the corresponding record from the underlying data store as well.
Entity Listeners An entity goes through multiple life-cycle events such as load, persist, update, and remove.
You can place the annotations listed in Table 13-2 on methods in the entity class or mapped superclass to receive notification of these life-cycle events.
PostLoad Executed after an entity has been loaded in the current persistence context or an entity has been refreshed.
PerPersist Executed before the entity manager persist operation is actually executed or cascaded.
If entities are merged, then this is invoked after the entity state has been copied.
PostPersist Executed after the entity has been persisted or cascaded.
PreRemove Executed before the entity manager remove operation is actually executed or cascaded.
The method studentLoaded is called after the entity has been loaded into the current persistence context or after the refresh operation has been applied to it.
The method newStudentAlert is called after the entity has been persisted to the data store.
The method studentUpdateAlert is called after the entity has been updated.
The method studentDeleteAlert is called before the entity is deleted.
The callback methods can have public, private, protected, or package-level access, but must not be static or final.
The callback methods may be defined on a separate class and associated with this entity via @EntityListeners.
The argument is the entity instance for which the callback method is invoked.
Multiple entity listeners may be defined for an entity class or mapped superclass.
Each listener is invoked in the same order as it is specified in the EntityListeners annotation.
You can define the callback listeners using the XML descriptors bundled in META-INF/ orm.xml:
Default entity listeners can be specified by way of the XML descriptor.
The callback methods from such a listener class will apply to all entities in the persistence unit:
In this code, MyListener is defined as the default entity listener that will be applied to all entities in the persistence unit.
The order specified in the XML descriptor overrides the order specified via metadata annotations, either in the entity class or through @EntityListeners.
Stored Procedures JPA 2.1 adds the capability to execute queries that invoke stored procedures defined in the database.
This annotation can be specified on an entity or mapped superclass:
In this code, name uniquely defines this stored procedure query element within a persistence unit, and procedureName identifies the name of the stored procedure in the database.
You specify different parameters of the stored procedure using the setPara meter method.
The parameters must be specified in the order in which they occur in the parameter list of the stored procedure.
Positional parameters are used to bind the value of the two parameters.
There are different setParameter methods for defining the temporal type of a parameter.
If the execute method returns true, then the first result is a result set; it returns false if it is an update count or there are no other results other than through the INOUT and OUT parameters, if any.
If a single result set plus any other results are passed back via the INOUT and OUT parameters, then you can obtain the results using the getResultList and getSingleResult methods.
The getUpdateCount method may be called to obtain the results if it is an update count.
The results from getRe sultList, getSingleResult, and getUpdateCount must be processed before the INOUT or OUT parameter values are extracted.
Validating the Entities Bean Validation allows you to specify validation metadata on JavaBeans.
For JPA, all managed classes (entities, managed superclasses, and embeddable classes) may be configured to include Bean Validation constraints.
These constraints are then enforced when the entity is persisted, updated, or removed in the database.
You can easily create a custom constraint by using the mechanisms defined in the Bean Validation specification and explained in this book.
Embeddable attributes are validated only if the Valid annotation has been specified on them.
By default, the validation of entity beans is automatically turned on.
You can change the default validation behavior by specifying the validation-mode element in persis tence.xml.
No validation takes place if no Bean Validation provider is found.
An error is reported if no Bean Validation provider is found.
By default, all entities in a web application are in the Default validation group.
The Default group is targeted in pre-persist and pre-update events, and no groups are targeted in pre-remove events.
So the constraints are validated when an entity is persisted or updated, but not when it is deleted.
You can override this default behavior by specifying the target groups using the following validation properties in persistence.xml:
And persistence.xml needs to have the following property defined: //
The life-cycle event validation only occurs when a Bean Validation provider exists in the runtime.
If a constraint is violated, the current transaction is marked for rollback.
The transactions are controlled either through JTA or through the use of the resource-local EntityTransaction API.
A container-managed entity manager must use JTA and is the typical way of having transactional behavior in a Java EE container.
A resource-local entity manager is typically used in a Java SE environment.
A transaction for a JTA entity manager is started and committed external to the entity manager:
In this Enterprise JavaBean, a JTA transaction is started before the addStudent method and committed after the method is completed.
The transaction is automatically rolled back if an exception is thrown in the method.
In addition to transactions, an entity may be locked when the transaction is active.
Optimistic locking allows anyone to read and update an entity; however, a version check is made upon commit and an exception is thrown if the version was updated in the database since the entity was read.
An entity is automatically enabled for optimistic locking if it has a property or field mapped with a Version mapping.
Only the persistence provider is permitted to set or update the value of the version attribute.
This field is used by the persistence provider to perform optimistic locking:
No database locks are held in optimistic locking, which delivers better scalability.
The disadvantages are that the user or application must refresh and retry failed updates.
Pessimistic locking gives an exclusive lock on the entity until the application is finished processing it.
Pessimistic locking ensures that multiple transactions cannot update the same entity at the same time, which can simplify application code, but it limits concurrent access to the data.
You can obtain a pessimistic lock on an entity by passing a LockModeType enum value during the find method:
The entities are cached by the entity manager at the first level in the persistence context.
The entity manager guarantees that within a single persistence context, for any particular database row, there will only be one object instance.
However, the same entity could be managed in another transaction, so appropriate locking should be used.
Second-level caching by the persistence provider can be enabled by the value of the shared-cache-mode element in persistence.xml.
This element can have the values defined in Table 13-4
This allows entity state to be shared across multiple persistence contexts.
The Cache interface can be used to interface with the second-level cache as well.
A standard set of query hints are also available to allow refreshing or bypassing the cache.
The first property is used to specify the behavior when data is retrieved by the find methods and by queries.
The second property is used to specify the behavior when data is read from the database and committed into the database:
The property values are defined on CacheRetrieveMode and CacheStoreMode enums and explained in Table 13-5
The Java Message Service is defined as JSR 343, and the complete specification can be downloaded.
Message-oriented middleware (MOM) allows sending and receiving messages between distributed systems.
Java Message Service (JMS) is a MOM that provides a way for Java programs to create, send, receive, and read an enterprise messaging system’s messages.
An implementation of the JMS interfaces, included in a Java EE implementation.
Any Java EE application component can act as a JMS client.
They typically refer to ConnectionFactory and Destination, and are identified by a JNDI name.
The ConnectionFactory is used to create a connection with the provider.
The Destina tion is the object used by the client to specify the destination of messages it is sending and the source of messages it is receiving.
In the Point-to-Point model, a publisher sends a message to a specific destination, called a queue, targeted to a subscriber.
Queues retain all messages sent to them until the messages are consumed or expire.
In the Publish-Subscribe model, a publisher publishes a message to a particular destination, called a topic, and a subscriber registers interest by subscribing to that topic.
Multiple publishers can publish messages to the topic, and multiple subscribers can subscribe to the topic.
By default, a subscriber will receive messages only when it is active.
However, a subscriber may establish a durable connection, so that any messages published while the subscriber is not active are redistributed whenever it reconnects.
The publisher and subscriber are loosely coupled from each other; in fact, they have no knowledge of each other’s existence.
They only need to know the destination and the message format.
Different levels of quality of service, such as missed or duplicate messages or deliveronce, can be configured.
This is a required part of the message and is used to identify and route messages.
Some fields are initialized by the JMS provider and others are initialized by the client on a per-message basis.
JMSDeliveryMode Delivery mode is PERSISTENT (for durable topics) or NON_PERSISTENT.
JMSMessageID String value with the prefix “ID:” that uniquely identifies each message sent by a provider.
JMSTimestamp Time the message was handed off to a provider to be sent.
This value may be different from the time the message was actually transmitted.
JMSCorrelationID Used to link one message to another (e.g., a response message with its request message)
JMSReplyTo Destination supplied by a client where a reply message should be sent.
JMSRedelivered Set by the provider if the message was delivered but not acknowledged in the past.
JMSType Message type identifier; may refer to a message definition in the provider’s respository.
Properties These are optional header fields added by the client.
The value can be boolean, byte, short, int, long, float,
JMS-defined properties are prefixed JMSX, and providerspecific properties are prefixed with JMS_<vendor_name>
Body This is the actual payload of the message, which contains the application data.
Different types of body messages are shown in Table 14-2
StreamMessage Payload is a stream of Java primitive types, written and read sequentially.
MapMessage Payload is a set of name/value pairs; order of the entries is undefined, and can be accessed randomly or sequentially.
It provides a single set of interfaces that could be used for both point-to-point and pub/sub messaging.
The following sections will explain the key JMS concepts using both the classic API and the simplified API.
Sending a Message Using the JMS 2 simplified API, you can send a message from a stateless session bean:
This annotation provides information that can be used at the application’s deployment to provision the required resource and allows an application to be deployed into a Java EE environment with less administrative configuration.
Properties are specified in the format property Name=propertyValue with one property per array element.
JMSContext is the main interface in the simplified JMS API.
This combines in a single object the functionality of two separate objects from the JMS 1.1 API: a Connection and a Session.
It provides a physical link to the JMS server and a singlethreaded context for sending and receiving messages.
Such a context is created and closed by the container, not the application.
If the @JMSConnection Factory annotation is omitted, then the platform default connection factory is used.
Passwords may be specified as an alias, which allows the password to be defined in a secure manner separately from the application.
You inject both of these objects by using @Resource and specifying the JNDI name of the resource.
When an application needs to send messages, it uses the createProducer method to create a JMSProducer, which provides methods to configure and send messages.
It provides various send methods to send a message to a specified destination.
Note that no explicit exception handling is required, as send methods throw only an instance of a runtime exception.
Various setter methods on JMSProducer all return the JMSProducer object.
This allows method calls to be chained together, allowing a fluid programming style:
This is not permitted in the Java EE or EJB container because it registers a callback method that is executed in a separate thread:
For an asynchronous message, part of the work involved in sending the message will be performed in a separate thread, and the specified CompletionListener will be notified when the operation has completed.
When the message has been successfully sent, the JMS provider invokes the callback method onCompletion on the CompletionListener object.
ConnectionFactory is a JMS-administered object and is used to create a connection with a JMS provider.
Destination is also an administered object and encapsulates a provider-specific address.
You inject both of these objects by using @Resource and specifying the JNDI name of the resource.
A Connection represents an active connection to the provider and must be explicitly closed.
A Session object is created from the Connection that provides a transaction in which the producers and consumers send and receive messages as an atomic unit of work.
The first argument to the method indicates whether the session is transacted; the second argument indicates whether the consumer or the client will acknowledge any messages it receives, and is ignored if the session is transacted.
If the session is transacted, as indicated by a true value in the first parameter, then an explicit call to Session.commit is required in order for the produced messages to be sent and for the consumed messages to be acknowledged.
The second argument indicates the acknowledgment mode of the received message.
This will likely result in the delivery of some duplicate messages (with the JMSRedelivered message header set to true)
However, it can reduce the session overhead by minimizing the work the session does to prevent duplicates.
Use the session and the injected Destination object, inboundQueue in this case,
A Topic or Queue may be used as the parameter to this method, as both inherit from Desti nation.
You can use this code to send messages via both messaging models.
It provides a combination of Connection and Session from the classic API.
Destination is an administered object and encapsulates a provider-specific address.
You inject both of these objects by using @Resource and specifying the JNDI name of the resource.
A JMSConsum er provides methods to receive messages either synchronously or asynchronously.
The receiveBody method is used to receive the next message produced for this JMSConsumer within the specified timeout period and returns its body as an object of the specified type.
This method does not give access to the message headers or properties (such as the JMSRedelivered message header field or the JMSXDeliver yCount message property) and should only be used if the application has no need to access them.
This call blocks until a message arrives, the timeout expires, or this JMSConsumer is closed.
A timeout of zero never expires, and the call blocks indefinitely.
If this method is called within a transaction, the JMSConsumer retains the message until the transaction commits.
ConnectionFactory and Destination are administered objects and are injected by the container via the specified JNDI name.
This is similar to what was done during the message sending.
As was the case during message sending, a Connection object and a Session object are created.
Instead of MessageProducer, a MessageConsumer is created from ses sion and is used for receiving a message.
In an infinite loop, consumer.receive waits for a synchronous receipt of the message.
The subscribers receive the message only when they are active.
However, a durable subscriber may be created that receives messages published while the subscriber is not active:
Topic Connection is created from the factory, which is then used to create TopicSession.
This method takes two arguments: the first is the durable Topic to subscribe to, and the second is the name used to uniquely identify this subscription.
A durable subscription can have only one active subscriber at a time.
The JMS provider retains all the messages until they are received by the subscriber or expire.
Receiving a Message Asynchronously You can receive a JMS message asynchronously using a message-driven bean:
The mappedName attribute specifies the JNDI name of the JMS destination from.
This is the same destination to which the message was targeted from the producer.
The bean must implement the MessageListener interface, which provides only one method, onMessage.
This code shows how a message received by the onMessage method is a text message, and how the message body can be retrieved and displayed:
Even though a message-driven bean cannot be invoked directly by a session bean, it can still invoke other session beans.
Quality of Service By default, a JMS provider ensures that a message is not lost in transit in case of a provider failure.
The messages are logged to stable storage for recovery from a provider failure.
However, this has performance overheads and requires additional storage for persisting the messages.
If a receiver can afford to miss the messages, NON_PERSISTENT delivery mode may be specified.
A JMS provider must deliver a NON_PERSISTENT message at most once.
This does not require the JMS provider to store the message or otherwise guarantee that it is not lost if the provider fails.
All messages sent by JMSProducer created here will follow the semantics defined by NON_PERSISTENT delivery mode.
In this code, textMessage is the message to be sent with the NON_PERSISTENT delivery mode.
The third argument defines the priority of the message and the last argument defines the expiration time.
These objects can also be created dynamically, where their scope is bound to the JMSContext or Connection from which they are created.
These temporary destinations are automatically closed and deleted, and their contents are lost when the connection is closed.
You can use these temporary destinations to simulate a request-reply design pattern by using the JMSReplyTo and JMSCorrelationID header fields.
Batch Applications for the Java Platform is defined as JSR 352, and the complete specification can be downloaded.
Batch processing is the execution of a series of jobs and is suitable for noninteractive, bulk-oriented, and long-running tasks.
These tasks are typically data or computationally intensive, execute sequentially or in parallel, and may be initiated through various invocation models, including ad hoc, scheduled, and on-demand.
This specification defines a programming model for batch applications and a runtime for scheduling and executing jobs.
Key concepts of a batch reference architecture are shown in Figure 15-1 and explained following it.
A job is an entity that encapsulates an entire batch process.
A job is typically put together with a Job Specification Language and consists of one or more steps.
A step is a domain object that encapsulates an independent, sequential phase of a job.
A step contains all of the information necessary to define and control the actual batch processing.
JobOperator provides an interface to manage all aspects of job processing, including operational commands (such as start, restart, and stop) and job repository commands (such as job retrieval and step executions)
JobRepository holds information about jobs currently running and jobs that have run in the past.
ItemReader and ItemProcessor read and process one item at a time and give it to ItemWriter for aggregation.
Once the “chunk” number of items is aggregated, they are written out, and the transaction is committed.
Alternatively, there is a roll-your-own batch pattern, called a batchlet.
This batch pattern is invoked once, runs to completion, and returns an exit status.
This pattern must implement and honor a “cancel” callback to enable operational termination of the batchlet.
Chunk-Oriented Processing The chunk-oriented processing style is the primary pattern for batch processing in the specification.
It is an item-oriented way of processing where multiple items are read and processed to create “chunks” that are then written out, all within a transaction boundary.
The ItemReader interface is used to read a stream of items, one item at a time.
An ItemReader provides an indicator when it has exhausted the items it can supply.
The ItemProcessor interface operates on an input item and produces an output item by transforming or applying other business processing.
An ItemProcessor hands over the processed item to ItemWriter for aggregation.
The ItemWriter interface is used to write a stream of a “chunk” number of aggregated items.
Generally, an item writer has no knowledge of the input it will receive next, only the item that was passed in its current invocation.
The convenience abstract classes AbstractItemReader and AbstractItemWriter provide implementations of less commonly implemented methods.
Table 15-1 shows the list of interfaces and corresponding abstract classes for different chunk-oriented artifacts.
Interfaces and classes for chunk-oriented artifacts Batch artifact Interface Abstract class.
MyInputRecord is an item that is read from the input source.
MyOutputRecord is an item that is generated after the item is processed.
The MyInpu tRecord and MyOutpuRecord classes look very similar in this case, but they might be very different in the real world.
For example, an input record might be reading account information and an output record might be an email statement.
It has a logical name id and is used for identification purposes.
A job may contain any number of steps identified by the step element.
Each step has a logical name id and is used for identification purposes.
A chunk type step is periodically checkpointed according to a configured checkpoint policy.
You can specify a “custom” value using the checkpoint-policy attribute, in which case the checkpointing algorithm needs to be specified as well.
This value is used to define the transaction boundary as well.
If this item is not specified, then all the elements from the item reader are passed to the item writer for aggregation.
The item reader is an implementation of the ItemReader interface or extends the Ab stractItemReader class:
We mark MyItemReader as an item reader by extending the convenient AbstractI temReader class.
The input parameter c represents the last checkpoint for this reader in a given job instance.
The checkpoint data is defined by this reader and is provided by the checkpointInfo method.
The checkpoint data provides the reader whatever information it needs to resume reading items upon restart.
A checkpoint value of null is passed upon initial start.
The readItem method returns the next item for chunk processing.
For all strings read from the List, a new MyInputRecord instance is created and returned from the readItem method.
The @Named annotation ensures that this bean can be referenced in Job XML.
We mark MyItemProcessor as an item processor by implementing the ItemProces sor interface.
This method accepts an input from the item reader and returns an output that gets passed to the output writer for aggregation.
In this case, the method receives an item of type MyInputRecord, applies the business logic, and returns an output item of type MyOutputRecord.
In the real world, the business logic of generating an email record from the account will be defined here.
Returning null indicates that the item should not continue to be processed.
This effectively enables processItem to filter out unwanted input items.
Named ensures that this bean can be referenced in Job XML.
The item writer is an implementation of the ItemWriter interface or extends Ab stractItemWriter class:
We mark MyItemWriter as an item writer by extending the convenient AbstractI temWriter class.
The writeItems method receives the aggregated items and implements the write logic for the item writer.
Named ensures that this bean can be referenced in Job XML.
If the Job XML is defined in a file named myJob.xml and packaged in the META-INF/ batch-jobs directory in the classpath, then we can start this chunk-oriented job using JobOperator:
The start method creates a new job instance and starts the first execution of that instance.
The method returns the execution ID for the first instance.
In this code, the execution ID of the job is used to restart a particular job instance.
A new set of properties may be specified when the job is restarted.
In this code, the execution ID of the job is used to cancel a particular job instance.
You may specify a different set of properties during multiple executions of the same job.
The number of instances of a job with a particular name can be found as follows:
In this code, the number of myJob instances submitted by this application, running or not, are returned.
This returns the unique set of job names submitted by this application.
Custom Checkpointing Checkpoints allow a step execution to periodically bookmark its current progress to enable restart from the last point of consistency, following a planned or unplanned interruption.
By default, the end of processing for each chunk is a natural point for taking a checkpoint.
You can specify a custom checkpoint policy using the checkpoint-policy attribute in Job XML:
The checkpoint-policy value is specified to custom, indicating that a custom checkpoint algorithm is used.
The method returns true if the chunk needs to be checkpointed, and false otherwise.
Exception Handling By default, when any batch artifact that is part of a chunk step throws an exception, the job execution ends with a batch status of FAILED.
You can override this default behavior for reader, processor, and writer artifacts by configuring exceptions to skip or to retry:
Batchlet Processing The batchlet style implements a roll-your-own batch pattern.
It is a task-oriented processing style where a task is invoked once, runs to completion, and returns an exit status.
The Batchlet interface is used to implement a batch step.
The convenience abstract class AbstractBatchlet provides implementations of less commonly implemented methods.
It has a logical name id and is used for identification purposes.
A job may contain any number of steps identified by the step element.
It has a logical name id and is used for identification purposes.
The ref attribute is identified as the CDI bean name of a class implementing the Batchlet interface or extending AbstractBatchlet:
The process method is called to perform the work of the batchlet.
If this method throws an exception, the batchlet step ends with a status of FAILED.
Named ensures that this bean can be referenced in Job XML.
Table 15-2 lists the interfaces and abstract classes that can be implemented to intercept batch execution.
None When a skippable exception is thrown from an item reader, processor, or writer.
None When a retriable exception is thrown from an item reader, processor, or writer.
The listeners for the job are specified as a child of <job>
All other listeners are specified as a child of <step>
The value of the ref attribute is the CDI bean name of a class implementing the corresponding listener.
Job Sequence A step is a basic execution element that encapsulates an independent, sequential phase of a job.
Each step may be either a chunk type step or batchlet type step.
By default, each step is the last step in the job.
The next step in the job execution sequence needs to be explicitly specified via the next attribute:
The order of steps is identified by the next attribute on step1
Other than the step, the specification outlines other execution elements that define the sequence of a job: Flow.
Defines a sequence of execution elements that execute together as a unit.
Decision Provides a customized way of determining sequencing among steps, flows, and splits.
The first step, flow, or split defines the first step (flow or split) to execute for a given Job XML.
Flow A flow execution element defines a sequence of execution elements that execute together as a unit.
When the flow is finished, it is the entire flow that transitions to the next execution element:
The execution elements within a flow may only transition among themselves; they may not transition to elements outside of the flow.
By default, flow is the last execution element in the job.
We can specify the next execution element using the next attribute.
The value of the next attribute can be a logical name of a step, flow, split, or decision.
Split A split execution element defines a set of flows that execute concurrently:
By default, split is the last execution element in the job.
You can specify the next execution element using the next attribute.
When the split is finished, the entire split transitions to the next execution element.
The value of the next attribute can be a logical name of a step, flow, split, or decision.
Decision A decision execution element provides a customized way of determining sequencing among steps, flows, and splits.
Four transition elements are defined to direct job execution sequence or to terminate job execution: next.
Causes a job to end with a FAILED batch status.
Causes a job to end with a COMPLETED batch status.
Causes a job to end with a STOPPED batch status.
A decision element is the target of the next attribute from a job-level step, flow, split, or another decision.
The decision element follows a step, flow, or split execution element.
This element has a reference to the Decider batch artifact.
A decider receives control as part of a decision element in a job and decides the next transition.
The decide method receives an array of StepExecution objects as input.
These objects represent the execution element that transitions to this decider.
The decider method returns an exit status that updates the current job execution’s exit status.
This exit status value also directs the execution transition using transition elements configured on the same decision element as the decider:
The decision execution element uses the next transition element to transfer the.
The job is terminated via the end transition element if the exit status is NOT_LOADED.
Fail, end, and stop are terminating elements, because they cause a job execution to terminate.
Partitioning the Job A batch step can run as a partitioned step.
A partitioned step runs as multiple instances of the same step definition across multiple threads, one partition per thread.
Each partition can have unique parameters that specify on which data it should operate.
This allows a step to be partitioned and run across multiple threads, without any change in the existing Java code.
The number of partitions and the number of threads is controlled through a static specification in the Job XML:
The partition plan is specified for a chunk step but can be specified for a batchlet step as well.
The partition to which the properties belong is specified via the partition attribute.
By default, the number of threads is equal to the number of partitions.
These properties are then available in the open method of the item reader.
Each thread runs a separate copy of the step: chunking and checkpointing occur independently on each thread for chunk type steps.
The number of partitions and the number of threads can also be specified through a batch artifact called a partition mapper:
The <mapper> element provides a programmatic means for calculating the number of partitions and threads for a partitioned step.
The ref attribute refers to the CDI bean name of a class implementing PartitionMapper interface.
You can define the mapper batch artifact by implementing the PartitionMapper interface:
The mapPartitions method returns an implementation of the PartitionPlan interface.
This code returns PartitionPlanImpl, a convenient basic implementation of the PartitionPlan interface.
The getThreads method returns the number of threads used to concurrently execute the partitions.
By default, the number of threads is equal to the number of partitions.
The partitions of a partitioned step may need to share results with a control point to decide the overall outcome of the step.
The PartitionCollector and PartitionAna lyzer batch artifact pair provide for this need.
Introduction This chapter provides self-paced instructions for building a typical three-tier end-toend application using the following Java EE 7 technologies:
Software Requirements You need to download and install the following software:
Figure 16-1 shows a preview of the downloads page and highlights the exact Download button to click.
Problem Statement This hands-on lab builds a typical three-tier Java EE 7 web application that allows customers to view the show times for a movie in a seven-theater cineplex and make reservations.
Total sales from each showing are calculated at the end of the day.
The different functions of the application, as previously detailed, utilize various Java technologies and web standards in their implementation.
Figure 16-3 shows how different Java EE technologies are used in different flows.
Table 16-1 details the components and the selected technology used in its implementation.
Ticket Sales Uses Batch Applications for the Java Platform to calculate the total sales and persist to the database.
Movie Points Uses Java Message Service (JMS) to update and obtain loyalty reward points; an optional implementation using database technology may be performed.
Lab Flow The attendees will start with an existing maven application, and by following the instructions and guidance provided by this lab, they will:
Read existing source code to gain an understanding of the structure of the application and use of the selected platform technologies.
Add new and update existing code with provided fragments in order to demonstrate usage of different technology stacks in the Java EE 7 platform.
This lab is not a comprehensive tutorial of Java EE.
You can learn Java EE concepts by reading through the previous chapters of this book.
The Java EE 7 Tutorial is also a good place to learn the concepts.
This is a sample application and the code may not follow the best practices to prevent SQL injection, cross-side scripting attacks, escaping parameters, and other similar features expected of a robust enterprise application.
This is intentional so as to stay focused on explaining the technology.
It is highly recommended that you make sure that the code copied from this sample application is updated to meet those requirements.
Walkthrough of a Sample Application PURPOSE: In this section, you will download the sample application to be used in this hands-on lab.
Then I’ll give you a walkthrough of the application to help you understand the application architecture.
This will create a movieplex7 directory and unzip all the content there.
Note that the APIs are specified in the “provided” scope and thus are not bundled with the application and instead provided by the container.
The default DataSource is used, as <jta-data-source> is commented out.
The database schema will be dropped and generated by way of scripts.
Feel free to open and read through the SQL scripts.
This folder also contains sales.csv, which carries some comma-separated data used later in the application.
Clicking back and forth between the Design and Source views may prompt the error shown in Figure 16-7
Each JPA entity has several convenient @NamedQuery annotations defined and uses Bean Validation constraints to enforce validation.
Each EJB has methods to perform CRUD operations on the JPA entity and convenience query methods.
The ApplicationConfig class defines the base path of the REST endpoint.
The path for the REST endpoint is the same as the JPA entity class name.
The mapping between JPA entity classes, EJB classes, and the URI of the corresponding REST endpoint is shown in Table 16-2
By default, Java EE 7 enables CDI discovery of beans.
There is no need to bundle beans.xml, and you’ll notice none exists in the WEB-INF folder.
Note, template.xhtml is in the WEB-INF folder, as it allows the template to be accessible from the pages bundled with the application only.
If it were bundled with the rest of the pages, it would be accessible outside the application and thus would allow other external pages to use it as well.
During the first run, the IDE will ask you to select a deployment server.
Show Booking (JavaServer Faces) PURPOSE: Build pages that allow a user to book a particular movie in a theater.
A new feature of JavaServer Faces 2.2 will be introduced and demonstrated in this application.
This application will build a Faces Flow that allows the user to make a movie reservation.
Starting from the home page, the flow will contain four pages, shown in Figure 16-9
Items in a flow are logically related to each other, so they must be kept together in a directory (Figure 16-10)
In the NetBeans IDE, right-click the Web Pages, select New and then Folder, specify the folder name booking, and click Finish.
Right-click the newly created folder; select New and then Facelets Template Client; and click Next >
Click Browse next to Template:, expand Web Pages and then WEB-INF, select template.xhtml, and click Select File such that it looks like Figure 16-11
Add the @Named class-level annotation to make the class EL-injectable.
Add @Flow Scoped("booking") to define the scope of the bean as the flow.
The bean is automatically activated and passivated as the flow is entered or exited.
This method will return the movie name based upon the selected movie.
Inject EntityManager in this class by adding the following code:
Alternatively, the movie ID and name may be passed from the selected radio button and parsed in the backing bean.
Add the following fields to the Booking class: String startTime; int startTimeId;
These methods will parse the values received from the form.
This method will find the first theater available for the chosen movie and show timing.
Additionally, a list of theaters offering that movie may be shown in a separate page.
The code displays the selected movie, showtime, and theater if available.
You can add actionListener to commandButton to invoke the business logic for making the reservation.
Additional pages may be added to take the credit card details and email address.
This code displays the movie name, showtimes, and the selected theater.
The action attribute defines a navigation rule that will be defined in the next step.
Now we need to inform the runtime that the views in this directory are to be treated as view nodes in a flow.
Right-click the Web Pages/booking folder; select New, Other, XML, and then XML Document; specify the name as booking-flow; click Next >; leave the default of WellFormed Document; and click Finish.
It uses the standard parent element used in any facesconfig.xml file but defines a <flow-definition>
In this case, the navigation returns to the home page.
The action attribute points to the directory where all views for the flow are stored.
Run the project by right-clicking the project and selecting Run.
Click Book to confirm and see the output in Figure 16-17
Feel free to enter other combinations, go back and forth in the flow, and notice how the values in the bean are preserved.
Clicking Home takes the user to the main application page as shown in Figure 16-13
Several new features of the Java API for WebSocket 1.0 will be introduced and demonstrated in this application.
This section will build a chat room for movie viewers.
The value defines the URI where this endpoint is published.
OnOpen and @OnClose decorate the methods that must be called when the WebSocket session is opened or closed.
The peer parameter defines the client requesting connection initiation and termination.
OnMessage decorates the message that receives the incoming WebSocket message.
The first parameter, message, is the payload of the message.
The second parameter, client, defines the other end of the WebSocket connection.
The method implementation transmits the received message to all clients connected to this endpoint.
The code builds an HTML form that has two textareas—one to display the chat log and the other to display the list of users currently logged in.
A single text box is used for the username or the chat message.
Clicking the Join button takes the username as the value, while clicking Send takes the chat message as the value.
JavaScript methods, which will be explained in the next section, are invoked when these buttons are clicked.
The chat messages are sent and received as WebSocket payloads.
There is an explicit button to disconnect the WebSocket connection.
The WebSocket initialization occurs in the websocket.js file included at the bottom of the fragment.
You calculate the WebSocket endpoint URI by using standard JavaScript variables and appending the URI specified in the ChatServer class.
Event handlers are registered for life-cycle events via onXXX messages.
The listeners registered in this script are explained in Table 16-3
Any relevant data is passed along as a parameter to the function.
Each method prints the status on the browser using the writeToScreen utility method.
The join method sends a message to the endpoint indicating that a particular user has joined.
The endpoint then broadcasts the message to all the listening clients.
The send_mes sage method appends the logged-in username and the value of the text field and broadcasts to all the clients similarly.
The onMessage method updates the list of logged-in users as well.
Run the project by right-clicking the project and selecting Run.
Click Chat Room to see the output shown in Figure 16-20
The “CONNECTED” status message is shown and indicates that a WebSocket connection with the endpoint has been established.
Please make sure your browser supports WebSocket in order for this page to show up successfully.
Enter Duke in the text box in the first browser and click Join.
Notice that the user list and the status message in both the browsers gets updated.
Enter Duke2 in the text box of the second browser and click Join.
Once again, the user list and the status message in both the browsers is updated.
Now you can type any message in either browser and click Send to send the message.
The output from two different browsers after the initial greeting looks like Figure 16-21
Chrome output is shown on the top and Firefox on the bottom.
Chrome Developer Tools can be used to monitor WebSocket traffic.
Several new features of JAX-RS 2 will be introduced and demonstrated in this application.
This section will enable us to view all the movies, view details of a selected movie, and delete an existing movie using the JAX-RS Client API.
This bean will be used to invoke the REST endpoint.
This allows the class to be injected in an EL expression and also defines the bean to be automatically activated and passivated with the request.
Add the following code to the class: Client client; WebTarget target;
The Client instance is created and destroyed in the life-cycle callback methods.
We set the endpoint URI on this instance by calling the target method.
We set the URI of the endpoint on the Client instance using the target method.
Invoke the HTTP GET method by calling the get method.
The response type is specified in the last method call, so the return value is of the type Movie[]
Java Class, specify the value as MovieBackingBean, and click Finish.
Add getters/setters by right-clicking on the editor pane and selecting Insert Code (use the Control + I shortcut on Mac)
All movies are displayed in a list with a radio button next to them.
This output uses a REST endpoint for querying instead of a traditional EJB/JPA-backed endpoint.
In MovieClientBean, inject MovieBackingBean to read the value of the selected movie from the page.
Change the <ui:define> element such that its content looks like:
Click the yellow lightbulb to resolve the namespace prefix-URI mapping for h:
Display the output values by calling the getMovie method and using the id, name, and actors property values.
Run the project, select Movies in the left navigation bar, select a radio button next to any movie, and click on details to see the output shown in Figure 16-24
This button displays a Delete label, invokes the method deleteMovie from Movie ClientBean, and then renders movie.xhtml.
This deletes the movie from the database and refreshes the page.
Several new features of the Java API for JSON Processing 1.0 will be introduced and demonstrated in this application.
This section will define JAX-RS entity providers that will allow reading and writing JSON for a Movie POJO.
This section will enable us to add a new movie to the application.
Typically, this functionality will be available after proper authentication and authorization.
Right-click the newly created package, select New and then Java Class, specify the name as MovieReader, and click Finish.
Provider allows this implementation to be discovered by the JAX-RS runtime during the provider scanning phase.
Consumes indicates that this implementation will consume a JSON representation of the resource.
This method ascertains if the MessageBodyReader can produce an instance of a particular type.
This code reads a type from the input stream in.
JsonParser, a streaming parser, is created from the input stream.
Key values are read from the parser and a Movie instance is populated and returned.
Right-click the newly created package, select New and then Java Class, specify the name as MovieWriter, and click Finish.
Provider allows this implementation to be discovered by the JAX-RS runtime during the provider-scanning phase.
Produces indicates that this implementation will produce a JSON representation of the resource.
This method ascertains if the MessageBodyWriter supports a particular type.
JsonGenerator writes JSON data to an output stream in a streaming way.
Overloaded write methods are used to write different data types to the stream.
This code creates a form to accept as input the movie’s id, name, and actors.
The click of the command button invokes the addMovie method from MovieClientBean and then renders movies.xhtml.
Click the hint (shown as a yellow lightbulb) to resolve the namespace prefix/URI mapping.
Add movieName and actors fields to MovieBackingBean as: String movieName; String actors;
This method creates a new Movie instance, populates it with the values from the backing bean, and POSTs the bean to the REST endpoint.
The register method registers a MovieWriter that enables conversion from the POJO to JSON.
Run the project to see the updated main page as shown in Figure 16-28
You can add a new movie by clicking the New Movie button.
The Movie Id value has to be greater than 20; otherwise, the primary key constraint will be violated.
The table definition may be updated to generate the primary key based upon a sequence; however, this is not done in the application.
Ticket Sales (Batch Applications for the Java Platform) PURPOSE: Read the total sales for each show and populate the database.
Several new features of the Java API for Batch Processing 1.0 will be introduced and demonstrated in this application.
This section will read the cumulative sales for each show from a CSV file and populate them in a database.
Right-click the newly created package, select New and then Java Class, and specify the name as SalesReader.
AbstractItemReader is an abstract class that implements the ItemReader interface.
The ItemReader interface defines methods that read a stream of items for chunk processing.
Add @Named as a class-level annotation; it allows the bean to be injected in Job XML.
Add @Dependent as another class-level annotation to mark this bean as a beandefining annotation so that this bean is available for injection.
Each line has a show identifier comma-separated by the total sales for that show.
Note that the last line (5th record in the sample) has an intentional typo.
The lab will use these lines to demonstrate how to handle parsing errors.
The readItem method returns the next item from the stream.
Note that the end of the stream indicates the end of the chunk, so the current chunk will be committed and the step will end.
ItemProcessor is an interface that defines a method that is used to operate on an input item and produce an output item.
This processor accepts a String input item from the reader, SalesReader in our case, and returns a Sales instance to the writer (coming shortly)
Sales is the prepackaged JPA entity with the application starter source code.
This method takes a String parameter coming from the SalesReader, parses the value, populates it in the Sales instance, and returns it.
The method can return null, indicating that the item should not be aggregated.
For example, the parsing errors can be handled within the method and return null if.
However, this method is implemented where any parsing errors are thrown as exceptions.
Job XML can be instructed to skip these exceptions, and thus that particular record is skipped from aggregation as well (shown later)
AbstractItemWriter is an abstract class that implements the ItemWriter interface.
The ItemWriter interface defines methods that write to a stream of items for chunk processing.
The batch runtime aggregates the list of Sales instances returned from the Sales Processor and makes it available as a List in this method.
This method iterates over the list and persists each item in the database.
The method also has a @Transactional annotation that provides transactional semantics to this method.
Specifying this element allows the application to skip the exception, ignore that particular element, and continue processing.
If this element is not specified, then the batch processing will halt.
The skip-limit attribute specifies the number of exceptions a step will skip.
This method uses BatchRuntime to get an instance of JobOperator, which is then used to start the job.
It can be used to start, stop, and restart jobs.
It can additionally inspect job history, to discover what jobs are currently running and what jobs have previously run.
This method uses a predefined @NamedQuery to query the database and return all rows from the table.
Right-click Web Pages, select New and then Folder, specify the name as batch, and click Finish.
The first command button invokes the job that processes the CSV file and populates the database.
Right-click the yellow lightbulb to fix the namespace prefix/URI mapping.
Run the project to see the output shown in Figure 16-32
Notice that a new Sales entry is displayed in the left navigation bar.
Click Sales to see the output shown in Figure 16-33
The empty table indicates that there is no sales data in the database.
Click the Run Job button to initiate data processing of the CSV file.
Wait a couple of seconds for the processing to finish and then click the Refresh button to see the updated output, as shown in Figure 16-34
Note that record 5 is missing from the table, as this record did not have the correct numeric entries for the sales total.
The Job XML for the application explicitly states to skip such errors.
This section will provide a page to simulate submission of movie points accrued by a customer.
These points are submitted to a JMS queue that is then read synchronously by another bean.
The JMS queue can continue further processing, possibly storing messages in the database using JPA.
Right-click the newly created package, select New and then Java Class, and specify the name as SendPointsBean.
This marks the bean to be EL-injectable and automatically activated and passivated with the request.
Typically, a message to a JMS queue is sent after the customer has bought the tickets.
Another bean will then retrieve this message and update the points for that customer.
This allows the two systems, one generating the data about tickets purchased and the other about crediting the account with the points, to be completely decoupled.
This lab will mimic the sending and consuming of a message via an explicit call to the bean from a JSF page.
This field’s value is bound to an inputText in a JSF page (created later)
It also has a Bean Validation constraint that enables validation of data on form submit.
It requires the data to consist of two digits, followed by a comma, and then two more digits.
If the message does not meet the validation criteria, then the error message to be displayed is specified via a message attribute.
You could think of this as conveying the customer identifier and the points accrued by that customer.
Add the following code to the class: @Inject JMSContext context;
This code uses the default factory to inject an instance of container-managed JMSContext.
The actual message is obtained from the value entered in the JSF page and bound to the message field.
This marks the bean to be referenced from an EL expression.
It also activates and passivates the bean with the session.
Add the following code to the class: @Inject JMSContext context;
The createConsumer method creates JMSConsumer, which is then used to synchronously receive a message.
This code creates a QueueBrowser to look at the messages on a queue without removing them.
It calculates and returns the total number of messages in the queue.
Right-click Web Pages, select New and then Folder, specify the name as points, and click Finish.
Click the yellow lightbulb to resolve namespace prefix/URI mapping for the h: prefix.
This page displays the number of messages in the current queue.
It provides a text box for entering the message that can be sent to the queue.
The first command button invokes the sendMessage method from SendPointsBean and refreshes the page.
An updated queue count, incremented by 1 in this case, is displayed.
The second command button invokes the receiveMessage method from Receive PointsBean and refreshes the page.
The queue count is updated again, decremented by 1 in this case.
If the message does not meet the validation criteria, then the error message is displayed on the screen.
This message does not meet the validation criteria, so the error message is displayed.
The updated count now shows that there is one message in the queue.
Click the Receive Message button to see the output in Figure 16-40
The updated count now shows that the message has been consumed and the queue has zero messages.
Click Send Message four times to see the output in Figure 16-41
The updated count now shows that the queue has four messages.
Click Receive Message twice to see the output in Figure 16-42
The count is once again updated to reflect the two consumed and two remaining messages in the queue.
Conclusion This hands-on lab built a trivial three-tier web application using Java EE 7 and demonstrated the following features of the platform:
All the commands to start, stop, and restart are available from the pop-up menu.
View the server log by clicking View Server Log, and view the web-based administration console by clicking View Admin Console.
Completed Solution The completed solution can be downloaded as a zip.
This appendix provides a reference to the specifications for different technologies included in the Java EE 7 platform.
We’d like to hear your suggestions for improving our indexes.
As a founding member of the Java EE team, he works to create and foster the community around Java EE, GlassFish, and WebLogic.
He led a cross-functional team to drive the global launch of the Java EE 7 platform through strategy, planning, and execution of content, marketing campaigns, and programs.
He is extremely passionate about developers and loves to engage with partners, customers, Java user groups, Java champions, and others around the world to spread the goodness of Java.
Arun has extensive speaking experience in more than 30 countries on myriad topics.
Colophon The animals on the cover of Java EE 7 Essentials are Asiatic glassfish (members of the family Ambassidae)
Found only in the waters of Asia and Oceania, the fish in this family are divided into eight genera that include around 40 species.
Most members of this family are quite small, but the larger species can grow to a maximum of 10 inches.
The most popular member of Ambassidae among aquarium hobbyists is the Indian glassfish, due to its distinctive transparent body.
In many species of glassfish, the internal organs and skeleton are visible through the skin.
Unfortunately, this remarkable trait has led to the practice of injecting dye directly into fish to produce neon stripes or spots.
This process is incredibly harmful to the fish, and most die during the procedure.
In 1997, the UK publication Practical Fishkeeping started a largely successful campaign to stop merchants from stocking fish that have been dyed.
While the movement was able to halt the sale of these fish in almost half the stores in the UK, the problem still persists in global markets.
Despite a reputation of being difficult to keep, glassfish actually make excellent aquarium additions if given the right environment.
Their natural habitats range from fresh to salt water depending on the species, but most prefer standing freshwater as opposed to brackish salt water.
It is better to keep a school instead of an individual or a pair, as a group of these fish will act much more energetically and boldly than would one or two alone.
The cover image is from a loose plate, origin unknown.
