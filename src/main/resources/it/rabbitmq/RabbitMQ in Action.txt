The publisher offers discounts on this book when ordered in quantity.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the publisher.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in the book, and Manning Publications was aware of a trademark claim, the designations have been printed in initial caps or all caps.
Recognizing the importance of preserving what has been written, it is Manning’s policy to have the books we publish printed on acid-free paper, and we exert our best efforts to that end.
Recognizing also our responsibility to conserve the resources of our planet, Manning books are printed on paper that is at least 15 percent recycled and processed without the use of elemental chlorine.
To my grandfather, Maximiliano Godoy, who showed me the ways of life.
So let me invite you to read on, if you think this description fits you:
You want a practical way to learn about push technology, streaming data, and other messaging patterns.
You want to achieve professional-level expertise with RabbitMQ, including best practices for design and running in production.
In other words, this book is not just a guide to RabbitMQ.
What are these patterns? If you’ve ever wanted to draw a picture of your system as an information flow or network, rather than as a stack, then you’re probably using xv.
You may be thinking of data delivery, nonblocking operations, or push notifications.
Or you want to use publish/subscribe, asynchronous processing, or work queues.
All of these are patterns, and they form part of the design canvas known as messaging.
Messaging is a critical capability: it enables software applications to connect and scale.
Applications can connect to each other as components of a larger application, or to user devices and data.
Messaging is essentially asynchronous in that it decouples applications by separating the sending and receiving of data.
The wonderful thing is that this connection pattern works in the same way at any scale.
The dominance of the internet as a basis for application delivery has made scale the critical factor in application design.
But everything is big now, compared to only a few years ago.
For example, the number of mobile-connected devices will exceed the number of people on earth soon, probably in 2012
Most applications used to look like this: you load a document or get data from a database, do some processing, and write the results to disk.
Future applications will look more like Facebook: always on, cloud hosted, and accessible anywhere.
Input and processing are continuous and automatic, and deliver a filtered stream of information that the user wants, as it happens.
These levels of automation, reach, and scale are impossible without adopting a very specific set of design patterns.
It is these patterns that you can learn in this book.
The patterns are presented as code examples that you can run, and the authors take special care to help you operate your system as well.
Williams and Alvaro Videla, you have access to experts who’ve been running large-scale RabbitMQ systems for years.
This book is a natural culmination of their outstanding work sharing these experiences with the community.
After you get a feel for RabbitMQ, it’s very easy to get help and find more examples via the extensive RabbitMQ user community, regardless of which languages you’re writing code in.
This makes RabbitMQ an excellent choice for your messaging needs.
I hope this has whetted your appetite to turn the page and read on.
There will be messages, and there will be rabbits, and all will be revealed.
We both had been active in the RabbitMQ community for the past two years, but we’d never actually bumped into each other.
Then one day a conversation with Alexis Richardson (Rabbit’s CEO at the time) introduced Alvaro and me to each other, and made what you hold in your hands possible.
What we had in common was a desire to write down in a single place all the knowledge we had acquired about RabbitMQ the hard way.
Back in 2010, that knowledge was (and today still largely is) scattered across the internet in a smattering of blog articles and terse technical tutorials.
In other words, we both wanted to write the book we wished had existed when we started with RabbitMQ two years earlier.
Neither of us came from a traditional messaging background, which made us fast friends and has largely informed the tone of RabbitMQ in Action; we wanted this book xvii.
In fact, when each of us discovered RabbitMQ, we didn’t even know what “messaging” was or that it was the solution to the problems we were having.
My (Jason’s) situation was that my company needed a way to take the spam reportings we received from our customers and process them out-of-band from our main stream of incoming messages.
In Alvaro’s case, his company had a social network whose member communication system was creaking under the load of a 200 GB database.
Like so many others who’ve come to messaging, both us had first tried to solve our queue-centric issues using database tables.
Problems, like ensuring that only one application instance consumed any particular queue item, plagued our attempts at a database-driven solution and sent us.
After all, we knew we couldn’t be the first people in the history of software to have these issues.
Halfway around the world, both of us discovered RabbitMQ in the same way, and in response to trying to solve almost exactly the same problem! In fact, since you’re reading this book about RabbitMQ, it’s likely that similar challenges have led you to discover RabbitMQ in the same way.
That speaks to the fact of why RabbitMQ is so popular: it  easily solves the basic problems of distributing data that each of us runs into again and again when trying to scale the software that we build.
Our hope is that RabbitMQ in Action will help you design solutions to those challenges more quickly and easily with RabbitMQ, so you can spend more time writing the software that will change the world and less time getting up to speed on the messaging broker that will help you do it.
Perhaps, along the way, RabbitMQ will introduce you to an awesome coauthor who will become the lifelong friend you never expected.1 This book is a product of how much we love writing software, and our hope is that it will help you do the same in ways you never thought possible.
They say that coauthor relationships have a worse “divorce” rate than marriage.
It’s not a bad comparison, since writing a book together requires the constant give-and-take and mutual respect that it takes to make living in close quarters work.
So it’s been an unexpected blessing to not only be able to write a book, but to discover a friend whose ideas can live in close quarters with yours and make a whole far greater than you could achieve alone.
First and foremost, we’d like to thank Alexis Richardson, RabbitMQ’s CEO when we started writing.
Without his recommendation, Manning would not have come knocking on our inboxes, and we would never have written a book together.
We also thank him for providing the foreword to our book.
In that vein, we need to express our utmost gratitude to the RabbitMQ team for continual help and answers to our incessant questions about the minutiae of Rabbit.
In particular, we owe a thank you to Matthew Sackman and Matthias Radestock, without whom the chapters on clustering and RabbitMQ internals would not have been possible.
Above all, we owe an incalculable debt of gratitude to Jerry Kuch from the RabbitMQ team.
Jerry volunteered countless hours repeatedly reviewing drafts of each chapter for accuracy, including doing the “official” technical review of the completed book by himself.
Every time we needed clarification or advice outside our experience, xix.
He was never cranky and never complained about being our point person on the RabbitMQ team.
If you find yourself discovering little picadillos you never knew about Rabbit’s operation, you likely have Jerry Kuch to thank.
He truly made this a better book, and is a fantastic engineer.
At Manning, we cannot thank our primary development editor Maria Townsley enough.
She put up with our work schedules, and our feast-or-famine style of delivering material.
Above all she was our advocate and fought for what was important to us.
If you enjoy the style of RabbitMQ in Action, thank Maria as she carried the flag for it.
We also need to thank Cynthia Kane tremendously for getting us through the final chapters and into print.
ACKNOWLEDGMENTSxx final development editor when we were set in our ways.
She adapted to our work style, and treated the book as if she’d been invested in it with us from day one.
Cynthia was truly our third-base coach and got us home.
I would like to thank my wife Silvana for being always there supporting me during the writing of this book.
Another big thanks goes to my mom for always believing in me.
I’d also like to thank my ol’ pals at The Netcircle in China where I caught the rabbit fever and made them hear the word RabbitMQ too many times a day.
Finally, I would like to thank Jason; Manning presented me with a coauthor and I ended up with a great friend.
I’m lucky enough to call my parents my partners in the startup we founded together, and as partners, I owe them and DigiTar a huge debt for never complaining when writing cut into work hours, and for giving me the flexibility to balance both.
Without our company, I would never have been driven to discover Rabbit or write the blog tutorials that led to being invited to write this book.
Among the many blessings and opportunities DigiTar has given me, this book is one of them.
You are the friend I never knew existed, my ever steadfast compatriot in arms, and truly my brother from another mother.
It doesn’t matter whether your project is big or small: RabbitMQ can adapt to your needs.
Do you want to quickly prototype one of your application components in language X and be sure you can easily switch it tomorrow to a more performant language? RabbitMQ can help you by decoupling the communication protocol.
Do you need to be able to process image uploads for your social website as they arrive, while adding or removing workers with ease? You can use Rabbit queues to store jobs and let the broker perform the load balancing and job distribution for you.
Problems like these can be easily and quickly solved by using RabbitMQ; this book is here to show you how to best implement your architectures around messaging.
Programming your application is one thing—keeping your application up and xxi.
Don’t worry; this book also covers best practices for RabbitMQ administration, clustering, securing, and monitoring, so you can also learn the operational side of things.
Finally, we’ll get into RabbitMQ’s brain and those inner details that will let you understand the system resources used by the broker so you can perform capacity planning while you design your architectures.
Next, you’ll install the server and create your first Hello World program that will send data via RabbitMQ.
We go from basic concepts up to seeing how to map those concepts in AMQP (the protocol used by RabbitMQ)
Once you’re past that, you’ll learn about message durability and what happens in the life of a message from being published to getting consumed on the other end of the network.
You’ll see how to start and stop nodes, how to configure permissions, and how to get statistics about what’s happening on the server.
And we give you some useful tips for troubleshooting the server.
Chapter 4 teaches you about messaging patterns and best practices.
You’ll learn about fire-and-forget models, RPC architectures, and much more.
Chapter 5 starts a series of three chapters on RabbitMQ clustering and setup for high availability.
Here you’ll set up a RabbitMQ cluster both on your local machine and on physical servers.
You’ll learn how to upgrade a cluster of RabbitMQ nodes and how to use mirrored queues.
Chapter 6 discusses how to load balance a set of RabbitMQ brokers using HAProxy while teaching how to create smart messaging clients that know how to reconnect to the broker in case of failures.
Chapter 7 ends the series on high availability by explaining how active/standby broker pairs work.
You’ll also learn about the Shovel plugin that allows RabbitMQ to replicate data across data centers.
You’ll learn about the RabbitMQ Management plugin and its web interface, but we don’t stop there: we also perform an overview of the REST API offered by the plugin.
Chapter 9 builds from the previous chapter by explaining the REST API in detail.
Here you’ll learn how most of the administration tasks can be performed from your code by using this API.
Provisioning new users and virtual hosts for your applications was never so easy.
Chapter 10 teaches you how to monitor RabbitMQ, from Nagios checks to using AMQP and the REST API to monitor the server internal state.
You’ll learn what you can do to detect problems before they happen.
Chapter 11 explains in detail the inner workings of exchanges (the routing algorithms used by RabbitMQ)
We go into the details of the resources used by your messaging fabric to see what to expect from your architectural decisions.
We also cover the security side of things by teaching you to enable SSL connections for your applications.
Chapter 12 ends the book by showing how to extend RabbitMQ’s behavior both by adding new plugins created by others and by creating your own plugin.
Code conventions and downloads All source code in listings or in text is in a fixed-width font like this to separate it from ordinary text.
Code annotations accompany many of the listings, highlighting important concepts.
In some cases, numbered bullets link to explanations that follow the listing.
Since one of RabbitMQ’s greatest strengths is gluing together applications written in different languages, we use both Python and PHP as the primary example languages (with a little .NET and Java thrown in for good measure in the appendixes)
But we want our examples to be as widely usable as possible to readers from all languages.
In the official Github repository you’ll find the latest versions of the example code from the book, along with a number of those examples already converted by other readers into languages like Ruby.
Note: you must use the same BSD license as our code for us to pull your changes in.)
The exact code as it appears in the latest published edition of the book will always be posted there.
The purchase of RabbitMQ in Action includes free access to a private forum run by Manning Publications where you can make comments about the book, ask technical questions, and receive help from the authors and other users.
This page provides information on how to get on the forum once you’re registered, what kind of help is available, and the rules of conduct in the forum.
Manning’s commitment to our readers is to provide a venue where a meaningful dialogue between individual readers and between readers and the authors can take place.
It isn’t a commitment to any specific amount of participation on the part of the authors, whose contribution to the book’s forum remains voluntary (and unpaid)
We suggest you try asking the authors some challenging questions, lest their interest stray!
The Author Online forum and the archives of previous discussions will be accessible from the publisher’s website as long as the book is in print.
The illustrations were obtained from a helpful librarian at the Ethnographic Museum in Split, itself situated in the Roman core of the medieval center of the town: the ruins of Emperor Diocletian’s retirement palace from around AD 304
The book includes finely colored illustrations of figures from different regions of Croatia, accompanied by descriptions of the costumes and of everyday life.
It is situated on the northeastern coast of the island of Korcula, one of a number of small islands in the Adriatic off the western coast of Croatia.
The farmer on the cover is wearing his work clothes, not one of the colorful and richly embroidered costumes that are typical for this region, worn only on Sundays and other special occasions.
He is smoking a pipe, leaning on a spade, and, appropriately enough, looking down at a white rabbit, in a moment of rest from his toils.
Dress codes and lifestyles have changed over the last 200 years, and the diversity by region, so rich at the time, has faded away.
It’s now hard to tell apart the inhabitants of different continents, let alone of different hamlets or towns separated by only a few miles.
Perhaps we have traded cultural diversity for a more varied personal life— certainly for a more varied and fast-paced technological life.
Manning celebrates the inventiveness and initiative of the computer business with book covers based on the rich diversity of regional life of two centuries ago, brought back to life by illustrations from old books and collections like this one.
We live in a world where real-time information is constantly available, and the applications we write need easy ways to be routed to multiple receivers reliably and quickly.
More important, we need ways to change who gets the information our apps create without constantly rewriting them.
Too often, our application’s information becomes siloed, inaccessible by new programs that need it without rewriting (and probably breaking) the original producers.
You’ve just finished implementing a great authentication module for your company’s killer web app.
On every page hit, your code efficiently coordinates with the authentication server to make sure your users can only access what Pulling RabbitMQ out of the hat.
You’re feeling smug, because every page hit on your company’s worldclass avocado distribution website activates your code.
That’s about when your boss walks in and tells you the company needs a way to log every successful and failed permission attempt so that it can be data mined.
After you lightly protest that that’s the job of the authentication server, your boss not so gently informs you that there’s no way to access that data.
The authentication server logs it in a proprietary format; hence this is now your problem.
Mulling over the situation causes a four-aspirin headache, as you realize you’re going to have to modify your authentication module and probably break every page in the process.
After all, that wonderful code of yours touches every access to the site.
Let’s punch the Easy button and time warp back to the beginning of the development of that great auth module.
Let’s assume you leveraged message queuing heavily in its design from day one.
With RabbitMQ in place, you brilliantly leveraged message queuing to decouple your module from the authentication server.
With every page request, your authentication module is designed to place an authorization request message into RabbitMQ.
The authentication server then listens on a RabbitMQ queue that receives that request message.
Once the request is approved, the auth server puts a reply message back into RabbitMQ where it’s routed to the queue that your module is listening on.
You realize you don’t need to touch your module or even write a new one.
All you need to do is write a small app that connects to RabbitMQ and subscribes to the authorization requests your auth module is already publishing.
It’s so simple a smile almost breaks out on your face.
That’s the power of messaging to make your day job easier.
Message queuing is simply connecting your applications together with messages that are routed between them by a message broker like RabbitMQ.
It’s like putting in a post office just for your applications.
The reality is that this approach isn’t just a solution to the real-time problems of the financial industry; it’s a solution to the problems we all face as developers every day.
We, the authors, don’t come from a financial services background.
We were simply devs like you with an itch that needed scratching: an itch to deal with real-time volumes of information and route it to multiple consumers quickly.
We needed to do it all without blocking the producers of that information … and without them needing to know who the final consumers might be.
RabbitMQ helped us to solve those common problems easily, and in a standards-based way that ensured any app of ours could talk to any other app, be it Python, PHP, or even Scala.
Over the next few chapters, we’ll take you on a ride.
It starts by explaining how message queuing works, its history, and how RabbitMQ fits in.
This is the book we wished was on the shelves when we entered the messaging wilderness.
We hope it will help you benefit from our experience and battle scars and free you to make amazing applications with less pain.
Before we’re done in this chapter, you’ll have a short history of messaging under your belt, and RabbitMQ up and running.
Without further ado, let’s take a look at where all this messaging fun started.
It didn’t take long for this model of data transfer to find many more killer uses.
After all, an application publishing data and an application consuming it no longer had to directly connect to each other.
Heck, they didn’t even have to know each other existed.
What Teknekron’s TIB allowed application developers to do was establish a set of rules for describing message content.
As long as the messages were published according to those rules, any consuming application could subscribe to a copy of the messages tagged with topics it was interested in.
Producers and consumers of information could now be completely decoupled and flexibly mixed on-the-fly.
The only thing that needed to remain stable was the TIB software and the rules for tagging and routing the information.
Since the financial trading industry is full of information with a constantly changing set of interested folks, TIB spread like wildfire in that sector.
That’s why mega news outfit Reuters purchased Teknekron in 1994
Through all of this evolution, message queuing (MQ) software primarily remained the domain of large-budgeted organizations with a need for reliable, decoupled, realtime message delivery.
The commercial MQ vendors wanted to help applications interoperate, not create standard interfaces that would allow different MQ products to interoperate or, Heaven forbid, allow applications to change MQ platforms.
Vendor lock-in has kept prices and margins high, and commercial MQ software out of reach of the startups and Web 2.0 companies that are abounding today.
As it turned out, smaller tech companies weren’t the only ones unhappy about the high-priced walled gardens of MQ vendors.
The financial services companies that formed the bread and butter of the MQ industry weren’t thrilled either.
Inevitably, the size of financial companies meant that MQ products were in place from multiple vendors servicing different internal applications.
If an application subscribing to information on a TIBCO MQ suddenly needed to consume messages from an IBM MQ, it couldn’t easily be done.
They used different APIs, different wire protocols, and definitely couldn’t be federated together into a single bus.
Technically, a Java application only needs to be written to the JMS API, with the appropriate MQ drivers selected.
A brief history of RabbitMQ problem is you’re trying to glue a single standard interface over multiple diverse interfaces.
It’s like gluing together different types of cloth: eventually the seams come apart and the reality breaks through.
By virtue of being an open standard, anyone can implement it, and anyone who codes to the standard can interoperate with MQ servers from any AMQP vendor.
In the early 2000s, a young entrepreneur out of the London financial sector cofounded a company for caching Java objects: Metalogic.
For Alexis Richardson, the theory was simple enough: use Java objects for distributed computing and cache them in transit for performance.
Varying versions of the Java Virtual Machine, as well as differing libraries on the client and server, could make the.
There were too many environment variables in the real world for Metalogic’s approach to be widely successful.
Matthias was working for LShift, where Alexis was subleasing office space while at Metalogic.
LShift at the time was heavily involved in language modeling and distributed computing contracts for a major software vendor.
The background in these areas triggered Matthias’s interest in Erlang, the programming language that Ericsson had originally developed for their telephone switching gear.
What grabbed Matthias’s attention was that Erlang excelled at distributed programming and robust failure recovery, but unfortunately at the time it wasn’t open source.
In the meantime, Metalogic had closed operations and LShift was in the process of winding down their primary distributed computing contract.
But Alexis had learned two valuable lessons from his experience at Metalogic: what works in a distributed computing environment, and what companies want for those environments.
Alexis knew he wanted to start a new company to solve the problems of communicating in a distributed environment.
He also knew the next company he started would be open source and build on the model just proved successful by JBoss and MySQL.
Looking back at where the Metalogic solution had run into problems, Alexis started to see that messaging was the right answer to distributed computing.
More important, in the tech world circa 2004 a huge gap existed for open source messaging.
No one was providing a messaging solution except for the big commercial vendors, and while “enterprise” open source was flourishing with databases (MySQL) and application servers (JBoss), no one was touching the missing component: messaging.
Interestingly, it was in 2004 that AMQP was just starting to be developed at JPMorgan Chase.
Through his background in the financial industry, Alexis had been introduced to the principal driver of AMQP at JPMorgan, John O’Hara (future founder of the AMQP Working Group)
Through O’Hara, Alexis became acquainted with AMQP, and started lining up the building blocks for what would become RabbitMQ.
That a key part of that stack would be distributed messaging seemed obvious to Alexis, who (still in the same office as LShift) started talking to Matthias about AMQP.
What was clear to Matthias was that he’d just found the application he’d been looking for to write in Erlang.
But before any of this could get started, Alexis and Matthias focused on three questions that they knew would be critical to an open source version of AMQP being successful if it was written in Erlang:
Would large financial institutions care whether their messaging broker was written in Erlang?
Was Erlang really a good choice for writing an AMQP server?
The first issue was quickly dispatched by a financial company who confirmed they didn’t care what it was written in if it helped reduce their integration costs.
The second question was answered by Francesco Cesarini at Erlang Solutions: from his analysis of AMQP, the specification implied an architecture present in every telephone switch.
In other words, you couldn’t pick a better implementation language than Erlang for building an AMQP broker.
The final question was put to rest by an entirely different messaging server: ejabberd.
By 2005, Extensible Messaging and Presence Protocol (XMPP) had become a respected standard for open instant messaging, and one of the foremost implementations was the Erlang-based ejabberd server package by Alexey Shchepin.
With the three major questions answered, Alexis and Matthias convinced CohesiveFT and LShift to jointly back the project.
The first thing they did was contract Matthew Sackman (now a core Rabbit developer) to write a prototype in Erlang to test latency.
They quickly discovered that using the distributed computing libraries built into Erlang produced incredible latency that was comparable to using raw sockets.
There was also the question of what to call this thing: everyone agreed on Rabbit.
After all, rabbits are fast and they multiply like crazy, making it a great name for distributed software.
Not the least of the reasons for this choice is that Rabbit is easy to remember.
Thus, in 2006 Rabbit Technologies was born: a joint venture between CohesiveFT and LShift that would hold the intellectual property for what we know today as RabbitMQ.
The timing couldn’t have been more perfect because, around the same time, the first public draft of the AMQP specification had become available.
By using Erlang, RabbitMQ could be developed quickly and keep pace with a moving target: the AMQP standard.
Amazingly, version 1.0 of RabbitMQ was written in only two and a half months by core developer Tony Garnock-Jones.
From the beginning, RabbitMQ has implemented a key feature of AMQP that differentiates it from TIBCO and IBM: provisioning resources like queues and exchanges can be done from within the protocol itself.
With the commercial vendors, provisioning is done by specialized staff at specialized administrative consoles.
RabbitMQ’s provisioning capabilities make it the perfect communication bus for anyone building a distributed application, particularly one that leverages cloud-based resources and rapid deployment.
Options like ActiveMQ, ZeroMQ, and Apache Qpid all providing different open source approaches to message queuing.
The question is, why do we think you should pick RabbitMQ?
Except for Qpid, RabbitMQ is the only broker implementing the AMQP open standard.
Perhaps the most important reason is that RabbitMQ is incredibly easy to install and use.
Whether you need a simple one-node setup for your workstation, or a sevenserver cluster to power your web infrastructure, RabbitMQ can be up and running in about 30 minutes.
With that in mind, it’s about time we fired up the little critter.
So far we’ve discussed the motivation behind the AMQP protocol and the history of the RabbitMQ server.
Now it’s time to get the broker up and running and start doing cool stuff with it.
The operating system requirements for running RabbitMQ are flexible because we can run it on several platforms including Linux, Windows, Mac OS X, and other Unix-like systems.
In this chapter we’ll go through the process of setting up the server for a generic Unix system (all examples and instructions in the book assume a UNIX environment unless otherwise noted)
Since RabbitMQ is written in Erlang, we need to have installed the language libraries to run the broker.
We recommend that you use the latest version of Erlang, which at the time of this writing is R14A.
You can obtain a copy of Erlang from its website (http://www.erlang.org/)
By running the latest version of Erlang on your system, you’ll be sure to have all the updates and improvements for the foundations RabbitMQ will run on.
Every new release of Erlang includes performance improvements that are worth having.
Once you have RabbitMQ dependencies solved, create a folder where you can perform our tests.
Assuming that you’re running a Unix-flavored system, fire up a terminal to start typing commands:
Select the package for a generic Unix system and download it:1
You’re nearly ready to start the broker, but there are a couple of folders to create before you do that.
The first one is where RabbitMQ will write the logs.
You can look into this folder in case you need to troubleshoot your installation.
The second folder is for the Mnesia database that RabbitMQ uses to store information about the broker, like queue metadata, virtual hosts, and so on.
You may need to run those commands as a super user.
If you have to do so, then don’t forget to chown the folders to your system user.
If all went as expected, you’ll see ASCII art of the RabbitMQ logo and the message broker running, as seen in figure 1.2
Now open a new terminal window and check the status of the server.
Pre-build installation packages for RabbitMQ are available for Windows, Debian/Ubuntu and RedHat (RPM) from http://www.rabbitmq.com/download.html.
If you installed from an RPM or Ubuntu/Debian package, you may need to run rabbitmqctl as root.
As you can see in figure 1.3, this command will output the status of the broker, the running applications, and nodes.
At this point you have a RabbitMQ broker running in your computer with the default configuration.
Now more theory about messaging, and then we’ll start running some examples against the broker.
Now you can see why we love RabbitMQ so much.
Despite being the progeny of technology from the financial industry, it’s dead simple to set up.
You get complex routing and reliability features pioneered by folks like TIBCO and IBM but in a package that’s easier to manage and use.
And the best part, it’s open source! We’ve shown how far.
Summary financial traders, to message routing monsters that are the beating heart of everything related to financial exchanges, to the manufacturing lines at semiconductor fabs.
Now you have that kind of power running on your dev laptop, and we’ve only finished chapter 1! With RabbitMQ running, it’s time to dive into the building blocks of messaging: queues, bindings, exchanges, and virtual hosts.
When you say messaging, programmers think of a lot of different things.
Email and IM come most readily to mind, but these models aren’t what we mean when we talk about messaging in terms of RabbitMQ.
Messaging in RabbitMQ has some elements in common with email and IM, but is a completely different paradigm.
For example, while AMQP, like email, stores messages for consumers who aren’t online, those messages are routed based on tags that are much more flexible.
Also different from email, the messages have no set structure and can even store binary data directly.
Unlike IM protocols, AMQP hides the sender and receiver from each other.
As a result, you have a flexible infrastructure that encourages pervasive decoupling of your applications.
Consumers and producers (not an economics lesson) Since AMQP messaging is different from other messaging protocols, we’ll spend the next few sections explaining the lingo and building blocks of AMQP.
If you have a good basis in enterprise messaging systems like TIBCO or IBM’s MQSeries, a lot of this will be familiar.
Let’s start by forgetting the client/server distinction we’ve had ingrained in us and begin figuring out consumers and producers.
Whether it’s a browser and a web server, or your app and a MySQL server, you have someone making requests and someone servicing them.
Your app places the order and the food truck fulfills it.
The source of the data you want is the food truck server.
This model is usually how we try to understand anything that involves our app and a service.
So with this new messaging approach, you might ask, who’s the customer, who’s the food truck, and how do I order?
The data your app gets from RabbitMQ is no more served from Rabbit than the package you pick up was produced by FedEx.
The server with the data you need can send and receive too.
The role RabbitMQ plays is as the router between your app and the “server” it's talking to.
Producers create messages and publish (send) them to a broker server (RabbitMQ)
What’s a message? A message has two parts: a payload and a label.
It can be anything from a JSON array to an MPEG-4 of your favorite iguana Ziggy.
It describes the payload, and is how RabbitMQ will determine who should get a copy of your message.
Unlike, for example, TCP, where you specify a specific sender and a specific receiver, AMQP only describes the message with a label (an exchange name and optionally a topic tag) and leaves it to Rabbit to send it to interested receivers based on that label.
We’ll get more details about how RabbitMQ interprets the label later when we talk about exchanges and bindings.
For now, all you need to know is that producers create messages and label them for routing (see figure 2.1)
They attach to a broker server and subscribe to a queue.
By the time a consumer receives a message, it now only has one part: a payload.
The labels attached to the message don’t get passed along with the payload when the message is routed.
It would be like picking up your mail but all of the envelopes are blank.
Similarly, if you need to know specifically who produced an AMQP message, it’s up to the producer to include that information as a part of the message payload.
From the outside it’s simple: producers create messages and consumers receive them.
Your app can be a producer when it needs to send a message to another app, or it can be a consumer when it needs to receive.
But before it can do either it has to set up a channel.
Before you consume from or publish to Rabbit, you first have to connect to it.
By connecting, you’re creating a TCP connection between your app and the Rabbit broker.
Once the TCP connection is open (and you’re authenticated), your app then creates an AMQP channel.
This channel is a virtual connection inside the “real” TCP connection, and it’s over the channel that you issue AMQP commands.
Every channel has a unique ID assigned to it (your AMQP library of choice will handle remembering the ID for you)
Whether you’re publishing a message, subscribing to a queue, or receiving a message, it’s all done over a channel.
Let’s say your app consumes messages from a queue and spins threads up or down based on service demand.
Consumers and producers (not an economics lesson) each thread would need its own connection to Rabbit, which could mean hundreds of connections per second during high load periods.
Not only would this be a massive waste of TCP connections, but an operating system can only build so many per second.
Wouldn’t it be cool if you could use one TCP connection for all of your threads for performance, but get the same privacy as giving each thread its own connection? This is where a channel comes in.
As each thread spins up, it creates a channel on the existing connection and gets its own private communication path to Rabbit without any additional load on your operating system’s TCP stack, as in figure 2.2
As a result, you can create a channel hundreds or thousands of times a second without your operating system seeing so much as a blip.
There’s no limit to how many AMQP channels you can have on one TCP connection.
Think of it like a bundle of fiber optic cable.
Each fiber strand in the cable can transmit (just like a channel)
But the cable has many fiber strands, allowing all the connected threads to transmit and receive simultaneously via multiple strands.
A TCP connection is like the cable, and an AMQP channel is like an individual fiber strand.
How about an example? Let’s say you’ve written a service for keeping track of valet parking, and everyone talks to it through RabbitMQ.
With the second task, your service is both a consumer and a producer.
It needs to receive messages that tell it a particular valet ticket ID and then it needs to publish a response message with the associated parking space number.
To fulfill the second task, your app is a producer.
When a ticket retrieval message is received by your app over chan_recv, it looks up the ticket ID contained in the message.
As soon as the associated parking space number has been identified, your app then creates a thread to send the response (letting the original thread continue to receive new requests)
The new reply thread then creates a message containing the parking space number.
Finally, the new thread labels the response message and publishes it to Rabbit using its chan_sendX channel.
If your app had only one channel, it wouldn’t be.
With multiple channels, many threads can share the same connection simultaneously, meaning that responding to requests doesn’t block you from consuming new requests and you don’t waste a TCP connection for each thread.
Sometimes you may choose to use only one channel, but with AMQP you have the flexibility to use as many channels as your app needs without the overhead of multiple TCP connections.
The important thing to remember about consumers and producers is that they map to the ideas of sending and receiving rather than client and server.
Messaging in general, and AMQP in particular, can be thought of as an enhanced transport layer.
With channels, you have the ability to create as many parallel transport layers as your app needs without being limited by TCP connection restrictions.
When you understand these concepts, you can begin thinking of RabbitMQ as a router for your software.
You have consumers and producers under your belt, and now you’re itching to get started eh? Not so fast.
Conceptually, there are three parts to any successful routing of an AMQP message: exchanges, queues, and bindings.
The exchanges are where producers publish their messages, queues are where the messages end up and are received by consumers, and bindings are how the messages get routed from the exchange to particular queues.
Before you get to examine exchanges and bindings, you need to understand what a queue is and how it works.
As we said when we were talking about producers and consumers, queues are like named mailboxes.
They’re where messages end up and wait to be consumed.
Consumers receive messages from a particular queue in one of two ways:
This will place the channel being used into a receive mode until unsubscribed from the queue.
While subscribed, your consumer will automatically receive another message from the queue (as available) after consuming (or rejecting) the last received message.
You should use basic.consume if your consumer is processing many messages out of a queue and/or needs to automatically receive messages from a queue as soon as they arrive.
Sometimes, you just want a single message from a queue and don’t need to be persistently subscribed.
Requesting a single message from the queue is done by using the basic.get AMQP command.
This will cause the consumer to receive the next message in the queue and then not receive further messages until the next basic.get.
You shouldn’t use basic.get in a loop as an alternative to basic.consume, because it’s much more intensive on Rabbit.
If one or more consumers are subscribed to a queue, messages are sent immediately to the subscribed consumers.
But what if a message arrives at a queue with no subscribed consumers? In that case, the message waits in the queue.
As soon as a consumer subscribes to the queue, the message will be sent to that consumer.
A more interesting question is how messages in a queue are distributed when multiple consumers are subscribed to the same queue.
When a Rabbit queue has multiple consumers, messages received by the queue are served in a round-robin fashion to the consumers.
Each message is sent to only one consumer subscribed to the queue.
As messages arrive in seed_bin, the deliveries would look like this:
You may have noticed that Farmers Bob and Esmeralda did something we haven’t talked about yet: they acknowledged receipt of the message.
Either the consumer must explicitly send an acknowledgement to RabbitMQ using the basic.ack AMQP command, or it can set the auto_ack parameter to true when it subscribes to the queue.
When auto_ack is specified, RabbitMQ will automatically consider the message acknowledged by the consumer as soon as the consumer has received it.
An important thing to remember is that message acknowledgements from the consumer have nothing to do with telling the producer of the message it was received.
Instead, the acknowledgements are a way for the consumer to confirm to RabbitMQ that the consumer has correctly received the message and RabbitMQ can safely remove it from the queue.
If a consumer receives a message and then disconnects from Rabbit (or unsubscribes from the queue) before acknowledging, RabbitMQ will consider the message undelivered and redeliver it to the next subscribed consumer.
If your app crashes, you can be assured the message will be sent to another consumer for processing.
On the other hand, if your consumer app has a bug and forgets to acknowledge a message, Rabbit won’t send the consumer any more messages.
This is because Rabbit considers the consumer not ready to receive another message until it acknowledges the last one it received.
If processing the contents of a message is particularly intensive, your app can delay acknowledging the message until the processing has finished.
This will keep Rabbit from overloading you with more messages than your app can handle.
What if you want to specifically reject a message rather than acknowledge it after you've received it? For example, let’s say that when processing the message you encounter an uncorrectable error, but it only affects this consumer due to a hardware issue (this is a good reason to never acknowledge a message until it’s processed)
As long as the message hasn’t been acknowledged yet, you have two options:
RabbitMQ to automatically requeue the message and deliver it to another consumer.
The advantage to this method is that it works across all versions of RabbitMQ.
The disadvantage is the extra load put on the RabbitMQ server from the connecting and disconnecting of your consumer (a potentially significant load if your consumer is encountering errors on every message)
If you’re running RabbitMQ 2.0.0 or newer, use the basic.reject AMQP command.
If you set the requeue parameter of the reject command to true, RabbitMQ will redeliver the message to the next subscribed consumer.
Setting requeue to false will cause RabbitMQ to remove the message from the queue immediately without resending it to a new consumer.
You can also discard a message simply by acknowledging it (this method of discarding has the advantage of working with all versions of RabbitMQ)
This is useful if you detect a malformed message you know none of your consumers will be able to process.
If you want your app to automatically take advantage of the dead letter queue feature when it’s added to Rabbit, use the reject command with requeue set to false.
There’s one more important thing you need to know about queues: how to create them.
Both consumers and producers can create queues by using the queue.declare AMQP command.
But consumers can’t declare a queue while subscribed to another one on the same channel.
They must first unsubscribe in order to place the channel in a “transmit” mode.
When creating a queue, you usually want to specify its name.
The name is used by consumers to subscribe to it, and is how you specify the queue when creating a binding.
Here are some other useful properties you can set for the queue:
This is useful when you need to limit a queue to only one consumer.
If you need a temporary queue used only by one consumer, combine auto-delete with exclusive.
What happens if you try to declare a queue that already exists? As long as the declaration parameters match the existing queue exactly, Rabbit will do nothing and return successfully as though the queue had been created (if the parameters don’t match, the declaration attempt will fail)
If you just want to check whether a queue exists, you can set the passive option of queue.declare to true.
With passive set to true, queue.declare will return successfully if the queue exists, and return an error without creating the queue if it doesn’t exist.
When you’re designing your apps, you’ll most likely ask yourself whether your producers or consumers should create the queues you need.
It might seem that the most natural answer is that your consumers should create your queues.
After all, they’re the ones that need to subscribe, and you can’t subscribe to a queue that doesn’t exist, right? Not so fast.
You need to first ask yourself whether the messages your producers create can afford to disappear.
Messages that get published into an exchange but have no queue to be routed to are discarded by Rabbit.
So if you can’t afford for your messages to be black-holed, both your producers and your consumers should attempt to create the queues that will be needed.
With queues under your belt, you’re ready to move to the next building block of Rabbit: exchanges and bindings!
As you saw in the previous sections, you want to have consumers fetching messages from your queues.
Now the question, is how does a message reach a queue? Meet AMQP bindings and exchanges.
Whenever you want to deliver a message to a queue, you do it by sending it to an exchange.
Then, based on certain rules, RabbitMQ will decide to which queue it should deliver the message.
A queue is said to be bound to an exchange by a routing key.
If they match, then the message will be delivered to the queue.
If the routing message doesn’t match any of binding patterns, it’ll be black-holed.
Let’s look at an example to understand the advantages of such concept.
You can compare this scenario with email: if you want to send a message to any of your contacts, you send it to his address, and the SMTP server will check whom the message is addressed to and will take care of delivering it to that user’s inbox.
But what happens if your contact wants every message sent from you to be filed into the business folder? Then they have to set up certain rules based on the content of the message in order to achieve such a goal.
They may also want rules that send the message to the same folder, for example, based on the hostname of some business providers.
With the concepts of exchanges, bindings, and queues, AMQP can accommodate such use cases and many more, so you can bind a queue to an exchange with no routing key and then every message with no routing key that you send to that exchange will be delivered to said queue, in a fashion similar to email.
If you require complex use cases, like publish/subscribe or multicast, you can achieve that too.
Getting together: exchanges and bindings accomplish—with a broker that only allows you to publish directly to queues.
As you’ve seen, the broker will route messages from exchanges to queues based on routing keys, but how does it handle delivery to multiple queues? Here come into play the different types of exchanges provided by the protocol.
We’ll go over all of them except the headers exchange, which allows you to match against a header in the AMQP message instead of the routing key.
Other than that, it operates identically to the direct exchange but with much worse performance.
As a result, it doesn’t provide much real-world benefit and is almost never used.
Let’s see each of the other exchange types in detail.
The direct exchange is pretty simple: if the routing key matches, then the message is delivered to the corresponding queue.
You can see a representation of this in figure 2.4
The broker must implement the direct exchange, including a default exchange with an empty string as its name.
When a queue is declared, it’ll be automatically bound to that exchange using the queue name as routing key.
This means that you can use code like the following to send messages to a previously declared queue, provided that you obtained a channel instance:
The first parameter is the message that you want to send, the second one is an empty string to specify the default exchange, and the third one will be the routing key, which is the name you used to declare the queue.
Later you’ll see how to achieve the RPC messaging pattern using the default exchange and temporary queues.
When the default direct exchange isn’t enough for your application’s needs, you can declare your own exchanges.
You can issue the exchange.declare command with appropriate parameters to accomplish that.
The next type of exchange that we’ll discuss is the fanout exchange.
As you can see from figure 2.5, this exchange will multicast the received message to the bound queues.
The messaging pattern is simple: when you send a message to a fanout exchange, it’ll be delivered to all the queues attached to this exchange.
This allows you to react in different ways based on only one message.
For example, a web application may require that when a user uploads a new picture, the user’s own image gallery cache.
You can have two queues bound to the upload-pictures exchange, one with consumers clearing the cache and the other one for increasing user points.
Also from this scenario, you can see the advantage of using exchanges, bindings, and queues over publishing messages directly to queues.
Let’s say that the first requirement of the application was that after a picture was uploaded to the website, the user gallery cache was cleared.
You can easily implement that by using just one queue, but what happens when the product owner comes to you with the new feature of giving awards to users for their actions? If you’re sending messages directly to queues, then you have to modify the publisher’s code to send message to the new points queue.
If you’ve been using fanout exchanges, the only thing that you have to do is to write the code for your new consumer and then declare and bind a new queue to the fanout exchange.
As we said earlier, the publisher’s code is completely decoupled from the consumer’s code, allowing you to increase your application functionality with ease.
This exchange allows you to achieve interesting messaging scenarios, where messages can arrive to the same queue coming from different sources.
Let’s take as an example a logging system for your web application.
You have several logging levels, like error, info, and warning, and at the same time your application is separated into modules like user-profile, image-gallery, msg-inbox, and so forth.
As you can see in figure 2.6, if you want to report an error when the send message action failed, you can do so with the following code:
Then, provided that you’ve declared a queue msg-inbox-errors, you can bind it to the exchange to receive the messages like this:
So far this looks very similar to a direct exchange.
You’ve used the same string error.msg-inbox as the binding rule for the queue-binding operation and for the message publication routing key.
That will ensure that your message is routed into the msg-inbox-errors queue, nothing fancy.
But what if you want to have a queue listening to all kinds of error levels that happen in the msg-inbox module? You can do so using the same exchange that you already have by binding a new queue like this:
The msg-inbox-logs queue will receive all the error, warning, and info log messages from the msg-inbox module.
What about receiving all the logs? That’s easy to accomplish too.
You can use a wildcard while binding the queue to the exchange.
As you can see from the previous examples, a single.
To perform a match-all rule you can use the # character:
With that binding, the all-logs queue will receive all the logs published by your web application.
Of course for all the previous examples to work you must have declared the queues in advance before performing the bindings.
Now that you know about these three exchange types, you can see the power offered by AMQP.
You can program the broker behavior to work in the way you want.
It can be used just as a queue server, in a publish/subscribe setup, or as an RPC server.
It just depends on how you wire the pieces together.
The key components in the AMQP architecture are exchanges, queues, and bindings.
With exchanges, bindings, and queues under your belt, you might think you have all the coolness that is Rabbit figured out.
But if you’ve played around much with Rabbit, you know there’s one nagging concept we haven’t talked about yet: the vhost.
Within every RabbitMQ server is the ability to create virtual message brokers called virtual hosts (vhosts)
Each one is essentially a mini-RabbitMQ server with its own queues, exchanges, and bindings … and, more important, its own permissions.
This lets you safely use one RabbitMQ server for multiple applications without worrying that your Sudoku app might delete queues used by your lost Fido tracker.
Vhosts are to Rabbit what virtual machines are to physical servers: they allow you to run data for multiple applications safely and securely by providing logical separation between instances.
This is useful for anything from separating multiple customers on the same Rabbit to avoiding naming collisions on queues and exchanges.
Where otherwise you might have to run multiple Rabbits and gain all the management headaches that come with that, you can instead run one Rabbit and build up or tear down vhosts on demand.
Vhosts are so fundamental to the concept of AMQP that you have to specify one when you connect.
RabbitMQ makes it easy to get started by including a default vhost called / right out of the box.
If you don’t need multiple vhosts, just use the default one.
It’s accessible using the default guest username with password guest, though you should change the password for security (more on this in chapter 3)
An interesting property of AMQP is that it doesn’t specify whether permissions are per vhost or server-wide.
This is left up to the broker developer and in RabbitMQ’s case permissions are per vhost.
When you create a user in Rabbit, it’s usually assigned to at least one vhost and will only be able to access queues, exchanges, and bindings on those assigned vhosts.
Also, when you’re designing your messaging architecture, keep in mind that separation between vhosts is absolute.
This is actually a good thing, not only for security, but also for portability.
Imagine for a second that you’ve designed the check cashing tier of your magnificent banking app to use its own vhost.
You might initially put this vhost on the same Rabbit that houses the vhosts for other tiers of your app.
But one day your customers start cashing millions of checks—good for you but bad for the Rabbit server.
Check cashing needs to be on a Rabbit server with less load.
If the check cashing tier had used the default vhost, you would have to worry about naming collisions (queues and exchanges) when you point it to the new Rabbit server.
But since it has its own vhost, you can safely move everything to any other Rabbit server and instantly start handling the new load without any name collisions.
Hence, we highly recommend identifying the common functionality groups in your infrastructure (such as web logging) and giving each one its own vhost.
Also, keep in mind that when you create a vhost on a RabbitMQ cluster, it’s created across the entire cluster.
Just as vhosts eliminate needing to run a RabbitMQ server for every tier in your infrastructure, they also avoid making you create different clusters for each tier.
We’ve talked about all of the great benefits of vhosts, but how do you create them? Vhosts and permissions are unique in that they’re the only primitives in AMQP (unlike queues, exchanges, and bindings) that can’t be created using the AMQP protocol.
For RabbitMQ they’re created using the rabbitmqctl utility found in the ./sbin/ directory of your RabbitMQ installation.
Once a vhost has been created, you can connect to it and start adding your queues and exchanges.
You need to make sure the server running the Rabbit node and the workstation you’re running rabbitmqctl on have the same Erlang cookie installed.
For more info on Erlang cookies, check out section 3.4.1
Now that you’ve secured your queues and exchanges with vhosts, it’s time to talk about making sure critical messages don’t disappear when Rabbit crashes or reboots.
There’s a dirty secret about creating queues and exchanges in Rabbit: by default they don’t survive reboot.
That’s right; restart your RabbitMQ server and watch those queues and exchanges go poof (along with the messages inside)
The reason is because of a property on every queue and exchange called durable.
It defaults to false, and tells RabbitMQ whether the queue (or exchange) should be re-created after a crash or restart of Rabbit.
Set it to true and you won’t have to re-create those queues and exchanges when the power supply in your server dies.
You might also think that setting durable to true on the exchanges and queues is all you need to do to make your messages survive a reboot, but you’d be wrong.
Whereas queues and exchanges must be durable to allow messages to survive reboot, it isn’t enough on its own.
A message that can survive a crash of the AMQP broker is called persistent.
You flag a message as persistent by setting the delivery mode option of the message to 2 (your AMQP client may use a human-friendly constant instead) before publishing it.
If this weren’t the case, the queue (or exchange) a persistent message was sitting in when Rabbit crashed wouldn’t exist when Rabbit restarted, thereby orphaning the message.
So, for a message that’s in flight inside Rabbit to survive a crash, the message must.
Do these three things and you won't have to play Where’s Waldo with your critical messages.
The way that RabbitMQ ensures persistent messages survive a restart is by writing them to the disk inside of a persistency log file.
When you publish a persistent message to a durable exchange, Rabbit won’t send the response until the message is committed to the log file.
Keep in mind, though, that if it gets routed to a nondurable queue after that, it’s automatically removed from the persistency log and won’t survive a restart.
When you use persistent messages it’s crucial that you make sure all three elements required for a message to persist are in place (we can’t stress this enough)
Once you consume a persistent message from a durable queue (and acknowledge it), RabbitMQ flags it in the persistency log for garbage collection.
If Rabbit restarts anytime before you consume a persistent message, it’ll automatically re-create the exchanges and queues (and bindings) and replay any messages in the persistency log into the appropriate queues or exchanges (depending on where in the routing process the messages were when Rabbit died)
You might be thinking that you should use persistent messaging for all of your messages.
You could do that, but you’d pay a price for ensuring your messages survive Rabbit restarts: performance.
The act of writing messages to disk is much slower than just storing them in RAM, and will significantly decrease the number of messages per second your RabbitMQ server can process.
Though RabbitMQ clustering allows you to talk to any queue present in the cluster from any node, those queues are actually evenly distributed among the nodes without redundancy (there’s no backup copy of any queue on a second node in the cluster)
More important, while the node is down its queues aren’t available and the durable ones can’t be re-created.
We’ll cover the behavior in more detail and show alternate clustering approaches to get around this in chapter 5
Given the trade-offs, when should you use persistent/durable messaging? First, you need to analyze (and test) your performance needs.
Placing your RabbitMQ’s message store on an SSD can greatly improve the performance of persistent messaging.
For example, your producer could listen to a reply queue on a separate channel.
Every time it publishes a message, it includes the name of the reply queue so that the consumer can send a reply back to confirm receipt.
If a message isn’t replied to within a reasonable amount of time, the producer can republish the message.
That said, the critical nature of messages requiring guaranteed delivery generally means they’re lower in volume than other types of messages (such as logging messages)
So if persistent messaging meets your performance needs, it’s an excellent way to help ensure delivery.
We’re just selective about what types of content use persistent messaging.
For example, we run two types of Rabbit clusters: traditional RabbitMQ clustering for nonpersistent messaging, and pairs of active/hot-standby nonclustered Rabbit servers for persistent messaging (using load balancers)
This ensures the processing load for persistent messaging doesn’t slow down nonpersistent messages.
It also means Rabbit’s built-in clustering won’t black-hole persistent messages when a node dies.
Do keep in mind that while Rabbit can help ensure delivery, it can never absolutely guarantee it.
Hard drive corruption, buggy behavior by a consumer, or other extreme events can trash/black-hole persistent messages.
It’s ultimately up to you to ensure your messages arrive where they need to go, and persistent messaging is a great tool to help you get there.
A concept that’s related to the durability of a message is the AMQP transaction.
So far we’ve talked about marking messages, queues, and exchanges as durable.
That’s all well and good for keeping a message safe once RabbitMQ has it in its custody, but since a publish operation returns no response to the producer, how do you know if the broker has persisted the durable message to disk? Should the broker die before it can write the message to disk, the message would be lost and you wouldn’t know.
When you absolutely need to be sure the broker has the message in custody (and has routed the message to all matching subscribed queues) before you move on to another task, you need to wrap it in a transaction.
If you come from a database background, it’s important not to confuse AMQP transactions with what “transaction” means in most databases.
In AMQP, after you place a channel into transaction mode, you send it the publish you want to confirm, followed by zero or more other AMQP commands that should be executed or ignored depending on whether the initial publish succeeded.
Once you’ve sent all of the commands, you commit the transaction.
If the transaction’s initial publish succeeds, then the channel will complete the other AMQP commands in the transaction.
If the publish fails, none of the other AMQP commands will be executed.
Though transactions are a part of the formal AMQP 0-9-1 specification, they have an Achilles heel in that they’re huge drains on Rabbit performance.
Knowing all of this, the guys at RabbitMQ decided to come up with a better way to ensure message delivery: publisher confirms.2 Similar to transactions, you have to tell Rabbit to place the channel into confirm mode, and you can’t turn it off without re-creating the channel.
Once a channel is in confirm mode, every message published on the channel will be assigned a unique ID number (starting at 1)
Once the message has been delivered to all queues that have bindings matching the message’s routing key, the channel will issue a publisher confirm to the producer app (containing the message’s unique ID)
This lets the producer know the message has been safely queued at all of its destinations.
If the message and the queues are durable, the confirm is issued only after the queues have written the message to disk.
The major benefit of publisher confirms is that they’re asynchronous.
Once a message has been published, the producer app can go on to the next message while waiting for the confirm.
When the confirm for that message is finally received, a callback function in the producer app will be fired so it can wake up and handle the confirmation.
If an internal error occurs inside Rabbit that causes a message to be lost, Rabbit will send a message nack (not acknowledged) that’s like a publisher confirm (it has the message’s unique ID) but indicates the message was lost.
Also, since there’s no concept of message rollback (as with transactions), publisher confirms are much lighter weight and have an almost negligible performance hit on the Rabbit broker.
We’ve talked about the history of RabbitMQ, we’ve discussed AMQP and its details, and we have the broker installed; now it’s time we get our hands dirty and write some code.
We’ll illustrate how a message is created, published, and then consumed on the other side of the wire.
We don’t want to break the tradition of the initial Hello World example, so let’s do that.
For our first program, we’ll use Python since the code is easy to understand and read even for people new to Python.
Let’s get started by going over what you’re going to need to build your Hello World.
You can install Python on your Linux of choice by telling your package manager to install the python package.
They’re only available in version 2.3.1 or higher of RabbitMQ.
To set up your environment, you first need to install easy_install (you may need to run these commands under sudo depending on your OS):
With easy_install ready to do your bidding, next get Pika installed:
The next step is to create a folder to store your sample code:
First at B you have boilerplate code to set up your connection to RabbitMQ (by not specifying the virtual host, you’re using the default one at /)
You’ll connect to a RabbitMQ server running on port 5672 on your local machine.
Then you obtain a channel C to communicate with RabbitMQ.
The next step is to declare an exchange D where your message will be sent to.
The first parameter is the exchange name, hello-exchange; the second one is the exchange type, direct.
The first Boolean flag tells RabbitMQ that you’re issuing the declare command in nonpassive mode—you want to declare the exchange, not just obtain information about it.
The last two flags will tell RabbitMQ that you want your exchange to be durable and to not be automatically deleted.
Once you get the message, you’ll publish it to the hello-exchange F issuing the basic_publish command.
You don’t have to close the connection right away every time.
You can send several messages through one channel/connection and then close them when you’re done.
You have your publisher ready; now let's create the message consumer.
You already wrote the first three steps and the last two in the previous code example.
What will be new is how to declare a queue, bind it to an exchange, and start consuming new messages.
As you can see, you have the same code as before for including the library and defining some constants for your connection parameters.
You could move those definitions to a config.py file and avoid duplicated code.
At point B you set up your connection to the broker and then C create your channel.
After you have the connection D, you declare the exchange again.
You do that to avoid errors when you later issue the queue_bind command in case the exchange hasn’t been created in advance.
At E you declare a queue with the name hello-queue using AMQP default options.
You’re using the routing key hola, which will work for this simple example.
You’re almost ready to start consuming messages, but you need a callback function where you’ll process the message.
At point G you create such a function that will acknowledge H the message so RabbitMQ can delete it and send a new one to your consumer.
At the end of your callback function you echo the body of the message.
Soon you’ll see what the code at point I is doing.
Once you have your callback function you can issue the J basic_consume command to subscribe to the queue.
The first parameter will be the callback that you just.
Next you pass as parameters the name of the queue and the consumer tag that you want to use to identify your process.
Every message that RabbitMQ sends to your consumer will be passed to your callback function.
For that you 1) start a blocking loop waiting for incoming data through the channel.
If RabbitMQ sends you a message, pika will take care of passing it to the callback function.
To make it end, you inserted a condition inside your callback stating that if a message has the text 'quit' as body, then you’ll issue the basic_cancel command to stop consuming (and then close the channel and connection)
You have to provide the consumer tag as parameter for basic_cancel.
First you have to start RabbitMQ, so open a new terminal window, move to the folder where you installed RabbitMQ and type the following command:
Once RabbitMQ is running, switch to the previous terminal window and start the consumer with the following command (see figure 2.7):
Open a new terminal window, move to the chapter-2 folder and type the following:
If everything went okay, you should see the text "Hello World!" in the terminal window where you’re running the consumer.
And you should see this text: "Hello Mundo!" And finally you stop the consumer with.
You wanted to send messages over the wire and consume them, so you declared your exchange in order to have a place to publish your messages.
You also created a queue and bound it to the hello-exchange.
Then based on text that you input at the command line, you created your message instances and send them over RabbitMQ.
Based on your direct exchange type, RabbitMQ routed your message to the hello-queue.
Since you had a consumer on the other side of the wire, RabbitMQ delivered the message and it was processed by your callback function.
You can see that no routing key was provided; that’s because AMQP can be as simple or complex as you want it to be.
We said that every message published gets a unique ID if the channel is in confirm mode.
This might make you think that basic _publish will suddenly start returning a message ID, but that’s not how message IDs work.
Since a channel can only be used by a single thread, you can be assured that all publishes using that channel are sequential.
As a result, RabbitMQ makes a simple assumption: the first message published on any channel.
Since transactions kill performance, we focus on publisher confirms as the preferred way to add delivery confirmation to your producers.
If you really need to learn how to add transactions to your producers, don’t worry.
The message IDs are unique to the channel, so once the channel is closed you won’t be able to track the status of any outstanding publisher confirms for messages published on that channel.
What this means is that RabbitMQ doesn’t have to tell you the ID of the message you just published; you keep track of it yourself in a counter internal to your app and increment that counter every time your app’s channel publishes.
Also, since every channel starts its message IDs at 1, if you have multiple channels open in parallel, you need to maintain a separate internal message ID counter for each channel.
Now that you understand how message IDs are assigned, let’s take a look at the following version of your Hello World producer, now updated to use publisher confirms.
This looks similar to your original Hello World producer, but you’ve now added a callback function B confirm_handler that will be called when the app receives a publisher confirm.
You then tell Pika to put the channel into confirm mode C and use confirm_handler as the callback that will receive publisher confirms as they arrive.
Once your channel is set up to handle publisher confirms, you then set up your.
Summary internal list (msg_ids) for tracking message IDs on the channel D, and publish the message E.
Inside confirm_handler is where all the interesting magic with confirms happens.
RabbitMQ sends a confirmation of type Confirm.SelectOk when you first put the channel into confirm mode.
It’s not a confirmation of a message, but rather a notification that your channel is now set to receive publisher confirms.
You might remember from our explanation of publisher confirms that Basic.Nack indicates the message was lost due to an internal RabbitMQ error.
In a more sophisticated application, this is where you’d put code that republishes the lost message.
Finally, if the confirmation isn’t Confirm.SelectOk or Basic.Nack, you check whether it’s Basic.Ack:
Providing the message is a publisher confirm acknowledgement (Basic.Ack), you need to make sure that the message ID is in your list of published message IDs:
If the message ID of the confirmation is one you’re tracking in msg_ids, you confirm to the user that the message was successfully queued and then remove the message ID from your list of IDs awaiting delivery acknowledgement.
It’s slightly more complicated than your original Hello World producer, but in only 12 lines of code you’ve added the ability to track delivery of your published messages.
Even more impressive is that this simple code can track delivery of millions of published messages per minute! That’s how much better publisher confirms perform than AMQP transactions.
But with what you've learned so far you can start coding right away on that distributed Twitter clone you’ve been dying to build.
Before we dive into more coding, let’s take a look at how to manage your RabbitMQ server more expertly.
For example, it’s probably not a great idea that anyone can connect to your virtual hosts and publish messages into any exchange they like.
That’s exactly the type of problem we’ll show you how to avoid next by setting permissions.
We’ve spent the majority of our time so far on the concepts of AMQP messaging and how to get a basic install of RabbitMQ running.
Now we’re ready to more deeply explore what it takes to administer RabbitMQ on a day-to-day basis.
Knowing how to get RabbitMQ started on your workstation is one thing, but how do you get it stopped cleanly? How do you limit the amount of RAM it can consume so it doesn’t starve other applications on the same server? These are the kinds of things you’ll run into when it comes time to move RabbitMQ out of development and into production.
We’ll use this chapter to show you how to run a top-notch production RabbitMQ environment so you can avoid the big gotchas.
Some background on how Erlang operates, including those mysterious Erlang cookies.
By the time we’re done, you’ll be a top-notch RabbitMQ admin and ready to tackle your production Rabbit environment.
Let’s get started with the basics and dive into how to manage a RabbitMQ server.
Running a RabbitMQ server effectively can be different from other products you’ve used.
This is primarily because RabbitMQ is written in Erlang and Erlang does things its own way.
Erlang was designed from day one to let apps talk to each other without having to know whether they’re on the same machine or different machines.
For RabbitMQ, this makes clustering and reliable routing of messages a breeze.
Not to worry; these concepts aren’t as alien as they may sound.
If you’re familiar with Java Virtual Machines (JVM), these ideas are very similar to the ideas behind the JVM.
As we move through this section, you’ll learn how to start and stop RabbitMQ nodes and how to work with the RabbitMQ config file.
Without further ado, we’ll begin by looking at what a node is and how to start it.
Up to this point, we’ve frequently used the term node to refer to a RabbitMQ server instance.
In reality, what a node really describes is an Erlang node running an Erlang application.
Don’t get scared off by the mention of Erlang—you don’t need to be an Erlang aficionado to understand what’s going on.
When you run a Java application, an instance of the JVM is spun up and begins executing the specified Java application.
Similarly, Erlang has a virtual machine and each instance of it is referred to as a node.
Unlike the JVM, multiple Erlang applications can run inside the same node, and more important, nodes can talk natively to each other (whether they’re on the same server or not)
For example, due to the magic of Erlang, an application on node asparagus can call functions in applications running on node artichoke as though those functions were local.
Also, if an application crashes for any reason (say, RabbitMQ crashing) the Erlang node will automatically attempt to restart the application (providing Erlang itself didn’t crash)
This has some interesting benefits when we start talking about plugins and clustering.
The important thing to remember right now is that when we talk about RabbitMQ nodes, we’re referring to the RabbitMQ application and the Erlang node it runs on.
Luckily for us, RabbitMQ makes it easy to start the Erlang node and the Rabbit application in one step.
If you encounter any errors during startup, take a look at the RabbitMQ log.
You can also start the Rabbit node in the background as a daemon by adding the -detached flag: ./rabbitmq -server -detached.
That’s all there is to getting a single RabbitMQ node started.
Now that it’s started though, how do you stop it?
When it comes to stopping RabbitMQ, there are two ways of doing it: the clean way and dirty way.
If you run RabbitMQ attached to the console, you might be confused when you punch CTRL-C and see something like this:
If you installed RabbitMQ from packages specific to your OS (say, RPMs), it’s a good idea to use the start/stop init.d scripts installed by the package.
Holey moley, what’s that all about? All you wanted to do was stop RabbitMQ.
What you’re looking at is the Erlang node asking you if you want to kill the application, the whole node, or if it’s all a mistake and you want to keep running.
Generally speaking, you want to kill the whole node, so abort is what you want.
But there’s a much better way to stop RabbitMQ—a way that will tell RabbitMQ to cleanly shut down and protect all those persistent queues.
You’ve already seen how it can help you create and list vhosts.
You can also specify a different node to shut down, including remote nodes, by passing the -n rabbit@[hostname] option.
If you watch the RabbitMQ log you’ll see something like this:
When you see that rabbit, mnesia, and os_mon are stopped, the Rabbit node is completely shut down.
If you installed RabbitMQ from a packaging system like APT on Ubuntu, you might also have a RabbitMQ startup/shutdown script installed in /etc/ init.d/
You can use that script to accomplish the same shutdown task.
At this point the entire RabbitMQ node is shut down, including its Erlang parent.
Sometimes, though, you want to just stop the RabbitMQ application and leave the Erlang parent running.
So far we’ve talked about stopping the entire RabbitMQ node (application and Erlang node together)
But sometimes you just want to restart the RabbitMQ application and keep the Erlang node running.
Since rabbitmq-server starts both the node and the application, it preconfigures the RabbitMQ application for standalone mode.
To add the node to an existing cluster, what you need to do is stop the application and reset the node to a pristine state so it can be prepared for clustering.
Server management other Erlang applications besides RabbitMQ on the same node, making stopping the whole node undesirable.
Stopping just the RabbitMQ application is a lot simpler than the reasons for wanting to.
The Rabbit logs will show the same shutdown messages as when shutting down the whole node.
Starting and stopping RabbitMQ is great, but what about when your problem is configuring RabbitMQ so it doesn’t gobble up all the RAM on your server? Or maybe you need to change the port RabbitMQ listens on.
Like most server applications, RabbitMQ allows you to set systemwide tunables and settings via a configuration file.
Typically, this file is located at /etc/rabbitmq/ rabbitmq.config, but its location can be changed via the CONFIG_FILE environment variable set in the rabbitmq-server script.
What you’re looking at is essentially a raw Erlang data structure.
But if you’re familiar with Python, JavaScript, or any other modern programming language, it’s easy to understand once you break it down.
Mnesia ensures RabbitMQ metadata integrity through crashes by writing first to an append-only log file.
It then regularly dumps the contents of the log into the actual Mnesia database files.
Integer 100 How often to flush/dump the contents of the append-only log into the actual database files.
It’s specified in terms of how many entries must be in the log before a dump operation occurs.
Setting this to a higher number can reduce I/O load and increase performance for persistent messages.
Defines which IP addresses and ports RabbitMQ should listen on for non-SSL-encrypted traffic.
Though the configuration files allow you to change a lot of different aspects about how RabbitMQ operates, one thing they don’t do is control access to RabbitMQ itself.
For that RabbitMQ has an entire specialized subsystem dedicated to permissions.
Let’s start getting familiar with permissions by learning how to create a user.
If you’re familiar with access control lists on various operating systems, understanding RabbitMQ’s permission system will come readily to you.
Like most permission systems, it starts with users who are then granted rights, as shown in figure 3.2
The nice thing about the RabbitMQ permission system is that a single user can be granted permissions across multiple vhosts.
This can greatly simplify the management of access control for an application that needs to talk across multiple security domains (using virtual hosts for separation)
Within RabbitMQ, users are the basic unit of access control.
They can be granted different levels of access to one or more vhosts, and use a standard username/password pair to authenticate the user.
Adding, deleting, and listing them is simple and is accomplished using rabbitmqctl.
This will create a new Rabbit user with the username cashing-tier and give it the password cashMe1
If you wanted to remove the user, you’d simply run.
Please note that when you delete a user, any access control entries referencing that user will be deleted automatically from the Rabbit permissions database.
So be careful when removing users; otherwise you may find yourself re-creating a bunch of access control entries.
Frequently, what you need to know is which users currently exist on your Rabbit server.
You do this by passing the list_users command to rabbitmqctl:
Simply run the change_password command, specify the user whose password you want to change, and what the new password should be:
As you can see, managing users in RabbitMQ is simple.
The complexity comes in when you start assigning those users to access control entries.
Starting with version 1.6.0, RabbitMQ implemented an access control list (ACL) style of permissions system.
Prior to this, users could only be granted or denied access to entire vhosts (within those vhosts, they could do anything)
The new system allows for a great deal of granularity, and gives the ability to grant users read, write, and configure permissions.
Client-named means your app set the name of the exchange/queue; server-named means your app didn’t supply a name and let the server assign a random one for you.
It’s important to remember that access control entries can’t span vhosts.
For example, if you wanted to grant the same permissions to the user cashing-tier on vhost oak and vhost sycamore, you’d need to create two access control entries (one for each vhost)
For this example, assume you have a vhost named sycamore, and you want to grant cashing-tier full access (configure, write and read permissions)
The permission values are the most interesting part of the command.
In this case, you used ".*" for every permission (configure, write, and read)
Let’s say for a minute that you need to grant cashing-tier access to the oak vhost.
You want to allow the user to be able to execute a read command against any queue or exchange, while restricting writes only to queues or exchanges whose names starts with checks-
To do this you’ll want to craft three regular expressions:2
Putting it all together, you’d execute a set_permissions that looks like this:
You can verify that the permissions have correctly applied to the oak vhost by using rabbitmqctl’s list_permissions command:
The empty column between cashing-tier and "checks-.*" on the output indicates the empty ("") value you passed for configure permissions.
As you can see, the permissions did correctly apply to the oak vhost and your queues/exchanges are secured as you want.
By running list_permissions you can see that the permissions are now gone:
It’s important to note that clear_permissions will remove all permissions for the user on the specified vhost.
If you only want to modify the existing permissions for a user,
Checking up just execute set_permissions with the new permission values.
Permissions in RabbitMQ are simple to create and very flexible.
The flexibility allows you to create complex permission structures for your vhosts, which can be a benefit when you need it, but can be difficult to interpret if they become too complex.
Where possible, try to use vhost separation as your primary method of securing one app from another, and keep the number of access control entries per vhost to a minimum.
This will help you to avoid unexpected permission behavior that can be difficult to debug.
Now that you can connect and secure your Rabbit server, maybe you’d like to see what's going on inside.
Perhaps you need to know how many provisioning messages are in your user creation queue.
Maybe you’d like to see if your exchanges are on the right vhost.
One of the most important parts of a healthy RabbitMQ server is being able to monitor its internals.
So let’s find out how to check up on our Rabbits!
As you might’ve noticed when we played with the rabbitmqctl script before, it accepts many options and commands.
It specifies the virtual host or path for which you want information.
If you omit that option, rabbitmqctl will take / as the default path.
To prepare the ground for experimenting with rabbitmqctl, let’s create an exchange and bind it to a couple of queues so you can have some sample data to play with.
As you know, most of the examples in this book will be in PHP or Python.
You already set up Python, so now it’s time to code this simple script in PHP.
Let’s see what you need to install to get your development environment ready.
First you need to get a PHP package that suits your operating system.
Since PHP is popular, you shouldn’t have problems there and chances are that your operating system already comes with PHP preinstalled.
Create a folder for your PHP examples and then download the library there:
First you created a folder called php and then changed directory into that folder.
Then you obtained the library tarball by using wget and decompressed the file that you got from GitHub.
Finally you moved the library to a most suitable location to save some typing later.
Now that you have php-amqplib downloaded, create the PHP script to initialize your queues and exchanges.
This script is fairly simple and we won’t go into detail about the AMQP methods that we call here because we have a whole chapter dedicated to AMQP usage.
Checking up try to understand the basics of this script.
First you connect to the broker and obtain a channel B so you have a way to communicate with RabbitMQ.
Once you have the channel, you declare an exchange called logs-exchange C and then create three queues: msg-inbox-errors, msg-inbox-logs, and all-logs D.
Finally you bind only two of the three queues to the logs-exchange using the error.msg-inbox binding rule in the first case and *.msg-inbox as the binding rule in the second example E.
The goal of the script is to have something to display when you run the rabbitmqctl commands for listing exchanges, queues, and bindings.
Just make sure that the path in the require_once line points to the place where you have the amqp.inc library installed.
If everything went well then you’re ready to keep experimenting with rabbitmqctl.
On the terminal, change to the sbin folder (or the folder where rabbitmqctl is located) and type.
The output of this command will depend on the queues that you have declared on your server, but you should see something similar to this:
There you see the queue name and the number of messages in each queue.
As we said, this information is for the default vhost.
If you want to get it for a different vhost, try adding the -p option like this:
Now let’s see which other options you have for this command.
Scroll down a bit and you’ll see what options are accepted as QueueInfoItem:
This means that if you want to know more information about the queues, like the name, number of messages, or number of consumers and memory used, you can issue this command:
You can also check the properties used to declare the queue:
There you can see that the queues are durable and the auto_delete property was set to false.
Of course nothing can stop you from playing with the other command options.
In this case the command to obtain the default information is.
By default, this command returns the exchange name and the exchange type.
You can see that several exchanges are declared already, such as amq.topic, amq.direct and amq.fanout.
On top of the list you see your own logs-exchanges and the type is topic.
If you look carefully at the bottom of the results, you’ll see that it says direct but there’s no exchange name.
That’s the anonymous exchange that we mentioned in chapter 1
As you’ll soon see, every queue is bound by default to that exchange.
Let’s run the rabbitmqctl command with no arguments and find out the expected options for list_exchanges:
The information that you can get is related to the options that you used to declare the exchanges.
You can tell by the options passed to this command that the logs-exchange exchange is durable and that it won’t be automatically deleted by the server.
After checking information about queues and exchanges, you naturally may want to see their bindings.
This command doesn’t accept extra options except for -p, which specifies the vhost path.
The output consists of rows containing the exchange name, queue name, routing key, and arguments.
The first three rows look special, like something is missing… That’s the anonymous exchange again.
Those rows are showing that each queue is bound to the anonymous exchange using the queue name as the routing key.
The other two queues are bound using *.msg-inbox and error.msg-inbox as routing keys respectively.
You’ll see some of them when we talk about clustering and monitoring RabbitMQ.
In the previous section you learned how to use the rabbitmqctl script to get information about what’s on the server, so let’s see how can you check what’s actually going on in the server—what kinds of events are happening.
RabbitMQ logs events for many reasons, such as connections attempts, user creation, and errors when decoding requests.
The cool thing about RabbitMQ is that you can get all this data and react to it in real time, using AMQP exchanges, queues, and bindings.
If you want to go the classic way, then you can also see the log files on the filesystem.
Let’s do that first and then you can build an AMQP consumer that will display RabbitMQ logs; later you could tweak it and set up a monitoring system for RabbitMQ.
The setting that you care when checking the logs is the LOG_BASE environment variable.
The default value, as it appears in the rabbitmq-server script, is this:
What’s the difference between the sasl log and the other one? SASL (System Application Support Libraries) is a set of libraries that are part of the Erlang-OTP distribution.
They help the developer to have a set of standards when developing their Erlang apps.
So, when RabbitMQ logs Erlang-related information, it’ll go to the rabbit-sasl.log files.
For example, there you can find Erlang’s crash reports that can be helpful when debugging a RabbitMQ node that doesn’t want to start.
Now if you want to see the events happening at the server, you could tail -f the rabbit.log file.
Also you can find out if someone is connecting to your broker from an IP address that shouldn’t be allowed.
Apart from network traffic information, in the rabbit.log file you’ll see events like operations on users, exchanges, queues, and so on.
The last bit of information to know about the log files is how to rotate them.
First you need to know that whenever the broker starts, it’ll create them afresh and will append a number to the old ones.
And then you should see the following files in the log folder:
Now let’s see how can you get all this information in real time using AMQP.
RabbitMQ will publish its logs to that exchange using the severity level as a routing key—you’ll get error, warning, and info.
Based on what you learned from the previous chapter, you can create a consumer to listen to those logs and react accordingly.
For the sake of the example you’ll just output the logs to the console.
Create a file called config .php in a folder called config and put the code from the following listing inside.
From now on we’ll assume that the file config.php and the amqp.inc library are already included, so we won’t mention them on future code examples.
We’ll also assume that you initialized the connection and you obtained a communication channel.
With that in mind, the code for the PHP consumers is shown in the following listing.
As you can see, you didn’t provide any options to the declare command, so RabbitMQ will assign a random name to your queue.
Besides that, the queue will be exclusive to your consumer, and it’ll be auto_deleted when you kill the script.
In this way you can attach your consumer to RabbitMQ at any time, spy what’s going on, and then detach, and everything will be cleaned up for you.
You use different routing keys depending on which logs you want to route to your queues.
Then at D you define three callback functions to process your.
They do basically the same thing: output the log with the log warning as prefix.
Then at E you send the basic_consume commands and set up your callbacks to start receiving messages form the server.
If you run this script you should start seeing logs like this:
If you were wondering what was the name of the queues that you just created, go to another terminal window and list the queues with rabbitmqctl.
The nice thing about this approach for creating queues is that you don’t have to worry about your queue names.
As you saw in this section, RabbitMQ is pretty informative about what’s going on in the server.
You have two ways of checking what’s happening; one way is by the traditional file logs, and the other is using the more advanced AMQP exchanges, which can give you flexibility when reacting to events and can make it easier for you to filter logs.
So far everything has been going fine, but what happens when your Rabbit doesn’t want to get domesticated? No matter what you try, it just doesn’t want to start, or is running but doesn’t want to reply to your messages.
Let’s see what you can do to troubleshoot those problems.
One common error that you can get when you start working with RabbitMQ is badrpc,nodedown.
It usually happens when you try to use the rabbitmqctl command, but instead of getting the expected result, you get that error message as a reply.
A server process is running, so what’s going on? Let’s try to understand how the rabbitmqctl command works.
For this to work, you need two things: the proper Erlang cookie and the proper node name.
So what’s an Erlang cookie? An Erlang cookie acts as a secret token that two Erlang nodes exchange in order to authenticate themselves.
Since you can execute commands on the remote node once you’re connected to it, there’s a need to make sure that the peer is trusted.
In order for rabbitmqctl to communicate with the RabbitMQ node, it needs to share the same cookie.
If you’re running RabbitMQ as the same user that you use to execute the rabbitmqctl command, then you won’t have any problem, but in production you’ll probably want to create a rabbitmq user and run the server with that user.
This means that you must share the cookie with the rabbitmq user or you have to switch to that user to be able to execute rabbitmqctl successfully.
When we talk about clustering several RabbitMQ servers, we’ll discuss Erlang cookies again.
What about nodes; what’s the problem with them? When you start an Erlang node, you can give it two mutually exclusive options, name and sname, which will specify the node name.
That node name can be long or short, hence the s in sname.
If you use short names, you’ll see something similar to this: rabbit@hostname.
When you want rabbitmqctl to be able to communicate with RabbitMQ, you have to get those options to match on both sides.
Save and run the following: ./rabbitmqctl list_queues Listing queues ...
Change the option back to read sname and everything should work as normal.
Again, later when we talk about clustering, we’ll have to tweak this option.
Next we have to take care of Mnesia, the Erlang database that was there even before NoSQL was cool.
RabbitMQ uses Mnesia to store information about queues, exchanges, bindings, and so on.
One of the things that RabbitMQ does at startup time is launch the Mnesia database.
Since this step is essential for the server to behave correctly, if Mnesia fails to start, then RabbitMQ will fail too.
There are a couple of reasons why Mnesia may fail to start.
The first and most common is a permission problem on the MNESIA_BASE directory.
The user that’s running the RabbitMQ server needs write permissions on that folder.
Another common problem is when you see an error message like this:
Here Mnesia failed to load the tables, as you can see from the message.
This happens if the hostname has changed or if the server is running in clustered mode and the other peer is unreachable during startup.
Why do you have to care about the hostname? Mnesia creates a database schema based on the machine hostname.
If hostname changes due to some network reconfiguration, then Mnesia won’t be able to load the old schema.
Also keep in mind that RabbitMQ uses the word rabbit as node name.
If you changed it using the Erlang sname option, then Mnesia will encounter the same problem again.
For the same reason you can see that if you rename the rabbit@hostname folder, then Mnesia won’t be able to find the old database files.
It’ll create the rabbit@hostname folder again and start a database from scratch.
Keep in mind that you still can find the old database files in the folder that you renamed.
Mnesia deserves a book for itself, so if you want to learn more about it, you can read the user guide at http://www.erlang.org/doc/apps/mnesia/users_guide.html.
To end this section, let’s do a simple exercise in Erlang that will help you understand what we just talked about.
You’ll connect an Erlang node to your running RabbitMQ server.
You could use this knowledge to monitor a running broker, execute Erlang functions on it remotely, and much more.
Providing that you started RabbitMQ using short names, run the following command:
Depending on your hostname and Erlang version, you should see something like this:
This means you started your Erlang node using test as node name.
There you can input commands, execute Erlang code, and so forth.
There you typed node() at the REPL and got back test@mrhyde as a result.
Your Erlang node will be known to other Erlang applications by that name.
As an example, if you start your own Mnesia database, that will be the name used for the schema folder.
Now let’s check which other nodes are running on your machine:
There you called the names function from the net_adm module.
As you can see, RabbitMQ is running on your machine, using rabbit as the node name and 59106 as the port.
Wait … that’s not the port you use to connect to RabbitMQ from an AMQP client.
What’s going on? Here’s when another piece comes into play: the Erlang Port Mapper Daemon (epmd)
Whenever you start a distributed Erlang node, it’ll register with the epmd process, giving it the address and port assigned to it by the OS kernel.
Then when another Erlang node comes to life, it’ll do the same.
Finally if the latter wants to connect to your first node, it’ll go through epmd to obtain the other node address.
In that way you don’t need to track that information yourself.
Then, that port number (59106 in the example) is the one assigned by the OS to the Erlang VM where RabbitMQ is running.
Now that you know that you can see the RabbitMQ node, let’s try to establish a connection to it:
You use the ping function to try to reach the other node, giving as argument the 'node@hostname' that you want to connect to.
If the answer is pong, then you succeeded; if you get pang as reply, that means you couldn’t connect to the other node.
Keep in mind that for all this to work you have to share the same Erlang cookie.
Finally, let’s execute a function on the remote rabbit node:
There you used Erlang’s rpc module to call a function on the rabbit@mrhyde node.
The function is erlang:system_info and you use it to obtain the number of Erlang processes running on that node.
You could use this to monitor the health of your RabbitMQ system.
Using rpc:call and providing the node, module, function, and arguments as parameters, you can execute other functions on the remote rabbit and obtain different information.
For a final example, let’s gather information about the running Mnesia system on the remote rabbit node:
The REPL will print out several lines of information regarding Mnesia, such as the tables created by RabbitMQ, the memory used to hold the information, and more.
Finally, to close the Erlang REPL, execute the q function and you should be back on the terminal command prompt:
Keeping aside the fact that Erlang deserves a book on its own, you can use the techniques described here to troubleshoot your RabbitMQ installation.
To name an example, if you start up the Erlang VM with the same parameters as the rabbitmqctl script, then you should be able to connect to the rabbit node.
If that’s not the case, you can start finding out what hostname your machine is getting.
Then you can continue by listing the names of the nodes registered with the epmd daemon, and so on.
With such simple tools you can be troubleshooting and monitoring your RabbitMQ servers in no time.
In this chapter we covered a lot of practical techniques that help you with your everyday working with RabbitMQ.
You saw how to perform server management tasks, such as working with the RabbitMQ permission system to add and remove users.
We went through RabbitMQ configuration files and we covered how to work with the rabbitmqctl command—the Swiss army knife for working with the server.
Then you saw how to get statistics out of the server to see the queues and exchanges that you’ve created and the relationships between them.
Last but not least, we went through some of the strange Erlang errors that RabbitMQ may throw at you from time to time.
Since Erlang is a fundamental piece in the server structure, you learned a bit about the language in order to perform more advanced management tasks, giving you a solid foundation of what means what in RabbitMQ and Erlang parlance.
With all this knowledge in place, let’s go to chapter 4 to see some real-world examples of how to power your applications with messaging.
At this point you know how to install, configure, and even run Rabbit in production.
First, you need to understand problems you’re trying to solve when you code messaging into your apps.
Like a lot of people who discover RabbitMQ, your lovable authors weren’t looking for a message queue; we were looking to solve a decoupling problem.
How do you take a time-intensive task and move it out of the app that triggers it (thereby freeing that app to service other requests)? Also, how do you glue together applications written in different languages like PHP and Erlang so that they act as a single system? These seem like Solving problems with Rabbit:
A decoupling story: what pushes us to messaging two different problems but they have a common kernel: decoupling the request from the action.
Or put another way, both problems demand moving from a synchronous programming model to an asynchronous one.
Normally, when programmers hear asynchronous programming they either go running for the hills or think “Cool.
The problem with normal approaches to asynchronous programming is that they’re all-or-nothing propositions.
You rewrite all of your code so none of it blocks or you’re just wasting your time.
It allows you to fire off a request for processing elsewhere so that your synchronous application can go back to what it was doing.
When you start using messaging, you can achieve most of the benefits of pure asynchronous programming without throwing your existing code or knowledge away.
In this chapter, we’ll show you what asynchronous coding means in the Rabbit world.
In particular, we’ll show you how to use Rabbit to solve a number of real-world problems from picture processing (parallel processing) and alerting (notifications) to using RabbitMQ for distributed remote procedure calls (APIs) that are as simple as pie.
We’ll start by teaching some fundamental messaging paradigms and then diving into the code.
You write your latest and greatest web app (scheduling Chihuahua walking), and decide the fastest way to go is to take web orders and stuff them directly into a database.
How much time can stuffing a small record into a database take? Not to mention, it’s so simple to code.
Guess what? It’s time to rip out all of that carefully debugged code.
Coupling an app directly to storage is usually a recipe for rip-and-replace later, and that’s where messaging can help you.
You watch TV or read a book, or maybe give your sweetie some quality conversation time.
Rarely do you put your life on hold waiting for a response to your requests.
You multitask, so your lives can scale and you can get more done.
Why do you design your apps to be synchronous in the first place? Mostly, because you think about the whole job instead of the smaller tasks that make it up.
Even if you make your app multithreaded, you’ve severely limited the rate at which you can take orders because each thread has to wait for the record to be stored and the dog walker to be alerted.
To hijack a great analogy from Gregor Hohpe, we could call it the Coffee Bean model (Coffee Bean & Tea Leaf is a chain of coffee houses in California)
When you place an order for your chai latte, you don’t wait at the cash register until your order is ready.
Instead, Coffee Bean splits the order taking operation from the order preparation operation.
The order taker collects your request (and your dinero), and transmits a message to the baristas telling them what you ordered.
You then wait for your order to be prepared, freeing up the order taker to take another order.
The most important part of the operation is getting your money collected, and so by separating order taking from order processing, Coffee Bean has maximized the number of orders they can take per minute.
Similarly, if the backlog of coffee waiting to be prepared gets too high, they can add more baristas to reduce the backlog without changing the number of order takers.
By decoupling the process (separating requests and actions), they’ve increased the amount of work they can accomplish with the same number of workers and made it easy to scale up when they need to.
So let’s reanalyze your Chihuahua app with decoupling in mind.
Figure 4.1 shows the steps in completing a dog walking order.
Meanwhile, dog_walk_process listens to a Rabbit queue and receives the message containing customer A’s scheduling order.
It then gets to work creating the required database entry for the order and firing off a text message to your main dog walker, Gustav.
Once Gustav has been sent his text message, dog _walk_process sends a message back.
A decoupling story: what pushes us to messaging to dog_walk_order that customer A’s request was successfully processed.
Had they still been one app, you would’ve received only one walking request during that whole interval.
By putting RabbitMQ between two parts of your app that were once tightly coupled, you’ve made it possible to continually receive requests, where before you could only process one at a time.
But you’ve also opened up a whole other world of benefits.
What if you get so much load that one order processing server is no longer enough?
One of the great things about using messaging is that it’s simple to add processing capacity to your apps.
Let’s say you’ve just expanded your service to Japan, and now you’re receiving 1,000,000 walking orders a second.
Though your frontend order taker is more than able to keep up with the load, your order processor is keeling over.
Taking a customer's order no longer keeps you from taking other orders, but those customers are getting fed up waiting for you to confirm their reservations.
Just like at Coffee Bean, you can add more baristas.
In your case, you spool up additional dog_walk_process servers and attach them to the queue that receives the orders.
The best part is that RabbitMQ will evenly distribute the requests among the processing servers due to the automatic roundrobin behavior we talked about in section 2.2
Store the request in a database or other permanent storage.
Load balancing hardware is expensive, which means you’re normally limited to how many places you can use it to decouple and scale your apps.
If instead you can use AMQP and Rabbit, then you can add decoupling and load balancing anywhere you want for free.
Not to mention, you can do more complex routing, such as send a message to more than one destination in addition to round-robin load balancing.
Load balancers will always have a place on the frontend distributing requests coming in from the internet, but if you can heavily leverage messaging, you can reduce your reliance on them inside the firewall and greatly increase the number of places you decouple your apps.
We’ve skipped over one of the best benefits of using AMQP to decouple your apps: APIs for free.
Today everyone is talking about web APIs that allow you to integrate an app’s functionality into any other app.
Generally, this takes a bit of effort because you end up writing a lot of code to translate incoming HTTP requests into your app’s function calls.
If you write your app using AMQP to connect the parts, you actually get an API for no additional effort—an API that uses messaging.
Let’s say you’ve expanded your Chihuahua walking business into dog washing.
Then you get a great idea: offer a free dog walk with every wash.
This means no recoding of the scheduling code and no need to duplicate that code inside the dog washing apps.
Equally important, there’s no requirement that the walking and washing apps be written in the same language.
When you wrote the dog walking apps, you may have chosen Erlang as the best language for the job.
But in the months since, you’ve discovered how much you like Clojure for building high-concurrency applications.
But because AMQP is language-agnostic and has native language bindings for dozens of languages, you can easily connect a Clojure request receiver to an Erlang request processor over Rabbit.
Using AMQP to connect your applications gives you the flexibility to use the right language for each part of the job, and even to change your mind later and connect in new applications written in completely different languages.
RabbitMQ makes it easy to connect any and all parts of your infrastructure in any way you want.
When we look at the types of problems messaging can solve, one of the main areas that messaging fits is fire-and-forget processing.
Whether you need to add contacts to a mailing list or convert 1,000 pictures into thumbnails, you’re interested in the jobs getting done but there’s no reason they need to be done in real-time.
In fact, you usually want to avoid blocking the user who triggered the jobs.
We describe these types of jobs as fire-and-forget: you create the job, put it on the exchange, and let your app get back to what it was doing.
Depending on your requirements, you may not even need to notify the user when the jobs complete.
Batch processing—Work and transformations that need be completed on a large data set.
This can be structured as a single job request or many jobs operating on individual parts of the data set.
This can be anything from a message to be logged, to an actual alert that should be sent to another program or an administrator.
We’re going to show you two different real-world examples of fire-and-forget apps that fit into these two categories.
The first is an alerting framework that will allow the apps in your infrastructure to generate administrator alerts without worrying about where they need to go or how to get them there.
The second example is a perfect demonstration of batch processing: taking a single image upload and converting into multiple image sizes and formats.
When you’re done with this section you’ll have the most fundamental type of RabbitMQ programming under your belt: triggering work with messages that need no reply.
No matter what type of apps you write, getting notifications when things go awry is critical.
Typically you run some sort of service monitor like Nagios to let you know when your app is down or services that it relies upon are unavailable.
But what about getting notified when your app is experiencing an unusual number of requests for user logins, all from a single IP? Or perhaps you’d like to allow your customers to be notified when unusual events occur to their data? What you need is for your app to generate alerts, but this opens up a whole new set of questions and adds a lot of complexity to your app.
For example, what happens when the SMS gateway is down? All of your web apps that need to alert now need error-handling code to deal with the SMS server being unavailable.
The only thing about alerting that inherently needs to be done in your web apps is generating the contents of the alert.
All you need to do is write a new alerting server app that receives alert messages via Rabbit, and then enhance your web app to publish these alert messages where appropriate.
The advantage is that your web app doesn’t have to know anything about how the alerts will be delivered to the ultimate receiver.
The disadvantage is that every alert transmitter gets a copy, so you get flooded with an IM, a text message, and a Twitter direct message every time an alert happens.
A better way to organize your alerting system would be to create three severity levels for your alerts: info, warning, and critical.
But with the fanout exchange, any alert published would get sent to all three severity level queues.
You could instead create your exchange as a direct exchange, which would allow your web app to tag the alert messages with the severity level as the routing key.
But what would happen if you chose a topic exchange? Topic exchanges let you create flexible tags for your messages that target them to multiple queues, but only the queues providing the services you want (unlike the fanout exchange)
If you were to use a topic exchange for your alerting framework, you wouldn’t be limited to just one severity level per alert.
In fact, you could now tag your messages not only with a severity level, but also the type of alert it is.
For example, let’s say Joe Don Hacker is hitting your statistics server with 10,000 requests per second for map data on your dog walking reservations.
In your organization, you need an alert about this to go both to the infrastructure admins (who get all alerts flagged as critical), and to your API dev team (who get all alerts tagged rate_limiting)
Figure 4.3 shows how the flow of your alerting system will work.
To build this alerting framework you’ll need the Pika library you installed as a part of your Hello World in chapter 2
If you skipped that part, here are some quick steps to get Pika installed (assuming you don’t have easy_install yet either):
Next you need to set up the RabbitMQ user and password the applications will use to publish and receive alert messages.
Let’s call the user alert_user and give it the password alertme.
From the ./sbin directory of your RabbitMQ install, run the following:
With the setup out of the way, you’re ready to work on the most important part of your alerting system: the AMQP consumer that will receive the alert messages and transmit them to their destinations.
Next, you establish the settings you need to make a successful connection to your broker (user, name, password, virtual host, and so forth)
The settings assume you have RabbitMQ running locally on your development workstation and are using the username and password you just created.
For simplicity, let’s use the default virtual host / where you’re going to create an exchange called alerts.
The auto_delete parameter you’re also passing to the exchange and queue declarations ensures they’ll stick around when the last consumer disconnects from them.
Remember that we talked about two tagging patterns for alerts:
What you need to do is create bindings that implement these rules so that the alert messages go to the queues you want.
For your example, let’s create a binding that routes any messages with tags starting with critical.
Go ahead and create the critical and rate_limit queues and bind them, as shown in the following listing.
Listing 4.2 Declare and bind queues and exchanges for the alert topics.
When using topic exchanges, it’s important to be careful to design your tagging patterns to use.
You could’ve also passed durable=True to the queue declarations and bindings, which would ensure that they survived a restart of RabbitMQ.
Since restarting your consumer will automatically create the exchange, queues, and bindings it needs, you don’t need to worry about durability for your alerting system.
The other reason you’re not concerned about making the queues durable is because you’re not going to flag your alert messages as durable either.
Your system could be handling very high volumes of alerts, so you want to ensure the highest performance and not use durable messaging, which is persisted to relatively slow disk.
It’s the function that will be called when a message is received for your subscription to the critical queue.
The Pika library will call critical_notify when a message is received on this subscription, passing in the channel, message headers, message body, and message method from the message.
Let’s go ahead and specify one of those in the following listing.
When a consumer callback is called, Pika passes in four parameters related to the message:
If you have multiple channels open, it’ll be the one associated with the subscription the message was received on.
Your alerts will be JSON encoded, so you’ll check the content type to make sure it’s application/ json.
The content_type is optional, but it’s useful when you want to communicate encoding information about the message between producer and consumer.
Once the email alert has been successfully sent, you send an acknowledgement back to RabbitMQ that you’ve received the message.
The acknowledgement is important because RabbitMQ won’t give you another message from the queue until you’ve acknowledged the last one you received.
By putting the acknowledgement as the last operation, you ensure that if your consumer were to crash, RabbitMQ would assign the message to another consumer.
With all of the pieces of your consumer explained, let’s look at the whole thing put together in the following listing.
You now have an elegant consumer that will translate alert AMQP messages into email alerts targeted at different groups simply by manipulating the message tag.
All you need to do is create a consumer callback to provide the new alert processing and connect it to a queue that’s populated via a binding rule for the new alert type.
Your consumer wouldn’t be very useful without alerts for it to process.
So let’s see what it takes to produce alerts that your consumer can act on.
Our goal when we started this section was to make producing alerts simple and uncomplicated for existing apps.
The sample producer can be run from the command line to generate alerts with any contents and routing tags you like.
The first part of the program simply extracts the message and the routing key from the command line.
From there you’re connecting to the RabbitMQ broker identically to the way you did in the alert consumer.
Where things get interesting is when you publish the message:
After you JSON-encode the alert’s message text, you create a BasicProperties object called msg_props.
This is where you can set the AMQP message’s optional content type header, and also where you’d make the message durable if you wanted persistency.
Finally, in one line of code you publish the message to the alerts exchange with the routing key that classifies what type of alert it is.
Since messages with routing keys that don’t match any bindings will be discarded, you can even tag alerts with routing keys for alert types you don’t support yet.
As soon as you do support those alert types, any alert messages with those routing keys will be routed to the right consumer.
This tells Pika to hold off on returning from basic_publish if RabbitMQ’s flow control mechanism tells it to stop publishing.
When RabbitMQ tells Pika it’s okay to proceed, it’ll finally return, allowing more publishing to occur.
This makes your producer play nicely with RabbitMQ so that if Rabbit becomes overloaded, it can throttle the.
In only 100 lines of code total, you’ve given your web apps a flexible and scalable way to issue alerts that then get transmitted asynchronously to their recipients.
You’ve also seen how beneficial the fire-and-forget messaging pattern can be when you need to transmit information to be processed quickly but don’t need to know the result of the processing.
For example, you could easily extend the alert consumer to add an additional processor that uses the binding pattern *.* to log a copy of all alerts to a database.
But alerting and logging are far from the only uses of the fire-and-forget messaging pattern.
Let’s look at an example where you need to perform CPU-intensive processing on the contents of the message, and how RabbitMQ can help you move that into an asynchronous operation.
Say you started running your own social network website and you just deployed a shiny new feature: picture uploads.
People want to share their holiday pictures with friends and family—perhaps you’ve seen this somewhere.
Also, to improve the interaction among users, you want to notify their friends when one of their contacts has uploaded a new picture.
A week after the new feature release, the marketing guys come to your desk asking you to give some points to the users, a reward for the pictures they upload to encourage them to keep submitting pictures and improve the activity on the site.
You agree and add a few lines of code, and now you hook a reward system into the upload picture process.
It looks a bit nasty for your coder eyes, but it’s working as expected and the boss is happy with the results.
Next month the bandwidth bill arrives and the ops guy is angry because the bandwidth usage has doubled.
The external API offered to clients is displaying full-size images when it should be offering links to small thumbnails.
So you’d better get your uploading code generating those thumbnails too.
What to do? The easy way would be to add one more hook in there and execute the thumbnail generation directly from the upload controller, but wait … If for every picture upload you have to execute a picture resize operation, this means the frontend web servers will get overloaded, so you can’t just do that.
And users of your website don’t want to wait for your picture processing script to get a confirmation that their upload is okay.
This means you need a smarter solution, something that allows you to run tasks in parallel and in a different machine than the one serving requests to the users.
You can see that resizing a picture, rewarding the user, and notifying friends are three separate tasks.
Those tasks are independent in that they don’t have to wait for each other’s results to be able to run, which means that you can refactor your code not only to process the image resize separately, but also to do those other things in parallel.
Also, if you achieve such design, you can cope with new requirements easily.
You need to log every picture upload? You just add a new worker to do the logging, and so on.
This sounds nice, almost like a dream, but all this parallelization stuff seems hard to accomplish.
How much do you have to code to achieve message multicast? Not much; enter the fanout exchange.
As we said when we described the exchange types, the fanout exchange will put a copy of the message into the bound queues, as simple as that, and that’s what you need for your upload picture module.
Every time the user uploads a picture, instead of doing all the processing work right away, you’ll publish a message with the picture metainformation and then let your asynchronous workers do the rest in parallel.
RabbitMQ will ensure that each consumer gets a copy of the message.
The messages will contain the following metainformation about the picture: the image ID of the picture, the user ID, and the path to locate the picture on the filesystem.
This will make it easier in the future if you need to support several languages for the different tasks.
Figure 4.4 shows that you’ll declare an upload-pictures exchange and will bind three queues to it: resize-picture, add-points, and notify-friends.
From this design you can tell that adding a new kind of task, like logging, is just a matter of declaring a new queue and binding it to the upload-pictures exchange.
Your focus as developers will be to code each of the workers and the publishing logic; RabbitMQ will do the rest.
Decla que So, let’s start by adding the publisher logic into the upload picture module, as in the following listing.
You omit the logic for taking the picture from the POST request and moving it to some place on the filesystem.
The code for obtaining an AMQP channel isn’t present since we covered that in previous examples.
At B you declare the upload-pictures exchange, with a fanout type and with durable properties.
Then at C you create the message metadata encoded as JSON.
Finally at E you publish the message to the upload-pictures exchange.
You don’t need to provide a routing key since the messages will be fanned-out to all the bound queues.
Next let’s create one of the consumers, the one for adding points to the users after each upload.
At B you declare the topic exchange as when publishing the message; then at C you create the add-points queue where the message will be delivered by RabbitMQ.
You bind that queue at D to the exchange using the empty routing key.
At E you omit the code for your callback function for now; at F you send the basic_consume command to prepare the consumer.
You also omit the wait loop and the channel and connection cleanup code.
In listing 4.9 you have the code for actually processing the message.
At B you add a dummy function that for now just echoes that it’s giving points to the user.
In a realworld application you’d include the logic for increasing the user points, say on a Redis database.
The tricky bit of code at D is a hook to stop consuming messages.
If the message body equals quit, then you stop the consumer.
This simple trick is sure to close the channel and the connection in a clean way.
Then at E you pass the message body to the json_decode function to obtain the metadata.
You give true as the second parameter to make sure PHP will decode the JSON object as an associative array.
You’ll just copy the code from the publisher and modify the logic for creating the message to have a simple test script.
In this case you’ll take three arguments from the command line: image ID, user ID, and image path.
You’ll encode them and send them over RabbitMQ to the consumer that you created before.
We won’t explain the following listing because it’s the same as you saw before in listing 4.7
In the other window, execute the publisher, passing some random parameters to simulate a request:
If everything went well, you can switch to the first terminal to see the following message:
Let’s add another consumer to see a fanout exchange and parallel processing in action.
The interesting bits are at B and C where you create and bind the resize-picture to the upload-picture exchange.
You can see that this uses the same exchange as the previous example.
As always with AMQP, the messages are published to one exchange and then, depending on the bindings, they can be routed to one or several queues (or none at all)
Finally the function resize_picture E echoes a message to tell you that it’s resizing the image.
As before, on a real setup, here you’d want to have the code to actually resize the image.
Now, open a third window on the terminal and type.
Then go back to the window where you have the publisher script and run it again:
If everything went fine, then you should see on each consumer window the following messages:
Based on the examples from the add points to user consumer, you can see that if you integrate RabbitMQ into your solution, then scaling the code to new requirements is simple.
To add the image resize consumer you just need a function that’s based on the image ID and path, and is able to load the picture from the filesystem, resize it (probably using some tool like Imagemagick), and then update the record on the database based on the image ID.
Taking the user ID as a parameter, you can retrieve the user’s contacts from the database and then send a notification, perhaps in the form of an email, to each of those friends.
What you can learn from this example is that the power of messaging with RabbitMQ resides in how you combine exchanges and queues together.
If you need some way to filter out messages, then you can use a topic exchange as in the previous section.
Does one action in your application trigger several others that can run in parallel? Then use topic exchanges.
If you want to “spy” on a flow of messages and then quit without leaving traces, then use anonymous queues set to be autodeleted.
Once you get used to thinking about messaging patterns, you’ll start seeing how simple some programming tasks can become.
But the advantages of this design over the one where everything happens in the same module don’t stop here.
Imagine now that the pictures are being resized too slowly; you need more computing power and you don’t want to change the code.
You can launch more consumer processes and RabbitMQ will take care of distributing the messages accordingly.
Try to imagine now how you’d scale the original code, where everything happened sequentially while you were serving the request to the user.
What all of these traditional methods of RPC have in common is a tight linkage between the client and server.
Remember me: RPC over RabbitMQ and waiting for answers the server, makes a request, and then blocks, waiting for a response from the server.
This model has a lot of benefits in that its point-to-point nature makes the topology simple at small scale.
But that simple topology also limits its flexibility and increases its complexity when it becomes time to scale up.
For example, how do your clients discover where to find servers with the services they want when there are multiple servers? SOAP and most enterprise RPCs have come up with complex supplementary protocols and service directories that layer on additional complexity and points of failure, all in the name of being able to serve APIs from multiple RPC servers without tight coupling between the clients and the server.
What if, instead of complex directories and multiple protocols, you could do RPC over one protocol? What if your client could issue an API call without worrying about which server was going to serve it, and what to do if the server failed? Using an MQ broker to do RPC can give you all of these things.
When you use RabbitMQ for RPC, you’re simply publishing a message.
It’s up to RabbitMQ to use bindings to route the message to the appropriate queue where it’ll be consumed by the RPC server.
RabbitMQ does all the hard work of getting the message to the right place, load balancing RPC messages across multiple RPC servers, and even retasking an RPC message to another server when the server it was assigned to crashes.
All of this without complicated WS-* protocols, or any routing intelligence on the part of the client.
The question is, how do you get replies back to the client? After all, your experience so far with RabbitMQ has been fire-and-forget.
Thankfully, the guys at RabbitMQ have an elegant solution: use messages to send replies back.
On every AMQP message header is a field called reply_to.
Within this field the producer of a message can specify the queue name they’ll be listening to for a reply.
The receiving RPC server can then inspect this reply_to field and create a new message containing the response with this queue name as the routing key.
You might be saying yourself, “That sounds like a lot of work to create a unique queue name every time.
How do we keep other clients from reading the replies?” Once again, RabbitMQ rides to the rescue.
You might remember from chapter 1 that if you declare a queue with no queue name, RabbitMQ will assign one for you.
This name happens to be a unique queue name, and when declared with the exclusive parameter ensures that only you can read from the queue.
Note that we didn’t say anything about binding the reply queue to an exchange.
This is because when the RPC server publishes its reply message to RabbitMQ without an exchange specified, RabbitMQ knows that it’s targeted for a reply queue and that the routing key is the queue’s name.
Enough talk; let’s look at how you get RPC working with RabbitMQ in real code.
Before we dive into the code, it might help to take a look at the flow of your RPC client and server, shown in figure 4.5
In the following listing you’ll build a simple API server that implements a ping call.
This call’s only function is to receive the ping invocation from the client, and send a Pong! reply with the timestamp included by the client in the original call.
We’ve covered the setup and connection to RabbitMQ, so let’s skip forward to the interesting part where the exchange and queues for receiving the API calls are created:
What you’ve done here is set up a typical direct exchange and created a queue and binding.
For the API, you’re following a pattern where the name of the RPC function call is what you use as the binding pattern (and queue name for those calls)
In this case, the ping API call is created by binding the ping queue to the rpc exchange using ping as the binding pattern.
All your clients need to do is put ping as their routing key and their arguments into the message body.
You could also use more complex routing of RPC requests by using a topic exchange.
All of this is similar to what you’ve done so far in the book.
What you’ll notice is different is the basic_publish command you issue after acknowledging the call message.
More important to focus on is the configuration of the basic_publish command.
It’s using the reply_to from the header as the routing key for the reply message.
Also, unlike any other publish you’ll ever do with RabbitMQ, there’s no exchange you’re publishing to.
Those are the only two special components you need to know about making RPC work over Rabbit: publish the reply using the reply_to as the target, and publish without an exchange specification.
The heart of making RPC work on the client side is this bit here:
In those three lines you create your reply queue and set the reply_to header on the message to the name of the new queue.
This ensures that no one else can pilfer your messages (though the queue name created by Rabbit is unique), and that when you disconnect from the queue after receiving your reply, the queue will be automatically deleted by Rabbit.
All that’s left is to publish the API call message and subscribe your callback function to the reply queue:
Once you have the reply queue set up, you can consume from it like any other queue.
Just be sure not to start consuming from the queue until after you publish your API call message.
Otherwise, the channel will be in consume mode and you’ll get an error when you try to publish.
So what does it look like on the client and server sides when you run your RPC app?
You can see that the server’s reply really was based on the client’s call because the timestamp included in the server’s reply is the one that was in the body of the client’s call message.
From here you can easily extend the API by creating new queues and bindings for new API methods.
You could easily write a new RPC server that performs image processing, for example, and run it even on a different physical box than the ping API server.
Your clients won’t know the difference, and you’re free to scale your APIs any way you see fit.
RabbitMQ does the magic of making it all act like one API fabric.
In this chapter we’ve covered the fundamental ways of writing apps that take advantage of RabbitMQ and the messaging patterns behind them.
We’ve discussed everything from fire-and-forget patterns, like alerting and image processing, to true bidirectional communication powering RPC APIs.
With these fundamental messaging architectures under your belt you’re free to start designing your own sophisticated patterns that combine the fundamentals into unique solutions that accomplish your specific goals.
Now that you’re starting to build RabbitMQ into the heart of your application architecture, it’s time we looked at how to run RabbitMQ in resilient configurations that ensure it’s always available when your apps need it.
So you just finished your phenomenal new web app powered by RabbitMQ’s queuing magic.
The user interface displays real-time notifications fed from your backend API, and Rabbit is routing to each API client only the notifications they’re interested in.
Everything looks great, and Rabbit has made you look like a programming guru to your boss.
Time to deploy to production; you can just throw up a RabbitMQ instance on a production server and call it a day, right? Not so fast.
Guess it’s time we talked about making RabbitMQ resilient to failure, so when Clustering and dealing with failure.
Murphy’s Law wreaks havoc with your apps, you can trust RabbitMQ to keep chugging as the heart of your application.
One is setting up your Rabbits so that you can survive the failure of any one Rabbit and your applications can keep functioning without a hiccup.
The other side is dealing with performance as your application scales.
Luckily, RabbitMQ comes with built-in clustering that can satisfy both problems and make sure your app always has a Rabbit to talk to, no matter whether server failure or massive success hits you.
We’re going to cover RabbitMQ’s amazing clustering in this chapter.
By the time we’re done you’ll understand how a cluster works under the hood, and how to create them in environments ranging from a small cluster on your development laptop to a real multiserver cluster in production.
You’ll even know how to upgrade your cluster when new versions of Rabbit come out.
Enough talking about it; let’s dive in and see how you can take a few Rabbits and turn them into a fire-breathing, message-passing cluster!
This sets it apart from almost every other open source messaging broker, and the fact that you can have a cluster up and running in 5 minutes sets it apart from every broker period.
Start with one Rabbit today and add more Rabbits on-the-fly with zero downtime to add high availability or more performance.
The clustering built in to RabbitMQ was designed with two goals in mind: allowing consumers and producers to keep running in the event one Rabbit node dies, and linearly scaling messaging throughput by adding more nodes.
RabbitMQ adeptly satisfies both requirements by leveraging the Open Telecom Platform (OTP) distributed communication framework provided by Erlang.
You can lose a RabbitMQ node and your applications can reconnect to any other node in the cluster and continue producing and consuming as if nothing had happened.
Similarly, if your Rabbit cluster is straining under the load of your messaging volume, adding more nodes will linearly add capacity to add more performance.
What RabbitMQ clustering doesn’t necessarily do is provide guarantees against message loss.
Even if you do everything right (set your messages, queues, and exchanges to durable, and so forth), when a Rabbit cluster node dies, the messages in queues on that node can disappear.
This is because RabbitMQ doesn’t replicate the contents of queues throughout the cluster by default.
Without specific configuration, they live only on the node that owns the queue.
To get a better understanding, let’s take a look at the architecture of a RabbitMQ cluster.
Up to this point we’ve been vague about the internals of RabbitMQ.
Sure, you know what queues and exchanges are—how to bind them together and why you’d want to use the various types.
At all times RabbitMQ is keeping track of four kinds of internal metadata:
Exchange metadata—The exchange’s name, the type of exchange it is, and what the properties are (durable and so on)
With a single node, RabbitMQ stores all of this information in memory while writing it to disk for any queues and exchanges (and their bindings) marked durable.
Writing it to disk is what ensures that your queues and exchanges will be re-created when you restart a RabbitMQ node.
When you add clustering into the mix, RabbitMQ now has to keep track of a new type of metadata: cluster node location and the nodes’ relationships to the other types of metadata already being tracked.
Clustering also adds the choice about whether to store metadata on disk (the default in a standalone node) or in RAM only.
But before we dive into cluster nodes and how they store their metadata, you should first understand how queues and exchanges behave in a cluster.
The minute you join one node to another to form a cluster, something dramatically changes: not every node has a full copy of every queue.
In a single node setup, all of the information about a queue (metadata, state, and contents) is fully stored in that node (see figure 5.1)
But in a cluster when you create queues, the cluster only creates the full information about the queue (metadata, state, contents) on a single node in the cluster1 rather than on all of them (queues are created on the node to which the client declaring the queue is connected)
The result is that only the owner node for a queue knows the full information about that queue.
All of the non-owner nodes only know the queue’s metadata and a pointer to the node where the queue actually lives.
So when a cluster node dies, that node’s queues and associated bindings disappear.
Consumers attached to those queues lose their subscriptions, and any new messages that would’ve matched that queue’s bindings become black-holed.
RabbitMQ 2.6.0 and newer provide mirrored queues that allow queue contents to survive cluster node failure.
We’ll cover mirrored queues in their own section in this chapter.
Not to worry: you can have your consumers reconnect to the cluster and recreate the queues, right? Only if the queues weren’t originally marked durable.
This ensures messages in that queue on the failed node don’t disappear when you restore it to the cluster.
The only way to get that specific queue name back into the cluster is to actually restore the failed node.
But if the queues your consumers try to re-create are not durable, the redeclarations will succeed and you’re ready to rebind them and keep trucking.
The nagging question is, why doesn’t RabbitMQ replicate queue contents and state across all nodes by default? There are two reasons:
Storage space—If every cluster node had a full copy of every queue, adding nodes wouldn’t give you more storage capacity.
For durable messages, that would require triggering disk activity on all nodes for every message.
Your network and disk load would increase every time you added a node, keeping the performance of the cluster the same (or possibly worse)
By making only one node in a cluster responsible for any particular queue, only the responsible node experiences disk activity for that queue’s messages.
All of the other nodes need to pass the messages they receive for that queue to its owner node.
As a result, adding more nodes to a Rabbit cluster means you have more nodes across which to spread queues, giving you an increase in performance for every node you add.
This makes RabbitMQ clustering excellent for scaling up as your load increases.
You might be wondering whether exchanges play by the same rules.
They don’t, and the reason is because exchanges are a figment of your imagination.
Up to now we’ve always described exchanges as if they were a living entity like queues.
The truth is that, unlike queues which get their own process, exchanges are just a name and a list of queue bindings.
When you publish a message “into” an exchange, what really happens is the channel you’re connected to compares the routing key on the message to the list of bindings for that exchange, and then routes it.
The channel does the actual routing of the message to the queue as specified by the matching binding.
Why does this matter? It’s important to understand that the channel is the actual router because that explains why exchanges don’t suffer from the same limitations as queues in a cluster.
Exchanges are simply a list of routing patterns and the queue process IDs where matching messages should be sent.
When you publish a message that matches a binding in an exchange, the channel is actually what does the matching, and once matched establishes a connection to the queue PID and transfers the message to it.
The process ID of the queue is essentially its Erlang address in the cluster.
Since an exchange is simply a lookup table rather than the actual router of messages, it’s much easier to replicate exchanges throughout the cluster (see figure 5.2)
For example, when you create a new exchange, all RabbitMQ has to do is add that lookup table to all of the nodes in the cluster.
Every channel on every node then has access to the new exchange.
So where the full information about a queue is by default on a single node in the cluster, every node in the cluster has all of the information about every exchange.
For availability this is great, because it means you don’t have to worry about redeclaring an exchange when a node goes down.
Just have your producers on the failed node reconnect to the cluster and they can begin publishing immediately into the exchange.
But what happens to messages that have been published into a channel but haven’t finished routing yet when the node fails?
The basic.publish AMQP command doesn’t return the status of the message.
This means the channel might still be routing the message when the channel’s node fails, though your producer has moved on to creating the next message.
Both solutions will also help you detect when a message is unroutable because a node has failed and the queue it’s destined for no longer exists.
When combined with the fact that exchanges are fully replicated throughout the cluster, transactions and publisher confirms can help ensure your apps can keep publishing and never lose a message.
Now that you understand how queues and exchanges behave in a cluster, it’s time to look at how RabbitMQ keeps track of them all and the nodes powering them.
Every RabbitMQ node, whether it’s a single node system or a part of a larger cluster, is either a RAM node or a disk node.
A RAM node stores all of the metadata defining the queues, exchanges, bindings, users, permissions, and vhosts only in RAM, whereas a disk node also saves the metadata to disk (see figure 5.3)
Single-node systems are only allowed to be disk nodes; otherwise every time you restarted RabbitMQ it would forget all of the configuration of the system.
But in a cluster, you can choose to configure some of your nodes as RAM nodes.
Why would you want to only store metadata in RAM? Because it makes operations like queue and exchange declarations faster.
When you declare a queue, exchange, or binding in a cluster, the operation won’t return until all of the cluster nodes have successfully committed the metadata changes.
For a RAM node, this means writing the changes into memory, but for a disk node this means an expensive disk write that must complete before the node can say “I’ve got it!” If you had a five-node cluster and all of the nodes were disk nodes, you’d have to wait for all five nodes to write the metadata to disk before a queue declaration could return.
For a broker where the queues are long-lived that isn’t a big deal.
Architecture of a cluster what if you’re doing heavy RPC? If every RPC client is creating and destroying hundreds of reply queues every second, you start to see where disk nodes can kill performance.
So how do you balance the performance of RAM nodes against the need to have some disk nodes that allow the cluster configuration to survive cluster restarts?
RabbitMQ only requires that one node in a cluster be a disk node.
Keep in mind that when nodes join or leave a cluster, they need to be able to notify at least one disk node of the change.
If you only have one disk node and that node happens to be down, your cluster can continue to route messages but you can’t do any of the following:
In other words, your cluster can keep running if its sole disk node is down but you’ll be unable to change anything until you can restore that node to the cluster.
The solution is to make two disk nodes in your cluster so at least one of them is available to persist metadata changes at any given time.
The only operation all of the disk nodes need to be online for is adding or removing cluster nodes.
When RAM nodes restart, they connect to the disk nodes they’re preconfigured with to download the current copy of the cluster’s metadata.
If you only tell a RAM node about one of your two disk nodes and that disk node is down when the RAM node’s power cable gets knocked loose, the RAM node won’t be able to find the cluster when it reboots.
So when you join RAM nodes, make sure they’re told about all of your disk nodes (the only metadata RAM nodes.
As long as the RAM node can find at least one disk node, it can restart and happily rejoin the cluster.
Understanding how RabbitMQ handles clustering internally is the hard part; setting a cluster up is easy! It’s so easy that you can set up a fully functional cluster on your development system.
This is great because it means that as you write your code, you can test failure scenarios and see how they’ll actually be handled in production.
From chapter 1 you should already have a RabbitMQ node installed on your development machine.
Before you start configuring your cluster you first need to make sure that your existing Rabbit node is not running.
To stop the node, change to your RabbitMQ installation’s directory and run sbin/rabbitmqctl stop.2 You should see a message like this to tell you that the node is stopped:
Now that the node is stopped, you can bootstrap the cluster.
Normally you’d start a node using the rabbitmq-server command and call it a day.
But without any additional arguments, this command will default the Rabbit node to use the node name rabbit and 5672 for the listener port.
If you were to try to start three nodes on the same machine this way, the second and third nodes would crash on startup due to node name and port collisions.
In this case, you’ll start the ports at 5672 and increment by one for every node you start.
You can use different node names and ports as long as they’re unique for each node.
If you have, you’ll want to disable those before starting the cluster nodes.
This is because plugins like the RabbitMQ management plugin will listen on dedicated ports to provide their services (like a web UI for the management plugin)
We haven’t covered yet how to tell some plugins to listen on alternate ports, so when your second and subsequent nodes start their plugins, they’ll clash with the ones running on the first node and the nodes will crash.
It’s also possible to configure cluster membership using the RabbitMQ central config file instead of rabbitmqctl.
We won’t cover this method as it can be error-prone and difficult to debug.
But each is still a standalone node with its own metadata and no idea that the others exist.
The first node of a cluster is the one that brings the initial metadata into the cluster and doesn’t need to be told to join.
Rather, the second and subsequent nodes are joined to it and acquire its metadata.
To join the second and third nodes, you first need to stop the RabbitMQ app running on their Erlang nodes and reset (empty) their metadata so they can be joined and acquire the metadata of the cluster.
The rabbitmqctl utility will let you communicate with each node and accomplish each of these tasks.
Start by stopping the RabbitMQ app on the second node:
Next, you need to reset the second node’s metadata and state to be empty:
Now that you have a stopped (and empty) Rabbit app, you’re ready to join it to the first cluster node:
Finally you can start the second node’s app again so it can start being a functioning member of the cluster:
When you join a new node to a cluster, you have to list all of the disk nodes in the cluster as arguments to the cluster command.
This is how a RAM node knows where to get its initial metadata and state if it reboots.
If one of the disk nodes you’re telling the new node about is itself, rabbitmqctl is smart enough to realize that you want the new node to also be a disk node.
The other key piece of information you passed to rabbitmqctl is the -n rabbit_1@Phantome argument.
This tells rabbitmqctl that you want it to execute the command you’re specifying against a node other than the default node (rabbit@)
You can use the -n argument to specify any RabbitMQ node either on your development system or on any other system reachable from your network.
Since rabbitmqctl uses the Erlang OTP communication mechanism to talk to the Rabbit nodes, the machine you’re running rabbitmqctl on and the Rabbit nodes you want to talk to must be using the same Erlang cookie.
At this point you have a two-node Rabbit cluster running on your development system along with a third standalone Rabbit node waiting to be clustered.
Let’s not leave that third node standing out in the cold! Joining the third node, as shown in the following listing, is almost identical to joining the second node.
When you ran the same commands to join the third node, all that changed was the -n argument to specify the third node.
Distributing the nodes to more machines result, rabbit_2 will know about the two disk nodes in your cluster, but won’t be a disk node itself.
Instead, by not specifying it as an argument, rabbit_2 will become a RAM node.
With all of your nodes running and successfully clustered, let’s look at your handiwork and ask rabbitmqctl what your cluster looks like:
The running_nodes section tells you which of those cluster nodes is currently running.
Right now you could connect to any of the three running_nodes and start creating queues, publishing messages, or performing any of the other AMQP tasks you’ve worked with up to this point.
But before you start using the cluster to learn how to write programs that can reconnect and otherwise deal with node failure, you should take your newly acquired cluster-building skills and see how to apply them to create a cluster across more than one computer.
Running a RabbitMQ cluster on more than one physical machine isn’t much more difficult than building a cluster on your development system.
The first thing you need to know is that RabbitMQ clustering is sensitive to latency and should only be used over a local area network.
With that in mind, we’ll create a distributed cluster on a local area network that looks like this:
Three nodes on three separate physical machines (Amazon EC2 micro instances/servers)
Though we’re using Ubuntu here, this section should work on any UNIX-based operating system.
So you can focus on the actual clustering instead of server setup, we’ve made our Amazon Machine Image (AMI) available that has Ubuntu and RabbitMQ already installed and ready to be clustered.
To use it, launch three new servers in the EC2 US West - N.
California region and search for AMI ID ami-69ebb42c when selecting the image for your new servers.
These are the hostnames that Amazon Web Services automatically assigned to our servers when we created them from our AMI.
Yours will be different, so use the hostnames assigned to your servers instead.
At this point, what you need to do is copy the Erlang cookie from ip-10-170-29145 to the other nodes so that they can communicate.
If the nodes don’t have the same Erlang cookie string, then joining the cluster will fail when the Erlang nodes attempt to authenticate each other.
This is actually the hardest part of building the distributed cluster.
If you build EC2 servers using our AMI, be sure to use ubuntu as the username when you SSH into the servers.
On separate physical systems, the first RabbitMQ node on that system will always be called rabbit.
With the second node under your belt, let’s add the third node, ip-10-170-29-88:
If you run sudo rabbitmqctl cluster_status on any of the nodes you should see that you now have a three-node cluster:
At this point you’ve built two different RabbitMQ clusters: one distributed across multiple servers, and one all on a single machine.
But one thing we haven’t covered is removing nodes from the cluster.
What happens if you want to make a cluster smaller or replace a node with one that has better hardware? In either case what you need to do is tell the node to leave the cluster.
Let’s remove ip-10-170-29-88 from the cluster and turn it back into a standalone node:
We’ve said before that reset empties the node of its metadata and restores it to an empty state.
This is true, but when the node being reset is a part of a cluster, the command also communicates with the disk nodes in the cluster to tell them that the node is leaving.
This is important because otherwise the cluster will consider the node failed and expect it to be eventually restored.
It’s particularly critical to formally leave the cluster when the node is a disk node.
As you recall, disk nodes are required for every metadata change, but all the disk nodes are required for a node to join or leave the cluster.
So if you don’t formally remove a disk node, the cluster will consider it failed and will wait for it to be restored before it allows any new nodes to join the cluster.
As a result, simply yanking a disk node from the cluster without formally removing it can render the cluster permanently unable to change.
So be careful to always reset nodes when removing them from the cluster.
If you check the status of the cluster from the removed node you’ll see that it now considers itself standalone:
Also, if you check the cluster status from any of the other nodes remaining in the cluster, you’ll see they no longer consider ip-10-170-29-88 a part of the cluster:
With building a distributed cluster and formally removing nodes under your belt, let’s talk about what upgrading a cluster to a new version of RabbitMQ means.
Generally, upgrading to new versions of RabbitMQ on standalone systems is easy.
You just unpack the new version and run it.4 The old data will be retained and you’ll be.
If you move between versions of RabbitMQ that have incompatible storage formats, RabbitMQ will automatically copy the old storage files to a backup location and create new empty files.
Mirrored queues and preserving messages running the latest and greatest version of RabbitMQ.
Simply unpacking new versions of RabbitMQ on your cluster nodes and restarting them will kill any configuration and data in the cluster.
If you don’t have anything stored in the cluster that can’t be recreated this isn’t much of a problem.
If you do, then upgrading is more of an involved process.
First you’ll need to back up the current configuration via the RabbitMQ management plugin using the instructions in chapter 6
Then shut down any producers and wait for your consumers to drain all of the queues (use rabbitmqctl to watch queue statuses until all of them are empty).5 Now, shut down the nodes and unpack the new version of RabbitMQ into your existing installation directories.
At this point, select one of the disk nodes to be your upgrader node.
When it starts, this node will upgrade the persisted cluster data to the new version.
Then you can start the remaining cluster disk nodes, which will acquire the upgraded cluster data.
With upgrades and the operation of a traditional cluster under your belt, it’s time to look at how to extend that cluster to preserve the contents of queues during node failure.
When we started talking about clustering, you may remember that we said queues only live on one node in the cluster by default.
That’s still true, and if you’re using any version of RabbitMQ before 2.6.0, that’s the only option you have.
But with version 2.6.0, the folks at Rabbit gave us a built-in active-active redundancy option for queues: mirrored queues.
Like a normal queue, the primary copy of a mirrored queue only lives on one node (the master), but unlike a normal queue, mirrored queues have slave copies on other nodes in the cluster.
In the event that the queue’s master node becomes unavailable, the oldest slave will be elected as the new master.
This sounds like the high availability panacea we’ve been looking for since we ventured into clustering, but there are a few caveats you need to be aware of.
Before we dive into the caveats, let’s look at how you can write consumer apps that take advantage of mirrored queues.
As with many aspects of AMQP, your application defines a queue as being mirrored rather than rabbitmqctl.
Declaring a mirrored queue is just like declaring a normal queue; you pass an extra argument called x-ha-policy to the queue.declare call.
To see how this looks in actual code, let’s update the Hello World consumer program you wrote in chapter 2 to declare a mirrored queue instead of a normal one.
Draining queues isn’t required with versions of RabbitMQ newer than 2.6.0, as the broker will upgrade them automatically.
But it’s still a good safety measure, just in case something goes awry with the upgrade.
In this case, you’re adding an argument called x-ha-policy and setting its value to all.
When set to all, x-ha-policy tells Rabbit that you want the queue to be mirrored across all nodes in the cluster.
This means that if a new node is added to the cluster after the queue is declared, it’ll automatically begin hosting a slave copy of the queue.
To test your new mirrored queue consumer, fire it up in one terminal and use rabbitmqctl in a separate terminal to see if the queue is really mirrored:
This tells rabbitmq to show you the name, pid, and slave_pids fields when listing the queues in the cluster.
When dealing with mirrored queues, pid is the Erlang process ID of the master copy of the queue, and slave_pids is a list of the slave copies and the nodes they’re on.
Since the mirrored nature of a queue is specified by the application at runtime, the guys at Rabbit HQ decided that you’d specify which nodes your mirrored queue lives on at runtime as well.
So, to make your mirrored queue live on a subset of nodes in the cluster, you have to specify in your application the exact node names of the cluster nodes you want the queue to live on (instead of specifying all)
This is the tricky part, because it means you’re hardcoding node names into your application.
If any of those nodes are down (or have been removed from the cluster) when your application tries to declare the queue, the declaration will fail.
There’s no concept of an availability group in Rabbit that would abstract the set of nodes you want your mirrored queue to live on into a general name that won’t change if your ops team decides to reshuffle your Rabbit cluster.
As a result, we highly recommend you use the all setting for x-ha-policy whenever possible so that your mirrored queue declarations aren’t hardcoded to specific node names that may change.
But suppose you absolutely need to specify a subset of cluster nodes for your mirrored queue.
You only need to make two changes to your mirrored queue declaration to make it use a subset of nodes, instead of all the nodes in a cluster.
Mirrored queues and preserving messages x-ha-policy to nodes6 instead of all.
This tells RabbitMQ you’re going to be giving it a specific list of cluster node names to mirror the queue on.
If you delete the mirrored queue (hello-queue) you created the first time you ran your updated Hello World consumer and re-run it, you should see that the mirrored queue now only lives on a single node in the cluster:
As expected, hello-queue only has a master copy and no slaves, even though there are two nodes in this cluster.
What would happen if you were to add a new slave node to the queue at this point? The new slave copy would only contain messages received by the mirrored queue after the slave was added.
RabbitMQ doesn’t yet (as of 2.7.0) synchronize the existing contents of a mirrored queue to newly added slave copies.
The theory goes that as messages are consumed from the existing master and slave copies, all of the old messages that the new slave doesn’t know about will be removed and the new slave copy will eventually have the same state as the existing queue copies.
But if you were to remove all of the nodes containing the existing master and slave copies before these old messages were consumed, and the new slave copy was promoted to be the master, you’d lose those old messages.
As a result, until RabbitMQ provides synchronization of a mirrored queue’s existing contents to new slaves, it’s important to be able to tell whether all of the slaves have the same contents.
But if any of the PIDs in the first bracketed list aren’t present in the second list, then the missing slave PIDs don’t yet have identical contents to the older slave copies.
This will ensure you don’t lose any messages that are only present on the nodes you may be removing.
This is one of the caveats that we alluded to when introducing mirrored queues.
To get a better understanding of how mirrored queues work (and the rest of the caveats), let’s dive into how mirrored queues operate under the covers.
So far you’ve learned how a cluster works (including mirrored queues) and how to deploy one either on a single development machine or distributed across a local area network.
You even know how to upgrade a cluster without losing all of your configuration forever.
What you don’t know how to do is write code that can deal with cluster node failure and auto-reconnect to other nodes in the cluster.
In a Rabbit cluster with nonmirrored queues, the channel does the job of routing messages to the appropriate queues in the cluster.
When you add mirrored queues into the mix, the channel does the exact same thing, except instead of just delivering the messages to the appropriate queues specified by the routing bindings, it also delivers the messages to the slave copies of the mirrored queues (as shown in figure 5.5)
In some ways you could view a mirrored queue as having a hidden fanout exchange that instructs the channel to also deliver to the queue’s slave copies.
Understanding that the channel is what publishes the message in parallel to both the master and slave copies of a mirrored queue can also help you understand how transactions and publisher confirms are affected by mirrored queues.
When dealing with nonmirrored queues, you only receive a publisher confirm back (or a successful transaction) after the channel has routed the message to all of the queues specified by the bindings that the message matched.
Rabbit uses the same concept, but extends it to the slave copies of the queues as well.
So if you need to ensure a message isn’t lost, you can use a publisher confirmation on the message and Rabbit will notify you when all of the queues and their slave copies have safely accepted the message.
But if a mirrored queue’s master fails before the message has been routed to the slave that will be become the new master, the publisher confirmation will never arrive and you’ll know that the message may have been lost.
But that only covers how publishers handle the failure of a mirrored queue’s master node.
What happens to consumers attached to the failed master copy?
If a mirrored queue loses a slave node, any consumers attached to the mirrored queue don’t notice the loss.
That’s because technically they’re attached to the queue’s master copy.
But if the node hosting the master copy fails, all of the queue’s consumers need to reattach to start listening to the new queue master.
For consumers that were connected through the node that actually failed, this isn’t hard.
Since they’ve lost their TCP connection to the node, they’ll automatically pick up the new queue master when they reattach to a new node in the cluster.
But for consumers that were attached to the mirrored queue through a node that didn’t fail, RabbitMQ will send those consumers a consumer cancellation notification telling them they’re no longer attached to the queue master.
If your AMQP client library understands consumer cancellation notifications, it’ll raise an exception and your app will know it’s no longer attached to the queue and needs to reattach.
On the other hand, if your client library doesn’t understand consumer cancellations, you’re in a bind.
The client has no way of telling your app that its consumption loops point to a master queue copy that no longer exists.
So your app will sit there dumb and happy, thinking there’s nothing in the queue to consume.
Unfortunately, there’s no clever way around this situation (such as Rabbit closing the consumer’s channel to force an exception)
So if your client library doesn’t understand consumer cancellation notifications, you should avoid mirrored queues until it does.
Otherwise, you could end up with a wake-up call in the middle of the night from your monitoring system telling you that your queues are chock full of unconsumed messages.
After cancellation notifications, the only remaining item to watch out for with mirrored queues is messages that have been consumed but not acknowledged.
When the master node of a mirrored queue fails, Rabbit has to make a decision about any messages that have been delivered to consumers, but not yet acknowledged by them.
Even though the messages were delivered to a consumer, Rabbit can’t tell the difference between acknowledgements that were lost during the failover and messages that weren’t acknowledged at all.
So to be safe, consumed but unacknowledged messages are requeued to their original positions in the queue (or to the back of the queue in versions before 2.7.0)
When you started this chapter, you were completely at the mercy of a single Rabbit node to keep your apps powered and communicating.
More important, you understand the ins and outs of how clustering is implemented internally so you can make intelligent design choices for your RabbitMQ architectures.
These choices can maximize uptime and scalability while minimizing your vulnerability to message loss.
Even with a hard charging Rabbit cluster at the heart of your infrastructure, your apps still only connect to one node.
If that one cluster node dies, they’re adrift about where to connect next in the cluster so they can keep operating without a hiccup.
It’s time to talk about how to write your apps so they can survive individual node failure and hold up their end of that bargain.
Building a RabbitMQ cluster to ensure availability and performance is only half the battle of ensuring a resilient messaging infrastructure.
The other half is writing applications that expect node failure and knowing how to reconnect to the cluster when it happens.
There are a number of strategies for handling reconnection to the cluster, but the one we’ll focus on is using a load balancer to handle node selection.
By using a load balancer you not only reduce the complexity of the failure handling code in your apps, but you also ensure even connection distribution across your cluster.
But even with a load balancer, there’s more to writing an app that can handle node failure than establishing a new connection to the cluster.
Your apps also need to be prepared to re-create exchanges and queues that may Writing code that survives failure.
This is particularly true when using two standalone Rabbit nodes in an active/standby configuration (which we’ll cover in chapter 7)
Before you start writing failure-handling code in your apps, we’ll look at what it takes to use a load balancer with RabbitMQ.
Depending on your background, you might be wondering what the heck a load balancer is.
A load balancer presents a single IP address behind which lie multiple servers.
Not only is this a lot to ask of your customers, it also gives you no control over how much load is on each of the servers at any given time.
If you have a load balancer, you could create an IP address on the load balancer that you name www.acme.com.
To your customer, it looks like you have one huge server called www and that’s all they need to care about.
All of the load balancing and failed server detection is handled by the load balancer transparently (see figure 6.1)
When using a load balancer with RabbitMQ, your cluster nodes are the servers behind the load balancer and your producers and consumers are the customers.
Your apps only need to know the frontend IP of the load balancer; it’ll transparently connect them to the cluster node with the lowest connection load.
If you want to grow your cluster for more performance, you don’t need to change any of your apps—you just need to join the new node to the cluster and then add the node to the load.
Without a load balancer, your apps would have to be manually configured with knowledge of every cluster node’s IP.
They’d also have to handle cluster node selection and failed server detection on their own.
Since each app would be handling its own node selection, you’d have no way to evenly spread the load across the cluster.
So by using a load balancer in front of your Rabbit cluster, you let it handle the complexities of node selection, failed server detection, and load distribution (see figure 6.2)
Many different load balancers are out there, but they fall into one of two categories: hardware appliances or software.
Hardware appliances are beefy dedicated network systems that can handle millions of connections a second without blinking an eye.
They also usually offer advanced clustering so that two load balancers can act as a single unit to remove the load balancer as a single point of failure.
If you have a hardware load balancer already, there’s no reason why you can’t use it to load balance RabbitMQ clusters.
Just use your appliance in layer 4 load balancing mode.
But for most situations, a software load balancer is more than adequate.
You’re more likely to hit the upper limit of the number of nodes a cluster can support than to outstrip a software load balancer’s ability to feed the cluster.
Of the many software load balancers out there, we’ll use HAProxy.
It’s freely available, is extremely reliable, and handles heavy loads across the internet for sites like StackOverflow.
Also, it’ll run on nearly any UNIX-based platform and is extremely easy to configure.
Most modern Linux distributions have HAProxy available in their packaging systems, but we’ll build it from source.
The first step is to download HAProxy to your development system and unpack the archive:
With the source unpacked you need to run make to build the HAProxy executable.
Before you can run make, you need to select the target platform.
For all other UNIX-based systems, TARGET=generic is usually the right choice.
This can reduce CPU usage and improve performance on heavily loaded systems.
FreeBSD has a similar feature called kqueues which HAProxy can take advantage of by setting TARGET=freebsd.
You should now have an executable named haproxy in the build directory.
If everything is built correctly you should be able to run haproxy --help to see its configuration options.
Finally, copy the haproxy executable to /usr/local/sbin so that it’s available on your UNIX path.
Now all you need is a configuration file for HAProxy so it can begin load balancing the RabbitMQ cluster on your development system.
HAProxy uses a single configuration file to define everything from the frontend IPs being advertised to the servers behind them.
The following listing shows the configuration you’ll use to load balance your local Rabbit cluster.
In B you define the IP and port your clients will be connecting to.
You use port 5670 so that it doesn’t conflict with the RabbitMQ cluster nodes themselves.
Then you tell HAProxy to use the round-robin algorithm C to distribute the load among the backends (see figure 6.3)
The most interesting part is D where we define the backends:
The final configuration section is for the statistics page E.
This can be useful when you want to see the load across your cluster or how many nodes are currently up or down.
There are many more configuration options for HAProxy that allow everything from complex load balancing rules to identifying backend nodes as backup servers that are only used if all of the main backends are down.
Let’s start up HAProxy with your new configuration and make sure it works.
Now that you have a functioning load balancer on your development system, we’re going dive into using it to build failover and resilience into your messaging apps.
When a cluster node fails, suddenly your app has a decision to make: where do I connect next? To be able to answer that question effectively, you must have anticipated it in your code long before it happens.
Lost connections and failing clients between servers problems; it means when there is a problem, nodes have somewhere else to go and keep running.
So the first step is to step back and consider what assumptions you can make before writing your code:
If I reconnect to a new server, what happens to my channels and all of the consumption loops attached to them? They’re invalid now and point nowhere.
You can’t assume queues and bindings survived the node failure.
You must assume that all of the queues you were consuming from were hosted on the node you were attached to—and no longer exist.
The same goes for those queues’ bindings, though exchanges are a different story.
If you’re using Rabbit’s built-in clustering you can assume exchanges will survive node failure due to being replicated to every node.
But if you’re using an active/standby setup like we describe in the next section, you can’t even assume exchanges will survive failover.
What you can take away from those questions is that you can’t assume anything about the state of the cluster when you fail over to a new node.
Though the Rabbit cluster has given your app a new place to connect to, you can’t make any assumptions about what does and doesn’t exist.
In some respects, you should always treat failover as if you were connecting to a completely unrelated RabbitMQ server, rather than a cluster node with some shared state.
As a result, whenever a node failure occurs, the first order of business after detecting the failure and reconnecting is to rebuild the fabric.
Connect RabbitM of exchanges, queues, and bindings that your app needs to operate.
Before we dive into some code, let’s talk about what you’ll need to run it.
You’ll build a sample producer and consumer that can survive cluster node failure.
Building a cluster-aware consumer is the more difficult task because the consumer is what builds your messaging fabric (exchanges, queues, and bindings)
As a result, it’s up to the consumer to rebuild that fabric after node failure.
With a standard consumer, your app’s body would look something like the following listing.
With the connection parameters already established, you build B your connection to the server.
Then you establish the channel C and begin declaring D exchanges, queues, and bindings (your messaging fabric)
After the fabric is built, you create E a consumption subscription (powered by the msg_rcvd function) and start consuming messages.
At this point if you were to experience node failure, your program would crash with an unhandled exception.
That’s because this code doesn’t know what to do when a connection error occurs.
What you need to do is wrap this code in an exception handler and initiate a reconnection when the failure occurs.
If you don’t assume any of the messaging fabric survives node failure, then all of your main body needs to be executed every time an error occurs.
If you rewrite the main body with this in mind, it’ll look something like the following listing.
By wrapping the main body in a try...except block you can now detect connection failures F and prevent them from crashing the consumer.
In this case, you trap out any errors and print them to the screen.
You’re no longer crashing when a node fails but you still need to reconnect and rebuild the fabric.
To do that you wrap the entire main body (including the new try...except block) with an infinite loop B.
When the app first starts, it enters the loop and then builds the connection C and the fabric D.
As long as there are no errors, this is as far as the outer loop will ever progress.
But the minute a node fails, a connection error is experienced.
This causes control to pass from the consumption code E to the outer exception handler F.
The exception handler then prevents the program from crashing by trapping the error, prints it to the screen, and then passes control back to the outer loop.
Now the loop starts the whole connection process over from scratch B by building a new connection C and fabric D just like before.
It’s a simple change, but one that enables your program to handle node failure within a RabbitMQ cluster.
It’ll also handle a variant of node failure we haven’t discussed yet, but that you need to know about.
So far when we’ve talked about a cluster node failing from your app’s perspective, we’ve always said it’s the node the app is connected to.
You might’ve assumed that as long as the node connected to your app doesn’t fail, then your app has nothing to worry about.
If you remember how queues operate in a cluster, you’ll note that they only exist on one node.
Since your app doesn’t know which node a queue is on when it starts consuming, it’s possible that your app is connected to node A in the cluster but is consuming from a queue on node B.
So what happens when node B fails? The app doesn’t experience a connection error but the queue it’s.
If you’re running a version of RabbitMQ earlier than 2.4.0 you’re somewhat out of luck.
Your consumer will sit there dumb and happy, doing nothing forever (at least until you restart it)
This limitation is more a property of AMQP than RabbitMQ itself.
But with RabbitMQ 2.4.0 came a new extension to AMQP called cancellation notification.
With cancellation notifications, your consumer receives a notification when its subscription terminates for any reason other than the consumer canceling it.
In Pika this manifests as an exception raised in the consumption code.
This will be trapped by your exception handler and your reconnect/rebuild code will reestablish the connection and rebuild the fabric.
With all of the pieces in place, the following listing shows what the consumer looks like all together.
As you can see, converting any consumer app to be cluster-aware isn’t difficult.
It just requires understanding what happens inside of RabbitMQ when a node fails and accommodating those behaviors in your code.
Now let’s fire up your consumer and see what happens:
What you need is a cluster producer to give your consumer some content to display! The producer is short-lived and doesn’t need any fancy failure-handling code.
This is because every invocation of the producer establishes a new connection from scratch, which enables the load balancer to select a new functional node.
The first part of the producer B is setting up the connection like you’ve done before.
It’s determining the IP address and port of the RabbitMQ “server” from the first and second command-line arguments passed to the producer.
You’re also using the builtin guest account that comes with every Rabbit install for authentication.
Then you create a JSON message C to send to your consumer that contains the phrase Cluster Test! and the current timestamp.
The last thing you do before publishing the message is to set the content_type header of the message so that your consumer knows.
Finally you publish the message and send it jetting through Rabbit to your consumer.
And if you check back on your running consumer …
First, use http://localhost:8100 to figure out which cluster node name your consumer is connected to.
It should be the node listed with a 1 in the Cur column under Sessions in the HAProxy stats page.
Now if you check back on your consumer, you should see some connection errors followed by a successful reconnection to the cluster:
The second Ready for Testing! line indicates your consumer has successfully recovered from the node failure and reconnected to the cluster.
Now if you publish a new message into the cluster you should see it echoed from your newly reconnected consumer:
Everything works! You now have a fully clustered RabbitMQ setup, complete with a load balancer to handle node selection and cluster-aware consumer and producers that can keep trucking when a cluster node dies.
At this point you could call it a day with the satisfaction that you have RabbitMQ's built-in clustering under your belt.
This necessitated an alternate approach with active and standby standalone RabbitMQ servers that could allow you to failover without losing the old queue’s contents.
Clustering RabbitMQ is only half of what you need to make a resilient messaging infrastructure.
Now you know how to write them to be resilient in the face of cluster node failure by reconnecting to new nodes and rebuilding the fabric your apps need to keep operating.
Equally as important, you can now set up and use a load balancer to be the glue that determines which cluster nodes have failed and intelligently route your apps to new nodes when they reconnect.
These techniques, when combined with a RabbitMQ cluster, give you a robust messaging infrastructure that can get hit with a failure without your applications missing a beat.
But there are still a couple of unanswered questions about making Rabbit highly available.
For example, how can you design a Rabbit infrastructure where the durable queues on that node aren’t unavailable to your apps when a node goes down? Also, what about designing a Rabbit architecture that can survive losing a whole data center and the clusters in it? For the answers to those questions, we need to break out our shovels and dive into a couple of warrens.
So far when we’ve talked about high availability, it’s always been in the context of RabbitMQ’s built-in clustering.
But clustering isn’t the only way to build resiliency into your Rabbit infrastructure, and depending on your needs it’s not always the right way either.
Clustering makes you trade the benefit of all the nodes acting as single unit to distribute the load for the drawback of not being able to use durable queues on downed nodes until the nodes are restored.
Also, clustering won’t give you what you need to build a RabbitMQ architecture that’s distributed across more than one data center.
So though clustering might initially sound like a Swiss army knife for our availability problems, you still need a couple of other tools in your toolbox.
Leveraging the knowledge you’ve acquired so far, you’ll learn how to build active/standby pairs of standalone RabbitMQ servers that let you trade scalability for Warrens and Shovels: failover and replication.
Warrens: another way of clustering more flexibility when it comes to durable messaging.
Then you’ll see how you can use the Shovel plugin to replicate the contents of queues on a Rabbit server in one city over long distances to a Rabbit server (or cluster) in another.
When you’re done you’ll have a complete toolbox for any high availability situation.
Best of all, if you’ve designed your apps with the new techniques you learned in the last chapter, you can use them unchanged to take advantage of these new RabbitMQ topologies.
Let’s get started by jumping into understanding active/standby pairs, or as we call them, warrens.
If a client re-created the durable queue while the node was still down, then the contents of the old queue would be lost when the downed node came back up.
When a node with a durable queue goes down, that queue can’t be re-created.
But until that node is restored, any messages that would’ve been delivered to it are either black-holed or errors are sent to the clients that set mandatory publish flags.
If your application can’t risk losing messages or deal with the latency of continuously republishing messages until their downed queue returns, then you need what we call warrens.
In our parlance, a warren is a pair of active/standby standalone servers with a load balancer in front handling failover (see figure 7.1)
The advantage to this setup is that it’s truly shared-nothing.
There’s no coordination between the active and standby servers, so any problem affecting the active server won’t be automatically transferred to the standby or vice versa.
The separation between them is so complete that you could run different versions of RabbitMQ on both.
This would allow you to roll out a new version of RabbitMQ into production while keeping the old version around as a precaution.
There are many reasons and situations where it’s advantageous to have two completely independent RabbitMQ servers available to handle each others load.
Whatever the reason, a warren can be useful when Rabbit’s built-in clustering doesn’t quite fit the bill.
We’d be remiss if we didn’t mention that there’s another way to set up a warren for high availability.
Instead our approach gives you an immediate place to start publishing and consuming messages again, and when you restore the active node, it allows your consumers to reattach and drain the messages that were in the queues when the active node went down.
You don’t lose any messages old or new, but you do have to wait for the active node to be restored for the old messages to become available again.
Then when a failure of the active server happens you use Pacemaker1 to transfer the RabbitMQ IP address to the standby node and then start up Rabbit on that node to pick up your current metadata, contents, and state from the shared storage.
There are only a couple of problems with that setup in our opinion.
First, the storage is shared, so if some kind of corruption kills your active node, that corruption will be present on the standby node too and prevent RabbitMQ from starting there.
Second, you need to be sure that the standby RabbitMQ has the same node name and UID as RabbitMQ on the primary node.
If either of these aren’t true, the standby Rabbit won’t be able to access the files on the shared storage and fire up.
Lastly, using this setup for a warren means your standby Rabbit isn’t actually running.
So there’s a possibility that something will have changed on the standby node that will prevent Rabbit from starting up when you need it.
Due to the fact that corruption gets replicated and the lack of a fully running RabbitMQ on both nodes with the shared storage approach, we prefer the load balancer–based warren and that’s the one we’ll show you.
But if a shared storage warren sounds appealing or fits your use case better, there’s a good tutorial on the RabbitMQ website that explains how to set it up: http://www.rabbitmq.com/ pacemaker.html.
Lastly, if you’ve built your app using the principle of “assume.
Pacemaker is a set of cluster utilities for Linux that handle IP failover between active and standby nodes, as well as automatically start up the protected application on the standby node when failure occurs.
Actually setting up a load balancer–based warren is simple and builds on all of the concepts you’ve acquired so far.
In fact the warren configuration for HAProxy (shown in the following listing) looks remarkably similar to the cluster configuration.
Here the HAProxy local socket B and stats page D have been changed to avoid conflicts with the Rabbit cluster HAProxy instance.
The more interesting change, though, is C the addition of a new HAProxy configuration option: backup.
When you add backup to a backend server directive you’re telling HAProxy to only use that backend server when all of the nonbackup servers are unavailable.
Light blue means rabbit_b is available but is a backup server (an unavailable backup server is colored red like any other backend server)
So you’ll need to wait 15 seconds before your consumer’s reconnections will succeed.
Once HAProxy has failed over to the standby RabbitMQ, you should see the following:
That confirms that your consumer is connected to the backup server.
The best part is that you can be assured that when the failover occurs, you don’t have to worry about RabbitMQ failing to start on the standby node, because it’s already running! Since Rabbit is running on both the active and standby nodes at all times, you can monitor both all the time and know immediately if your standby has become unavailable before it’s ever called on.
That’s something else you can’t do with a shared storage–warren.
With clustering and warrens under your belt, you’re covered when it comes to handling failure and scaling within your data center.
But what do you do when you need to replicate messages between Rabbits in different data centers? That’s when you need a Shovel.
RabbitMQ clustering is great for expanding your messaging performance inside one data center, but where it breaks down is when you need to route messages from a Rabbit server in one city to a Rabbit server in another.
You might try to use clustering to bridge your geo-diverse data centers, but you’ll run into a couple of show stoppers.
First and foremost, you have no control over the cluster nodes on which RabbitMQ chooses to place your queues.
So even if you had two cluster nodes in Chicago and a third in Los Angeles, you’d have no way of ensuring that queue A is in one city and queue C is in the other.
So those expensive WAN links between Chicago and LA are going to cause havoc and all sorts of strange behavior within your cluster.
Then there’s the fact that RabbitMQ has no strategy to cope with network partitioning if that WAN link fails.
But before you can use it, you need to know some background on how Shovel works.
Shovel is a plugin for RabbitMQ that enables you to define replication relationships between a queue on one RabbitMQ server and an exchange on another.
Originally designed by LShift (one of the original parents of Rabbit Technologies), Shovel is now maintained by RabbitMQ’s core development team.
Shovel is its own Erlang application that just happens to be loaded by Rabbit on startup.
In some respects, Shovel could’ve been written as a standalone Erlang application instead of as a RabbitMQ plugin.
But by virtue of being a RabbitMQ plugin, you can rely on RabbitMQ to automatically start Shovel and the defined replication relationships every time you boot Rabbit.
Perhaps a real-world example would demonstrate how Shovel can help.
Jacques has a problem: for many years, Avocados Supreme has operated out of a single warehouse in Goleta, California, but recently the warehouse has been operating at 80% and sometimes orders experience delays when inventory runs out.
To fix this, Jacques opens up a second warehouse down the road in Carpinteria (see figure 7.4)
The only purpose of the Carpinteria warehouse is to carry extra inventory and ship orders when Goleta runs out.
One of the crown jewels in the Avocados Supreme operation is their orderprocessing system that uses RabbitMQ to link their website to fulfillment in the Goleta.
With the Carpinteria warehouse now online, Pierre (Avocado Supreme’s technology architect) has been in a pickle trying to figure out how to link in the new warehouse to receive orders Goleta can’t fulfill.
Since he can’t use RabbitMQ clustering to bridge the two warehouses, Pierre had been planning on updating the website to start publishing to RabbitMQ servers in both Goleta and Carpinteria.
But Pierre’s concerned that this will slow down ordering on the website since the web app now has to publish to both Goleta (where the website is) and to Carpinteria (a much longer round trip) before he can confirm the order to the customer (see figure 7.5)
Not to mention that Pierre now has to modify the web app to do this, when one of the reasons why he chose messaging was the ability to route messages without changing the frontend code.
After doing some experimenting, Pierre discovers he can use Shovel to create a new queue in Goleta that subscribes to the incoming_orders exchange that the website publishes to.
The best part is the website doesn’t have to slow down order confirmation at all.
It can keep publishing to the Goleta RabbitMQ that’s on the same LAN and give zippy order confirmations back to avocado-loving customers.
Then Shovel can asynchronously replicate those orders to Carpinteria without the website ever being aware or affected by the increased latency.
It’s a perfect scenario for Pierre, who receives a beach vacation to Monterey for his brilliance.
So whether you need to replicate messages between RabbitMQ servers across the country or across the street, Shovel is your go-to solution.
If you’re running a version of RabbitMQ older than 2.7.0, you’ll need to retrieve and install the plugins yourself.
To do so, first download the rabbitmq-shovel and amqp_client plugins from http://www.rabbitmq.com/plugins.html and install them in the ./plugins/ directory of your RabbitMQ installation:
You still need to configure Shovel and start up your RabbitMQ brokers.
All of Shovel’s configuration information, from replication relationships to reconnection settings, goes into the rabbitmq.config file.
Like the rest of RabbitMQ’s config file, Shovel’s configuration is formatted as a valid Erlang tuple called rabbitmq_shovel with configuration directives nested inside.
Since the configuration can look fairly complicated, let’s look at the following listing, which shows how your rabbitmq.config with a Shovel configuration looks, and then examine the individual parts.
Right under the rabbitmq_shovel directive you see a subsection called shovels.
This is a list of shovel definitions where each shovel defines a replication relationship between two RabbitMQ servers.
Within that shovel, you define the sources that your messages to be replicated will come from and the destinations where those messages will go to.
Both sources and destinations contain the same types of configuration directives:
This will let Shovel fail over to another cluster node if the primary node fails.
They’re nested inside a list (array) where each member is an Erlang tuple defining the AMQP command to run along with another list of tuples that provide the arguments to that AMQP command:
You may notice a couple of funny things about those directives.
The angle brackets tell Erlang not to treat the information as a string but as a special data type called a binary.
You don’t have to understand what a binary is, only that Shovel will crash on startup if you forget the angle brackets.
The other funny thing you may notice is that the durable argument doesn’t get wrapped in curly braces like all of the other arguments.
You only need the curly braces when it’s an argument that takes a value.
Otherwise, the AMQP commands and their arguments should look familiar to you, and you can specify any of the arguments you’d normally have in the language of your choice.
Like durable, since auto_delete doesn’t take a value, just add it (separate by a comma) without curly braces after durable in the queue.declare arguments list.
After you’ve defined the sources and destinations, you also need to define some general settings for the shovel.
All of these settings take values, so they’re wrapped in curly braces.
The internal buffer is a stopover point between the source and destination that’s not protected during failure of Shovel.
Finally, you want Shovel to wait 5 seconds before reconnecting if it becomes disconnected.
Putting this all together, here’s what it looks like in the configuration file:
You’ll spin up two standalone RabbitMQ nodes on your development system for the test.
Since both the source and destination servers will be using the same rabbitmq.config file, you’ll end up with two identical shovels running: one on the source and one on the destination.
Normally, you’d only want one shovel, but since you’re running both nodes locally, one configuration file for both is simpler for testing.
With both your source and destination running, you’re going to need a consumer and producer to test the setup.
Variants of your cluster consumer and producer modified to handle avocado orders should do nicely.
First let’s look at the consumer, shown in the following listing.
It’s not much different than the consumers you built in chapter 4 for processing alerts.
Your producer (shown in the following listing) is even simpler, with the only change being the format of the avocado order you’re sending.
Your consumer takes two command-line arguments: the destination host name and the destination port.
The producer takes the same arguments but adds a third: the avocado type (hass, fuerte, and so on—any single word will do)
You’re going to publish an avocado order into the source node with the producer, and then through the magic of Shovel, receive and print the order from the consumer attached on the completely independent destination server.
Let’s fire up your consumer and connect it to the destination node:
Now let’s send it an avocado order by publishing into the source node:
Back on the consumer, you should see something like this:
Hot diggity, you have a working shovel that’s enabling publishes on one RabbitMQ server to be consumed on a completely independent one.
Though more tedious to set up than clustering, Shovel extends the reach of RabbitMQ by allowing you to create even more robust topologies that now include federation between independent RabbitMQ servers and clusters.
In the future RabbitMQ will support robust federation natively, but until then Shovel will provide you the federation you need today.
It’s been a long trip through all the options for making Rabbit resilient, but when we started you were at the mercy of server failure taking down your Rabbits and knocking your messaging infrastructure offline.
Now you no longer have to fear the power cord.
If what you really need is absolute high availability with no possibilities of message loss, you can build a warren using two standalone RabbitMQ servers, with a load balancer making them appear as one to your applications.
If for some reason you then need to extend this reliability to bridge Rabbits in multiple data centers, you know how to use Shovel to provide the replication to make that a reality.
Perhaps most important, you know how to make your applications resilient in the face of individual Rabbit failure.
By making them assume nothing about the state of the servers they’re connecting to and implementing reconnecting functionality, your consumers and producers can take advantage of any of the RabbitMQ redundancy options you’ve learned and survive node failure without missing a beat.
So far our way of administering RabbitMQ has been based on the command line via the rabbitmqctl script.
After typing rabbitmqctl so many times, you may have dreamed about a way to administer the server from a graphical interface, since there’s phpMyAdmin for MySQL or Futon for CouchDB.
The need for such a graphical interface led the RabbitMQ community to produce several web admins for RabbitMQ with more or less the same features: displaying queue stats, adding users, creating vhosts, and so on.
Thankfully the RabbitMQ team listened to the call from the community and developed the RabbitMQ Management plugin.
Along the way, they improved the server’s Erlang API in order to collect more stats about the broker usage, such as messages sent per second, queue usage rates, and more.
Further on you’ll learn about the new REST API, which can be easily accessed via the new rabbitmqadmin script.
They’re a way to extend the behavior of the server in ways that weren’t envisioned by its creators.
Plugins for RabbitMQ are written in Erlang and they run together with the server in the same Erlang VM.
We’ll have a chapter later devoted to building your own RabbitMQ plugin; therefore, in this one we’ll focus on enabling and working with one of them.
Let’s see why you need the Management plugin, what its features are, and how to get it enabled and running on your machines.
Say you love your rabbitmqctl script (we do as well)
We understand if you ask why you’d ever need to use this plugin.
The rabbitmqctl script is cool and it lets you do a lot of things for managing your server, but it has a couple of shortcomings.
First, to run the rabbitmqctl script, your current Linux user needs to have access to the Erlang cookie that was used to start the server.
Since the server will probably be running as root or as a rabbit user, you need access to their files.
That’s not a problem if you have a one-man team or a small number of developers, but what happens with big teams? Managing permissions for that file can get messy.
Do you share passwords across the teams? And the story doesn’t end there.
When you have access to the content of the .erlang.cookie file it means you can connect directly from an Erlang console to the RabbitMQ process.
Apart from the security problems, not all the team members on a project are CLI addicts.
We’ve worked in projects where even the product owner was interested in knowing how many background notifications were left on the queue.
Besides that, sometimes you just want to click and see the information with nice colors; it’s easier to understand than text output produced by the rabbitmqctl script.
Overview server stats—messages delivered, server memory information, number of Erlang processes, and so on.
Now let’s get your fingers to work and enable the plugin.
With the latest release of RabbitMQ (2.7.0 as of this writing), installing plugins became simple.
As a matter of fact there’s nothing to install anymore since the newer server packages come with the plugins bundled in the distribution.
The only thing you need to do is to enable them.
If you go to the folder where you installed RabbitMQ, you can see the plugins that you have available by entering the following command:
The files ending with the .ez extension are the plugins and their supporting libraries.
To enable the Management plugin, you have to run the following command from the broker sbin folder:
If everything went well, you can point your browser to http://localhost:55672/mgmt/ where you should be welcomed by an authentication prompt asking for a username and a password.
In the meantime you can use guest as user and password.
Do that by chowning that folder to the user that runs the rabbitmq process and then try again to enable the plugin.
Managing RabbitMQ from the web console submit the information, you should see the management interface as in figure 8.1
If you’re not running the server in localhost, then you’ll have to modify that URL to fit your environment.
By following such easy steps, you got the plugin up and running.
Now it’s time to learn how to use it, so let’s move on to the next section to start playing with it.
As you can see, you have a navigation menu on top where you can browse several items like Connections, Exchanges, or Queues.
Then the interface presents a general overview of the server status.
You can see how many messages are ready to be delivered from all of your queues, how many are waiting to be acknowledged, and the total number of messages.
This information can be useful when debugging your applications because, for example, the number of unacked messages tells you about the work your consumers are performing.
If the number starts to get too high, that could be a sign that your consumers are getting slow.
The good thing is that you can see this information right on the front page, without clicking 20 times to reach it.
There’s more to it in the web console; in this section you’ll learn how to monitor the Erlang VM to find out the number of processes running on it, and also see how to export your configuration into JSON format, as well as how to import your configuration back to the server.
If you scroll down the page a bit you’ll see some useful information about the Erlang node where RabbitMQ is running.
As you saw in chapter 3, you can use the node name information to remotely connect to RabbitMQ and perform advanced administration operations on it.
Another interesting value is the number of Erlang processes: if it reaches the limit, then RabbitMQ will stop working.
Whenever you send a bug report to the RabbitMQ mailing list, you should attach those values because that will make it easier for people to diagnose the problem and be able to help you.
On the next table you can see which port and host RabbitMQ is listening on.
How many times have you scratched our head because you couldn’t connect to the server and at the end the problem was wrong connection options? Here you can see the correct options to avoid such problems.
The file where this option may be found will vary depending on how you installed RabbitMQ.
If you followed the installation instructions in chapter 1, then the rabbitmq-server script will be inside the sbin folder.
When you get to the end of the Overview page you can see a nice feature: you can export the server configuration as a JSON file.
Let’s see what this file looks like for the installation on your machine right now.
Click on Download Broker Configuration and save the file to your hard drive.
The following listing shows a formatted version of such file.
For the sake of testing, try to add a new virtual host called book.
Save your changes and upload the new file by clicking on the Upload button and selecting your modified .json file.
Once you’ve selected the file, click the Upload Broker Configuration button.
If everything went well, you should see a confirmation message as in figure 8.2
With this simple mechanism, you can update your server configuration with ease.
Also you can export and version the configuration files so you can keep track of the server configuration at different points in time.
Every time you make a change in the config, you can keep the old settings just in case.
Let’s continue exploring the features provided by the Management plugin; in this case, let’s see how you can manage the users that can access your server.
Your next step will be to learn how to manage users from the web interface.
You’ve been using the default guest user in the book, which is fine for learning purposes, but if you want to run RabbitMQ in production you need to take the precaution of creating your own users and passwords.
So in this section you’ll learn the easy way of doing that via the web console.
User management doesn’t end at user creation; you also have to grant permissions to users.
The second part of this section will deal with that task.
Remember that when you opened the management page for the first time, you were prompted for user and password information, and replied using guest:guest as values? It’s time to change that, because you don’t want your systems to be running with the default user settings.
Click on the Users link on the upper navigation menu, and you should see the dialog box shown in figure 8.3
You’ll be presented with a list of the current users on the system.
Below the list is a form where you can add a new user.
As in figure 8.3, create a user called rmqinaction using rmqinaction as the password too.
Finally, set the user as an administrator by entering administrator in the tags field.
The Management plugin supports the concepts of user roles, which will determine what the user can do in the management interface.
Your users can be part of the management role, which means they can log in to this interface.
If you set the user as part of the monitoring role, then they can see connections and node-related information.
Your rmqinaction user was set as administrator to grant access to all the features the Management plugin offers.
In figure 8.4 you can see the confirmation of your new user.
As you can see from figure 8.5, the user that you just created doesn’t have permissions to access any virtual host so it’s time to change that.
Let’s grant the permissions to configure the server and to write and read from queues.
Click on the user name to go to the permissions settings dialog box, shown in figure 8.5
Use the default settings that the Management plugin presents, as in the figure, so just click on the Set Permission button to save those changes.
As a last note on user management, you can also delete users from this page by clicking the Delete button as in figure 8.6
With your users set up, the next step is to learn about managing queues and exchanges.
Using the Management plugin, you can create exchanges from the browser.
You’ll get a list of the current exchanges on the server, as in figure 8.7
By clicking on the exchange name, you can see more details about it, such as the exchange bindings.
You can also add new bindings and even delete the exchange completely.
Finally, if you go back to the exchange list page and scroll down, you’ll see the form that allows you to create a exchange, as you can see in figure 8.9
Let’s create one using test as the name, direct as the exchange type, and leaving all the other options as they appear on the form.
In this chapter you’ve seen how the Management plugin aids comprehension of your RabbitMQ architecture by providing visual representations of the fabric you’ve been building.
To nail down the point, let’s compare listing queues using rabbitmqctl versus the management web console.
Move to the sbin folder of your RabbitMQ installation and do the following:
Then go back to your browser and click on the Queues link.
Compare that with the table you see in figure 8.11
You even got some extra goodies such as information telling you whether the queue is exclusive, the queue’s status, and the queue’s message rates—the latter being information that you can get only via the Management plugin.
This last feature likely convinced you to use the plugin!
Another thing you can’t do from the rabbitmqctl script is create queues.
As you did when creating an exchange, type test as the queue name and then click the Add Queue button.
In figure 8.12 you can see what the form looks like once filled.
If you click on it, you can inspect its properties in detail.
An interesting feature here is that you can delete it or purge it directly from the browser.
That means if you have some queue in your server lying around but not in use anymore, you can just click Delete and the queue is gone.
In figure 8.13 you can see details about the status of a particular queue, for example,  how many messages are ready to be delivered by consumers or how many of them have pending acks.
With this tool, it’s easy to see how much memory is used by this queue, so you can use this information to monitor the health of the system in ways that weren’t possible before by just using the rabbitmqctl script.
For it to be really useful to sysadmins, it has to provide command-line tools that allow access to its features from a machine that lacks a window system, like most *nix servers.
The Management plugin also comes packed with a new command-line interface that will add flexibility to the management process, liberating your sysadmins from their mice.
It would be great if you could automate all that you’ve seen so far—say, write a script that would get some queue details, like number of messages held in memory waiting to be acked, and publish that to a graphing tool like Ganglia or Graphite.
If you want to do that via the Management plugin web interface, you’ll have to get your hands dirty by performing some screen scraping.
This means that if the web interface changes on a new plugin version, your script will break.
There has to be a better way of doing this.
Well, suffer no more, for there’s a new command-line tool, the RabbitMQ Management CLI.
In this section we’ll go through the reasons for yet another command-line tool.
Then you’ll install the new rabbitmqadmin script and use it to automate tasks like purging queues, creating exchanges, and more.
As we already mentioned at the beginning of this chapter, the rabbitmqctl script is the default way of administering RabbitMQ, but it has its own shortcomings, like dealing with Erlang cookies, for example.
Apart from that, it’s hard to integrate with other programming languages and tools, since you need to be parsing the output it produces in its own format.
It’ll be better if, for example, you could get a list of queues in JSON format and let your JSON library of choice parse the results to give you back a Python hash.
Such features justify the investment in learning this CLI API.
We’ve already played with the first one, so let’s take a look at what the other options have to offer.
If you click on HTTP API, you’ll get a page with the documentation for this REST interface.
Anything you can do with the Management plugin (Management Web UI), you can also do by using curl3 and invoking commands on this API.
As an example, if you want to list the vhosts on your server, execute the following code on your terminal:
It supports several formats like HTTP, RTMP, IMAP, and many more.
In case you need to install it on your machine, you can get the program from its website: http://curl.haxx.se/
And list all the vhosts back to see the one you just created:
Of course you can delete it if you don’t need it anymore:
By following this REST API you can easily automate tasks that so far have been only possible via a clickable interface.
If you want to learn about the available methods of the REST API, you can do so by pointing your browser to the excellent documentation that’s distributed with the Management plugin.
Something interesting to notice if you’ve been paying attention to the response headers is that the response is sent as application/json, which means parsing the results will be as hard as knowing how to use a JSON library in your language of choice (which you probably already do)
The preceding method is convenient and flexible, but there’s still an easier way to administer the server: the command-line tool.
The command-line tool is a Python script that you can download directly from your RabbitMQ Management plugin installation and execute on your machine.
The advantages of this script over the REST-based API is that you don’t need to hand-craft your requests.
Setting up the rabbitmqadmin admin script is dead simple: the only requirement is to have Python installed.
Assuming you do have Python installed, then what you have to do is to fetch the script out of the Management plugin and make it executable.
This will place a rabbitmqadmin script in your current folder that can be easily invoked from the terminal.
By using this you can avoid learning all the intricacies about curl.
As you can see, the output is formatted, returning some pretty tables with the information related to the exchanges that are part of the "/" vhost.
Let’s strip apart the command you just invoked: rabbitmqadmin is the name of the executable file, the Python script you just downloaded; -V "/" is the option used to specify the vhost you want to use; finally, list exchanges is the command you want to execute.
Say that for some reason you had a consumer acting awry, unable to consume and ack messages from the queue it was subscribed.
By the time you notice the problem, you have a queue filled up with messages that aren’t relevant anymore.
You could write a simple script to purge the queue using AMQP, or you can just call the following command:
Let’s go back to the example of creating new exchanges.
Let’s see how you can declare a direct exchange called cli_test authenticating with the user guest and password guest:
Another interesting command is the ability to close connection, say because of misbehaving consumers that are unable to ack messages, thus disrupting the message flow.
First you’ll get a list of connections, getting only the connection name property:
If you want to disconnect said consumer, you can do it by calling the close connection command:
Though we don’t describe every command in detail, we’ve presented the basics of using the rabbitmqadmin script and from here it’ll be easy for you to get started and perform other tasks.
When it comes to system administration, some people prefer command-line tools and others prefer GUI programs.
In this chapter, you've seen that there are plenty of choices when it comes to administering a RabbitMQ server.
The good thing is that the tools we presented in this chapter are all produced by the RabbitMQ developers, which means they’re maintained and on par with the latest features.
Depending on your taste, you’ll feel inclined to use the web UI, which is convenient for everyday development, to get a visual representation of what’s happening on the server.
The web UI will make it easier to work in teams and even your marketing people can now see how many campaign emails were delivered to customers.
If you want to automate such tasks, you can resort to the REST-based API that you can invoke via curl.
Since you’ll get the responses as JSON objects, it becomes easy to integrate with your current tools and languages.
Finally, if you want to extract some information from the server but require something simpler than manually building your HTTP requests with curl, you can resort to the rabbitmqadmin script to get nicely formatted output to help you manage and monitor your RabbitMQ installations.
In the next chapter we’ll dig deeper into the REST API, learning how to automate several administration tasks like user and vhost provisioning.
Start warming up your fingers, because we’ll get our hands dirty with some Python code.
Up to this point, you’ve been limited in your ability to configure RabbitMQ servers from apps or scripts.
Sure, you could write code that runs rabbitmqctl and then tries to “scrape” the output for results but that’s a brittle solution and is likely to break anytime the guys at Rabbit decide to change rabbitmqctl’s output.
In reality, both rabbitmqctl and the management web UI are designed for interaction with something that has a heartbeat.
It provides web-based access that allows you to manage and control a RabbitMQ server from your browser.
Via the included web UI, an administrator can do everything from creating users and vhosts to viewing queue statistics and overall configuration.
The best part is that when you install the Management plugin, you not only get the web UI, you also get a RESTful web API for free.
The API provides to your apps and scripts the same full functionality as the web UI or rabbitmqctl.
When Rabbit HQ released the Management plugin, they not only gave developers a human-friendly web UI, they also included a RESTful web management API.
The API is a simple, language-neutral, and Erlang-free way to configure and keep tabs on your Rabbit nodes running the Management plugin.
The Erlang-free part is particularly important, because though Erlang provides the foundation for RabbitMQ to be distributed, scalable, and stable, you may want to control Rabbit from systems that do not have Erlang installed.
Fortunately, the RabbitMQ management API uses HTTP to communicate, so you can talk to it from any programming or scripting language that has an HTTP client library.
It describes a convention for HTTP-based APIs that encodes the item you’re changing and the state of the action on the item in the URL.
For example, you could have a non-RESTful API that has a single URL like http://my-api.com/calls, and then put the particulars about the item and action in the body of the request.
But if you want to do any sort of data mining on the API server’s logs, all you’ll see is a list of requests for/calls.
When you use a RESTful convention for your API, you end up with a URL like http://my-api.com/item (where item is the name of the item you’re acting on) and then use standard HTTP verbs like POST, PUT, and DELETE to create, modify, or delete the item.
Now your logs are full of useful information showing exactly the item being manipulated, and the action (verb) performed on it.
Before we dive into writing programs that interact with the management API, we need to cover some ground about what the API does (and doesn’t) allow you to do.
Once that’s under your belt, you’ll be ready to start looking at how to create access credentials for your API clients, and then begin using that access to view internal RabbitMQ statistics and perform changes to the Rabbit server like adding users and virtual hosts.
Let’s get started and see what the management API has to offer!
It’s available in most Linux/UNIX distributions and can also be downloaded directly from http://curl.haxx.se/ download.html.
Wow, besides the fairly readable HTTP headers, what does that load of jumble mean? The headers give you a clue.
If you look at the Content-Type header, you see that the response is encoded as application/json.
For those not familiar with it, JSON stands for JavaScript Object Notation and is an alternative to XML for encoding data (check out http://en.wikipedia.org/wiki/JSON for a deep dive on JSON)
If you understand JavaScript, you’ve probably figured out that the API is returning all the data about the queue as a hash table.
For example, the memory element of the hash table tells you how much RAM (in bytes) the queue is currently consuming.
When working with the management API, every call will return either an empty body (for actions that create or delete items) or a JSON hash table containing the data you requested (for actions that list or show items)
Just as important as the data an API request can return is the HTTP verb you use to make the request; you used a GET request.
For the examples in this chapter we assume that RabbitMQ is running on localhost and that you haven’t modified the Management plugin’s default listening port of 55672
Granting your clients access the branches queue doesn’t exist yet, and you want to create it using the API.
By using the same URL as before but changing the verb to PUT, you can convert the request to create the queue instead of returning its details:
So you can create queues and view their statistics, but what else can you do? Here are a few other things the API will enable your scripts to do:
Since the management API (and plugin) is always being enhanced, that’s just a small list of the functions the API provides.
You can always see the most current (and complete) list of API calls and the HTTP verbs they support by loading http://localhost:55672/api in your web browser.
You may have noticed that both of the API requests you made using cURL had -u guest:guest as an argument.
For example, if you have a monitoring script that should only be able to check on queue statistics, you could create a new Rabbit user whose permissions for the virtual host were.
This would allow the script (and anyone who knew the script’s Rabbit username and password) to only monitor the queues but not publish to them or change their configuration.
So how do you create a username for API access? Simple: create a user via rabbitmqctl and set the admin property to true.
Let’s create a user called monitor that your scripts can use to monitor statistics in the default (/) virtual host (but not write or change anything)
Without setting the admin flag on the username, it won’t be allowed to access the API regardless of the permissions that are set.
The last command (set_permissions) grants the monitor user no configure or write permissions, and full read permissions within the default (/) virtual host.
With your monitor user in hand, you’re ready to write your first API script and start viewing queue statistics.
There are many times on a daily basis when you need to see how many messages are sitting in a particular queue.
Sometimes it’s to debug a new app you’re writing; other times it’s to monitor in production the ratio between messages waiting to be consumed and those that have been delivered to a consumer and are still unacknowledged (the latter can be a useful metric for discovering messages that are crashing your consumers)
You could use rabbitmqctl to list the total message count in your queues, but this has two major disadvantages:
You can only run rabbitmqctl from computers that have Erlang installed and the same Erlang cookie as the RabbitMQ server.
It won’t differentiate between delivered messages waiting for acknowledgement and messages waiting to be consumed in the first place.
Sounds like a perfect job for the Rabbit management API! You’ll use Python’s built-in httplib and json libraries to communicate with Rabbit and encode/decode the requests and responses.
Since you want to be able to run your query statistics script from the command line, you need to start by parsing the command line arguments, as in the following listing.
The utility takes five arguments besides the program name: server name/port (in host:port notation), username for API authentication, password for API authentication, name of the virtual host containing the queue, and the queue name whose statistics you want to view.
After you’ve validated B that the minimum number of required arguments is present, you assign them C to more memorable variables based on the argument’s position in the argument list.
Since you’re passing the hostname and port of the Rabbit server as a single argument delimited by : (localhost:55672), you split that argument into its individual hostname and port parts.
The separated parts are then assigned into the server and port variables.
With the arguments parsed, you’re ready to build the request.
All API queue operations are located under the /api/queues path.
You may notice that you escaped B both the virtual host name and queue name before putting them into the request’s path.
If you don’t quote the virtual host, then specifying the default virtual host (/) will raise an API error since the server considers /  a path.
Finally, you set the HTTP method to GET so that the server will know you want to retrieve details about the queue rather than create it.
With the request path and method set, you’re ready to fire off the request to the server, as the in the following listing.
The script first establishes an HTTP connection B with the API server.
At this point, the server is waiting for the API request and authorization credentials.
One of those headers is the Authorization header that contains your Base64-encoded credentials appended to the ASCII string "Basic"
The other header is Content-Type and is equally important because it lets the API server know your request body (if there is one) will be encoded as JSON.
Since your utility is only issuing GET requests, the request bodies will always be empty, but it’s good form to set the Content-Type so you don’t forget when it does matter (PUT or POST requests)
Finally, you send E the prepared request to the API server and receive the response F back.
If there isn’t an error, you’re ready to parse the response and display the queue details to the user, as in the following listing.
Since the API server always returns information as a JSON hash table, you have to first JSON-decode B the response.
This converts the JSON-encoded hash table into the actual hash table type supported by your programming language.
For Python, this means the response is converted into a Python dictionary.
The beauty of the response being JSON-encoded is that once the decoding is done, you can access the fields in resp_payload just like any other dictionary (hash table)
So what does it look like if you run the utility?
You can see from the output that the test queue in the default (/) virtual host is consuming 9104 bytes of memory, has three consumers attached to it, and contains a total of seven messages.
Not only can you tell that the queue contains seven messages, you can see that three of them have been delivered to consumers and are waiting for those consumers to acknowledge them, and the other four are waiting to be delivered to the next available consumer.
It empowers you to introspect and control your Rabbits from anywhere that has network access.
But for all this talk about controlling RabbitMQ, so far all we’ve done is read statistics.
Before the management API came along, one of the biggest hassles in deploying RabbitMQ was automating the creation of the virtual hosts and users that apps need.
Frequently, when deploying your apps with automated deployment tools like Chef or Puppet, the recipe to deploy your app is run on a server that’s different from the.
There are many more statistics in the resp_payload dictionary than just the ones we display.
Inside there’s also information on how many of the messages are persistent, how many messages are pending acknowledgement, the average ingress and egress rates of messages in the queue, and much more.
When all you have is rabbitmqctl to create users and virtual hosts, that’s a problem, because it means Erlang and rabbitmqctl must be installed on every app server for the sole purpose of creating users and vhosts on the central RabbitMQ server.
Wouldn’t it be nice if there was a way to create users and vhosts from the servers running your apps without having to put Erlang on every one (and synchronize them all to the same Erlang cookie)? Since we live in the age of the Rabbit management API, fret no more intrepid Rabbit developer! You can write a command-line script that will let you create, delete, show, and list users by using the management API (extending the script to provision vhosts will be simple)
Since we’ve already covered how to connect, authenticate, and send a basic API request, we’ll focus on what makes a request that creates or deletes users (or vhosts) different.
Let’s start by looking at the user_manager.py script in its entirety, as shown in the following listing.
As with the queue statistics script, you validate B the command-line arguments and assign them into more memorable variables.
The only difference so far is that the number of arguments has grown.
Instead of the final arguments indicating a vhost and queue name, they now represent the action to take (create, delete, list, show) and parameters for that action.
This will connect to the localhost API server using the username and password guest, and will create a new user called myuser whose password is password and who is an administrator (true)
If you change the true to false, the user won’t be created as an administrator.
The base path for all use API calls is/ api/users.
Here is where you can see clearly how the API interprets different HTTP verbs on the same request path.
But setting the method to DELETE for the same request path will cause the user to be deleted.
Similarly, GET will be interpreted by the API server as an instruction to return details about the user in a JSON hash table.
The only oddball is what you do to list all users.
Rather than issue GET on /api/ users/<username> (which would specify a specific user), you issue the GET request on/api/users.
Since that request path specifies no user in particular, the API server returns a list of all the users in the RabbitMQ server (the server returns a list of hash tables, where each hash table has the full details for a user)
After the path is built, you need to determine D whether the request being crafted is supposed to create a user.
If it is, you need to build a JSON-encoded hash table that contains the password and administrator status for the new user:
The hash table for creating a user needs two fields: password and administrator.
With the request now built, you connect and send E the request just as you did with the queue statistics script.
The only difference is that you now specify a request for the body when the action is to create a user.
Once the request has been sent and you’ve verified that the server didn’t return an error, you read F the response and get to work.
If the action was to create or delete a user I, there’s no result so you just print a confirmation that the request succeeded to the user.
If the requested action was to list or show users, then you JSON-decode the response.
After the response has been decoded, you have a native Python data structure you can work with.
If the user requested a list of users, then the response is an array of hash tables.
You may notice that we’re using Python’s string formatting capabilities.
If the action was to show a specific  user, then the response won’t be an array of hash tables.
Instead, the response will itself be a single hash table, similar to what you saw with the queue statistics script, except that this time the hash table H contains the name, password_hash, and administrator status for the user:
You now have a fully featured utility that can create, delete, show, and list users on any RabbitMQ server that has the Management plugin installed.
Let’s see what creating and then showing a user looks like with the utility:
Though you’d probably want to add more stringent argument validation to the script for production use, the fact is you could  use it as-is to manage the creation of users from any system.
In fact, the authors use a similar script for automating RabbitMQ user creation when deploying apps.
By building this script you’ve learned how to not only show a single item via the management API, but how to show lists of items and how to create and delete those items.
You can apply these concepts to working with any of the different item/resource types available via the API (users, queues, exchanges, connections, permissions, and so on)
It extends this user manager script to manage the creation of vhosts, and also enables the manipulation of user/vhost permissions.
Before we began, you were limited to managing your Rabbit servers by hand either through rabbitmqctl or the management web UI.
You were completely unable to write automated scripts or utilities that could integrate with Rabbit to help you manage its configuration or monitor its internal state.
But by learning how the Rabbit management API works, you’re now able to build tools that let you monitor queue state and manage your users according to your own needs.
With the management API at your disposal, the only limit to the Rabbit management tools you can build is your own imagination.
One of the areas that the API opens up is automated monitoring of RabbitMQ’s health.
Now that you understand how to build tools with the API, you’re ready to look at using those skills in more depth to enhance the monitoring of your Rabbit infrastructures and make sure they’re running in tip-top shape.
Your RabbitMQ server is up and running and your snazzy dog walking app is bringing in thousands of orders nationwide.
Everything seems to be going great when you suddenly get the call: customers are getting errors from your web app and the flow of orders has stopped completely.
The RabbitMQ server has died, and to make matters worse it appears that it’s been down for hours.
If only you’d been proactively notified the instant RabbitMQ went offline instead of having to wait for your customers to tell you and losing thousands of dollars in orders in the process.
Setting up Rabbit to be highly available and writing your apps to use it are only two legs of the stool.
If you’re going to run a truly Monitoring: Houston, we have a problem.
Properly monitored, you can find out not only when things have gone horribly wrong (like the Rabbit server dying), but also when your messaging infrastructure is suffering—well before it takes down your customers and your bottom line.
You’ll then be able to take these monitoring programs and plug them into the monitoring and alerting framework of your choice so you can be alerted when things have gone off course with your messaging.
Let’s get started by learning how to monitor RabbitMQ internals both over AMQP and with the REST API.
Monitoring RabbitMQ isn’t just about making sure that port 5672 is open and accepting TCP connections.
With a complicated system like Rabbit it’s better if you can simulate an AMQP client to make sure that you can actually acquire a channel after you connect.
It would also be great if you could use the REST API to find out if all of the different Erlang components that make up Rabbit are running and talking correctly to each other.
To do any of this, you first have to understand how write a health check that your monitoring system can understand.
In this case, that system is going to be Nagios, so let’s look at what Nagios is and what a health check has to do to talk to it.
Many different commercial and open source monitoring frameworks are available today.
It’s freely available from http:// nagios.org and has a flexible API that makes it easy to write your own health check programs in any language you choose.
In addition, many of the other open source monitoring frameworks (like Zenoss and Zabbix) also support the Nagios health check API, making it possible for your Rabbit health checks to be used with many other monitoring systems besides Nagios.
So what’s a Nagios health check and how does it work?
A Nagios health check is a standalone program that monitors a service when it’s run and indicates the healthiness of the service (or lack thereof) by its exit code when the program terminates.
You technically don’t even need Nagios to run a health check—you can execute it anytime from the command line and manually observe the output.
A Nagios health check can be written as anything from a Python program to a BASH script as long as it prints the human-readable status of the thing it’s monitoring to STDOUT and returns one of the following four integer exit codes:
OK—The service being checked is functioning normally and is completely within any thresholds given to the health check via command-line arguments.
CRITICAL—The service is down, unresponsive, and/or has crossed the critical threshold for the metric being monitored.
Using the RAM usage example, the health check would return a CRITICAL exit code when RAM usage is over 4 GB.
For example, if the health check were monitoring the number of messages in a queue and it couldn’t connect to the server, instead of returning a critical status it could return unknown as the status.
Returning the status as unknown only makes sense when you’re unable to sample the current state of the metric.
If the metric you’re monitoring is connectivity and you can’t connect, then definitely return critical instead of unknown.
Now that you understand what Nagios expects from a health check program, let’s build one in the following listing.
Though you can use any language to write your health checks, for these examples you’ll use Python again and the Pika AMQP library you installed in chapter 4
Your first health check is going to be simple—it’s not going to check anything.
It’s going to take warning, critical, unknown, or ok as an argument and exit with that Nagios status code.
Though Nagios doesn’t understand what that message means, it does understand that 2 as your exit code indicates that the health check is in critical status.
All of our health checks will build on this example to add logic that actually checks a live service, and also to take commandline arguments so that you can tell the health check what service to monitor and what constitutes a critical or warning threshold.
Before we jump into making a health check that can see whether RabbitMQ is alive and capable of building channels, we need to talk about Nagios itself.
Though you’ll be building health checks that can be used by Nagios, we won’t cover configuring Nagios to use them.
This will let us focus on how to monitor different aspects of Rabbit.
If you want to learn more about Nagios and how to install it, a great place to start is the documentation site: http://www.nagios.org/documentation.
Without writing a line of code, you could use the TCP health check that comes with most monitoring systems to do a simple TCP connect to check whether Rabbit is responding on port 5762
This would tell you that the RabbitMQ daemon is running, but it wouldn’t tell you whether the daemon is functioning.
For example, what if RabbitMQ is running out of memory? It’s possible that the daemon could be functional enough to complete the TCP handshake but has insufficient memory to actually respond to AMQP commands.
What you need to truly determine whether Rabbit is capable of servicing requests is to actually issue AMQP commands.
It’ll return a critical status if any of the following conditions are true:
Only if none of those conditions are true will the program return an OK status from the health check.
The health check code itself looks like a simplified version of your initial Hello World consumer.
After creating a few constants to refer to the status codes B that Nagios will expect the health check to return, you get right to parsing the command-line arguments passed to the check C.
Since this health check is simply verifying that the RabbitMQ server is able to respond to AMQP commands, it only needs to be passed four arguments when it’s invoked: the server name and port for the RabbitMQ server, the virtual host (vhost) on which to build the channel, and the username and password that permit access to the vhost.
To simplify the number of arguments you have to pass to the check, combine the hostname and port into a single argument delimited by a colon.
What’s different from the earlier examples is that if an exception is thrown for any reason when you try to connect, you exit immediately with a critical exit code E (and print that you couldn’t connect)
In previous examples, when an error occurred, you’d catch the error and immediately try to reconnect to keep your consumer running.
In this case, since a bad connection is exactly what you’re trying to tell Nagios about, you don’t want to cleanly hide the error.
Rather, by catching the generic Exception error class, all exceptions will match your error handling code and return a critical status (exit code 2) to Nagios for any issue related to connecting to the Rabbit server (including timeout errors)
What’s important to notice in this simple health check is that Nagios has no intimate knowledge of RabbitMQ at any point in the process.
With your shiny new health check in hand, let’s give it a test drive and see what happens with a healthy RabbitMQ server:
Terrific, the RabbitMQ server running on your local development machine is running and able to process AMQP commands.
As desired, your new AMQP-based health check for Rabbit successfully detects a failed Rabbit and returns an error code of 2 to indicate a critical failure to the monitoring framework.
With your new health check in hand, you can easily configure your monitoring framework of choice to start monitoring your Rabbit server and notify you when it’s unable to service connections.
But what if you want your health check not to stop at simply building a channel, but rather want to fully test that you can publish a message and consume it? You could extend your AMQP health check with this additional functionality, but if you have the Rabbit management API installed, you have an even better option at your disposal.
Let’s look at how you can build a health check that uses the REST API to do a full produce/consume test for you and lets your health check know the result.
Testing that RabbitMQ is accepting new connections and able to build an AMQP channel is a good way to test that a Rabbit server is healthy.
But as we’ve all learned the hard way, if you don’t test every part of a process you rely on, you can get bitten when the part you don’t test fails.
With that in mind, let’s take the monitoring a step further and test the process of publishing a message into RabbitMQ and then consuming that message to verify it was routed correctly.
One of the features of the REST API that ships with the Rabbit management plugin is an API call that tests the health of the Rabbit server internally.
The aliveness-test, as it’s called, performs three steps to verify the health of a Rabbit server:
Since this check runs internally inside the Erlang virtual machine (alongside RabbitMQ) it’s not affected by network issues that might prevent you from connecting to Rabbit’s port (5672) externally.
Though this means that using the API to health check Rabbit lets you focus on internal message routing issues that may be occurring, it also means that the check won’t tell you whether a firewall rule is preventing outside consumers (like your dog walking app) from connecting to Rabbit at all.
So in reality, it’s advisable to use the AMQP health check you built in the previous section in conjunction with an API-based health check to ensure you have complete monitoring coverage of your Rabbit server.
It’s also important to note that the aliveness-test API call uses an intelligent implementation of its check process, which doesn’t delete the queue it creates.
This means you won’t fill the Mnesia database with thousands of queue metadata transactions if your health check runs repeatedly in short intervals.
As with the AMQP health check, the first things you do are set up constants B for the exit codes and parse C the command-line arguments.
This health check takes exactly the same arguments as the AMQP health check, with the change that the server and port are for the API server (instead of the RabbitMQ server itself)
Where you start to diverge from the AMQP health check is that you’re building an HTTP connection D to the API server rather than an AMQP connection.
Once you’ve built the HTTP connection to the API server, you then create the request path for the aliveness-test call E.
At the end of the path, you append the vhost to be used for creating the test queue.
Since it’s possible to have a vhost named / (the HTTP path separator), you also need to escape any special characters in the vhost name using urllib.quote before appending it to the path.
The safe="" argument tells urllib.quote that it should escape all special characters without exception (by default urllib.quote won’t escape / characters)
Also, you set the request method to GET since you’re retrieving information via the API rather than modifying or creating it.
You could return a warning or unknown status instead, since technically you only know that the API server is down as opposed to the RabbitMQ server itself.
But since the API runs as a plugin to RabbitMQ, it’s unlikely that the API server would be down if the RabbitMQ server wasn’t down as well.
Providing you’re able to connect to the API server and transmit your request, you’ll receive a response object back.
The response object stores the HTTP status code in response.status, and the body text of the response as a file descriptor you can access using response.read()
All that you care about is the HTTP status code.
If the aliveness-test call is successful, it’ll return a 200-level HTTP status code.
Any other code above 299 is either an error or additional instructions to the client.
Chapter 9 on the REST API has more information on how to craft the HTTP Basic authentication header.
So what happens if you run your API ping health check against your local development machine?
The health check correctly determines that the RabbitMQ server is alive and able to produce and consume messages.
But what happens if you simulate a node failure and rerun the health check?
Nagios is only looking for the exit code (2) to determine that the health check failed, but it’ll send you everything from CRITICAL:...
What the aliveness-test call is returning to you in the body, and which your health check is outputting verbatim, is the internal Erlang crash report that was generated because the API couldn’t talk to RabbitMQ.
So if someone were to stop the RabbitMQ node, not only would your monitoring system be able to alert you thanks to your new health check, but it would also give you the detailed Erlang crash report that you can use to track down why Rabbit is having issues.
You now have the ability to monitor not only that RabbitMQ is able to accept connections, but also that it’s able to successfully route messages.
RabbitMQ server’s health? Easy: just write a health check that can monitor a queue (or exchange) configuration.
Verifying that RabbitMQ is running and healthy is only part of ensuring the reliability of your messaging infrastructure.
You also need to make sure that your messaging fabric isn’t accidentally changed into a configuration that would cause message loss for your apps.
For example, imagine that your hard-working fellow developer Rolf is deploying the latest version of your dog walking app.
Since you wisely wrote the app to configure the queues, exchange, and bindings it will need, you don’t have to worry that the app will crash if the RabbitMQ server is missing parts of that fabric when the app starts (the app will just create what’s missing)
But this autoconfiguration of the fabric by the app is going to cause problems this morning because Rolf had a late night of quashing the final bugs in Dog Walker 10.0 and made a typo.
Accidentally, Rolf erased the code that creates the walking_orders queue upon app startup.
Realizing his problem, he retyped the queue declaration back into the app’s code before he committed the code to the production repository.
The issue is that when Rolf retyped the queue declaration, he forgot to make the queue durable.
This is a big problem, because if a power failure hits the RabbitMQ server in production, all the dog walking orders in the queue will vaporize when the power is cut.
But since the queue exists and is named correctly, you wouldn’t notice any problems until a power outage occurs, at which point it’s too late.
Since we’re all Rolf from time to time, you need to create a health check that can monitor the configuration of a queue so that you’re notified proactively if it changes.
Before the creation of the Rabbit Management plugin and API, it was difficult to monitor queue (or exchange) configuration.
About the only way you could verify a queue’s configuration was to attempt to redeclare the queue with the desired parameters, and trust that RabbitMQ would reject the redeclaration if the configuration was different from the queue that already existed.
The biggest issue with this approach is that it can actively change.
RabbitMQ monitoring: keeping an eye on your warren the messaging fabric since you’re declaring a queue to see if a failure occurs.
In other words, if the health check has a bug it could trigger the very condition (a queue adversely changing configuration) it’s trying to detect.
Fortunately, with the existence of the RabbitMQ API, you now have a better way.
Not only can you view the configuration, you can also view statistics about the queue like how much memory it’s consuming or the queue’s average messaging throughput.
Even though you’ve trimmed out some of the statistics for brevity (the ...
For your current needs, you’re interested in the queue configuration elements at the bottom of the JSON output D.
Armed with this kind of information, your new health check could easily monitor the durable and auto_delete parameters from the API call’s output to alert you when either changes.
Like the previous health checks you’ve written, you’ll use command-line arguments to let the check know which API server to check.
In addition to the usual server, port, vhost, username, and password details, you also need to know.
Since the API call is going to return the value of durable and auto_delete as JSONencoded Booleans, you’re going to expect true or false on the command line in JSON format:
This will let you JSON-decode the arguments and compare them to the values of their respective parameters from the call output.
Your code to generate the HTTP request for the API call is also remarkably similar to the API ping health check.
The only change is to the request path itself to point to the queue inspection call:
You may have noticed one other change from the HTTP connection code in the API ping health check you built: your new health check returns EXIT_UNKNOWN if it can’t connect to the API server.
With the API ping health check you were verifying the availability of the RabbitMQ server itself, so the API server not being available meant the health check had failed and should return EXIT_CRITICAL.
But the mission of this new health check is not to monitor the availability of the Rabbit server but to keep an.
As a result, if you can’t connect to the API server, you should return EXIT_UNKNOWN since your health check can’t determine the configuration of the queue one way or the other.
Whether you receive an alert from your monitoring system when this new check enters into the state unknown is up to how you configured the monitoring system (Nagios) to treat UNKNOWN.
By returning UNKNOWN instead of CRITICAL, you’re providing a more accurate response and giving the administrator of the monitoring system the flexibility to configure the system to handle UNKNOWN the way they think is best.
Where this check truly diverges from the checks you’ve written so far is in the way it handles the HTTP response from the API call, as shown in the following listing.
The API ping health check either succeeded or failed and there was no differentiation between the failure codes.
But the queue inspection API call gives you more information through the HTTP status code when it fails.
If the HTTP status code is 404, you know that the queue this check is trying to validate doesn’t exist B.
EXIT_UNKNOWN as the health check exit code is appropriate because as with the last use of the unknown status, an error you’re not expecting prevents the check from determining the queue configuration one way or the other.
In the remainder of the new health check, you JSON-decode D the HTTP response and compare the auto_delete E and durable F parameters against the values provided to the health check via its command-line arguments.
Now you may wonder why you’re setting the health check’s status to warning instead of critical if the configuration parameters you’re verifying aren’t correct.
If you care more about the queue existing and less about its actual configuration, a warning status for durable or auto_delete not matching is fine.
But if it would be fatal for the queue not to be durable when a power failure occurs (as with the dog walking order queue) you definitely want to use the exit code EXIT_CRITICAL instead.
If everything about the queue’s configuration is correct, you exit normally G.
With this health check you can easily set up multiple instances in the monitoring system to monitor the configuration of all the queues that are vital to your apps.
As with most of your adventures in the book so far, you’ve been focusing on monitoring the aspects of a Rabbit server that apply equally whether you’re running a standalone server or a cluster.
But if you’re running a cluster it’s equally important to know when individual nodes have disappeared or their internal statistics are above desirable levels.
So let’s look at what it takes to make a check that can monitor the health of a RabbitMQ cluster as a whole.
But imagine for a moment that you’re loading a replacement server for a node that went down due to a hard drive crash.
This new server is an identical replacement all the way down to the IP address and Erlang node name of the dead system.
Once you’re done loading RabbitMQ onto the fresh server, you then get an alert from your monitoring system.
It tells you that the AMQP ping health check for that node is now reporting RabbitMQ to be up and running again.
RabbitMQ monitoring: keeping an eye on your warren health check is reporting everything is A-OK on the replacement node.
When you’re depending on a RabbitMQ cluster to power your apps, it’s not enough to make sure all the nodes are simply running and accepting AMQP commands.
You need to ensure they’re acting together as a single unit, and that each one is joined to the cluster.
There’s also another reason for creating a special health check for monitoring your RabbitMQ clusters: you need to be alerted proactively when a cluster node is running up against its maximum memory limit.
There are a number of reasons why RabbitMQ can use too much memory and run into the maximum memory cap set in the Rabbit configuration file.
Your app has a bug that consumes a message but forgets to send an acknowledgement back to RabbitMQ.
This can result in thousands or millions of messages building up and exhausting Rabbit’s RAM in a high-volume environment.
You’ve written an app that’s using RabbitMQ to route large data (like images) to processing nodes.
There’s a shiny new feature you’re using in the latest version of RabbitMQ, but it has a bug that causes a slow memory leak.
No matter what the reason, once RabbitMQ has run out of RAM, bad things often start to happen—like RabbitMQ becoming completely unresponsive or crashing.
Yes, RabbitMQ will try to use disk for storing messages when it experiences memory exhaustion, but if you’re running in an environment with any significant message volume your disks won’t be able to keep up.
When memory exhaustion happens to a node that’s part of a cluster, you can start to see strange and intermittent behavior that may not make sense.
For example, your AMQP channel may appear to hang when a message is published to a fanout exchange on node A, but node A appears to be fine.
In reality, the channel is locking up not because of anything wrong with node A, but because node A has a binding that delivers the message to a queue on node B, which is out of RAM.
Since node A can’t get node B to deliver the message, the channel to node A appears to hang while you wait for the publish to timeout.
It would be much better to have a health check that could monitor the cluster and let you know that one of the nodes is almost out of RAM so you can correct the problem before the node becomes unresponsive.
Fortunately, you don’t need separate health checks to monitor cluster membership and the RAM usage of the members.
That’s because the smart guys at Rabbit HQ gave you a single API call that tells you everything you could want to know about a cluster and its members: /api/nodes.
If you use curl to query /api/nodes manually, you’ll get a JSON array with a dictionary for each node in the cluster:
The dictionary for each node contains statistics and configuration elements for that node.
If you were using a standalone Rabbit server you could also query /api/nodes for information about that server, with the only difference being you’d get a single node dictionary instead of multiple dictionaries for the nodes in a cluster.
With this basic knowledge of what to expect in the /api/nodes response, you’re ready to start building your cluster health check.
Since the health check you’re basing on /api/nodes is going to monitor both node membership and memory usage, your check first needs to know which cluster members it should expect and what memory levels you consider warranting a warning or critical status.
To acquire these settings you’ll add three new arguments (node list, RAM usage warning threshold, RAM usage critical threshold) to the server, port, and credentials arguments you normally expect:
This will let users pass the node list as a single argument rather than multiple arguments that are more difficult to parse.
With the check’s configuration settings acquired, you’re ready to make the connection to the API server in the following listing and post your request to /api/nodes.
As with the previous API-based health checks, you connect to the API server over HTTP B and send credentials via a Base64-encoded header D.
The only difference is that for this health check you’re posting to the /api/nodes endpoint C.
With the request sent, you’re ready to start processing the API server’s response in the next listing.
Since you need to check both the node membership for missing members as well as the RAM usage of each of the nodes, you’ll make two passes over the array of node dictionaries containing the statistics and configurations.
After decoding the JSON array of node dictionaries to their native Python equivalents B, you try to match the node name element in each dictionary C to the list of expected member nodes that were passed on the command line.
As you iterate through the node dictionaries, if the name element in that dictionary matches an expected node name (and that node is notated as running), you remove that name from the list of expected nodes.
The result is that if all of the expected member nodes are present, your list of expected nodes will be empty when you’re done iterating.
On the other hand, if your list of expected node names has any entries still in it, you know that those nodes weren’t present or weren’t running according to /api/nodes.
If your check determines that nodes are missing from the cluster, then you set the exit code to EXIT_WARNING and exit without any further analysis.
The reason you set the status to warning is because a missing cluster node degrades the performance of the cluster but doesn’t necessarily prevent the cluster from doing its work.
If you feel a missing cluster node is more serious, set the exit code to EXIT_CRITICAL instead.
Once you’ve verified that all of the expected nodes are present in the cluster, you then iterate through each node dictionary again to evaluate how much RAM each node is using D.
Finally, if all of the expected cluster members are present and none of them exceed the warning or critical RAM usage thresholds, you exit with the EXIT_OK status code E and output that all of the nodes’ RAM usage is below the warning threshold number.
Let’s give your health check a quick run and see what happens:
But let’s see how your check handles one of the cluster nodes disappearing:
So far, so good; your health check not only detects that an expected cluster mode is missing from the cluster, it correctly tells you which node is missing.
Finally, you need to make sure your check correctly detects nodes crossing both the warning and critical RAM thresholds that you set:
You now have a complete set of Rabbit-facing health checks that can let you know not only if your RabbitMQ servers individually become unavailable, but can also warn you if your Rabbit clusters are missing members or if any of those members are nearing RAM exhaustion.
But what if the issue isn’t the health of Rabbit, but whether your apps are properly consuming the messages they’re supposed to? Your cluster health check can let you know about RAM exhaustion, but if the problem is that your dog walking app isn’t properly consuming orders out of an order queue, wouldn’t it be nice to know that before RAM exhaustion becomes an issue? If your message volume (or size) is low, monitoring how many messages are in a particular queue can be even more important because the message build-up may go completely unnoticed until a customer complains that their order hasn’t been processed.
With that in mind it’s time to look at how to build health checks that can let you know when your consumers stop consuming.
Up to this point, we’ve primarily been concerned with making sure your RabbitMQ servers are running, able to route messages, and clustered properly.
But we haven’t talked about one of the few downsides to using messaging: it becomes harder to monitor your consumers.
A key part of the site is the daemon that runs continuously behind the scenes to process orders recorded by the user-facing web app.
If you didn’t have messaging, it’s likely you’d design the order processing daemon as a server app that communicates over HTTP.
After collecting order information from a customer, your web app would connect to the server port the order processing app is listening on and, once connected, would transmit the order.
As we’ve discussed before, the major disadvantage to this approach is that the web app can’t get back to taking another order until the order processing app confirms custody of the order, usually after processing it.
The decoupling of frontend web app from backend order processor is a huge benefit of using messaging, but the question becomes how you monitor that the order processor is functioning.
When it comes to monitoring them, server-type apps that accept TCP connections are straightforward to monitor.
Once you convert that app to use messaging, you can no longer just connect to the server app’s listener port to make sure it’s up and able to process traffic.
Fear not! You can still monitor your order processing app that uses messaging; you just have to think differently about what to monitor.
You may remember earlier in the book we encouraged writing consumers so that they don’t acknowledge messages they’ve received until they’ve successfully finished processing them.
One of the reasons we encouraged this approach (besides ensuring your messages don’t get black-holed), is that if your consumer is continually crashing when processing messages, those messages will build up in the queues and a health check can then trigger an alert.
So as you may have guessed by now, the way you’ll monitor whether your consumers are functioning properly is by monitoring the message count in a queue and triggering an alert when that count crosses the warning or critical threshold you set.
As with the ping health checks you wrote earlier, there are two ways you can monitor queue message counts:
When you declare a queue in AMQP, the result from the command contains the queue message count if the passive argument is set to True.
Leverage our old friend the Rabbit management API to pull the statistics on the queue, among which is the current queue message count.
After you’ve learned how to build each version of the queue count check (and the benefits of each approach), we’ll look at how you can analyze your messaging traffic to figure out what the warning and critical thresholds should be for each of the queues your apps use.
Without further ado, let’s dive into using AMQP to monitor the message counts in your queues.
Using AMQP to monitor message counts will only show you the aggregate number of messages in the queue with no differentiation between unconsumed and unacknowledged messages.
But if you’re using an older version of RabbitMQ that doesn’t work with the Management plugin, or if for technical/security reasons you can’t install the Management plugin, then using AMQP to monitor message counts is your only option.
Given the choice between not monitoring your queues or using an AMQP-based check to do so, it’s not much of a choice if the reliability of your applications matters.
In common with the AMQP-based ping health check you’ve already written, your AMQP queue count check will expect server, port, vhost, and credential arguments on the command line.
Your new health check will also build its connection to Rabbit identically to the AMQP ping check.
Contained within the response object is the current message count for the monitored queue.
The passive argument tells RabbitMQ you don’t want to actually declare the queue; you want to know whether it exists.
With passive set to True, queue_declare will raise an exception if the queue doesn’t exist, and will return the current message count in the queue if it does.
It’s crucial to make sure the passive argument is included not only because it’s the only way to return the queue message count, but also because without it the check will actually try to declare the queue.
Once the passive queue_declare operation completes, you’re left with the response object, inside of which the message count is buried.
The message_count attribute is an integer so it’s simple to compare against the check’s message count thresholds.
Other than the code to set up the AMQP connection to Rabbit, this health check is simple.
With the queue created, next you’ll click on the Exchanges tab in the management web UI and then click on (AMQP default) in the resulting listing.
Using the Publish Message controls on the (AMQP default) page in the management web UI, publish a message with the payload Any payload will do.
You should now have two messages waiting in my_queue, so let’s run your health check to find out if it sees them:
You told the health check to consider four or more messages a critical status and three or more a warning.
As a result, the check returned an OK status and told you correctly that there are two messages in my_queue.
Let’s change the critical and warning thresholds to three and two messages respectively, and run the check again:
As it should, your health check now returns a warning because two messages is the new warning threshold for the queue message count, but you haven’t exceeded the threemessage critical threshold.
If you reduce the critical and warning thresholds again, but to two and one messages this time, the check should now return a critical status:
In less than 50 lines of code, you now have a way to monitor the message count in any queue and know proactively when to check your consumers because their queue message count has grown to dangerous levels.
Sometimes, the message count has built too high not because your consumers are crashing, but rather the high queue count might be due to a bug where the consumers don’t acknowledge messages they’ve successfully processed.
Wouldn’t it be helpful to know whether the high message count is due to unconsumed (crashing consumers) or simply unacknowledged (buggy consumers) messages? Though your AMQP-based check can’t give you that information, the Rabbit API definitely can.
Let’s see how you can create a better queue count check that can answer those questions through using the Rabbit Management API.
Among those was the number of messages currently in the queue:
Making sure consumers are consuming example, let’s say your dog walking order app gets temporary spikes of orders every day after your ad comes on during The Dog Whisperer.
During the period of time after the ad, your order queues show a 10x increase in message counts.
With the AMQP health check this would definitely exceed your critical threshold and would trigger a false positive alert every day.
By creating a new message count health check using the API, you could set a much higher critical threshold for unconsumed messages while still maintaining a low threshold for unacknowledged messages.
This would let you eliminate false alarms on unconsumed message counts, while still being notified quickly of bugs in your consumers that manifest as elevated unacknowledged message counts.
As with every health check so far, first you need to acquire the RabbitMQ connection and authentication information from the command line.
But in addition you also need to acquire the name of the queue to monitor as well as the critical and warning thresholds for both unconsumed (ready) and unacknowledged message counts:
With the settings for the health check in hand, you’re ready to connect to the API server.
At last, with the unconsumed (ready) and unacknowledged message counts extracted, you’re able to compare them against the supplied thresholds in the following listing.
The first thing to check is whether the unacknowledged message count has exceeded critical or warning levels B.
Providing that none of the unacknowledged message count thresholds have been exceeded, you next analyze the unconsumed (ready) message counts C.
Finally, if neither the unconsumed nor unacknowledged message counts are above their critical or warning thresholds, you set the status exit code to EXIT_OK to let Nagios know everything is healthy D and then output the total (unconsumed + unacknowledged) number of messages in the queue along with the amount of RAM the queue is currently consuming.
Though it’s complicated to test the unacknowledged message thresholds, you should be able to use the messages still sitting in my_queue from testing the AMQPbased message count check to verify your new API-based version of the check.
If you set the unconsumed critical/warning thresholds to two and one messages respectively, your API message count check should correctly detect an excessive number of unconsumed (ready) messages:
If you raise the critical/warning unconsumed thresholds to four and three messages respectively, your check should now consider the unconsumed message count in the queue healthy again:
As it should, the check reports that you have a total of two messages in the queue, and that the queue is consuming 9800 bytes of memory (the exact memory usage will vary)
You now have a health check that can differentiate between an excessive number of unacknowledged versus unconsumed messages in your queues.
That will help you more quickly determine whether your queue counts are indicating an increased load or simply defects in your apps.
The question remains: how do you determine baseline message counts for your queues so that you can set the critical and warning thresholds on your health checks?
There are a number of approaches for determining what should be considered critical and warning thresholds for queue message counts.
If you’re converting an existing application to use messaging, the logs for that application can provide a reasonably accurate source of information.
For example, if your application processes credit card orders, it’s highly likely you already log each order with a timestamp to a database.
It’s generally a good rule of thumb to use those logs to see how many orders you process in a 10-second interval.
This number should generally be your warning threshold because the health check is taking a snapshot of the queue message counts when it runs, and that snapshot generally represents a 1-second or shorter period of time.
It should be unusual for the number of messages in the queue at any given time to exceed the number of messages/orders processed over 10 seconds.
Similarly, set the critical threshold at the number of orders/messages processed in 20 seconds.
Keep in mind that this approach is approximate and you need to monitor the actual queue levels to make sure these thresholds are correct for your environment.
The best way to determine the warning and critical message count thresholds for your environment is to monitor the queues with a graphing monitoring system like Cacti or Graphite.
By modifying the message count checks to work with these systems, they can graph the actual message counts in your queues by sampling the counts at regular intervals.
The resulting graphs will tell you almost exactly what your actual average unconsumed and unacknowledged message counts are.
But 100% or more above normal definitely is worth looking into as a sign that something has gone awry.
When we started you may have had a robust RabbitMQ architecture built, but you had no way to monitor it to ensure it was truly reliable.
Now you’ve built health check programs that can not only query a RabbitMQ server to make sure it’s able to process AMQP commands, but which can also monitor actual message count levels to determine the health of the programs that are consuming from your queues.
In addition, you can also keep an eye on the configuration of your queues to make sure human error doesn’t change your queues from durable to nondurable and set you up for disaster during the next server failure.
Monitoring RabbitMQ is a vital part of ensuring it’s running properly and is efficiently powering your applications.
But once you start monitoring RabbitMQ, those health checks can open your eyes to inefficiencies and issues that can be corrected by tuning Rabbit.
With that in mind it’s time you took a look at ways to analyze RabbitMQ’s performance and behavior so you can maximize both in your applications.
In previous chapters you’ve seen how to design your architectures around messaging.
You’ve seen many ways for implementing several messaging patterns using the various AMQP building blocks like exchanges, queues, and bindings.
Depending on the problem at hand, you chose a particular combination of those items to bring about a solution.
If you needed to distribute logs across many machines, you followed a pub-sub pattern using topic or fanout exchanges; if you needed point-topoint communication, then you use direct exchanges, and so on.
In this chapter we’ll review the performance characteristics of these design decisions.
You’ll see the advantages and disadvantages of using direct exchanges over topic exchanges; the minimum memory footprint an exchange, queue, or binding has; what happens when you have hundreds of bindings to a topic exchange in contrast with a fanout exchange, and more.
Also you may have questions like, when is a message Supercharging and securing your Rabbit.
We’ll do so by analyzing the path that a message takes while traveling from the producer to the consumer, depending on the several AMQP options.
After we’ve talked about performance, you’ll see how to secure your RabbitMQ installation and more specifically how to use SSL to establish trusted communications with the broker.
We’ll cover the configuration aspects to enable SSL listeners in RabbitMQ, how to generate the SSL certificates, and how to connect to the broker using SSL.
Let’s move to the first section where you’ll see what affects the speed of messaging delivery from an AMQP point of view.
Several factors can modify the speed at which RabbitMQ delivers messages, depending on the hardware and software configuration.
On the hardware side, you have factors like network configuration, disk arrangement, number of cores, and so on.
On the software level, you can configure several AMQP parameters like message durability, routing algorithm, number of bindings, and message acknowledgment strategy.
Since the first totally depend on your setup, we won’t cover them in this chapter.
We’ll focus on the AMQP specifics and on what RabbitMQ does about them.
Let’s start by reviewing how message durability and message acknowledgment affect the speed of message delivery.
When discussing software performance, everything has to be taken with a grain of salt or even two.
Why? Because whatever decision you make has to take into account the context in which it’s applied.
For every decision you make there are pros and cons.
For example, you can speed up message delivery for system logs which you might not even need to persist to disk, but when it comes to order processing for shopping carts you’d better make sure nothing is lost in the process.
So although you could send logs as nonpersistent messages and consume them without acknowledgment, you can’t afford such luxury when customer money is in play.
So whenever you deal with these kinds of performance tweaks, you have to think of the trade-offs you’re making.
When you publish messages, you have to decide whether it’s okay to lose any of them.
If it’s okay that a couple of messages out of thousands can be lost (for whatever reason), then you may publish them with the property delivery-mode set to 1, which means nonpersistent.
Usually you’d deliver messages as persistent by setting the delivery-mode to 2, but at the cost of forcing the broker to write them to disk.
For example, on a Mac, RabbitMQ can easily deliver up to 12,000 messages per second.
If you turn on message persistence, then that number drops to around 4,000 message deliveries per second.
The number of messages is still high but has dropped considerably.
How do you manage this setting? You have to specify it as part of the message properties for every message that you publish to the server.
Another setting that will affect messaging speed is message acknowledgment.
In the previous section we looked at the settings that involve message publication; now it’s time to see how you can configure during message consumption.
One setting that will speed up message delivery is the no-ack flag that you can specify during queue subscription time.
If set to true, the server will automatically dequeue the message after it’s sent to the client.
If for some reason the connection is lost or your client application dies, the message will be lost forever.
The speed advantage of subscribing to a queue with no-ack set to true comes from the fact that you don’t need to send an acknowledgment back to the server after you process the message, which will speed up your consumers.
On the server side, things will be simplified since RabbitMQ can forget about your message after it’s delivered.
Here’s a Python snippet showing how to consume from a queue with no-ack set to true:
You’ll consume from the critical queue using critical as the consumer tag as well.
For every message that you receive, the callback critical_notify will be called.
Now it’s time to see what happens during message routing.
In the next section we’ll look at each of the main routing algorithms used by RabbitMQ.
In this book we’ve discussed three kinds of exchanges: direct, fanout, and topic.
You know that each exchange type implies a particular routing algorithm that’s implemented by the server.
When the exchange is required to route a message, it’ll select the queues where the message should go based on the message routing key and the bindings it holds to queues.
The selection process will vary according to the exchange type, since each exchange type will treat the message routing key differently.
On the server side, exchanges and bindings are record entries in Mnesia, which means that when RabbitMQ is matching the message routing key, what it’s doing is trying to find a binding that corresponds to that routing key.
Mnesia is a highly performant database whose storage is based on Erlang’s ETS and DETS tables.1 ETS stands for Erlang term storage and is an in-memory storage for data, whereas DETS is the disk-based counterpart.
The advantage of using Mnesia over plain ETS function calls is that Mnesia can coordinate access to the tables in a cluster.
So, for example, when you create an exchange on a clustered node, Mnesia will take care of replicating the information to all the other nodes in the cluster; the same can be done while adding.
Although Mnesia works great for maintaining consistency, the extra layer on top of ETS can slow things down when you need to perform certain kind of queries like performing a routing key match.
That part of the process has been optimized for the direct and fanout exchanges so you don’t have to suffer Mnesia coordination penalties.
According to the documentation for ETS tables, access time for such tables is logarithmic in relation to the number of entries in the database.
Also due to the nature of the ordered_set table type, the RabbitMQ developers were able to perform some interesting optimizations when selecting data from the table that allowed them to bypass Mnesia for these kinds of queries.
This means that RabbitMQ routing tables have the consistency guarantees offered by Mnesia while keeping the data retrieval speed offered by plain ETS tables.
The difference between the direct exchange versus the fanout exchange is that the latter ignores the routing key when it comes to querying to the rabbit_route table.
So although you can provide a routing key during queue binding to a fanout exchange, keep in mind that the routing key will be ignored when routing messages.
The same thing happens when publishing messages with routing keys to fanout exchanges: the routing key is ignored.
The case of the topic exchange is completely different because the stored routing information is more complex.
Matching a message routing key goes beyond simple string comparison, since the routing key can contain several words separated by dots (.)
For that reason, RabbitMQ implements a trie data structure where the binding keys patterns are stored in a format that allows for fast querying.
Keep in mind that, usually, bindings on topic exchanges use more memory than in direct or fanout exchanges.
Finding the message destination is one thing; delivering the messages is another.
Let’s see what happens after the exchange processes the message routing information.
After the exchange has found where the message should be routed, it’ll return a list of destinations to the rabbit_router and later proceed to deliver copies of the messages to each of the destinations (queues or exchanges)
If you published your message with the mandatory and immediate flags set to false then this process can be done asynchronously, and the server will be faster from the client point of view.
Here is where things start to get tricky, so we represented this process in figure 11.1
If the queue where the message is being delivered is empty and a consumer is ready to receive a message, then the message goes straight to the consumer without even touching the queue.
As you can guess, this greatly improves message delivery speeds.
The next question to ask is whether the consumer is in auto-ack mode.
If the consumer is subscribed using the no-ack flag set to true, then the message is forgotten by the server.
The next question is whether the message is being routed to a durable queue and whether the message was published as persistent.
If so, the message is written to disk but marked as already delivered so while the message is sitting in the queue, it won’t be sent to another consumer.
Now let’s go back in time to the point when RabbitMQ checks whether the queue is empty.
If the queue isn’t empty, then the message is queued.
If the message isn’t persistent, then it’s kept in memory only if there’s enough memory to hold the message.
If there’s not enough memory, then the message will be written to disk to the transient store.
In the case of persistent messages, they’ll be written to disk and at the same time be kept in memory to speed up message delivery.
If memory pressure occurs, then messages will get flushed to disk.
By doing that, the server ensures message properties such as persistence while still delivering the messages as quickly as it can.
As you can see in figure 11.1, if the message is routed to a durable queue, then if it’s written to disk, it’ll go to the durable store; otherwise it’ll go to the transient store.
If RabbitMQ has to restart and recover durable queues, it only needs to go through the contents of the durable store, and can wipe out the transient store without worrying.
Something to keep in mind is that RabbitMQ is optimized to deliver messages as quickly as possible to consumers.
If you do capacity planning and calculate your messages’ ingress/egress rates, then you should try to keep your queues as empty as possible; though this isn’t the latest discovery, it’ll help you have a fast-paced broker.
But if consumers start to lag behind and queues start to fill up, then at some point the memory alarm will fire on the server and it’ll start to flush messages to disk no matter what properties were used to publish the messages.
The lesson is to always keep an eye on your queue sizes.
In this section you saw how the different algorithms and message publish and subscribe settings can affect the overall system speed, and how a different flag setting like auto-ack mode can immensely affect the system performance.
In the next section we’ll look at the hard limits imposed on the RabbitMQ server by the hardware (RAM) and by the Erlang virtual machine itself.
When you design applications you usually have two basic constraints: what the chosen technology allows you to do, and what your current hardware setup allows you to do.
In this section we’ll review some of the hard limits imposed by your hardware or by the Erlang virtual machine on RabbitMQ so you can plan ahead and see how much you should be able to scale up RabbitMQ in a single box.
For example, one interesting metric to know about RabbitMQ is the memory required to create each of the AMQP components like queues, exchanges, and bindings.
Another value to take into account is the number of Erlang processes that RabbitMQ creates for those elements, since there’s a hard limit in the Erlang VM to how many processes you can create.
Let’s look at each of those elements in detail so you can start from solid ground when doing capacity planning calculations.
The first question to ask is what happens when you declare a queue.
When you declare a queue, RabbitMQ will add several entries into various Mnesia tables, depending on the kind of queue.
In the case of a nondurable queue, there will be an entry for it only in the rabbit_queue table.
An entry in any of those tables will take approximately 29 words of memory.
So what does that mean? In Erlang the size of a word will depend on your system.
We said approximately 29 words because the size of the record will depend also on the name of the queue you declared.
According to the AMQP specification, every queue is bound to the anonymous exchange, which means that after a queue declare there will also be an entry in the rabbit_route table that keeps tracks of the bindings between queues and exchanges.
There might be entries in another Mnesia tables, which we’ll come back to later when we take a look at bindings.
Apart from that you’ll also have more entries on the routing tables, as you’ll soon see.
The x shows which tables will have new entries for a queue declare; you can also see the word size of each item stored in those tables.
When you declare an exchange, something similar happens, but in this case it’s simpler.
Now it’s time to see what happens when you bind a queue to an exchange.
In this case there are two situations: binding a queue to a direct or fanout exchange, or binding a queue to a topic exchange.
The latter case is more complex to explain, so we’ll analyze it last.
When a queue is bound to a direct or fanout exchange, RabbitMQ will create an entry in at least two Mnesia tables to keep track of the binding.
The size of those records are 44 words of memory.
There are several combinations that will make RabbitMQ create entries on other tables.
Those combinations depend on the durability properties of the queue and the exchange that participate in the binding.
In table 11.3 you can see this in more detail.
A record in that table will occupy approximately 45 words of memory.
So a pattern like a.b.c.d will create four entries in that table with a size of 38 words of memory each.
With those numbers, you can do capacity planning for your messaging applications and determine the upper bound on RabbitMQ when it comes to RAM usage.
As you can see, the footprint for queues, exchanges, and bindings is small when it comes to memory usage.
As an example, you can see that on a 64-bit system, a durable queue.
Another factor that imposes a hard limit on RabbitMQ is the maximum number of Erlang processes per Erlang node.
Erlang applications create and destroy processes many times during their lifetime.
For example, when RabbitMQ accepts a TCP connection to your AMQP client, an Erlang process will be spawned to manage that connection.
At the same time, there are Erlang processes that handle the logic of the RabbitMQ message store.
Other processes are there to monitor child processes to ensure they’re kept alive, and so on.
If you just start a RabbitMQ server, you’ll have around 126 processes laying around, which is fairly low for a server like RabbitMQ.
But what happens if you surpass the default limit of 220? Sadly, Erlang will crash and therefore RabbitMQ will crash too, which means you want to make sure that you set that number properly.
Now 220 processes is a lot and good enough for most users, but your mileage may vary.
Let’s see what events make that number increase so you know what to add to your capacity planning calculations.
The events you may produce as users of RabbitMQ that will increase the number of processes are new connections to the broker, new channel creations, and queue.
A new connection will create four new processes and opening a new channel on that connection will create four new processes as well.
The overhead per queue is minimal: just one process per queue.
As we said already, a limit of 220 processes is more than enough in most cases; still, doing some math while planning your messaging architecture won’t hurt anyone.
Now that you have an idea of what’s happening inside RabbitMQ for the different AMQP operations that you might perform, it’s time to see how you can secure your RabbitMQ setup by enabling SSL.
When you work on a closed network inside a corporation where you deploy your applications, you can be almost 100% sure you can trust the parties involved.
Most of the time there’s no reason to suspect the request, but when you start to work with sensitive data like credit card information, you might need to restrict access to certain areas of your applications.
Since you don’t want to compromise such information, you need a way to establish encrypted connections with RabbitMQ in order to transmit data in a secure way.
You can use SSL2 as a protocol to transmit the data between messaging endpoints like consumers and producers.
RabbitMQ comes with SSL support out of the box, so from your side you have to set up all the SSL machinery to use such infrastructure.
In this section we’ll address how to establish secure connections to your RabbitMQ installations by using SSL.
We’ll use the OpenSSL library, which has support for most *nix-style operating systems as well as Windows.
OpenSSL and security itself are broad topics that we can’t cover in detail in this chapter.
If you want to get detailed information on how to secure your network with OpenSSL, we recommend that you consult the book Network Security with OpenSSL (Viega et al., 2002, O’Reilly Media)
In the following sections you’ll see how to create an SSL Certificate Authority and from there create certificates for your clients and servers.
Such a setup is often referred to as public key infrastructure or PKI.
Finally, you’ll use those certificates to establish an SSL connection with RabbitMQ.
One way to exchange information in a secure way is to encrypt it using public key cryptography.3 In this technique, the parties exchanging information have a private key and a public key that are mathematically related so they can be used to encrypt and decrypt.
It’s a cryptographic protocol that allows for secure network communications.
Table 11.4 Erlang process used by connections, channels, and queues.
Though the public key can be widely distributed, the private key must be kept, well, private.
This technique uses asymmetric algorithms, so the key used to encrypt the message can’t be used to decrypt it.
If the user Bob wants to exchange data with Alice, then they exchange their respective public keys.
When Alice sends data to Bob, she will encode the information using her private key and then Bob will decode the data using Alice’s public key.
The digital signature of the messages are computed based on the private key; in this way the receiver can assume that the message comes from the expected party by checking the signature against the sender’s public key.
Knowing that the key actually belongs to this party is a different matter.
To ensure that a key does belong to the assumed owner, the keys are exchanged together with certificates that prove the authenticity of the key.
The certificates are emitted by trusted third parties that work as certificate authorities who take care of proving that the key belongs to its advertised owner.
Though this may sound too complex, there’s a nice analogy in the book Network Security with OpenSSL that compares the certificate with a passport.
A passport not only has your picture but also includes some personal information about you that allows someone to certify that the picture actually belongs to whom it says it does.
Of course you could have forged a passport in your basement trying to trick the authorities.
To prevent that, your passport includes information about the issuing authorities from your government acting as the certificate authority for your passport.
When you travel abroad, the immigration officers can identify you based on your passport and can prove its authenticity based on the watermark and other means added by your government.
To get a valid SSL certificate, you’ll have to pay a trusted third-party company to issue one for you.
You may want to do so if you plan to exchange data with the public, but if you just want to share data inside your organization, then you can set up your private certification authority which you implicitly trust.
You’ll use it to emit certificates that will be used by both RabbitMQ and its messaging clients to exchange data.
In the following sections you’ll learn how to set up your own certificate authority and from there you’ll issue certificates for your clients and servers to be able to establish SSL connections between them.
See the Wikipedia entry for more information on this topic: http://en.wikipedia.org/wiki/Public-key _cryptography.
To set up your certificate authority you’ll use the openssl command-line utility.
This utility accepts plenty of options that are hard to remember.
To make things easier, openssl can work with configuration files where you specify the options you want using key/value pairs.
You can also track which parameters were used to generate your certificates by checking this configuration file.
Let’s start by creating the basic environment for your certificate authority (CA)
If you had OpenSSL installed before you built Erlang then you probably are all set to use it.
If you don’t have OpenSSL in your system then you’ll have to install it and then reinstall Erlang with OpenSSL enabled.
You need to create a folder to hold your certificates plus the CA configuration files.
Open a terminal window and then type the following commands:
First you created an rmqca folder to hold your files.
We used the name rmqca, which stands for RabbitMQ certificate authority, but feel free to give a name that fits your organization.
Once that folder is created, you then create a couple of folders: certs and private; the first will hold the certificates generated by your CA, whereas the second will hold the CA private key.
Keep in mind that the CA private key must not be disclosed to third parties; therefore you chmod the private folder to be accessible only for your current user.
To be able to generate certificates, OpenSSL requires a couple more files.
Since certificates created by one CA can’t share the same serial number, you need to create a file where you can keep track of the last certificate’s serial number.
Every time you issue a new certificate, OpenSSL will take care of incrementing this number.
OpenSSL expects the number to be in hexadecimal and to contain at least two digits, so when you first create such a file you have to pad the number by adding a zero to the left like this:
The last file you need to create works like a database where OpenSSL will keep track of the certificates issued by your CA.
We’ll call this file index.txt; because you haven’t created any certificates yet, this file will be empty.
Now that you have the basic environment to work with OpenSSL, you need to create your configuration file.
As you’ll see, the configuration is split into several sections for each of these commands, which makes it easier to follow.
One of those commands is called ca and is used to set up a CA and a certificate revocation list (CRL).4
Let’s create a file called openssl.conf inside the rmqca folder and then add the following content for the ca command section.
In this file you’re providing default options for the ca command that you can still override on the command line when you invoke openssl.
As you can see, the sections of the .conf file are marked by headers between a pair of square brackets ([])
The configuration file is a set of key/value pairs holding your configuration options.
You start by declaring the ca section B where you tell openssl that your default CA will be called rmqca.
OpenSSL then will look for a section with that name from where it will load the remainder of the configuration options.
In the rmqca section C, you set up a variable called dir that points to the same directory where the .conf file is.
That variable is referenced in the next few lines so you don’t need to type the full path to your current folder every time.
There you tell openssl that the certificate will be stored in the file cacert.pem in the same directory as the configuration file.
Certificate revocation lists are used to inform clients when the certificates emitted by your CA have expired.
Clients can download the list from the CA and then reject certificates that are revoked in your CRL.
Then you need to configure the expiration time for your certificates D.
There you say that your certificates will expire after a year, that you’ll provide a CRL file every seven days, and that your certificates will be generated by using sha15 as the hash function.
The next part of the file configures your CA policy E where you tell openssl which fields are mandatory in your certificates.
For this CA, the commonName has to be provided, whereas the other fields like countryName or emailAddress are optional.
That basically means the certificates issued by your CA can’t be used as certificate authorities themselves—they can’t be used to sign and issue new certificates.
Now you need to configure the req command that’s used to generate certificates.
You’ll add new sections to openssl.conf, where you’ll provide new key/value pairs.
In this section B you start configuring the req command by specifying that you want to generate 2048-bit keys for your certificates.
More information about the x509 extensions can be found at the OpenSSL website: http://www.openssl.org/
By setting prompt to yes, you tell the req command that it should prompt you whenever it needs to fill up the values specified under by distinguished_name.
Then you have the section where you provide some extensions for your root certificate C.
In this case you set that the root certificate can be used to sign other certificates (that’s the point of this whole setup)
When you set up the client extensions D you say that the client certificates can’t be used as certificate authority themselves but can be used to sign the data they send back and forth.
The extendedKeyUsage field has some particular set of numbers7 that in this case indicates that the certificate can be used for client authentication.
Finally comes the server extensions section E where in this case you want certificates that are used for encrypting data and for authenticating the server.
As you can see, you specify that information with a different set of values for the extendedKeyUsage key.
With those settings, you finished setting up your OpenSSL environment and are now ready to start creating certificates.
Though this process was complex, you had to do it once, with the advantage that by keeping the configuration options in this file, you don’t need to remember all the settings by heart.
Let’s move on to the next section to see how to create your own certificates.
The first thing you need to do is to generate a CA certificate.
All your other certificates will descend from it, and it will be used to establish the chain of trust between the different applications.
For specific details on the req command and its options, you can consult http://www.openssl.org/docs/apps/req.html.
For more details we refer you again to the book Network Security with OpenSSL by Viega et al.
OpenSSL is a broad topic so if you want to learn it in detail you’ll be best served by reading that book.
The next thing you’ll do is to create the same certificate but using the DER format which is preferred by Microsoft products.
Now that you have your root certificate, it’s time to create the client and server certificates.
To issue your server certificate, you need to create a folder to store it in.
Then you’ll proceed to generate the server key and finally to certify it using your root certificate:
First you moved into the folder that contains the rmqca, and there you created your server folder and then moved into it.
There you invoked the openssl command to generate the RSA key.
What you need to do next is create a certificate request for that key:
The certificate request now can be used by your certificate authority to provide a certificate for your RabbitMQ server.
Write out database with 1 new entries Data Base Updated.
What you did there is first change directories to the rmqca folder and, from there, you ran the openssl ca command using your openssl.conf file.
The input file is the req.pem that you created before, and the output file is the cert.pem certificate that will reside inside your server folder.
Now you need to repeat the same process to create the client certificate.
Considering that the process is much the same, we won’t explain it in detail this time.
As in the previous case, first you create a key for your client, then you have to generate a certificate request based on that key, and finally you hand that certificate request to your certificate authority to issue the client certificate that will reside in the file called cert.pem inside the client folder.
The following shows the commands that need to be run and the output they produce, which might be different on your computer:
Write out database with 1 new entries Data Base Updated.
Now that you have the certificates sorted out, it’s time to configure RabbitMQ to be able to use SSL when accepting incoming connections.
It’s worth noting that if you check the contents of the files serial and index.txt inside the rmqca folder, you’ll see that the serial file now has the number 03 in it because you’ve generated three certificates so far and that the index.txt file lists the certificates you issued.
To enable SSL with RabbitMQ, you need to add a couple of configuration values to the rabbitmq.config file.
If you haven’t created that file yet, now is the time to do it.
The location of that file will vary depending on your operating system and the RabbitMQ distribution that you’re using.
For example, in a generic Unix installation, that file will go inside the /etc/rabbitmq folder.
For more information on where to locate that file according to your current setup, you can consult the RabbitMQ online documentation at http://www.rabbitmq.com/configure.html#config-location.
The first will enable the TCP listener for incoming connections, and the second will tell RabbitMQ where to find the server certificates and what authentication requirements it will impose on clients connecting via SSL.
If you already have this file on your system, then add the configuration entries just after the ones you already have.
As you know, the rabbitmq.config file uses Erlang syntax to specify configuration options.
The options cacertfile, certfile, and keyfile are self-explanatory: cacertfile is your CA’s private certificate, certfile is the server’s own certificate, and keyfile is the server’s key.
They will be used to authenticate the server with the client and also to verify the client authenticity.
That’s similar to how browsers work, where the server sends the certificate but the browser isn’t required to send your certificate back (most people don’t have their own SSL certificates when browsing the web)
Now it’s time to apply this configuration to your RabbitMQ installation.
Restart RabbitMQ (or start it if it wasn’t running) and you should see the following entries in rabbit.log telling you that the new SSL listener has been started:
There you can find a description of all the options it accepts.
The next thing to do is to test your new configuration by connecting to RabbitMQ using the PHP client library.
To test and try out your SSL setup, you’ll connect to RabbitMQ using the php-amqplib library.
Go to the command line and type the following commands:
Your PHP client will use the phpcert.pem file when dealing with SSL connections with RabbitMQ.
If you run this script you’ll start seeing debug information from the AMQP library showing you how it negotiates a connection with RabbitMQ.
After the connection is established successfully, if you tail the RabbitMQ logs you should see messages similar to the following, showing you that RabbitMQ established a connection with your PHP script and then that connection was upgraded to the SSL protocol:
First you include the AMQP library as usual and then declare B some constants that you’ll use as the connection configuration.
Then you created an array with the SSL options for PHP C so it knows where to find your key and certificates information.
You opened a connection by using the AMQPSSLConnection class D, passing a sixth argument with your SSL options.
Finally, you prepared the connection cleanup E by setting up a shutdown function that will take care of closing the connection when your script terminates, for example, when you press ctrl-c to kill the script.
With this, we finish our coverage of SSL with RabbitMQ.
Now you can establish connections between the broker and its messaging clients, knowing that both ends can certify the authenticity of their peers.
By checking the server certificate when you open a connection to the broker, you can be sure that the messages are coming from a trusted source.
At the same time, the broker can verify the client’s certificates so it won’t accept connections from untrusted parties.
As we’ve said already many times, this is a large topic that goes well beyond what we can cover in a book about RabbitMQ.
Note that depending on the language you’re using, you’ll have to see how to open SSL connections specifically for your platform, since the implementation details vary across vendors.
Keep in mind that the PKI setup that we prepared in this section can be used in many places in your organization well beyond RabbitMQ usage.
Your certificate authority isn’t limited to only certify RabbitMQ brokers and their respective clients; you can also use it to certify the communication among other applications.
For example, you can issue certificates for your intranet to enable secure web browsing (using HTTPS) for the company’s internal websites.
In this chapter we covered some interesting topics like performance, capacity planning, and security.
One thing that’s clear is that there’s no secret sauce when it comes to scaling your RabbitMQ installation.
All will depend on your use case; you’ll always have to consider the trade-offs.
If you want to get more performance out of RabbitMQ, then you’ll need to judiciously analyze the pros and cons of each of the routing algorithms provided by the different exchange types.
Moreover, you saw how the combination of properties like message persistence, queue durability, and consumer acknowledgment mode will affect the path of a message through the broker, which will modify the performance characteristics of your applications.
Regarding capacity planning, you saw that to calculate memory usage for your messaging fabric, you have to consider factors like the kinds of queues or exchanges you’re using and which of the AMQP elements will spawn Erlang processes on the broker.
Though the process limit in Erlang is high, it’s not infinite, so by performing some simple math you can calculate a number that matches your needs.
Finally, we covered the essentials of a broad topic like OpenSSL.
You configured your broker to be able to accept SSL connections and to authenticate clients.
To give your setup a test ride, you have a PHP client connecting to the server via SSL, but not without a small hassle to get PHP to accept your certificates.
Such quirks happen with almost every platform that uses OpenSSL.
In the next chapter we’ll enter the world of RabbitMQ plugins.
You’ll see which plugins you can obtain to augment your broker capabilities, but we won’t stop there...
Fasten your seat belt because in the next chapter you’ll be programming in Erlang.
At this point you’ve learned how to use RabbitMQ as an AMQP message broker using what comes out of the box.
In chapter 8 you saw that some customization was required in order to have an easier way to manage the broker.
You enabled the Management plugin, which includes a slick web interface that adds a bunch of functionality to the server.
Taking that into account, wouldn’t it be nice if you could add custom behaviors to the broker?
In this chapter we’ll take a deep dive into RabbitMQ plugins, seeing what you can do with them and what features they bring to the table.
You’ll learn how to enable plugins and, in case you don’t need their functionality anymore, you’ll also see how to uninstall them.
You might be wondering where you can get plugins for Smart Rabbits: extending RabbitMQ.
Many cool plugins are out there and you’ll see where to get them.
In the second section of the chapter you’ll make your own plugins.
You’ll get your hands dirty programming with Erlang and create your own.
Don’t worry if you don’t know Erlang; we’ll cover enough to get you started, but you will feel more comfortable if you already know about it.
So let’s move onto the next section to pimp up our rabbit.
If you look at a system like RabbitMQ you’ll see that the features shipped with it are those that are useful to a large set of users.
The same thing happens with server default configurations or with the new characteristics shipped with new broker releases.
But what happens when you need something that doesn't come out of the box? For that situation, RabbitMQ can be enhanced by adding plugins.
You can find plugins on the internet or create your own.
Let’s first look at when you might need a plugin, and then we’ll see where you can get new plugins for your broker.
So which use cases go beyond what RabbitMQ provides out of the box? Here’s a list of possible scenarios or needs that can be solved by installing a plugin:
One area where there has been a lot of experimentation is adding support for other protocols on top of RabbitMQ.
As you know, AMQP is the default protocol supported by RabbitMQ, but one size doesn’t fit all, so there’s also a plugin for the STOMP protocol.
One advantage of STOMP is that it works with other brokers like ActiveMQ.
If you have a code base that targets ActiveMQ and STOMP and you want to only use RabbitMQ, then you can start to migrate step by step by using the STOMP plugin.
Or if you work with a programming language that lacks an AMQP client but has one for STOMP, then you can start using RabbitMQ by installing this plugin.
If you want to learn more about STOMP you can do so on its web page: http://stomp.github.com/
Another use case for RabbitMQ plugins is the need to authenticate to the broker via some method other than plain AMQP.
Install the plugin, add the proper configuration, and you can get going with LDAP authentication.
New protocols and different authentication mechanisms aren’t the only things that you can add on top of RabbitMQ.
You can go low-level on AMQP and implement your own exchanges with custom routing rules.
Riak is a Dynamo-inspired key/value store that offers fault tolerance out of the box.
What if you need to replicate messages from one broker to another that lives in a data center miles away? For such use cases there’s the RabbitMQ shovel plugin.
You specify a queue name on the plugin’s configuration and a destination exchange on a remote broker, and it will take care of shoveling the messages over the wire to the remote exchange.
You don’t have to limit yourself to adding new exchange types or authentication methods.
With plugins you can do almost everything that Erlang allows you to do; the limit is your imagination—and judgment.
After all, you don’t want the broker crashing because you tried to implement some wild ideas on top of it.
Now that you know what’s doable with RabbitMQ plugins, let’s see where to find them.
There you can find a list of maintained plugins and a second list of what are called experimental plugins.
The former are maintained by the RabbitMQ crew and are kept up to date with new broker releases.
Also you can file bugs and feature requests via the RabbitMQ mailing list at http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss.
Though you can do the same with the experimental plugins, you can’t be sure that there will be an answer to your issues with them.
The plugin is ready to be used! Now the question is what happens when you want to enable a plugin that’s not part of the broker distribution.
Buckets in Riak are a way to organize data in a way similar to the use of tables in SQL databases.
Move into the sbin folder of your RabbitMQ installation and type the following:
Now stop the broker in case you had it running:
And then start it again to load the new plugin:
The STOMP plugin will be up and running with its default configuration.
To test that it works as expected, let’s connect to RabbitMQ using the STOMP protocol with the default user credentials.
The previous command will open a connection to the server.
All the input you type now will be sent to the STOMP adapter which will try to parse the frames.
If you don't have the plugins folder, just create it inside RabbitMQ's installation directory.
This folder can also be safely removed later in case you don't want to use any plugin.
If everything went well you should get a reply with a new session like this:
With this small example we end our test of the STOMP plugin.
Our goal was to install it and see that with zero configuration you could get it up and running.
If you want to learn more about using STOMP with RabbitMQ you can consult the documentation at http://www.rabbitmq.com/ stomp.html.
Now let’s say you don’t need the STOMP plugin anymore and want to remove it.
That’s easy to achieve by using the same rabbitmq-plugins commands that you’ve been using so far.
First you have to disable the plugin by running the following from the sbin folder:
You can list the enabled plugins to make sure that the STOMP plugin has been disabled:
You can see that the list option displays the enabled plugins along with their versions, and that the STOMP plugin doesn’t appear in that list.
Now that you’ve seen the power of plugins, it’s time to create your own plugin.
Get your fingers ready because in the next section you’ll be coding in Erlang.
So far we’ve discussed what you can do with plugins; now it’s time to create your own.
The goal will be to add your own custom exchange to RabbitMQ.
Why might you need a new exchange type? Imagine that you need to model a chat application with RabbitMQ where you have a global room where all the users connect.
Each user gets their own queue that’s bound to the global fanout exchange.
Every time a new message is sent to the exchange, this message gets fanned out to every queue bound to it.
Now what happens when a new client connects to the chat room? Though they will get all the new messages that are sent to the chat room, they won’t have any context about what happened before they joined the conversation.
After a message is consumed from a queue, it’s not seen anymore in the broker.
You can change that if you create an exchange that caches the last 20 messages that it has routed.
Then whenever a new user connects to the room (which means a new queue is bound to the exchange) your exchange will deliver the last 20 messages.
Figure 12.1 explains the idea: the area of the figure that’s separated with a dotted line is what your exchange will add to your application.
Though you might not need to implement a chat room using RabbitMQ, there are cases when your new consumers need to know the last value seen on this exchange.
An easy way to implement that is with this kind of exchange.
In this section you’ll implement such an exchange, which will be called RabbitMQ Recent History Exchange.
As usual, the complete source code for this project can be found with the code that accompanies this book.
In the next section you’ll set up your development environment in order to get ready to start creating plugins.
To write your own plugins you’ll need to set up a basic development environment to build your plugins upon.
The RabbitMQ developers have facilitated such a task for you by creating an environment in what’s called the RabbitMQ Public Umbrella (from now on let’s call it umbrella)
Installing it is a matter of checking out its repository and then adding your own plugin into that project structure.
To get the umbrella code you’ll have to set up Mercurial, which is a distributed revision control system similar to Git.
Mercurial is the system used by the RabbitMQ developers to publish and manage their open source code.
If you already have it installed, then you’re good to go.
Mercurial is a multiplatform system, so you should be able to install it for your platform.
Don’t worry if you haven’t used Mercurial before; you’ll be using just a couple of commands to get the umbrella source code.
If you’ve been following along with the book code examples, then you probably have Python installed already; if not, it’s time to do so because some tools under the umbrella require it (including Mercurial itself)
The last requirement is to have Erlang installed on your machine; if you can run RabbitMQ, then you must have it installed as well.
As with Python, please consult the Erlang website to get installation instructions: http://www.erlang.org/
Assuming you installed Mercurial, you can get the code with the following command:
Once the repository has been cloned to your computer, it’s time to get the projects contained inside it.
Run the following commands, but grab a cup of coffee since it may take a while:
As an optional step to check that your setup is working properly, you can run the following two commands to compile the rabbitmq-stomp plugin:
The next thing to do is to create the folder structure for your plugin.
You’ll build your plugin following the Open Telecom Platform (OTP) coding standards—you’ll follow a certain folder structure, file naming conventions, and source code organization using several programming patterns that fit Erlang.
Since this is a book about RabbitMQ, we won’t have time to cover Erlang in detail but if you’re curious and want to learn more, we recommend the book Erlang and OTP in Action from Manning (http://manning.com/logan/) or Learn You Some Erlang for Great Good (http://learnyousomeerlang.com/)
The code presented will be easy to grasp even if you don’t have any Erlang experience, but be warned that some techniques may seem strange if you’ve never used Erlang or functional programming before.
Inside it you’ll need one folder to hold your source code called src.
The next step will be to include the umbrella build system into your project.
To be able to use the umbrella build system, you need to add a couple of files to your project root folder.
The first file is called Makefile and will reference the umbrella make file.
By referencing the umbrella.mk file, you benefit from all commands already created for you.
There are commands that can package your plugin as an .ez file, and others that can run your plugin inside the broker directly from the project folder, making it easier to test your plugin.
There are commands to clean up the built files and much more.
For a full list of options, consult the file README.makefiles inside the umbrella folder.
Now that your Makefile is in place, you can add your package.mk file that will contain the plugin-specific configuration options for the build system.
Create that file inside your project folder and add the following content to it:
As you can see, this is as simple as it can get.
The cool thing here is that the umbrella build system will take care of resolving the dependencies for you.
Now that you have everything ready to start coding your plugin, let’s continue by writing the application specification file.
Now that you have the basic requirements in place, let’s create the application specification file.
Things like the list of Erlang modules included with the application or the configuration options are specified in the application specification file.
When you create your application specification file, you need to indicate a list of the Erlang modules included in your application, something that’s a bit tedious.
Luckily this step can be simplified by using application specification templates that later are automatically filled with such information by the umbrella build system.
This means that you don’t have to worry about keeping the list of modules up to date; the build system will do that for you.
So although in a normal Erlang project you’ll create a plain application file, in this case you’ll create a template for it and let the umbrella system fill in the information automatically.
What you have here is an Erlang tuple, a compound data type that holds a fixed number of Erlang values (terms).3 If you simplify that structure you can see that it has the following shape:
Before starting to write the exchange logic, let’s make sure the Makefile is set up properly.
You should start seeing a lot of output on your command line.
That’s normal: it's the build system making all your plugin dependencies like the Erlang AMQP client and the broker itself.
After the process is finished, you’ll notice that you have some new folders in your project root.
The most interesting one is called dist or distribution folder, where your final plugin files will be put.
There you have your plugin files together with their dependencies.
Though your plugin still lacks functionality, you could at least test that the build system is properly set up.
After you have your plugin final version, you’ll have to copy those files into the plugins folder of your RabbitMQ installation.
Modules hold functions that implement the features offered by your applications.
There are no classes or packages like in Java or C#, which makes the structure flat and simple.
Your plugin will need only one module containing the custom exchange implementation.
So, for example, to implement the Visitor pattern you can check the Visitor interface that will tell you that you need to provide a Visit method, an Iterator will have to implement the methods hasNext and next, and so on.
In Erlang you have the same concept but with a different name: behaviour.
An Erlang behaviour will specify which functions a module has to implement and export, so code calling your module knows what to expect from it.
What you have is just a list of functions that your module exports.
So if your module implements functions foo, bar, and baz but only exports foo, then bar and baz can’t be called from outside.
Just telling which functions a module has to export is one part of the story; the other is the number of arguments a function accepts.
Erlang has the concept of function arity—the number of arguments a function takes.
When specifying function names, put a forward slash between the function name and its arity.
Since your exchange will be a beefed-up fanout exchange that will cache the last 20 messages, you’ll base your implementation in the code for the actual fanout exchange that comes with the broker, which will simplify the task.
In figure 12.2 you can see what you have to do differently from the default fanout implementation.
Whenever your exchange routes a message, you’ll keep it on some database.
Then, when a queue is bound to your exchange, you have to deliver the cached messages to it in case you have any.
Finally, when your exchange is deleted, you have to drop the cache to avoid memory leaks, which will be handled by the function delete/3
Note that you have to implement other functions as well.
The ones mentioned in the figure are those that differ from the fanout exchange default implementation.
As a last implementation detail you’ll use Mnesia, the Erlang built-in database that’s already used by RabbitMQ to store bindings and exchange meta information.
You’ll implement your exchange step by step and then, at the end, we’ll show you the complete source code for the module.
First, you provide the name of your module B, which has to match the filename minus the .erl extension.
Finally, you declare the list of functions that your module exports E.
Note that you have several export declarations in this code.
You do that for readability’s sake, since you could provide just one export with all the functions there.
For example, you have to implement a function called description that doesn’t take any arguments, a function called route that accepts two arguments, and so on.
As you can see, you can export more functions than those required by the behaviour that you’re implementing.
For RabbitMQ to pick up your exchange and be able to use it, it has to know about its existence.
RabbitMQ maintains a registry where all the exchange types with their respective module names are tracked.
Let’s say you publish a message to a fanout exchange.
What RabbitMQ will do is to go to the registry and check which module implements the fanout exchange.
When it has the module name, it will proceed to call the routing function on that module.
In this case, you need to find a way to add your exchange to that registry to make it available for the broker.
RabbitMQ supports the concept of boot steps—a series of steps that have to be called while the server starts up.
You’ll add one boot step to your module and then RabbitMQ will magically execute it and add your exchange to the rabbit_registry.
Add the following code to the module to accomplish that.
A rabbit_boot_step B has the following components: a description telling what the boot step is about (note that this is for documentation; it doesn’t matter what you put there as long as it’s a string)
Next is the mfa or module function arguments section, where you invoke the function register in the rabbit_registry, passing as arguments your exchange type and the module related to it.
Your exchange type at the AMQP level will be called x-recent-history.
According to the AMQP spec, all the custom elements that you add to the protocol need to have the x- prefix.
You also take advantage of the rabbit_boot_step system to initialize your plugin C.
Since your plugin will use Mnesia to store the cached messages, you add an extra step here to set up the database schema for your plugin; the mfa part of the boot step will invoke the function setup_schema that belongs to your exchange module.
The ?MODULE piece that you see there works similar to a C macro, so in this case it will be expanded to your module name.
Speaking of Mnesia tables, you need to define the schema for a table, and you do that with the -record declaration at the end.
The records that you’ll store will be called cached and they’ll have two elements: the key and the content.
In the key property, you’ll store the exchange name and in the content property you’ll keep a list of the last 20 messages that passed through the.
That will provide you with an easy-to-access map from exchange name to cached messages.
When the time comes to deliver the last 20 messages from the cache, you’ll need to look up the message list by your exchange name.
First you have the function header B with the function name, the list of arguments that go between parentheses (in this case you have none), and the arrow -> that indicates what follows is the function body.
There you have a case expression with the following shape:
Erlang will evaluate Expr, and the Body part that gets executed will depend on the result of that expression; you mark the end of the case expression with the word end.
As you can see, this works similarly to switch/case statements in other languages.
The attributes or columns of your table will be the fields of the cached record—key and content fields that you defined earlier.
You tell Mnesia that the name of the record used will be cached and that the type of your table will be set, which means that there won’t be any duplicated values.
If you store a new value with the same key, then the old value will be overwritten by the new value.
You’ll add a bunch of functions whose implementation is simple, since you’ll be reusing the default implementation provided by RabbitMQ.
First you have a function called description B that’s only used for informative purposes.
It returns a property list having the exchange name and its description.
The implementation of remove_bindings, validate, and create D is straightforward.
You return the atom ok because you don’t need to do any bookkeeping when such operations happen to your exchange; RabbitMQ will perform the default actions.
Now that you’ve implemented the basics, it’s time to define the functions that will add that extra set of functionalities to your exchange.
First you call the function cache_msg/2, passing the exchange name and the message content D.
Once the message is cached, you call the default rabbit_router E to provide your exchange with the same behaviour as provided by the fanout exchange.
The first function, cache_msg/2, takes two parameters: the exchange name and the message content.
In this function you need to access Mnesia to retrieve the messages that may be in the cache and append to them the latest message.
Because your exchange can be called concurrently, you need to run the read and update operations inside a transaction to ensure that you have consistent data.
That function takes a function as argument and runs it in the context of a Mnesia.
As with many functional languages, Erlang provides the ability to define anonymous functions, or funs as they’re are called in the Erlang world.
Functions are first-class citizens, which means they can be passed as normal values to other functions and can also be returned by functions.
If you’ve used JavaScript, then you’ve probably used some anonymous functions when working with callbacks.
The simplified syntax for an Erlang fun is like this:
The fun in this code doesn’t take any arguments since it closes over the arguments passed to the cache_msg function.
You bind the result of that function call to the variable Cached and then pass that code to the function store_msg/3 that will take care of storing the data.
By having these two separate steps, you can reuse the code that retrieves the data from Mnesia and the code that stores data in Mnesia as well.
The first argument is the table name; the second argument is the record that you want to store.
Note that you use the exchange name as the value for the key field.
To store the cached content, you dynamically create an Erlang list using the syntax [Head|Tail]
By doing that, you make sure to have at most 20 elements in your cache.
You may wonder why you prepend the new element to the list head.
Lists in Erlang are implemented as linked lists, so it’s cheaper to prepend elements to the list first and then do a list reverse when you want to deliver the messages in the same order as they arrived.
The last parameter to the Mnesia function is write, which is used to ask Mnesia for a write lock to the ?RH_TABLE table.
The case expression will call mnesia:read/2 by providing it the table and the exchange names.
If the database returns an empty list denoted by [], you return that empty list B.
If you get a list with one element being the #cached record, you extract from the record the exchange name and the content.
Now you might be wondering why you associate the value of the key field with the variable XName.
This again has to do with pattern matching in Erlang.
In this case you use this technique as a sanity check to ensure that you got a value that’s associated with the exchange name.
How does that work? When your function is called, the variable XName (which is the only argument the function takes) will be bound to the value passed to the function.
In Erlang, as with many functional languages, variables don’t vary.
Variables work the same way as variables do in high school math.
The value bound to XName can’t be changed during the scope and lifetime of your function execution.
So the only way the second expression of case will match is if the value contained in the key field matches the contents of the XName variable.
By doing that you make sure that you get back from Mnesia the values that you cached for your current exchange.
Even if this seems complex at the beginning, it will simplify your code a lot later; you won’t need to add needless if/then/else cases to your code because you’ll pattern match variables in advance.
If the pattern match fails, then your code won’t be executed at all.
Coming back at the code, you can see the second part of the case expression returns the cached content C.
Now it’s time to see what you have to do when somebody deletes one of your custom exchanges.
RabbitMQ will call it whenever the exchange has to be deleted.
Though it takes three arguments in this case, you’ll only use the second one to extract the value of the exchange name and then use it to delete from Mnesia the information belonging to that exchange.
Keep in mind that there can be many instances of your custom exchange type, each caching different messages.
To prevent memory leaks, whenever any instance of your exchange type is removed from the server you have to take care to delete the messages associated with its name.
The next callback to implement is the one used to bind queues to your exchange.
To finish with the implementation, let’s take a look a the helper functions used in the previous code.
The first function is a simple helper used to send a protocol error to the client B.
It takes the queue name as argument and uses it to format a string that tells the user that the queue can’t be found.
Keep in mind that you pass to this function a list of Content values; therefore you must map over that list applying the fun that you define in there to each of the elements of the list.
When you call the map function, you have to remember to reverse the list of messages to get them in the same order as they were received.
To get the list in reverse order, you call the Erlang function lists:reverse/1
An AMQP message is composed of a set of properties and the payload.
The next thing to do is to add to the message the name of the exchange that routed it and the routing key used to route the message.
Last but not least you have the helper function deliver_messages/2 that takes a queue Pid and a list of messages, and maps over that list to deliver each of the messages to the queue.
This function takes four arguments: the first tells whether the message delivery is mandatory, which you set as false; the second says that the message isn’t immediate; the third is the actual message; and the last parameter is the message sequence ID, which in this case is undefined.
For the purposes of this chapter let’s say that binaries are an efficient way to represent strings in Erlang.
For more information on binaries and other Erlang data types, see the nice introduction given by the book Learn You Some Erlang for Great Good: http://learnyousomeerlang.com/starting-out-for-real#bit-syntax:
As you can see, it’s easy to extend RabbitMQ and add new exchange types.
You just have to follow a couple of rules imposed by the Erlang behaviour that you want to implement.
To ease your implementation, you could even base your exchange on the fanout type, making things easier for you.
Let’s recap what you just did: you overrode the implementations for message routing, queue binding, and exchange deletion to be able to cache and deliver messages.
In order to have clean code and keep your functions short, you wrote a couple of helpers to access Mnesia whether you needed to write to the cache or to read messages from it.
Now let’s try to compile and run RabbitMQ with your custom exchange plugin.
Luckily the umbrella build system includes a command that allows you to run your plugin directly into the broker by automatically installing your plugin.
You’ll see a lot of output when you press Enter.
First your plugin will be built and, if everything went well, RabbitMQ will be launched.
You should see a message like the following confirming that your plugin was enabled:
The usual RabbitMQ logo will appear and after the rabbit registry is started, you should see the following output:
Pay attention to the line that says: starting recent history exchange type: registry ...done.
Later you’ll see how to close it and exit Erlang.
Before you write a consumer and a publisher, let’s see the complete listing for your custom exchange module.
Now that your exchange is running, it’s time to test it.
Let’s write a publisher and a consumer to give it a try.
To test your custom exchange you’ll create a couple of PHP scripts: one with a consumer and the other with a producer.
Your test will consist of starting a consumer and then running the producer in a separate terminal window publishing 100 messages to your recent history exchange.
The expected result is that your consumer receives and consumes all the messages.
In a normal AMQP scenario, you shouldn’t see those messages anymore in the server.
In this case since you’re using your custom exchange, you should have the last 20 messages still available in the exchange cache.
To prove this, you’ll start another consumer in a separate window and bind its queue to your exchange.
By doing that, you expect to receive the last 20 messages.
The code here is similar to previous consumers that you’ve already seen in the book.
An important detail is that when you declare the exchange B, you specify its type as x-recent-history to tell RabbitMQ that you want to use your custom exchange.
Keep in mind that if you’re running the broker without your plugin installed, then this code will throw an exception and fail because RabbitMQ won’t be able to find the module for that exchange type.
After you create your exchange, you declare an anonymous queue and bind it to the exchange C.
Your callback will echo to STD_OUT the content of the messages received.
Finally, you wait on the channel for incoming messages E.
Let’s continue coding your producer by creating a file called recent_history_ producer.php with the following code inside.
As with your consumer, this code is similar to other producers that you’ve already created in the book.
What you do here is send 100 messages B to the exchange called rh-exchange that you created in your previous script.
To be able to identify each message, you tag them with the value of your loop variable.
Now let’s open three terminal windows to test this code.
Keep in mind that you should have left RabbitMQ running from the previous call to make run-in-broker.
Open a terminal window, cd into the folder where you saved the previous PHP code, and type.
That will start a consumer and output the queue name from where it’s consuming.
Keep in mind that the queue name might be different in your machine.
Then, on another terminal, you can launch the producer and send 100 messages over RabbitMQ.
If everything went well and the messages got routed through the exchange to your consumer, then in the first window you should see output like the following:
Now if you switch to the last window and start a second consumer, you should get the last 20 messages.
First, you started your consumer, which declared the exchange named rh-exchange; that consumer bound an anonymous queue to it and then subscribed to that queue.
Finally, you started another consumer in a separate window and without the need to publish any new messages, the last 20 messages were delivered to the consumer.
Let’s look at figure 12.3 to see how both tests look when run at the same time.
With this, you finish the exercise of creating your own plugin, namely your own custom exchange.
Now it’s time to stop the RabbitMQ instance that you’ve been using for testing the plugin.
If you don’t include it, then the Erlang interpreter will keep waiting for more input.
When you’re back at the shell command line, you can type ls dist/ to see the product of your hard work: your plugin’s .ez files.
RabbitMQ installation and then run the following command followed by a server restart:
If you wish to uninstall the plugin, you’ll have to first delete any exchange that you’ve declared with the type x-recent-history and then you can proceed to disable the plugin followed by a server restart.
If you thought that you were limited to the factory defaults when using RabbitMQ, then with this chapter you learned otherwise.
Many plugins are out there for RabbitMQ, including officially supported ones like the Management plugin or the STOMP plugin, which can add extra features and new protocols to the server, and community-provided plugins like the Riak Exchange.
You also went all the way down the rabbit hole and implemented your own plugin.
Of course we wanted to give you something that goes beyond a mere Hello World project, so you created your own custom exchange.
Along the way you had a quick overview of Erlang programming, which can help later if you ever want to dig deeper into RabbitMQ’s source code to learn more about its own internal behavior.
To create your plugin, you learned about the RabbitMQ Public Umbrella build system, which can be used to build the broker from source as well as other plugins.
All in all, now you can make the little rabbit behave as you choose.
Being able to bend RabbitMQ completely to your will through your own custom code is the pinnacle of Rabbit knowledge … and the end of our journey.
You started with humble intentions: to free yourself from tight coupling and synchronous communications between your applications.
Whether you’re really writing the next successful dog walking app, changing the way doctors help patients, or helping a traveling dad see his daughter from the road, we hope you’ll see the possibilities for messaging everywhere you build software.
Most of all, we hope that what we’ve written has helped you, so that you can focus on using RabbitMQ instead of digging it out yourself.
As our journey together has ended, your journey with Rabbit is just beginning and there’s a whole world of messaging ahead.
If you need any help along the way, we’d love to hear from you (and help where we can) on the RabbitMQ in Action forums.
Though we chose Python and PHP for their clarity and suitability as teaching languages, we realize there are a lot of .NET and Java programmers out there.
Also, most of the AMQP clients for different languages are similar in their interfaces.
But the Java and .NET clients diverge significantly enough from the other language clients that they warrant some advice on how to map the examples in RabbitMQ in Action to those languages.
With that in mind, we’ll translate a few examples from the book into their .NET and Java equivalents.
Specifically, we’ll show you how the Hello World example would look in C#
In each case, our goal is to stick as closely as possible to the structure, comments, and naming conventions of the original Python and PHP examples.
Our hope is that this will help you build a mental map so that when you look at any other example in the book, you can easily translate that into how it would work in Java or .NET.
In the repository, you’ll find not only the .java and .cs source files, but also Visual Studio projects for the .NET examples that are ready to be built with msbuild.
But before you can dive into writing your C# Hello World, you have to first install the RabbitMQ.NET client.
On the .NET client download page you’ll find both autoinstaller (.MSI) and .ZIP packaged versions of the client.
We recommend using the .MSI for convenience, so download the .MSI installer and run it (see figure A.1)
Now that you have the client installed, go ahead and create the Visual Studio project (choose Empty Project) for your Hello World consumer, as in figure A.2
The last thing you need to do before starting to write your code is to add a reference to the RabbitMQ.NET client in your project.
Otherwise, Visual Studio (or msbuild) won’t be able to find it.
First, right-click on References under your new project in the Solution Explorer and select Add Reference (see figure A.3)
You also have to import RabbitMQ.Client .Events so you can access the arguments that are passed back to your consumer when a message delivery event occurs.
Since your RabbitMQ server will likely not be on the same box as your consumer, you’ll collect the Rabbit host to connect to as a command-line argument to the.
The first thing your consumer does is create a ConnectionFactory object that will generate and manage the actual connection to the broker.
After you’ve used the factory to create the connection B, you then use the connection object (conn) that’s returned to create the channel C.
You may notice that the channel object (chan) is of type IModel, which represents the AMQP channel you’ll use.
This is unlike any other Rabbit client library (including the Java client), which all use the word channel to.
With your channel created, you’re ready to start declaring the exchange and.
As with the original Hello World consumer in chapter 2, you want your exchange (helloexchange) to be declared D as a direct exchange that’s durable but not autodelete.
In the RabbitMQ.NET client, exchange types are specified using constants from the ExchangeType class.
You then create E your nondurable, non-autodelete queue (hello-queue) with QueueDeclare, and bind it F to hello-exchange on the routing key hola.
Finally, you’re ready to subscribe to hello-queue and start processing messages.
The use of model to describe a channel in the .NET client is a historic holdover from the early days of AMQP when the thought was that other transports besides TCP (HTTP, SCTP, and so on) might be used for AMQP.
Since the channel concept is specific to the TCP transport, the .NET client was architected to use the more generic term model for the same concept.
Now that TCP is the only transport for AMQP, all of the newer clients use the channel term.
There are a lot of moving parts in this last piece of your consumer, so let’s break it down.
When the channel object receives a new message that consumer is subscribed for, it fires consumer’s HandleBasicDeliver method.
This receives the message and stuffs it into a threadsafe SharedQueue instance inside of the consumer object.
This means new subscribed messages can stream into consumer unblocked by the actions of your code actually processing those messages from the SharedQueue.
With consumer created, you start the consumption by invoking BasicConsume on the channel with consumer as an argument.
This tells the channel to subscribe to hello-queue and, when messages arrive from the subscription, to stuff them into consumer’s SharedQueue.
BasicConsume You can call BasicConsume multiple times with different queues to subscribe to the same consumer object.
This will cause all messages from the different subscriptions to be placed in the same SharedQueue in the consumer object.
You’d want to take this approach because consumer.Queue .Dequeue() will halt execution waiting for a message if the SharedQueue is empty.
By using a single consumer object for multiple subscriptions, you only need one Dequeue() call to service all the subscriptions without blocking each other.
You may notice that you also passed a second argument false to BasicAck.
This tells BasicAck you’ll only be acknowledging one message at one time.
Finally, the only thing left to do with your decoded message is print its contents to the user or terminate F the app if the message contained quit.
With your Hello World consumer converted to .NET, you need to convert your producer so that you have something to consume! As has been the case throughout these examples, the producer is much simpler than the consumer.
In addition to the broker to connect to, you also need to collect the message to publish from the command line B.
Then you’re ready to connect C and declare helloexchange D to make sure you have a place to publish to.
Creating your message E to publish is similar to the steps you used to process the message, just in reverse.
First, you grab the message contents from the command line and store them in the string msg_body.
Next, you create an IBasicProperties object (msg_props) to store your message’s publishing properties and set the message’s content type to text/plain so that the consumer knows the message body is plain ASCII text.
The only requirement is that it be a sequence of 8-bit bytes.
Because of this, the BasicPublish command in the Rabbit .NET client will only accept byte arrays for the message body.
You may need to add the full path to your .NET framework to your system’s PATH environment variable.
Saying hello again (library options and Hello World) Now in your other terminal build your producer and send a test message:
Figure A.5 Create terminals for your consumer and producer tests.
A.2 Alerting revisited: porting the alert app to event-oriented .NET With Hello World under your belt, you might think we’ve covered enough RabbitMQ.NET basics for you to be able to mentally translate the examples in the rest of the book.
What we haven’t covered is how to consume messages using an event-based approach.
In the Python client Pika, all consumers are built using callbacks (event-oriented) that are registered for each subscription and then fired when messages for those subscriptions arrive.
Unfortunately, the RabbitMQ Java client doesn’t have an event-oriented consumption interface available.
Before we get started, you’ll need to select a .NET JSON library since the original alerting examples communicate using JSON.
In this case you’ll use the JSON.NET 4.0 library from James Newton-King: http://json.codeplex.com/
To add a function (critical_notify in this case) to that list of callbacks, you add it to the consumer object’s Received property and then issue BasicConsume:
As before, you’ll extract B the message properties and message body.
But because the message body is actually JSONencoded, you’ll use the JSON.NET library C to further decode the message body into a .NET data type.
Then you’ll send the alert email D and notify the user onscreen.
Where things get interesting is E where you acknowledge the message.
Since BasicAck is a method of the channel object, you need to get access to that object in order to acknowledge the message.
You do that by way of the Model property on the consumer object that was passed in.
As you may remember, the .NET client calls AMQP channels models, and the Model property of consumer contains a reference to the channel that received the message being consumed.
Using event-oriented message consumption in .NET is really that simple.
Definitely check out the full code for this C# consumer in the examples repository for RabbitMQ in Action.
Enough .NET; let’s show some love to Java and see how to use Rabbit with the world’s most popular bytecode interpreter.
The client will send a message containing the client version and the current timestamp encoded as a JSON object.
When the request has been sent to the server, the client will then wait for the server reply.
In this section you’ll implement an RPC client and server to illustrate how to translate the examples from chapter 4
Having said that, it’s worth mentioning that the official RabbitMQ Java client implements basic RPC functionality as described here: http://www.rabbitmq.com/api-guide.html#rpc.
The first thing you need to do is to download the latest version of the RabbitMQ Java client.
You can go directly to the client download page located here and then select the package that matches your platform: http://www.rabbitmq.com/java-client.html.
For this example you’ll download the one named Binary, compiled for Java 1.5 or newer (zip)
Create a folder called java-rpc and then download the library using wget.
Alternatively, you can point and click with your browser to get the file downloaded to the new folder:
Now that you’ve downloaded the library, you’ll unzip its contents and then copy the *.jar files into a folder called lib that you’ll use to keep the libraries used by the application:
Since you also need to send JSON messages, download Douglas Crockford’s org.json Java library:
If you type ls lib, you should see the following files inside:
As you know, every time you run a Java program, you have to specify the class path so the JVM knows where to find the packages and the classes required by your program.
The class path can start to get lengthy easily, so you’ll create a shell variable that will hold the class path information so you don’t have to type it over and over again.
On Unix-like systems you can create a variable to hold our class path like this:
On Windows you’ll have to replace colons with semicolons in order to separate .jar files.
Now that you have the basic setup out of the way, it’s time to code your RPC server and client.
In the rest of this section you’ll jump right into the Java code.
If you want to know more about the library, you can read the online API guide at http://www.rabbitmq.com/api-guide.html, and the Javadocs are located here: http://www.rabbitmq.com/releases/rabbitmq-java-client/v2.7.0/rabbitmq-java-clientjavadoc-2.7.0/
As with every Java program, first you need to import the classes that you’ll use in your program, so create a file called Client.java inside the java-rpc folder.
We’ll describe the code of this class step by step, and then at the end we’ll provide the whole source file.
As you can see in that snippet, you import the ConnectionFactory, Connection, and Channel classes from the RabbitMQ client which are needed to establish a connection to the broker and then to obtain a channel.
The final class that you include is the JSONObject class from the org.json package that’s used to load JSON objects in memory.
Now let’s look at the init() method of your class where you’ll create the AMQP connection, obtain a channel, and then use that channel to start your AMQP fabric by declaring the exchange, queues, and finally binding them together.
The first thing you have to do is create an instance of the ConnectionFactory class B that you’ll use to set up your connection.
As you can see, the factory accepts calls to methods like setUsername and setPassword where you provide the required connection information.
The ConnectionFactory class also has methods like setVirtualHost and so on.
In this case you’ll connect using the rpc_user name and rpcme password.
Once the factory is set up, you can call the method newConnection in order to obtain the connection object, which you then use to get a channel object C.
As you can see, you don’t declare the connection or the channel variables since you’ll add them as members of your class.
Then you use the channel to set up your AMQP fabric D.
First you declare an exchange by calling exchangeDeclare on the channel object.
The parameters passed to that method are the exchange name and type.
The remainder of the parameters stand for durable, exclusive, autodelete, and extra arguments respectively.
As you can see, you created a nondurable, nonautodelete, nonexclusive queue.
After the queue is created, you bind it to the ping exchange by using the ping routing key.
The final step of your init method is to start the consumer.
First you obtain a new instance of a QueueingConsumer by passing it the channel object E.
Then you subscribe to the ping queue by calling the basicConsume method.
You also use the string ping as your consumer tag and pass the consumer object as the message callback so every time a new message is delivered it’ll be sent to your consumer.
The mysterious second parameter to the basicConsume method specifies that you’re consuming in non-auto-ack mode—you’ll issue a message acknowledgment for each message delivery that you receive.
In this method you enter an endless loop where you process one message at a time.
You get the last message sent by the server by calling nextDelivery on the consumer object B.
The delivery object has both the message payload and the message properties that you’ll later use in your method.
Then you acknowledge the message back to the server by calling basicAck C where you pass the message delivery tag, which you obtain by first getting the message envelope out of the delivery object and then by chaining the call to getDeliveryTag.
You can also use the Envelope object to obtain the exchange used to route the message by calling getExchange or the message routing key by calling getRoutingKey, and so on.
Finally, you send your reply back to the client by calling basicPublish to send a message D to the anonymous exchange using as routing key the reply_to property from the original client request.
The response message itself is created by calling the method getResponse, which you’ll implement right away.
To sum up what happens in this method: First you get the next delivery out of the consumer.
You acknowledge the message using the message envelope to get the delivery tag, and after that you publish a reply back to the client.
The method takes a Delivery object as parameter so it can extract the message body B and stores it in the message variable as a string.
The next thing you need to do is to parse that string as a JSON object so you can get the timestamp sent by your client C.
To extract a property from a JSONObject instance, you call the getString method, which takes the object property key as parameter to return its value.
Finally, let’s see the main method of your Server class where you instantiate the server so it can wait for client requests.
Apart from the try/catch/finally logic, you just create an instance of your Server class, initialize it by calling init, and finally chain the method call to serveRequests to start processing messages.
The full code of the class is presented next, including the method closeConnection that you use in the finally block.
Now that you have the server fully implemented, let’s compile it by running the following command:
Let’s move on now so you can start coding your client.
You’ll create a file called Client.java and add your code there.
As usual, the complete source code will be given at the end of this section.
The first thing to add is the list of imports:
The only difference here from the previous server code are the JSON libraries that you need to import.
Because in the client you have to create a JSON object, you’ll import the JSONStringer object that lets you create JSON strings in an OOP way.
The JSONException is required because when you convert the JSON object to a string, it might throw an exception.
The code here is similar to that used by the server.
You create an instance of the ConnectionFactory object and then set up the user and password.
You get a Connection instance and from there you obtain a channel object.
You keep the channel and the connection objects as members of your class.
After you have the connection, you need to set up your consumer.
The important bit from that method is that you declare an anonymous queue and let RabbitMQ generate a queue name for you.
Later you’ll use that variable as the value of your reply_to message property.
The call method accepts a string as parameter, which will represent the message payload that you want to send to the server.
You’ll publish that message B to the rpc exchange using the string ping as routing key.
Then you wait for a reply inside the while (true) loop D.
To receive a message from RabbitMQ you use the same technique that you employed on the server code.
After you have the delivery, you get the message body as a string and return that response to whomever called the method.
Let’s see now how you can create the message properties that will include your replyQueueName as part of the reply_to message’s basic properties.
You create a BasicProperties object that uses a builder technique where you can chain calls to set each of the basic properties that you might need.
In this case you’ll only set the replyTo property, but you can also use this technique to set properties like correlationId or deliveryMode.
The code here is similar to that which initializes the server.
The interesting bit is how you call the server B.
After you have the consumer instance, you execute the call method and then wait for a reply from the server.
Note that for a user of your RPC client, there’s no apparent difference between doing a local method call from an RPC call, so be careful in this regard because an RPC call is many orders of magnitude slower than a local method call.
First you get the current UNIX timestamp, which you need to send with your RPC message.
Then you create an instance of the JSONStringer object, which provides an OOP interface to build the JSON object.
First you have to instantiate your RPC client inside the main method of your class.
After you have a Client instance, you can use the call method to get a reply from the server.
The JSON object that you send as a message is constructed inside the createRequest method.
During the client initialization, you also declared a queue in the server for the client and kept the queue name in the object state.
That name is passed along with your JSON object to the server so the server will know where to reply to.
Once you get the reply back from the server, you print it to the console and exit the program.
Before terminating the app, you take care to clean up resources by closing the connection.
Here’s the complete code for the RPC client including the Client.close method.
If the compilation was successful, then you should have a new Client.class file:
Now start your RabbitMQ server so you can test drive your RPC clients and server.
Open two terminal windows and then type the following on the first to start your server:
Your server should then be ready to accept client requests.
Let’s move on to the second terminal window, set up the CP variable as explained before, and then type.
You’ll see the reply being printed on the screen right away.
On the other hand, in the terminal window where the server is running, you should see the following output:
With this example we finish our coverage of the RabbitMQ client for Java.
As an exercise, try to run the Python RPC server with the Java client or vice versa to test the interoperability of both AMQP clients.
A.4 Summary When we started this appendix, you might have had RabbitMQ’s basics under your belt, but using those basics from Java and .NET might’ve proven elusive.
We hope this whirlwind jaunt through using Rabbit with Java and .NET has provided the necessary mental map for utilizing all of the concepts and examples in the book with your interpreted bytecode language of choice.
In this appendix we gathered some interesting online resources that should make your life easier whenever you go looking for some information related to RabbitMQ, whether that’s a client library for your favorite programming language or the latest messaging design pattern to use for your current problem.
Well, let’s be fair: we can’t cover all of your needs but we’ll make the effort by listing resources that have been helpful to us.
B.1 Websites you should know Let’s start by reviewing some websites:
RabbitMQ official documentation—This is the place to go first if you’re looking for information about RabbitMQ.
Since we started writing this book, the resources available on the official websites have augmented considerably.
Apart from those links, the RabbitMQ developers created an AMQP Quick Reference at http://www.rabbitmq.com/amqp-0-9-1-quickref.html.
Whenever you want to know what the fourth argument to that AMQP method means, go and check that web page.
Enterprise Integration Patterns —If you’re interested in knowing more about messaging and integration patterns, then the book Enterprise Integration Patterns written by Gregor Hohpe and Bobby Woolf is the one to read.
The small caveat we must mention for an AMQP user is that all the examples are targeted for technologies like JMS or MSMQ.
The pattern narratives and diagrams are released under the Creative Commons.
Attribution License so you can read them online at http://www.eaipatterns.com/ eaipatterns.html.
Patterns like Publish Subscribe, Competing Consumers and many others were covered in the examples we presented in chapter 4
Ruby AMQP gem documentation site—The Ruby AMQP gem website is filled with documentation and examples of how to use RabbitMQ and AMQP.
RabbitMQ development RSS feed—The RabbitMQ Mercurial repository offers an RSS feed with the latest code changes to the server.
From time to time, someone rediscovers it and it pops up again on Twitter.
Alvaro’s blog —Alvaro maintains a blog where he discusses messaging and many other software topics.
Here we list some interesting libraries for AMQP and RabbitMQ in particular:
Java—Besides the official Java client, you have other options to integrate Java and RabbitMQ.
Marek Majkowski, one of the RabbitMQ developers, started working on a new one called Puka and he explains the design reasons behind his new library at http://www.rabbitmq.com/blog/2011/07/08/puka-rethinking-amqp-clients/
C—For C there’s a library called rabbitmq-c written and maintained by David Wragg, which also works for RabbitMQ.
The library has been wrapped by C++ and Objective-C users as well.
The library is hosted at the RabbitMQ Mercurial repository: http://hg.rabbitmq.com/rabbitmq-c/
PHP—For PHP we used the php-amqplib client library, which is a pure PHP implementation.
There’s also a PECL extension for AMQP that you can find at http://pecl.php.net/package/amqp.
At the time of this writing, that library is under heavy development.
Keep in mind that it depends on the rabbitmq-c library.
Another pure PHP library is worth mentioning due to its active development and documentation efforts by its author.
Ruby—For Ruby you can try the Ruby AMQP Gem that we mentioned earlier (http://rubyamqp.info/)
The good news is that it’s maintained by one of the AMQP Gem authors too.
Erlang—If you need to use RabbitMQ from Erlang, the language in which RabbitMQ is written, a client library is offered by the RabbitMQ team.
This library is used by most of the RabbitMQ plugins, so chances are you’re using it indirectly in your RabbitMQ installation.
Details on its usage can be found on the RabbitMQ official website: http://www.rabbitmq.com/erlang-client-userguide.html.
JavaScript, Node.js, and web messaging—Though JavaScript is a frontend language, lately server-side frameworks have appeared that present the language as an interesting choice for backend programming.
Discussions and mailing lists to write server-side code in JavaScript, and as you can imagine we didn’t have to wait long before someone wrote an AMQP client for it.
The main library is called node-amqp and it’s maintained by Theo Schlossnagle, the author of the book Scalable Internet Architectures.
There’s also a library called Rabbit.js, which implements several messaging patterns for the web.
It was created by Michael Bridgen, one of the RabbitMQ developers.
The library design is built on top on his experience writing the Ruby clients.
The library wraps the Java official library into idiomatic Clojure.
Scala—For Scala there’s an AMQP library that can be used directly with the AKKA Scalability framework.
Documentation for the library can be found in its repo at http://doc.akka.io/docs/akka-modules/1.3.1/modules/amqp.html.
Haskell—If you want to use RabbitMQ with Haskell, take a look at this package on hackage: http://hackage.haskell.org/package/amqp.
NoSQL—RabbitMQ has also been integrated with some NoSQL databases; most notable is the work by Jon Brisbin, who’s been working on bridging RabbitMQ with Riak.
Also, if you want to receive change notifications of what’s going on in your Riak database, Jon wrote a Riak post-commit-hook.
Feel free to chime in; there are always members from the community who are willing to help.
We provided a selection of links from interesting websites and blogs and a small commentary on each of the libraries that we mentioned here.
You can see that with RabbitMQ and AMQP, you don’t need to be locked into a particular language solution.
Finally, if you want to get in touch with the community, you can do so via traditional email, direct IRC chat, or keep track of what’s happening with RabbitMQ users in real time via Twitter.
Fortunately, the kind folks at Rabbit HQ have provided MSI-based installers that make the process rather painless.
But before you install Rabbit, you must first install a recent version of Erlang from http://www.erlang.org/download.html.
Generally, the latest version of Erlang available from erlang.org will work with the latest version of RabbitMQ.
So go ahead and grab the download labeled Windows Binary File (see figure C.1)
All of the defaults in the Erlang for Windows installer are acceptable when using Rabbit, so click Next (or Finish) on all the stages of the installer wizard to deploy a default installation of Erlang.
Using the RabbitMQ for Windows installer is as easy as the Erlang installer: run the downloaded installer file (see figure C.4) and click through the stages using the defaults.
One thing that’s different from the UNIX versions of RabbitMQ is that utilities in the .\sbin subdirectory end with .bat.
Also, the first time you run any of the utilities (like rabbitmqctl.bat) that communicate with Rabbit via Erlang, you’ll receive a warning from the Windows Firewall (see figure C.5) asking whether to allow network access for erl.exe.
RabbitMQ in Action teaches you to build and manage scalable applications in multiple languages using the RabbitMQ messaging server.
You’ll learn how message queuing works and how RabbitMQ fi ts in.
Th en, you’ll explore practical scalability and interoperability issues through many examples.
Written for developers familiar with Python, PHP, Java, .NET, or any other modern programming language.
Alvaro Videla is a developer and architect specializing in MQ-based applications.
Williams is CTO of DigiTar, a messaging service provider, where he directs design and development.
