This book was set in Times Roman and Mathtime Pro 2 by the authors.
But now that there are computers, there are even more algorithms, and algorithms lie at the heart of computing.
This book provides a comprehensive introduction to the modern study of computer algorithms.
It presents many algorithms and covers them in considerable depth, yet makes their design and analysis accessible to all levels of readers.
We have tried to keep explanations elementary without sacriﬁcing depth of coverage or mathematical rigor.
Each chapter presents an algorithm, a design technique, an application area, or a related topic.
Algorithms are described in English and in a pseudocode designed to be readable by anyone who has done a little programming.
The book contains 244 ﬁgures—many with multiple parts—illustrating how the algorithms work.
Since we emphasize efﬁciency as a design criterion, we include careful analyses of the running times of all our algorithms.
The text is intended primarily for use in undergraduate or graduate courses in algorithms or data structures.
Because it discusses engineering issues in algorithm design, as well as mathematical aspects, it is equally well suited for self-study by technical professionals.
In this, the third edition, we have once again updated the entire book.
The changes cover a broad spectrum, including new chapters, revised pseudocode, and a more active writing style.
We have designed this book to be both versatile and complete.
You should ﬁnd it useful for a variety of courses, from an undergraduate course in data structures up through a graduate course in algorithms.
Because we have provided considerably more material than can ﬁt in a typical one-term course, you can consider this book to be a “buffet” or “smorgasbord” from which you can pick and choose the material that best supports the course you wish to teach.
You should ﬁnd it easy to organize your course around just the chapters you need.
We have made chapters relatively self-contained, so that you need not worry about an unexpected and unnecessary dependence of one chapter on another.
Each chapter presents the easier material ﬁrst and the more difﬁcult material later, with section boundaries marking natural stopping points.
In an undergraduate course, you might use only the earlier sections from a chapter; in a graduate course, you might cover the entire chapter.
Each section ends with exercises, and each chapter ends with problems.
The exercises are generally short questions that test basic mastery of the material.
Some are simple self-check thought exercises, whereas others are more substantial and are suitable as assigned homework.
The problems are more elaborate case studies that often introduce new material; they often consist of several questions that lead the student through the steps required to arrive at a solution.
Departing from our practice in previous editions of this book, we have made publicly available solutions to some, but by no means all, of the problems and exercises.
You will want to check this site to make sure that it does not contain the solution to an exercise or problem that you plan to assign.
We expect the set of solutions that we post to grow slowly over time, so you will need to check it each time you teach the course.
We have starred (?) the sections and exercises that are more suitable for graduate students than for undergraduates.
A starred section is not necessarily more difﬁcult than an unstarred one, but it may require an understanding of more advanced mathematics.
Likewise, starred exercises may require an advanced background or more than average creativity.
We hope that this textbook provides you with an enjoyable introduction to the ﬁeld of algorithms.
We have attempted to make every algorithm accessible and interesting.
To help you when you encounter unfamiliar or difﬁcult algorithms, we describe each one in a step-by-step manner.
We also provide careful explanations of the mathematics needed to understand the analysis of the algorithms.
If you already have some familiarity with a topic, you will ﬁnd the chapters organized so that you can skim introductory sections and proceed quickly to the more advanced material.
This is a large book, and your class will probably cover only a portion of its material.
We have tried, however, to make this a book that will be useful to you now as a course textbook and also later in your career as a mathematical desk reference or an engineering handbook.
You should have some facility with mathematical proofs, and especially proofs by mathematical induction.
A few portions of the book rely on some knowledge of elementary calculus.
Beyond that, Parts I and VIII of this book teach you all the mathematical techniques you will need.
We have heard, loud and clear, the call to supply solutions to problems and exercises.
Our Web site, http://mitpress.mit.edu/algorithms/, links to solutions for a few of the problems and exercises.
We ask, however, that you do not send your solutions to us.
The wide range of topics in this book makes it an excellent handbook on algorithms.
Because each chapter is relatively self-contained, you can focus in on the topics that most interest you.
Most of the algorithms we discuss have great practical utility.
We often provide practical alternatives to the few algorithms that are primarily of theoretical interest.
If you wish to implement any of the algorithms, you should ﬁnd the translation of our pseudocode into your favorite programming language to be a fairly straightforward task.
We have designed the pseudocode to present each algorithm clearly and succinctly.
We attempt to present each algorithm simply and directly without allowing the idiosyncrasies of a particular programming language to obscure its essence.
We understand that if you are using this book outside of a course, then you might be unable to check your solutions to problems and exercises against solutions provided by an instructor.
Our Web site, http://mitpress.mit.edu/algorithms/, links to solutions for some of the problems and exercises so that you can check your work.
We have supplied an extensive bibliography and pointers to the current literature.
Each chapter ends with a set of chapter notes that give historical details and references.
The chapter notes do not provide a complete reference to the whole ﬁeld.
Though it may be hard to believe for a book of this size, space constraints prevented us from including many interesting algorithms.
Despite myriad requests from students for solutions to problems and exercises, we have chosen as a matter of policy not to supply references for problems and exercises, to remove the temptation for students to look up a solution rather than to ﬁnd it themselves.
What has changed between the second and third editions of this book? The magnitude of the changes is on a par with the changes between the ﬁrst and second editions.
As we said about the second-edition changes, depending on how you look at it, the book changed either not much or quite a bit.
A quick look at the table of contents shows that most of the second-edition chapters and sections appear in the third edition.
We removed two chapters and one section, but we have added three new chapters and two new sections apart from these new chapters.
We kept the hybrid organization from the ﬁrst two editions.
Rather than organizing chapters by only problem domains or according only to techniques, this book has elements of both.
But it also has entire parts on sorting, on data structures for dynamic sets, and on algorithms for graph problems.
We ﬁnd that although you need to know how to apply techniques for designing and analyzing algorithms, problems seldom announce to you which techniques are most amenable to solving them.
We removed two chapters that were rarely taught: binomial heaps and sorting networks.
The treatment of Fibonacci heaps no longer relies on binomial heaps as a precursor.
We revised our treatment of dynamic programming and greedy algorithms.
Dynamic programming now leads off with a more interesting problem, rod cutting, than the assembly-line scheduling problem from the second edition.
In our opening example of greedy algorithms, the activity-selection problem, we get to the greedy algorithm more directly than we did in the second edition.
The way we delete a node from binary search trees (which includes red-black trees) now guarantees that the node requested for deletion is the node that is actually deleted.
In the ﬁrst two editions, in certain cases, some other node would be deleted, with its contents moving into the node passed to the deletion procedure.
With our new way to delete nodes, if other components of a program maintain pointers to nodes in the tree, they will not mistakenly end up with stale pointers to nodes that have been deleted.
The material on ﬂow networks now bases ﬂows entirely on edges.
This approach is more intuitive than the net ﬂow used in the ﬁrst two editions.
With the material on matrix basics and Strassen’s algorithm moved to other chapters, the chapter on matrix operations is smaller than in the second edition.
We have modiﬁed our treatment of the Knuth-Morris-Pratt string-matching algorithm.
Most of these errors were posted on our Web site of second-edition errata, but a few were not.
Based on many requests, we changed the syntax (as it were) of our pseudocode.
We now use “D” to indicate assignment and “==” to test for equality, just as C, C++, Java, and Python do.
In other words, rather than running methods on objects, we simply call procedures, passing objects as parameters.
We also updated many bibliography entries and added several new ones.
Finally, we went through the entire book and rewrote sentences, paragraphs, and sections to make the writing clearer and more active.
You can use our Web site, http://mitpress.mit.edu/algorithms/, to obtain supplementary information and to communicate with us.
The Web site links to a list of known errors, solutions to selected exercises and problems, and (of course) a list explaining the corny professor jokes, as well as other content that we might add.
The Web site also tells you how to report errors or make suggestions.
We used the Times font with mathematics typeset using the MathTime Pro 2 fonts.
As in the previous two editions, we compiled the index using Windex, a C program that we wrote, and the bibliography was produced with BIBTEX.
The PDF ﬁles for this book were created on a MacBook running OS 10.5
Unfortunately, MacDraw Pro is legacy software, having not been marketed for over a decade now.
Happily, we still have a couple of Macintoshes that can run the Classic environment under OS 10.4, and hence they can run MacDraw Pro—mostly.
Even under the Classic environment, we ﬁnd MacDraw Pro to be far easier to use than any other drawing software for the types of illustrations that accompany computer-science text, and it produces beautiful output.1 Who knows how long our pre-Intel Macs will continue to run, so if anyone from Apple is listening: Please create an OS X-compatible version of MacDraw Pro!
We have been working with the MIT Press for over two decades now, and what a terriﬁc relationship it has been! We thank Ellen Faran, Bob Prior, Ada Brunstein, and Mary Reilly for their help and support.
We were geographically distributed while producing the third edition, working in the Dartmouth College Department of Computer Science, the MIT Computer.
We investigated several drawing programs that run under Mac OS X, but all had signiﬁcant shortcomings compared with MacDraw Pro.
We brieﬂy attempted to produce the illustrations for this book with a different, well known drawing program.
We found that it took at least ﬁve times as long to produce each illustration as it took with MacDraw Pro, and the resulting illustrations did not look as good.
Hence the decision to revert to MacDraw Pro running on older Macintoshes.
We thank our respective universities and colleagues for providing such supportive and stimulating environments.
Julie Sussman, P.P.A., once again bailed us out as the technical copyeditor.
Time and again, we were amazed at the errors that eluded us, but that Julie caught.
She also helped us improve our presentation in several places.
If there is a Hall of Fame for technical copyeditors, Julie is a sure-ﬁre, ﬁrst-ballot inductee.
Thank you, thank you, thank you, Julie! Priya Natarajan also found some errors that we were able to correct before this book went to press.
Any errors that remain (and undoubtedly, some do) are the responsibility of the authors (and probably were inserted after Julie read the material)
The treatment for van Emde Boas trees derives from Erik Demaine’s notes, which were in turn inﬂuenced by Michael Bender.
The chapter on multithreading was based on notes originally written jointly with Harald Prokop.
The material was inﬂuenced by several others working on the Cilk project at MIT, including Bradley Kuszmaul and Matteo Frigo.
The design of the multithreaded pseudocode took its inspiration from the MIT Cilk extensions to C and by Cilk Arts’s Cilk++ extensions to C++
We also thank the many readers of the ﬁrst and second editions who reported errors or submitted suggestions for how to improve this book.
We corrected all the bona ﬁde errors that were reported, and we incorporated as many suggestions as we could.
We rejoice that the number of such contributors has grown so great that we must regret that it has become impractical to list them all.
The patience and encouragement of our families made this project possible.
This part will start you thinking about designing and analyzing algorithms.
It is intended to be a gentle introduction to how we specify algorithms, some of the design strategies we will use throughout this book, and many of the fundamental ideas used in algorithm analysis.
Later parts of this book will build upon this base.
Chapter 1 provides an overview of algorithms and their place in modern computing systems.
This chapter deﬁnes what an algorithm is and lists some examples.
It also makes a case that we should consider algorithms as a technology, alongside technologies such as fast hardware, graphical user interfaces, object-oriented systems, and networks.
In Chapter 2, we see our ﬁrst algorithms, which solve the problem of sorting a sequence of n numbers.
They are written in a pseudocode which, although not directly translatable to any conventional programming language, conveys the structure of the algorithm clearly enough that you should be able to implement it in the language of your choice.
We determine these running times in Chapter 2, and we develop a useful notation to express them.
Chapter 3 precisely deﬁnes this notation, which we call asymptotic notation.
It starts by deﬁning several asymptotic notations, which we use for bounding algorithm running times from above and/or below.
The rest of Chapter 3 is primarily a presentation of mathematical notation, more to ensure that your use of notation matches that in this book than to teach you new mathematical concepts.
It provides additional examples of divide-and-conquer algorithms, including Strassen’s surprising method for multiplying two square matrices.
Chapter 4 contains methods for solving recurrences, which are useful for describing the running times of recursive algorithms.
One powerful technique is the “master method,” which we often use to solve recurrences that arise from divide-andconquer algorithms.
Although much of Chapter 4 is devoted to proving the correctness of the master method, you may skip this proof yet still employ the master method.
We typically use probabilistic analysis to determine the running time of an algorithm in cases in which, due to the presence of an inherent probability distribution, the running time may differ on different inputs of the same size.
In some cases, we assume that the inputs conform to a known probability distribution, so that we are averaging the running time over all possible inputs.
In other cases, the probability distribution comes not from the inputs but from random choices made during the course of the algorithm.
An algorithm whose behavior is determined not only by its input but by the values produced by a random-number generator is a randomized algorithm.
We can use randomized algorithms to enforce a probability distribution on the inputs—thereby ensuring that no particular input always causes poor performance—or even to bound the error rate of algorithms that are allowed to produce incorrect results on a limited basis.
Appendices A–D contain other mathematical material that you will ﬁnd helpful as you read this book.
You are likely to have seen much of the material in the appendix chapters before having read this book (although the speciﬁc deﬁnitions and notational conventions we use may differ in some cases from what you have seen in the past), and so you should think of the Appendices as reference material.
On the other hand, you probably have not already seen most of the material in Part I.
All the chapters in Part I and the Appendices are written with a tutorial ﬂavor.
What are algorithms? Why is the study of algorithms worthwhile? What is the role of algorithms relative to other technologies used in computers? In this chapter, we will answer these questions.
Informally, an algorithm is any well-deﬁned computational procedure that takes some value, or set of values, as input and produces some value, or set of values, as output.
An algorithm is thus a sequence of computational steps that transform the input into the output.
We can also view an algorithm as a tool for solving a well-speciﬁed computational problem.
The statement of the problem speciﬁes in general terms the desired input/output relationship.
The algorithm describes a speciﬁc computational procedure for achieving that input/output relationship.
For example, we might need to sort a sequence of numbers into nondecreasing order.
This problem arises frequently in practice and provides fertile ground for introducing many standard design techniques and analysis tools.
Because many programs use it as an intermediate step, sorting is a fundamental operation in computer science.
As a result, we have a large number of good sorting algorithms at our disposal.
Which algorithm is best for a given application depends on—among other factors—the number of items to be sorted, the extent to which the items are already somewhat sorted, possible restrictions on the item values, the architecture of the computer, and the kind of storage devices to be used: main memory, disks, or even tapes.
An algorithm is said to be correct if, for every input instance, it halts with the correct output.
We say that a correct algorithm solves the given computational problem.
An incorrect algorithm might not halt at all on some input instances, or it might halt with an incorrect answer.
Contrary to what you might expect, incorrect algorithms can sometimes be useful, if we can control their error rate.
We shall see an example of an algorithm with a controllable error rate in Chapter 31 when we study algorithms for ﬁnding large prime numbers.
Ordinarily, however, we shall be concerned only with correct algorithms.
An algorithm can be speciﬁed in English, as a computer program, or even as a hardware design.
The only requirement is that the speciﬁcation must provide a precise description of the computational procedure to be followed.
Sorting is by no means the only computational problem for which algorithms have been developed.
You probably suspected as much when you saw the size of this book.
Practical applications of algorithms are ubiquitous and include the following examples:
Although the solutions to the various problems involved are beyond the scope of this book, many methods to solve these biological problems use ideas from several of the chapters in this book, thereby enabling scientists to accomplish tasks while using resources efﬁciently.
The savings are in time, both human and machine, and in money, as more information can be extracted from laboratory techniques.
The Internet enables people all around the world to quickly access and retrieve large amounts of information.
With the aid of clever algorithms, sites on the Internet are able to manage and manipulate this large volume of data.
Electronic commerce enables goods and services to be negotiated and exchanged electronically, and it depends on the privacy of personal information such as credit card numbers, passwords, and bank statements.
The core technologies used in electronic commerce include public-key cryptography and digital signatures (covered in Chapter 31), which are based on numerical algorithms and number theory.
Manufacturing and other commercial enterprises often need to allocate scarce resources in the most beneﬁcial way.
An oil company may wish to know where to place its wells in order to maximize its expected proﬁt.
A political candidate may want to determine where to spend money buying campaign advertising in order to maximize the chances of winning an election.
An airline may wish to assign crews to ﬂights in the least expensive way possible, making sure that each ﬂight is covered and that government regulations regarding crew scheduling are met.
An Internet service provider may wish to determine where to place additional resources in order to serve its customers more effectively.
The number of possible routes can be huge, even if we disallow routes that cross over themselves.
How do we choose which of all possible routes is the shortest? Here, we model the road map (which is itself a model of the actual roads) as a graph (which we will meet in Part VI and Appendix B), and we wish to ﬁnd the shortest path from one vertex to another in the graph.
A subsequence of X is just X with some (or possibly all or none) of its elements removed.
For example, one subsequence of hA;B; C;D;E;F;Gi would be hB; C; E; Gi.
The length of a longest common subsequence of X and Y gives one measure of how similar these two sequences are.
For example, if the two sequences are base pairs in DNA strands, then we might consider them similar if they have a long common subsequence.
Selecting all possible subsequences of X and Y and matching them up could take a prohibitively long time unless m and n are very small.
We shall see in Chapter 15 how to use a general technique known as dynamic programming to solve this problem much more efﬁciently.
We are given n points in the plane, and we wish to ﬁnd the convex hull of these points.
The convex hull is the smallest convex polygon containing the points.
Intuitively, we can think of each point as being represented by a nail sticking out from a board.
The convex hull would be represented by a tight rubber band that surrounds all the nails.
Each nail around which the rubber band makes a turn is a vertex of the convex hull.
Any of the 2n subsets of the points might be the vertices of the convex hull.
Knowing which points are vertices of the convex hull is not quite enough, either, since we also need to know the order in which they appear.
There are many choices, therefore, for the vertices of the convex hull.
Chapter 33 gives two good methods for ﬁnding the convex hull.
These lists are far from exhaustive (as you again have probably surmised from this book’s heft), but exhibit two characteristics that are common to many interesting algorithmic problems:
They have many candidate solutions, the overwhelming majority of which do not solve the problem at hand.
Finding one that does, or one that is “best,” can present quite a challenge.
Of the problems in the above list, ﬁnding the shortest path provides the easiest examples.
A transportation ﬁrm, such as a trucking or railroad company, has a ﬁnancial interest in ﬁnding shortest paths through a road or rail network because taking shorter paths results in lower labor and fuel costs.
Or a routing node on the Internet may need to ﬁnd the shortest path through the network in order to route a message quickly.
Or a person wishing to drive from New York to Boston may want to ﬁnd driving directions from an appropriate Web site, or she may use her GPS while driving.
Not every problem solved by algorithms has an easily identiﬁed set of candidate solutions.
For example, suppose we are given a set of numerical values representing samples of a signal, and we want to compute the discrete Fourier transform of these samples.
The discrete Fourier transform converts the time domain to the frequency domain, producing a set of numerical coefﬁcients, so that we can determine the strength of various frequencies in the sampled signal.
In addition to lying at the heart of signal processing, discrete Fourier transforms have applications in data compression and multiplying large polynomials and integers.
Chapter 30 gives an efﬁcient algorithm, the fast Fourier transform (commonly called the FFT), for this problem, and the chapter also sketches out the design of a hardware circuit to compute the FFT.
A data structure is a way to store and organize data in order to facilitate access and modiﬁcations.
No single data structure works well for all purposes, and so it is important to know the strengths and limitations of several of them.
Although you can use this book as a “cookbook” for algorithms, you may someday encounter a problem for which you cannot readily ﬁnd a published algorithm (many of the exercises and problems in this book, for example)
This book will teach you techniques of algorithm design and analysis so that you can develop algorithms on your own, show that they give the correct answer, and understand their efﬁciency.
Our usual measure of efﬁciency is speed, i.e., how long an algorithm takes to produce its result.
There are some problems, however, for which no efﬁcient solution is known.
Chapter 34 studies an interesting subset of these problems, which are known as NP-complete.
Why are NP-complete problems interesting? First, although no efﬁcient algorithm for an NP-complete problem has ever been found, nobody has ever proven.
In other words, no one knows whether or not efﬁcient algorithms exist for NP-complete problems.
Second, the set of NP-complete problems has the remarkable property that if an efﬁcient algorithm exists for any one of them, then efﬁcient algorithms exist for all of them.
This relationship among the NP-complete problems makes the lack of efﬁcient solutions all the more tantalizing.
Third, several NP-complete problems are similar, but not identical, to problems for which we do know of efﬁcient algorithms.
Computer scientists are intrigued by how a small change to the problem statement can cause a big change to the efﬁciency of the best known algorithm.
You should know about NP-complete problems because some of them arise surprisingly often in real applications.
If you are called upon to produce an efﬁcient algorithm for an NP-complete problem, you are likely to spend a lot of time in a fruitless search.
If you can show that the problem is NP-complete, you can instead spend your time developing an efﬁcient algorithm that gives a good, but not the best possible, solution.
As a concrete example, consider a delivery company with a central depot.
Each day, it loads up each delivery truck at the depot and sends it around to deliver goods to several addresses.
At the end of the day, each truck must end up back at the depot so that it is ready to be loaded for the next day.
To reduce costs, the company wants to select an order of delivery stops that yields the lowest overall distance traveled by each truck.
Under certain assumptions, however, we know of efﬁcient algorithms that give an overall distance which is not too far above the smallest possible.
For many years, we could count on processor clock speeds increasing at a steady rate.
Physical limitations present a fundamental roadblock to ever-increasing clock speeds, however: because power density increases superlinearly with clock speed, chips run the risk of melting once their clock speeds become high enough.
In order to perform more computations per second, therefore, chips are being designed to contain not just one but several processing “cores.” We can liken these multicore computers to several sequential computers on a single chip; in other words, they are a type of “parallel computer.” In order to elicit the best performance from multicore computers, we need to design algorithms with parallelism in mind.
Chapter 27 presents a model for “multithreaded” algorithms, which take advantage of multiple cores.
This model has advantages from a theoretical standpoint, and it forms the basis of several successful computer programs, including a championship chess program.
Then come up with one in which a solution that is “approximately” the best is good enough.
Suppose computers were inﬁnitely fast and computer memory was free.
Would you have any reason to study algorithms? The answer is yes, if for no other reason than that you would still like to demonstrate that your solution method terminates and does so with the correct answer.
If computers were inﬁnitely fast, any correct method for solving a problem would do.
You would probably want your implementation to be within the bounds of good software engineering practice (for example, your implementation should be well designed and documented), but you would most often use whichever method was the easiest to implement.
Of course, computers may be fast, but they are not inﬁnitely fast.
And memory may be inexpensive, but it is not free.
Computing time is therefore a bounded resource, and so is space in memory.
You should use these resources wisely, and algorithms that are efﬁcient in terms of time or space will help you do so.
Different algorithms devised to solve the same problem often differ dramatically in their efﬁciency.
These differences can be much more signiﬁcant than differences due to hardware and software.
For a concrete example, let us pit a faster computer (computer A) running insertion sort against a slower computer (computer B) running merge sort.
They each must sort an array of 10 million numbers.
To make the difference even more dramatic, suppose that the world’s craftiest programmer codes insertion sort in machine language for computer A, and the resulting code requires 2n2 instructions to sort n numbers.
Suppose further that just an average programmer implements merge sort, using a high-level language with an inefﬁcient compiler, with the resulting code taking 50n lg n instructions.
In general, as the problem size increases, so does the relative advantage of merge sort.
The example above shows that we should consider algorithms, like computer hardware, as a technology.
Total system performance depends on choosing efﬁcient algorithms as much as on choosing fast hardware.
Just as rapid advances are being made in other computer technologies, they are being made in algorithms as well.
Although some applications do not explicitly require algorithmic content at the application level (such as some simple, Web-based applications), many do.
For example, consider a Web-based service that determines how to travel from one location to another.
Its implementation would rely on fast hardware, a graphical user interface, wide-area networking, and also possibly on object orientation.
However, it would also require algorithms for certain operations, such as ﬁnding routes (probably using a shortest-path algorithm), rendering maps, and interpolating addresses.
Moreover, even an application that does not require algorithmic content at the application level relies heavily upon algorithms.
Does the application rely on fast hardware? The hardware design used algorithms.
Does the application rely on graphical user interfaces? The design of any GUI relies on algorithms.
Does the application rely on networking? Routing in networks relies heavily on algorithms.
Was the application written in a language other than machine code? Then it was processed by a compiler, interpreter, or assembler, all of which make extensive use.
Algorithms are at the core of most technologies used in contemporary computers.
Furthermore, with the ever-increasing capacities of computers, we use them to solve larger problems than ever before.
As we saw in the above comparison between insertion sort and merge sort, it is at larger problem sizes that the differences in efﬁciency between algorithms become particularly prominent.
Having a solid base of algorithmic knowledge and technique is one characteristic that separates the truly skilled programmers from the novices.
With modern computing technology, you can accomplish some tasks without knowing much about algorithms, but with a good background in algorithms, you can do much, much more.
For which values of n does insertion sort beat merge sort?
For each function f .n/ and time t in the following table, determine the largest size n of a problem that can be solved in time t , assuming that the algorithm to solve the problem takes f .n/ microseconds.
This chapter will familiarize you with the framework we shall use throughout the book to think about the design and analysis of algorithms.
It also contains several summations, which Appendix A shows how to solve.
We deﬁne a “pseudocode” that should be familiar to you if you have done computer programming, and we use it to show how we shall specify our algorithms.
Having speciﬁed the insertion sort algorithm, we then argue that it correctly sorts, and we analyze its running time.
The analysis introduces a notation that focuses on how that time increases with the number of items to be sorted.
Following our discussion of insertion sort, we introduce the divide-and-conquer approach to the design of algorithms and use it to develop an algorithm called merge sort.
We end with an analysis of merge sort’s running time.
Our ﬁrst algorithm, insertion sort, solves the sorting problem introduced in Chapter 1:
In this book, we shall typically describe algorithms as programs written in a pseudocode that is similar in many respects to C, C++, Java, Python, or Pascal.
If you have been introduced to any of these languages, you should have little trouble.
Figure 2.1 Sorting a hand of cards using insertion sort.
What separates pseudocode from “real” code is that in pseudocode, we employ whatever expressive method is most clear and concise to specify a given algorithm.
Sometimes, the clearest method is English, so do not be surprised if you come across an English phrase or sentence embedded within a section of “real” code.
Another difference between pseudocode and real code is that pseudocode is not typically concerned with issues of software engineering.
Issues of data abstraction, modularity, and error handling are often ignored in order to convey the essence of the algorithm more concisely.
We start with insertion sort, which is an efﬁcient algorithm for sorting a small number of elements.
Insertion sort works the way many people sort a hand of playing cards.
We start with an empty left hand and the cards face down on the table.
We then remove one card at a time from the table and insert it into the correct position in the left hand.
To ﬁnd the correct position for a card, we compare it with each of the cards already in the hand, from right to left, as illustrated in Figure 2.1
At all times, the cards held in the left hand are sorted, and these cards were originally the top cards of the pile on the table.
We use loop invariants to help us understand why an algorithm is correct.
Initialization: It is true prior to the ﬁrst iteration of the loop.
Maintenance: If it is true before an iteration of the loop, it remains true before the.
Termination: When the loop terminates, the invariant gives us a useful property.
When the ﬁrst two properties hold, the loop invariant is true prior to every iteration of the loop.
Of course, we are free to use established facts other than the loop invariant itself to prove that the loop invariant remains true before each iteration.
Note the similarity to mathematical induction, where to prove that a property holds, you prove a base case and an inductive step.
Here, showing that the invariant holds before the ﬁrst iteration corresponds to the base case, and showing that the invariant holds from iteration to iteration corresponds to the inductive step.
The third property is perhaps the most important one, since we are using the loop invariant to show correctness.
Typically, we use the loop invariant along with the condition that caused the loop to terminate.
The termination property differs from how we usually use mathematical induction, in which we apply the inductive step inﬁnitely; here, we stop the “induction” when the loop terminates.
Let us see how these properties hold for insertion sort.
We shall use this method of loop invariants to show correctness later in this chapter and in other chapters as well.
Using indentation instead of conventional indicators of block structure, such as begin and end statements, greatly reduces clutter while preserving, or even enhancing, clarity.3
The looping constructs while, for, and repeat-until and the if-else conditional construct have interpretations similar to those in C, C++, Java, Python, and Pascal.4 In this book, the loop counter retains its value after exiting the loop, unlike some situations that arise in C++, Java, and Pascal.
Thus, immediately after a for loop, the loop counter’s value is the value that ﬁrst exceeded the for loop bound.
We used this property in our correctness argument for insertion sort.
We use the keyword to when a for loop increments its loop.
In an if-else statement, we indent else at the same level as its matching if.
Although we omit the keyword then, we occasionally refer to the portion executed when the test following if is true as a then clause.
For multiway tests, we use elseif for tests after the ﬁrst one.
Each pseudocode procedure in this book appears on one page so that you will not have to discern levels of indentation in code that is split across pages.
Most block-structured languages have equivalent constructs, though the exact syntax may differ.
Python lacks repeat-until loops, and its for loops operate a little differently from the for loops in this book.
When the loop counter changes by an amount greater than 1, the amount of change follows the optional keyword by.
Variables (such as i , j , and key) are local to the given procedure.
We typically organize compound data into objects, which are composed of attributes.
We access a particular attribute using the syntax found in many object-oriented programming languages: the object name, followed by a dot, followed by the attribute name.
For example, we treat an array as an object with the attribute length indicating how many elements it contains.
To specify the number of elements in an array A, we write A: length.
We treat a variable representing an array or object as a pointer to the data representing the array or object.
For all attributes f of an object x, setting y D x causes y: f to equal x: f.
In other words, x and y point to the same object after the assignment y D x.
Our attribute notation can “cascade.” For example, suppose that the attribute f is itself a pointer to some type of object that has an attribute g.
Then the notation x: f :g is implicitly parenthesized as .x: f /:g.
In other words, if we had assigned y D x: f , then x: f :g is the same as y:g.
Sometimes, a pointer will refer to no object at all.
In this case, we give it the special value NIL.
We pass parameters to a procedure by value: the called procedure receives its own copy of the parameters, and if it assigns a value to a parameter, the change is not seen by the calling procedure.
When objects are passed, the pointer to the data representing the object is copied, but the object’s attributes are not.
For example, if x is a parameter of a called procedure, the assignment x D y within the called procedure is not visible to the calling procedure.
A return statement immediately transfers control back to the point of call in the calling procedure.
Most return statements also take a value to pass back to the caller.
Our pseudocode differs from many programming languages in that we allow multiple values to be returned in a single return statement.
The keyword error indicates that an error occurred because conditions were wrong for the procedure to have been called.
The calling procedure is responsible for handling the error, and so we do not specify what action to take.
The sum of the two integers should be stored in binary form in.
State the problem formally and write pseudocode for adding the two integers.
Analyzing an algorithm has come to mean predicting the resources that the algorithm requires.
Occasionally, resources such as memory, communication bandwidth, or computer hardware are of primary concern, but most often it is computational time that we want to measure.
Generally, by analyzing several candidate algorithms for a problem, we can identify a most efﬁcient one.
Such analysis may indicate more than one viable candidate, but we can often discard several inferior algorithms in the process.
Before we can analyze an algorithm, we must have a model of the implementation technology that we will use, including a model for the resources of that technology and their costs.
For most of this book, we shall assume a generic oneprocessor, random-access machine (RAM) model of computation as our implementation technology and understand that our algorithms will be implemented as computer programs.
In the RAM model, instructions are executed one after another, with no concurrent operations.
Strictly speaking, we should precisely deﬁne the instructions of the RAM model and their costs.
To do so, however, would be tedious and would yield little insight into algorithm design and analysis.
Yet we must be careful not to abuse the RAM model.
For example, what if a RAM had an instruction that sorts? Then we could sort in just one instruction.
Such a RAM would be unrealistic, since real computers do not have such instructions.
The RAM model contains instructions commonly found in real computers: arithmetic (such as add, subtract, multiply, divide, remainder, ﬂoor, ceiling), data movement (load, store, copy), and control (conditional and unconditional branch, subroutine call and return)
Real computers contain instructions not listed above, and such instructions represent a gray area in the RAM model.
For example, is exponentiation a constanttime instruction? In the general case, no; it takes several instructions to compute xy when x and y are real numbers.
Many computers have a “shift left” instruction, which in constant time shifts the bits of an integer by k positions to the left.
We will endeavor to avoid such gray areas in the RAM model, but we will treat computation of 2k as a constant-time operation when k is a small enough positive integer.
In the RAM model, we do not attempt to model the memory hierarchy that is common in contemporary computers.
That is, we do not model caches or virtual memory.
Several computational models attempt to account for memory-hierarchy effects, which are sometimes signiﬁcant in real programs on real machines.
A handful of problems in this book examine memory-hierarchy effects, but for the most part, the analyses in this book will not consider them.
Models that include the memory hierarchy are quite a bit more complex than the RAM model, and so they can be difﬁcult to work with.
Moreover, RAM-model analyses are usually excellent predictors of performance on actual machines.
Analyzing even a simple algorithm in the RAM model can be a challenge.
The mathematical tools required may include combinatorics, probability theory, algebraic dexterity, and the ability to identify the most signiﬁcant terms in a formula.
Because the behavior of an algorithm may be different for each possible input, we need a means for summarizing that behavior in simple, easily understood formulas.
Even though we typically select only one machine model to analyze a given algorithm, we still face many choices in deciding how to express our analysis.
We would like a way that is simple to write and manipulate, shows the important characteristics of an algorithm’s resource requirements, and suppresses tedious details.
The time taken by the INSERTION-SORT procedure depends on the input: sorting a thousand numbers takes longer than sorting three numbers.
Moreover, INSERTIONSORT can take different amounts of time to sort two input sequences of the same size depending on how nearly sorted they already are.
In general, the time taken by an algorithm grows with the size of the input, so it is traditional to describe the running time of a program as a function of the size of its input.
To do so, we need to deﬁne the terms “running time” and “size of input” more carefully.
The best notion for input size depends on the problem being studied.
For many problems, such as sorting or computing discrete Fourier transforms, the most natural measure is the number of items in the input—for example, the array size n for sorting.
For many other problems, such as multiplying two integers, the best measure of input size is the total number of bits needed to represent the input in ordinary binary notation.
Sometimes, it is more appropriate to describe the size of the input with two numbers rather than one.
For instance, if the input to an algorithm is a graph, the input size can be described by the numbers of vertices and edges in the graph.
We shall indicate which input size measure is being used with each problem we study.
The running time of an algorithm on a particular input is the number of primitive operations or “steps” executed.
A constant amount of time is required to execute each line of our pseudocode.
One line may take a different amount of time than another line, but we shall assume that each execution of the i th line takes time ci , where ci is a constant.
This viewpoint is in keeping with the RAM model, and it also reﬂects how the pseudocode would be implemented on most actual computers.5
In the following discussion, our expression for the running time of INSERTIONSORT will evolve from a messy formula that uses all the statement costs ci to a much simpler notation that is more concise and more easily manipulated.
This simpler notation will also make it easy to determine whether one algorithm is more efﬁcient than another.
We start by presenting the INSERTION-SORT procedure with the time “cost” of each statement and the number of times each statement is executed.
When a for or while loop exits in the usual way (i.e., due to the test in the loop header), the test is executed one time more than the loop body.
We assume that comments are not executable statements, and so they take no time.
Computational steps that we specify in English are often variants of a procedure that requires more than just a constant amount of time.
For example, later in this book we might say “sort the points by x-coordinate,” which, as we shall see, takes more than a constant amount of time.
Also, note that a statement that calls a subroutine takes constant time, though the subroutine, once invoked, may take more.
That is, we separate the process of calling the subroutine—passing parameters to it, etc.—from the process of executing the subroutine.
The running time of the algorithm is the sum of running times for each statement executed; a statement that takes ci steps to execute and executes n times will contribute cin to the total running time.6 To compute T .n/, the running time of INSERTION-SORT on an input of n values, we sum the products of the cost and times columns, obtaining.
This characteristic does not necessarily hold for a resource such as memory.
A statement that references m words of memory and is executed n times does not necessarily reference mn distinct words of memory.
Typically, as in insertion sort, the running time of an algorithm is ﬁxed for a given input, although in later chapters we shall see some interesting “randomized” algorithms whose behavior can vary even for a ﬁxed input.
Knowing it provides a guarantee that the algorithm will never take any longer.
We need not make some educated guess about the running time and hope that it never gets much worse.
For example, in searching a database for a particular piece of information, the searching algorithm’s worst case will often occur when the information is not present in the database.
In some applications, searches for absent information may be frequent.
In some particular cases, we shall be interested in the average-case running time of an algorithm; we shall see the technique of probabilistic analysis applied to various algorithms throughout this book.
The scope of average-case analysis is limited, because it may not be apparent what constitutes an “average” input for a particular problem.
Often, we shall assume that all inputs of a given size are equally likely.
In practice, this assumption may be violated, but we can sometimes use a randomized algorithm, which makes random choices, to allow a probabilistic analysis and yield an expected running time.
We explore randomized algorithms more in Chapter 5 and in several other subsequent chapters.
We used some simplifying abstractions to ease our analysis of the INSERTIONSORT procedure.
First, we ignored the actual cost of each statement, using the constants ci to represent these costs.
Then, we observed that even these constants give us more detail than we really need: we expressed the worst-case running time as an2 C bn C c for some constants a, b, and c that depend on the statement costs ci.
We thus ignored not only the actual statement costs, but also the abstract costs ci.
We shall now make one more simplifying abstraction: it is the rate of growth, or order of growth, of the running time that really interests us.
We therefore consider only the leading term of a formula (e.g., an2), since the lower-order terms are relatively insigniﬁcant for large values of n.
We also ignore the leading term’s constant coefﬁcient, since constant factors are less signiﬁcant than the rate of growth in determining computational efﬁciency for large inputs.
For insertion sort, when we ignore the lower-order terms and the leading term’s constant coefﬁcient, we are left with the factor of n2 from the leading term.
We write that insertion sort has a worst-case running time of ‚.n2/ (pronounced “theta of n-squared”)
We usually consider one algorithm to be more efﬁcient than another if its worstcase running time has a lower order of growth.
Due to constant factors and lowerorder terms, an algorithm whose running time has a higher order of growth might take less time for small inputs than an algorithm whose running time has a lower.
How many elements of the input sequence need to be checked on the average, assuming that the element being searched for is equally likely to be any element in the array? How about in the worst case? What are the average-case and worst-case running times of linear search in ‚-notation? Justify your answers.
We’ll use divideand-conquer to design a sorting algorithm whose worst-case running time is much less than that of insertion sort.
Many useful algorithms are recursive in structure: to solve a given problem, they call themselves recursively one or more times to deal with closely related subproblems.
These algorithms typically follow a divide-and-conquer approach: they break the problem into several subproblems that are similar to the original problem but smaller in size, solve the subproblems recursively, and then combine these solutions to create a solution to the original problem.
The divide-and-conquer paradigm involves three steps at each level of the recursion:
Divide the problem into a number of subproblems that are smaller instances of the same problem.
If the subproblem sizes are small enough, however, just solve the subproblems in a straightforward manner.
Combine the solutions to the subproblems into the solution for the original problem.
Divide: Divide the n-element sequence to be sorted into two subsequences of n=2 elements each.
Combine: Merge the two sorted subsequences to produce the sorted answer.
We repeat this step until one input pile is empty, at which time we just take the remaining input pile and place it face down onto the output pile.
Computationally, each basic step takes constant time, since we are comparing just the two top cards.
Since we perform at most n basic steps, merging takes ‚.n/ time.
We must show that this loop invariant holds prior to the ﬁrst iteration of the for loop of lines 12–17, that each iteration of the loop maintains the invariant, and that the invariant provides a useful property to show correctness when the loop terminates.
When an algorithm contains a recursive call to itself, we can often describe its running time by a recurrence equation or recurrence, which describes the overall running time on a problem of size n in terms of the running time on smaller inputs.
We can then use mathematical tools to solve the recurrence and provide bounds on the performance of the algorithm.
The lengths of the sorted sequences being merged increase as the algorithm progresses from bottom to top.
In Chapter 4, we shall see how to solve common recurrences of this form.
Although the pseudocode for MERGE-SORT works correctly when the number of elements is not even, our recurrence-based analysis is simpliﬁed if we assume that.
Each divide step then yields two subsequences of size exactly n=2
In Chapter 4, we shall see that this assumption does not affect the order of growth of the solution to the recurrence.
We reason as follows to set up the recurrence for T .n/, the worst-case running time of merge sort on n numbers.
Divide: The divide step just computes the middle of the subarray, which takes constant time.
This sum is a linear function of n, that is, ‚.n/
It is unlikely that the same constant exactly represents both the time to solve problems of size 1 and the time per array element of the divide and combine steps.
We can get around this problem by letting c be the larger of these times and understanding that our recurrence gives an upper bound on the running time, or by letting c be the lesser of these times and understanding that our recurrence gives a lower bound on the running time.
Both bounds are on the order of n lg n and, taken together, give a ‚.n lgn/ running time.
Part (a) of the ﬁgure shows T .n/, which we expand in part (b) into an equivalent tree representing the recurrence.
The cn term is the root (the cost incurred at the top level of recursion), and the two subtrees of the root are the two smaller recurrences T .n=2/
Part (c) shows this process carried one step further by expanding T .n=2/
The cost incurred at each of the two subnodes at the second level of recursion is cn=2
We continue expanding each node in the tree by breaking it into its constituent parts as determined by the recurrence, until the problem sizes get down to 1, each with a cost of c.
Next, we add the costs across each level of the tree.
The bottom level has n nodes, each contributing a cost of c, for a total cost of cn.
The base case occurs when n D 1, in which case the tree has only one level.
To compute the total cost represented by the recurrence (2.2), we simply add up the costs of all the levels.
Ignoring the low-order term and the constant c gives the desired result of ‚.n lg n/
Part (a) shows T .n/, which progressively expands in (b)–(d) to form the recursion tree.
The fully expanded tree in part (d) has lgn C 1 levels (i.e., it has height lgn, as indicated), and each level contributes a total cost of cn.
The total cost, therefore, is cn lg nC cn, which is ‚.n lg n/
Thus, it makes sense to coarsen the leaves of the recursion by using insertion sort within merge sort when.
Consider a modiﬁcation to merge sort in which n=k sublists of length k are sorted using insertion sort and then merged using the standard merging mechanism, where k is a value to be determined.
Show that insertion sort can sort the n=k sublists, each of length k, in ‚.nk/ worst-case time.
Show how to merge the sublists in ‚.n lg.n=k// worst-case time.
To prove that BUBBLESORT is correct, we need to prove that it terminates and that.
In order to show that BUBBLESORT actually sorts, what else do we need to prove?
State precisely a loop invariant for the for loop in lines 2–4, and prove that this.
Your proof should use the structure of the loop invariant proof presented in this chapter.
Your proof should use the structure of the loop invariant proof presented in this chapter.
What is the worst-case running time of bubblesort? How does it compare to the running time of insertion sort?
The following code fragment implements Horner’s rule for evaluating a polynomial.
In terms of ‚-notation, what is the running time of this code fragment for Horner’s rule?
What is the running time of this algorithm? How does it compare to Horner’s rule?
Following the structure of the loop invariant proof presented in this chapter, use this loop invariant to show that, at termination, y DPnkD0 akxk.
What is the relationship between the running time of insertion sort and the number of inversions in the input array? Justify your answer.
Give an algorithm that determines the number of inversions in any permutation on n elements in ‚.n lg n/ worst-case time.
They also popularized the use of recurrence relations to describe the running times of recursive algorithms.
Knuth [211] provides an encyclopedic treatment of many sorting algorithms.
His comparison of sorting algorithms (page 381) includes exact step-counting analyses, like the one we performed here for insertion sort.
Knuth’s discussion of insertion sort encompasses several variations of the algorithm.
The most important of these is Shell’s sort, introduced by D.
Shell, which uses insertion sort on periodic subsequences of the input to produce a faster sorting algorithm.
The early history of proving programs correct is described by Gries [153], who credits P.
The textbook by Mitchell [256] describes more recent progress in proving programs correct.
The order of growth of the running time of an algorithm, deﬁned in Chapter 2, gives a simple characterization of the algorithm’s efﬁciency and also allows us to compare the relative performance of alternative algorithms.
Although we can sometimes determine the exact running time of an algorithm, as we did for insertion sort in Chapter 2, the extra precision is not usually worth the effort of computing it.
For large enough inputs, the multiplicative constants and lower-order terms of an exact running time are dominated by the effects of the input size itself.
When we look at input sizes large enough to make only the order of growth of the running time relevant, we are studying the asymptotic efﬁciency of algorithms.
That is, we are concerned with how the running time of an algorithm increases with the size of the input in the limit, as the size of the input increases without bound.
Usually, an algorithm that is asymptotically more efﬁcient will be the best choice for all but very small inputs.
This chapter gives several standard methods for simplifying the asymptotic analysis of algorithms.
The next section begins by deﬁning several types of “asymptotic notation,” of which we have already seen an example in ‚-notation.
We then present several notational conventions used throughout this book, and ﬁnally we review the behavior of functions that commonly arise in the analysis of algorithms.
Such notations are convenient for describing the worst-case running-time function T .n/, which usually is deﬁned only on integer input sizes.
For example, we might extend the notation to the domain of real numbers or, alternatively, restrict it to a subset of the natural numbers.
We should make sure, however, to understand the precise meaning of the notation so that when we abuse, we do not misuse it.
This section deﬁnes the basic asymptotic notations and also introduces some common abuses.
We will use asymptotic notation primarily to describe the running times of algorithms, as when we wrote that insertion sort’s worst-case running time is ‚.n2/
Recall that we characterized insertion sort’s worst-case running time as an2CbnCc, for some constants a, b, and c.
By writing that insertion sort’s running time is ‚.n2/, we abstracted away some details of this function.
In this book, the functions to which we apply asymptotic notation will usually characterize the running times of algorithms.
But asymptotic notation can apply to functions that characterize some other aspect of algorithms (the amount of space they use, for example), or even to functions that have nothing whatsoever to do with algorithms.
Even when we use asymptotic notation to apply to the running time of an algorithm, we need to understand which running time we mean.
Often, however, we wish to characterize the running time no matter what the input.
In other words, we often wish to make a blanket statement that covers all inputs, not just the worst case.
We shall see asymptotic notations that are well suited to characterizing running times no matter what the input.
Instead, we will usually write “f .n/ D ‚.g.n//” to express the same notion.
You might be confused because we abuse equality in this way, but we shall see later in this section that doing so has its advantages.
An asymptotically positive function is one that is positive for all sufﬁciently large n.
Consequently, the function g.n/ itself must be asymptotically nonnegative, or else the set ‚.g.n// is empty.
We shall therefore assume that every function used within ‚-notation is asymptotically nonnegative.
This assumption holds for the other asymptotic notations deﬁned in this chapter as well.
Intuitively, the lower-order terms of an asymptotically positive function can be ignored in determining asymptotically tight bounds because they are insigniﬁcant for large n.
When n is large, even a tiny fraction of the highest-order term sufﬁces to dominate the lower-order terms.
This latter notation is a minor abuse, however, because the.
The ‚-notation asymptotically bounds a function from above and below.
When we have only an asymptotic upper bound, we use O-notation.
For a given function g.n/, we denote by O.g.n// (pronounced “big-oh of g of n” or sometimes just “oh of g of n”) the set of functions O.g.n// D ff .n/ W there exist positive constants c and n0 such that.
If you have seen O-notation before, you might ﬁnd it strange that we should write, for example, n D O.n2/
In the literature, we sometimes ﬁnd O-notation informally describing asymptotically tight bounds, that is, what we have deﬁned using ‚-notation.
In this book, however, when we write f .n/ D O.g.n//, we are merely claiming that some constant multiple of g.n/ is an asymptotic upper bound on f .n/, with no claim about how tight an upper bound it is.
Distinguishing asymptotic upper bounds from asymptotically tight bounds is standard in the algorithms literature.
Using O-notation, we can often describe the running time of an algorithm merely by inspecting the algorithm’s overall structure.
Since O-notation describes an upper bound, when we use it to bound the worstcase running time of an algorithm, we have a bound on the running time of the algorithm on every input—the blanket statement we discussed earlier.
Thus, the O.n2/ bound on worst-case running time of insertion sort also applies to its running time on every input.
Technically, it is an abuse to say that the running time of insertion sort is O.n2/, since for a given n, the actual running time varies, depending on the particular input of size n.
Equivalently, we mean that the worst-case running time is O.n2/
From the deﬁnitions of the asymptotic notations we have seen thus far, it is easy to prove the following important theorem (see Exercise 3.1-5)
We have already seen how asymptotic notation can be used within mathematical formulas.
In general, however, when asymptotic notation appears in a formula, we interpret it as standing for some anonymous function that we do not care to name.
Using asymptotic notation in this manner can help eliminate inessential detail and clutter in an equation.
For example, in Chapter 2 we expressed the worst-case running time of merge sort as the recurrence.
The number of anonymous functions in an expression is understood to be equal to the number of times the asymptotic notation appears.
In some cases, asymptotic notation appears on the left-hand side of an equation, as in.
In other words, the right-hand side of an equation provides a coarser level of detail than the left-hand side.
We can chain together a number of such relationships, as in.
We can interpret each equation separately by the rules above.
The asymptotic upper bound provided by O-notation may or may not be asymptotically tight.
We use o-notation to denote an upper bound that is not asymptotically tight.
Some authors use this limit as a deﬁnition of the o-notation; the deﬁnition in this book also restricts the anonymous functions to be asymptotically nonnegative.
That is, f .n/ becomes arbitrarily large relative to g.n/ as n approaches inﬁnity.
Many of the relational properties of real numbers apply to asymptotic comparisons as well.
For the following, assume that f .n/ and g.n/ are asymptotically positive.
Because these properties hold for asymptotic notations, we can draw an analogy between the asymptotic comparison of two functions f and g and the comparison of two real numbers a and b:
One property of real numbers, however, does not carry over to asymptotic notation:
For a given function g.n;m/, we denote by O.g.n;m// the set of functions.
This section reviews some standard mathematical functions and notations and explores the relationships among them.
The ﬂoor function f .x/ D bxc is monotonically increasing, as is the ceiling function f .x/ D dxe.
Given a nonnegative integer d , a polynomial in n of degree d is a function p.n/ of the form.
We can relate the rates of growth of polynomials and exponentials by the following fact.
An important notational convention we shall adopt is that logarithm functions will apply only to the next term in the formula, so that lg n C k will mean .lg n/ C k and not lg.nC k/
By equation (3.15), changing the base of a logarithm from one constant to another changes the value of the logarithm by only a constant factor, and so we shall often use the notation “lg n” when we don’t care about constant factors, such as in O-notation.
Computer scientists ﬁnd 2 to be the most natural base for logarithms because so many algorithms and data structures involve splitting a problem into two parts.
Thus, any positive polynomial function grows faster than any polylogarithmic function.
We use the notation f .i/.n/ to denote the function f .n/ iteratively applied i times to an initial value of n.
Formally, let f .n/ be a function over the reals.
Use the deﬁnitions of the asymptotic notations to prove the following properties.
Rank the following functions by order of growth; that is, ﬁnd an arrangement.
Some authors also deﬁne O in a slightly different manner; let’s use O 0 for the alternative deﬁnition.
We say that f .n/ D O 0.g.n// if and only if jf .n/j D O.g.n//
Not all authors deﬁne the asymptotic notations in the same way, although the various deﬁnitions agree in most common situations.
Some of the alternative definitions encompass functions that are not asymptotically nonnegative, as long as their absolute values are appropriately bounded.
In Section 2.3.1, we saw how merge sort serves as an example of the divide-andconquer paradigm.
Divide the problem into a number of subproblems that are smaller instances of the same problem.
If the subproblem sizes are small enough, however, just solve the subproblems in a straightforward manner.
Combine the solutions to the subproblems into the solution for the original problem.
When the subproblems are large enough to solve recursively, we call that the recursive case.
Once the subproblems become small enough that we no longer recurse, we say that the recursion “bottoms out” and that we have gotten down to the base case.
Sometimes, in addition to subproblems that are smaller instances of the same problem, we have to solve subproblems that are not quite the same as the original problem.
We consider solving such subproblems as part of the combine step.
Recurrences go hand in hand with the divide-and-conquer paradigm, because they give us a natural way to characterize the running times of divide-and-conquer algorithms.
A recurrence is an equation or inequality that describes a function in terms.
For example, in Section 2.3.2 we described the worst-case running time T .n/ of the MERGE-SORT procedure by the recurrence.
We use techniques for bounding summations to solve the recurrence.
The master method provides bounds for recurrences of the form.
In practice, we neglect certain technical details when we state and solve recurrences.
Technically, the recurrence describing the worst-case running time of MERGE-SORT is really.
Boundary conditions represent another class of details that we typically ignore.
Since the running time of an algorithm on a constant-sized input is a constant, the recurrences that arise from the running times of algorithms generally have T .n/ D ‚.1/ for sufﬁciently small n.
Consequently, for convenience, we shall generally omit statements of the boundary conditions of recurrences and assume that T .n/ is constant for small n.
The reason is that although changing the value of T .1/ changes the exact solution to the recurrence, the solution typically doesn’t change by more than a constant factor, and so the order of growth is unchanged.
When we state and solve recurrences, we often omit ﬂoors, ceilings, and boundary conditions.
We forge ahead without these details and later determine whether or not they matter.
They usually do not, but you should know when they do.
Experience helps, and so do some theorems stating that these details do not affect the asymptotic bounds of many recurrences characterizing divide-and-conquer algorithms (see Theorem 4.1)
In this chapter, however, we shall address some of these details and illustrate the ﬁne points of recurrence solution methods.
Suppose that you been offered the opportunity to invest in the Volatile Chemical Corporation.
Like the chemicals the company produces, the stock price of the Volatile Chemical Corporation is rather volatile.
You are allowed to buy one unit of stock only one time and then sell it at a later date, buying and selling after the close of trading for the day.
To compensate for this restriction, you are allowed to learn what the price of the stock will be in the future.
Of course, you would want to “buy low, sell high”—buy at the lowest possible price and later on sell at the highest possible price—to maximize your proﬁt.
Unfortunately, you might not be able to buy at the lowest price and then sell at the highest price within a given period.
You might think that you can always maximize proﬁt by either buying at the lowest price or selling at the highest price.
If this strategy always worked, then it would be easy to determine how to maximize proﬁt: ﬁnd the highest and lowest prices, and then work left from the highest price to ﬁnd the lowest prior price, work right from the lowest price to ﬁnd the highest later price, and take the pair with the greater difference.
The horizontal axis of the chart indicates the day, and the vertical axis shows the price.
The bottom row of the table gives the change in price from the previous day.
Figure 4.2 An example showing that the maximum proﬁt does not always start at the lowest price or end at the highest price.
Again, the horizontal axis indicates the day, and the vertical axis shows the price.
We can easily devise a brute-force solution to this problem: just try every possible pair of buy and sell dates in which the buy date precedes the sell date.
So let us seek a more efﬁcient solution to the maximum-subarray problem.
When doing so, we will usually speak of “a” maximum subarray rather than “the” maximum subarray, since there could be more than one subarray that achieves the maximum sum.
The maximum-subarray problem is interesting only when the array contains some negative numbers.
If all the array entries were nonnegative, then the maximum-subarray problem would present no challenge, since the entire array would give the greatest sum.
This recurrence is the same as recurrence (4.1) for merge sort.
Thus, we see that the divide-and-conquer method yields an algorithm that is asymptotically faster than the brute-force method.
With merge sort and now the maximum-subarray problem, we begin to get an idea of how powerful the divideand-conquer method can be.
Sometimes it will yield the asymptotically fastest algorithm for a problem, and other times we can do even better.
As Exercise 4.1-5 shows, there is in fact a linear-time algorithm for the maximum-subarray problem, and it does not use divide-and-conquer.
How would you change any of the algorithms that do not allow empty subarrays to permit an empty subarray to be the result?
The for loop of lines 3–7 computes the entries of each row i , and within a given row i , the.
Again, we use index calculations to place the results of the matrix additions into the correct positions of matrix C , with an overhead of ‚.1/ time per entry.
The total time for the recursive case, therefore, is the sum of the partitioning time, the time for all the recursive calls, and the time to add the matrices resulting from the recursive calls:
Notice that if we implemented partitioning by copying matrices, which would cost ‚.n2/ time, the recurrence would not change, and hence the overall running time would increase by only a constant factor.
The factor of 2 determined how many children each tree node had, which in turn determined how many terms contributed to the sum at each level of the tree.
Bear in mind, therefore, that although asymptotic notation subsumes constant multiplicative factors, recursive notation such as T .n=2/ does not.
We have traded off one matrix multiplication for a constant number of matrix additions.
Once we understand recurrences and their solutions, we shall see that this tradeoff actually leads to a lower asymptotic running time.
The notes at the end of this chapter discuss some of the practical aspects of Strassen’s algorithm.
Now that we have seen how recurrences characterize the running times of divideand-conquer algorithms, we will learn how to solve recurrences.
We substitute the guessed solution for the function when applying the inductive hypothesis to smaller values; hence the name “substitution method.” This method is powerful, but we must be able to guess the form of the answer in order to apply it.
Unfortunately, there is no general way to guess the correct solutions to recurrences.
Fortunately, though, you can use some heuristics to help you become a good guesser.
You can also use recursion trees, which we shall see in Section 4.4, to generate good guesses.
If a recurrence is similar to one you have seen before, then guessing a similar solution is reasonable.
Consequently, we make the guess that T .n/ D O.n lg n/, which you can verify as correct by using the substitution method (see Exercise 4.3-6)
Sometimes you might correctly guess an asymptotic bound on the solution of a recurrence, but somehow the math fails to work out in the induction.
The problem frequently turns out to be that the inductive assumption is not strong enough to prove the detailed bound.
If you revise the guess by subtracting a lower-order term when you hit such a snag, the math often goes through.
Sometimes, a little algebraic manipulation can make an unknown recurrence similar to one you have seen before.
Indeed, this new recurrence has the same solution: S.m/ D O.m lgm/
Although you can use the substitution method to provide a succinct proof that a solution to a recurrence is correct, you might have trouble coming up with a good guess.
Drawing out a recursion tree, as we did in our analysis of the merge sort recurrence in Section 2.3.2, serves as a straightforward way to devise a good guess.
In a recursion tree, each node represents the cost of a single subproblem somewhere in the set of recursive function invocations.
We sum the costs within each level of the tree to obtain a set of per-level costs, and then we sum all the per-level costs to determine the total cost of all levels of the recursion.
A recursion tree is best used to generate a good guess, which you can then verify by the substitution method.
When using a recursion tree to generate a good guess, you can often tolerate a small amount of “sloppiness,” since you will be verifying your guess later on.
If you are very careful when drawing out a recursion tree and summing the costs, however, you can use a recursion tree as a direct proof of a solution to a recurrence.
In this section, we will use recursion trees to generate good guesses, and in Section 4.6, we will use recursion trees directly to prove the theorem that forms the basis of the master method.
We start by focusing on ﬁnding an upper bound for the solution.
For convenience, we assume that n is an exact power of 4 (another example of tolerable sloppiness) so that all subproblem sizes are integers.
Part (a) of the ﬁgure shows T .n/, which we expand in part (b) into an equivalent tree representing the recurrence.
Part (c) shows this process carried one step further by expanding each node with cost T .n=4/ from part (b)
The cost for each of the three children of the root is c.n=4/2
We continue expanding each node in the tree by breaking it into its constituent parts as determined by the recurrence.
Part (a) shows T .n/, which progressively expands in (b)–(d) to form the recursion tree.
Because subproblem sizes decrease by a factor of 4 each time we go down one level, we eventually must reach a boundary condition.
How far from the root do we reach one? The subproblem size for a node at depth i is n=4i.
Now we add up the costs over all levels to determine the cost for the entire tree:
This last formula looks somewhat messy until we realize that we can again take advantage of small amounts of sloppiness and use an inﬁnite decreasing geometric series as an upper bound.
Backing up one step and applying equation (A.6), we have.
Since the root’s contribution to the total cost is cn2, the root contributes a constant fraction of the total cost.
In other words, the cost of the root dominates the total cost of the tree.
In another, more intricate, example, Figure 4.6 shows the recursion tree for.
As before, we let c represent the constant factor in the O.n/ term.
When we add the values across the levels of the recursion tree shown in the ﬁgure, we get a value of cn for every level.
Intuitively, we expect the solution to the recurrence to be at most the number of levels times the cost of each level, or O.cn log3=2 n/ D O.n lg n/
Figure 4.6 shows only the top levels of the recursion tree, however, and not every level in the tree contributes a cost of cn.
Moreover, as we go down from the root, more and more internal nodes are absent.
Consequently, levels toward the bottom of the recursion tree contribute less than cn to the total cost.
We could work out an accurate accounting of all costs, but remember that we are just trying to come up with a guess to use in the substitution method.
Let us tolerate the sloppiness and attempt to show that a guess of O.n lg n/ for the upper bound is correct.
The master method provides a “cookbook” method for solving recurrences of the form.
The recurrence (4.20) describes the running time of an algorithm that divides a problem of size n into a subproblems, each of size n=b, where a and b are positive constants.
The a subproblems are solved recursively, each in time T .n=b/
The function f .n/ encompasses the cost of dividing the problem and combining the results of the subproblems.
As a matter of technical correctness, the recurrence is not actually well deﬁned, because n=b might not be an integer.
Replacing each of the a terms T .n=b/ with either T .bn=bc/ or T .dn=be/ will not affect the asymptotic behavior of the recurrence, however.
We normally ﬁnd it convenient, therefore, to omit the ﬂoor and ceiling functions when writing divide-and-conquer recurrences of this form.
Before applying the master theorem to some examples, let’s spend a moment trying to understand what it says.
In each of the three cases, we compare the function f .n/ with the function nlogb a.
Intuitively, the larger of the two functions determines the solution to the recurrence.
Beyond this intuition, you need to be aware of some technicalities.
In the ﬁrst case, not only must f .n/ be smaller than nlogb a, it must be polynomially smaller.
Note that the three cases do not cover all the possibilities for f .n/
If the function f .n/ falls into one of these gaps, or if the regularity condition in case 3 fails to hold, you cannot use the master method to solve the recurrence.
To use the master method, we simply determine which case (if any) of the master theorem applies and write down the answer.
You might mistakenly think that case 3 should apply, since.
As is our practice, we omit stating the base case in the recurrence.
This section contains a proof of the master theorem (Theorem 4.1)
You do not need to understand the proof in order to apply the master theorem.
This part gives all the intuition needed to understand why the master theorem is true.
The second part shows how to extend the analysis to all positive integers n; it applies mathematical technique to the problem of handling ﬂoors and ceilings.
In this section, we shall sometimes abuse our asymptotic notation slightly by using it to describe the behavior of functions that are deﬁned only over exact powers of b.
Nevertheless, we must always be on guard when we use asymptotic notation over a limited domain lest we draw improper conclusions.
For example, proving that T .n/ D O.n/ when n is an exact power of 2 does not guarantee that T .n/ D O.n/
Because of this sort of drastic consequence, we shall never use asymptotic notation over a limited domain without making it absolutely clear from the context that we are doing so.
The ﬁrst reduces the problem of solving the master recurrence to the problem of evaluating an expression that contains a summation.
The third lemma puts the ﬁrst two together to prove a version of the master theorem for the case in which n is an exact power of b.
The root of the tree has cost f .n/, and it has a children, each with cost f .n=b/
Figure 4.7 The recursion tree generated by T .n/ D aT .n=b/Cf .n/
The tree is a complete a-ary tree with nlogb a leaves and height logb n.
The cost of the nodes at each depth is shown at the right, and their sum is given in equation (4.21)
In general, there are aj nodes at depth j , and each has cost f .n=bj /
There are alogb n D nlogb a leaves in the tree.
In the underlying divide-and-conquer algorithm, this sum represents the costs of dividing problems into subproblems and then recombining the subproblems.
The summation in equation (4.21) describes the cost of the dividing and combining steps in the underlying divide-and-conquer algorithm.
The next lemma provides asymptotic bounds on the summation’s growth.
Thus, we can conclude that g.n/ D ‚.f .n// for exact powers of b.
With case 3 proved, the proof of the lemma is complete.
We can now prove a version of the master theorem for the case in which n is an exact power of b.
Then T .n/ has the following asymptotic bounds for exact powers of b:
To complete the proof of the master theorem, we must now extend our analysis to the situation in which ﬂoors and ceilings appear in the master recurrence, so that the recurrence is deﬁned for all integers, not for just exact powers of b.
As we go down in the recursion tree, we obtain a sequence of recursive invocations on the arguments.
Let us denote the j th element in the sequence by nj , where.
Figure 4.8 The recursion tree generated by T .n/ D aT .dn=be/Cf .n/
We have now proved the upper bounds in the master theorem for all integers n.
Throughout this book, we assume that parameter passing during procedure calls takes constant time, even if an N -element array is being passed.
This assumption is valid in most systems because a pointer to the array is passed, not the array itself.
Time D ‚.N /, where N is the size of the array.
Give recurrences for the worst-case running times of binary search when arrays are passed using each of the three methods above, and give good upper bounds on the solutions of the recurrences.
Let N be the size of the original problem and n be the size of a subproblem.
Redo part (a) for the MERGE-SORT algorithm from Section 2.3.1
Give asymptotic upper and lower bounds for T .n/ in each of the following recurrences.
Assume that T .n/ is constant for sufﬁciently small n.
Make your bounds as tight as possible, and justify your answers.
This problem develops properties of the Fibonacci numbers, which are deﬁned by recurrence (3.22)
We shall use the technique of generating functions to solve the Fibonacci recurrence.
Deﬁne the generating function (or formal power series) F as.
Professor Diogenes has n supposedly identical integrated-circuit chips that in principle are capable of testing each other.
The professor’s test jig accommodates two chips at a time.
When the jig is loaded, each chip tests the other and reports whether it is good or bad.
A good chip always reports accurately whether the other chip is good or bad, but the professor cannot trust the answer of a bad chip.
Thus, the four possible outcomes of a test are as follows: Chip A says Chip B says Conclusion B is good A is good both are good, or both are bad B is good A is bad at least one is bad B is bad A is good at least one is bad B is bad A is bad at least one is bad.
Show that if more than n=2 chips are bad, the professor cannot necessarily determine which chips are good using any strategy based on this kind of pairwise test.
Assume that the bad chips can conspire to fool the professor.
Consider the problem of ﬁnding a single good chip from among n chips, assuming that more than n=2 of the chips are good.
Show that bn=2c pairwise tests are sufﬁcient to reduce the problem to one of nearly half the size.
Give and solve the recurrence that describes the number of tests.
Hint: For the “if” part, use induction separately on rows and columns.
Construct a submatrix A0 of A consisting of the even-numbered rows of A.
Recursively determine the leftmost minimum for each row of A0
Then compute the leftmost minimum in the odd-numbered rows of A.
Explain how to compute the leftmost minimum in the odd-numbered rows of A (given that the leftmost minimum of the even-numbered rows is known) in O.mC n/ time.
Write the recurrence describing the running time of the algorithm described in part (d)
It might have been used well before then, however; according to Heideman, Johnson, and Burrus [163], C.
Gauss devised the ﬁrst fast Fourier transform algorithm in 1805, and Gauss’s formulation breaks the problem into smaller subproblems whose solutions are combined.
From a practical point of view, Strassen’s algorithm is often not the method of choice for matrix multiplication, for four reasons:
When the matrices are sparse, methods tailored for sparse matrices are faster.
The submatrices formed at the levels of recursion consume space.
Higham [167] demonstrated that the difference in numerical stability had been overemphasized; although Strassen’s algorithm is too numerically unstable for some applications, it is within acceptable limits for others.
Bailey, Lee, and Simon [32] discuss techniques for reducing the memory requirements for Strassen’s algorithm.
The exact value of the crossover point is highly system dependent.
D’Alberto and Nicolau [81] developed an adaptive scheme, which determines the crossover point by benchmarking when their software package is installed.
De Moivre introduced the method of generating functions (see Problem 4-4) for solving recurrences.
We describe the result of Akra and Bazzi here, as modiﬁed by Leighton [228]
The Akra-Bazzi method can be somewhat difﬁcult to use, but it serves in solving recurrences that model division of the problem into substantially unequally sized subproblems.
The master method is simpler to use, but it applies only when subproblem sizes are equal.
If you are unfamiliar with the basics of probability theory, you should read Appendix C, which reviews this material.
We shall revisit probabilistic analysis and randomized algorithms several times throughout this book.
Suppose that you need to hire a new ofﬁce assistant.
Your previous attempts at hiring have been unsuccessful, and you decide to use an employment agency.
You interview that person and then decide either to hire that person or not.
You must pay the employment agency a small fee to interview an applicant.
To actually hire an applicant is more costly, however, since you must ﬁre your current ofﬁce assistant and pay a substantial hiring fee to the employment agency.
You are committed to having, at all times, the best possible person for the job.
Therefore, you decide that, after interviewing each applicant, if that applicant is better qualiﬁed than the current ofﬁce assistant, you will ﬁre the current ofﬁce assistant and hire the new applicant.
You are willing to pay the resulting price of this strategy, but you wish to estimate what that price will be.
The procedure HIRE-ASSISTANT, given below, expresses this strategy for hiring in pseudocode.
It assumes that the candidates for the ofﬁce assistant job are numbered 1 through n.
The procedure assumes that you are able to, after interviewing candidate i , determine whether candidate i is the best candidate you have seen so far.
To initialize, the procedure creates a dummy candidate, numbered 0, who is less qualiﬁed than each of the other candidates.
We focus not on the running time of HIRE-ASSISTANT, but instead on the costs incurred by interviewing and hiring.
On the surface, analyzing the cost of this algorithm may seem very different from analyzing the running time of, say, merge sort.
The analytical techniques used, however, are identical whether we are analyzing cost or running time.
In either case, we are counting the number of times certain basic operations are executed.
Interviewing has a low cost, say ci , whereas hiring is expensive, costing ch.
Letting m be the number of people hired, the total cost associated with this algorithm is O.cin C chm/
No matter how many people we hire, we always interview n candidates and thus always incur the cost cin associated with interviewing.
This scenario serves as a model for a common computational paradigm.
We often need to ﬁnd the maximum or minimum value in a sequence by examining each element of the sequence and maintaining a current “winner.” The hiring problem models how often we update our notion of which element is currently winning.
In the worst case, we actually hire every candidate that we interview.
This situation occurs if the candidates come in strictly increasing order of quality, in which case we hire n times, for a total hiring cost of O.chn/
Of course, the candidates do not always come in increasing order of quality.
In fact, we have no idea about the order in which they arrive, nor do we have any control over this order.
Therefore, it is natural to ask what we expect to happen in a typical or average case.
Probabilistic analysis is the use of probability in the analysis of problems.
Most commonly, we use probabilistic analysis to analyze the running time of an algorithm.
Sometimes we use it to analyze other quantities, such as the hiring cost.
In order to perform a probabilistic analysis, we must use knowledge of, or make assumptions about, the distribution of the inputs.
Then we analyze our algorithm, computing an average-case running time, where we take the average over the distribution of the possible inputs.
Thus we are, in effect, averaging the running time over all possible inputs.
When reporting such a running time, we will refer to it as the average-case running time.
We must be very careful in deciding on the distribution of inputs.
For some problems, we may reasonably assume something about the set of all possible inputs, and then we can use probabilistic analysis as a technique for designing an efﬁcient algorithm and as a means for gaining insight into a problem.
For other problems, we cannot describe a reasonable input distribution, and in these cases we cannot use probabilistic analysis.
Section 5.2 contains a probabilistic analysis of the hiring problem.
In order to use probabilistic analysis, we need to know something about the distribution of the inputs.
In many cases, we know very little about the input distribution.
Even if we do know something about the distribution, we may not be able to model this knowledge computationally.
Yet we often can use probability and randomness as a tool for algorithm design and analysis, by making the behavior of part of the algorithm random.
In the hiring problem, it may seem as if the candidates are being presented to us in a random order, but we have no way of knowing whether or not they really are.
Thus, in order to develop a randomized algorithm for the hiring problem, we must have greater control over the order in which we interview the candidates.
We say that the employment agency has n candidates, and they send us a list of the candidates in advance.
On each day, we choose, randomly, which candidate to interview.
Instead of relying on a guess that the candidates come to us in a random order, we have instead gained control of the process and enforced a random order.
When analyzing the running time of a randomized algorithm, we take the expectation of the running time over the distribution of values returned by the random number generator.
We distinguish these algorithms from those in which the input is random by referring to the running time of a randomized algorithm as an expected running time.
In general, we discuss the average-case running time when the probability distribution is over the inputs to the algorithm, and we discuss the expected running time when the algorithm itself makes random choices.
What is the expected running time of your procedure, as a function of a and b?
What is the expected running time of your algorithm as a function of p?
In order to analyze many algorithms, including the hiring problem, we use indicator random variables.
Indicator random variables provide a convenient method for converting between probabilities and expectations.
Suppose we are given a sample space S and an event A.
Then the indicator random variable I fAg associated with event A is deﬁned as.
As a simple example, let us determine the expected number of heads that we obtain when ﬂipping a fair coin.
Our sample space is S D fH;T g, with Pr fH g D Pr fT g D 1=2
We can then deﬁne an indicator random variable XH , associated with the coin coming up heads, which is the event H.
The expected number of heads obtained in one ﬂip of the coin is simply the expected value of our indicator variable XH :
Thus the expected number of heads obtained by one ﬂip of a fair coin is 1=2
As the following lemma shows, the expected value of an indicator random variable associated with an event A is equal to the probability that A occurs.
Proof By the deﬁnition of an indicator random variable from equation (5.1) and the deﬁnition of expected value, we have.
Although indicator random variables may seem cumbersome for an application such as counting the expected number of heads on a ﬂip of a single coin, they are useful for analyzing situations in which we perform repeated random trials.
For example, indicator random variables give us a simple way to arrive at the result of equation (C.37)
The simpler method proposed in equation (C.38) instead uses indicator random variables implicitly.
Making this argument more explicit, we let Xi be the indicator random variable associated with the event in which the i th ﬂip comes up heads: Xi D I fthe i th ﬂip results in the event H g.
Let X be the random variable denoting the total number of heads in the n coin ﬂips, so that.
We wish to compute the expected number of heads, and so we take the expectation of both sides of the above equation to obtain.
The above equation gives the expectation of the sum of n indicator random variables.
By Lemma 5.1, we can easily compute the expectation of each of the random variables.
By equation (C.21)—linearity of expectation—it is easy to compute the expectation of the sum: it equals the sum of the expectations of the n random variables.
Linearity of expectation makes the use of indicator random variables a powerful analytical technique; it applies even when there is dependence among the random variables.
We now can easily compute the expected number of heads:
Returning to the hiring problem, we now wish to compute the expected number of times that we hire a new ofﬁce assistant.
In order to use a probabilistic analysis, we assume that the candidates arrive in a random order, as discussed in the previous section.
We shall see in Section 5.3 how to remove this assumption.
Let X be the random variable whose value equals the number of times we hire a new ofﬁce assistant.
We could then apply the deﬁnition of expected value from equation (C.20) to obtain.
We shall instead use indicator random variables to greatly simplify the calculation.
Lemma 5.2 Assuming that the candidates are presented in a random order, algorithm HIREASSISTANT has an average-case total hiring cost of O.ch lnn/
Proof The bound follows immediately from our deﬁnition of the hiring cost and equation (5.5), which shows that the expected number of hires is approximately ln n.
The average-case hiring cost is a signiﬁcant improvement over the worst-case hiring cost of O.chn/
Each of n customers gives a hat to a hat-check person at a restaurant.
The hat-check person gives the hats back to the customers in a random order.
What is the expected number of customers who get back their own hat?
In the previous section, we showed how knowing a distribution on the inputs can help us to analyze the average-case behavior of an algorithm.
Many times, we do not have such knowledge, thus precluding an average-case analysis.
As mentioned in Section 5.1, we may be able to use a randomized algorithm.
For a problem such as the hiring problem, in which it is helpful to assume that all permutations of the input are equally likely, a probabilistic analysis can guide the development of a randomized algorithm.
Instead of assuming a distribution of inputs, we impose a distribution.
In particular, before running the algorithm, we randomly permute the candidates in order to enforce the property that every permutation is equally likely.
Although we have modiﬁed the algorithm, we still expect to hire a new ofﬁce assistant approximately lnn times.
Let us further explore the distinction between probabilistic analysis and randomized algorithms.
In Section 5.2, we claimed that, assuming that the candidates arrive in a random order, the expected number of times we hire a new ofﬁce assistant is about ln n.
Note that the algorithm here is deterministic; for any particular input, the number of times a new ofﬁce assistant is hired is always the same.
Furthermore, the number of times we hire a new ofﬁce assistant differs for different inputs, and it depends on the ranks of the various candidates.
Consider, on the other hand, the randomized algorithm that ﬁrst permutes the candidates and then determines the best candidate.
In this case, we randomize in the algorithm, not in the input distribution.
Given a particular input, say A3 above, we cannot say how many times the maximum is updated, because this quantity differs with each run of the algorithm.
The third time we run it, we may perform some other number of updates.
Each time we run the algorithm, the execution depends on the random choices made and is likely to differ from the previous execution of the algorithm.
For this algorithm and many other randomized algorithms, no particular input elicits its worst-case behavior.
Even your worst enemy cannot produce a bad input array, since the random permutation makes the input order irrelevant.
The randomized algorithm performs badly only if the random-number generator produces an “unlucky” permutation.
For the hiring problem, the only change needed in the code is to randomly permute the array.
With this simple change, we have created a randomized algorithm whose performance matches that obtained by assuming that the candidates were presented in a random order.
Proof After permuting the input array, we have achieved a situation identical to that of the probabilistic analysis of HIRE-ASSISTANT.
In Lemma 5.2, we make an assumption about the input.
In Lemma 5.3, we make no such assumption, although randomizing the input takes some additional time.
In the remainder of this section, we discuss some issues involved in randomly permuting inputs.
Many randomized algorithms randomize the input by permuting the given input array.
We assume that we are given an array A which, without loss of generality, contains the elements 1 through n.
Our goal is to produce a random permutation of the array.
Lemma 5.4 Procedure PERMUTE-BY-SORTING produces a uniform random permutation of the input, assuming that all priorities are distinct.
We need to show that this invariant is true prior to the ﬁrst loop iteration, that each iteration of the loop maintains the invariant, and that the invariant provides a useful property to show correctness when the loop terminates.
A randomized algorithm is often the simplest and most efﬁcient way to solve a problem.
He questions whether it is true prior to the ﬁrst iteration.
He reasons that we could just as easily declare that an empty subarray contains no 0-permutations.
Rewrite the procedure RANDOMIZE-IN-PLACE so that its associated loop invariant applies to a nonempty subarray prior to the ﬁrst iteration, and modify the proof of Lemma 5.5 for your procedure.
Does this code produce a uniform random permutation? Why or why not?
This advanced section further illustrates probabilistic analysis by way of four examples.
The ﬁrst determines the probability that in a room of k people, two of them share the same birthday.
The second example examines what happens when we randomly toss balls into bins.
The third investigates “streaks” of consecutive heads when we ﬂip coins.
The ﬁnal example analyzes a variant of the hiring problem in which you have to make decisions without actually interviewing all the candidates.
How many people must there be in a room before there is a 50% chance that two of them were born on the same day of the year? The answer is surprisingly few.
The paradox is that it is in fact far fewer than the number of days in a year, or even half the number of days in a year, as we shall see.
The probability that two given people, say i and j , have matching birthdays depends on whether the random selection of birthdays is independent.
We assume from now on that birthdays are independent, so that the probability that i’s birthday.
Thus, the probability that they both fall on the same day is.
Thus, the probability that i and j have the same birthday is the same as the probability that the birthday of one of them falls on a given day.
Notice, however, that this coincidence depends on the assumption that the birthdays are independent.
We can analyze the probability of at least 2 out of k people having matching birthdays by looking at the complementary event.
The probability that at least two of the birthdays match is 1 minus the probability that all the birthdays are different.
Letting X be the random variable that counts the number of pairs of individuals having the same birthday, we have.
Taking expectations of both sides and applying linearity of expectation, we obtain.
Although the exact numbers of people differ for the two situations, they are the same asymptotically: ‚
The tosses are independent, and on each toss the ball is equally likely to end up in any bin.
The probability that a tossed ball lands in any given bin is 1=b.
This model is particularly useful for analyzing hashing (see Chapter 11), and we can answer a variety of interesting questions about the ball-tossing process.
How many balls fall in a given bin? The number of balls that fall in a given bin follows the binomial distribution b.kIn; 1=b/
If we toss n balls, equation (C.37) tells us that the expected number of balls that fall in the given bin is n=b.
How many balls must we toss until every bin contains at least one ball? Let us call a toss in which a ball falls into an empty bin a “hit.” We want to know the expected number n of tosses required to get b hits.
It therefore takes approximately b ln b tosses before we can expect that every bin has a ball.
This problem is also known as the coupon collector’s problem, which says that a person trying to collect each of b different coupons expects to acquire approximately b ln b randomly obtained coupons in order to succeed.
What is the longest streak of consecutive heads that you expect to see? The answer is ‚.lg n/, as the following analysis shows.
Note that Boole’s inequality holds even for events such as these that are not independent.
We now use inequality (5.9) to bound the length of the longest streak.
By equation (5.8), the probability that the group starting in position i comes up all heads is.
Thus, the probability that the longest streak exceeds b.lg n/=2c is nX.
We can now calculate a lower bound on the expected length of the longest streak, beginning with equation (5.10) and proceeding in a manner similar to our analysis of the upper bound:
As with the birthday paradox, we can obtain a simpler but approximate analysis using indicator random variables.
We let Xik D I fAikg be the indicator random variable associated with a streak of heads of length at least k beginning with the i th coin ﬂip.
To count the total number of such streaks, we deﬁne.
By plugging in various values for k, we can calculate the expected number of streaks of length k.
If this number is large (much greater than 1), then we expect many streaks of length k to occur and the probability that one occurs is high.
If k D c lg n, for some positive constant c, we obtain.
As a ﬁnal example, we consider a variant of the hiring problem.
Suppose now that we do not wish to interview all the candidates in order to ﬁnd the best one.
We also do not wish to hire and ﬁre as we ﬁnd better and better applicants.
Instead, we are willing to settle for a candidate who is close to the best, in exchange for hiring exactly once.
We must obey one company requirement: after each interview we must either immediately offer the position to the applicant or immediately reject the applicant.
What is the trade-off between minimizing the amount of interviewing and maximizing the quality of the candidate hired?
We approximate by integrals to bound this summation from above and below.
Each toss is independent, and each ball is equally likely to end up in any bin.
What is the expected number of empty bins? What is the expected number of bins with exactly one ball?
Show that the expected value represented by the counter after n INCREMENT operations have been performed is exactly n.
This problem examines three algorithms for searching for a value x in an unsorted array A consisting of n elements.
Write pseudocode for a procedure RANDOM-SEARCH to implement the strategy above.
Be sure that your algorithm terminates when all indices into A have been picked.
Finally, consider a randomized algorithm SCRAMBLE-SEARCH that works by ﬁrst randomly permuting the input array and then running the deterministic linear search given above on the resulting permuted array.
Which of the three searching algorithms would you use? Explain your answer.
Several variants of the hiring problem have been widely studied.
These problems are more commonly referred to as “secretary problems.” An example of work in this area is the paper by Ajtai, Meggido, and Waarts [11]
This part presents several algorithms that solve the following sorting problem:
In practice, the numbers to be sorted are rarely isolated values.
Each is usually part of a collection of data called a record.
Each record contains a key, which is the value to be sorted.
The remainder of the record consists of satellite data, which are usually carried around with the key.
In practice, when a sorting algorithm permutes the keys, it must permute the satellite data as well.
If each record includes a large amount of satellite data, we often permute an array of pointers to the records rather than the records themselves in order to minimize data movement.
In a sense, it is these implementation details that distinguish an algorithm from a full-blown program.
A sorting algorithm describes the method by which we determine the sorted order, regardless of whether we are sorting individual numbers or large records containing many bytes of satellite data.
Thus, when focusing on the problem of sorting, we typically assume that the input consists only of numbers.
Translating an algorithm for sorting numbers into a program for sorting records.
For example, a program that renders graphical objects which are layered on top of each other might have to sort the objects according to an “above” relation so that it can draw these objects from bottom to top.
We shall see numerous algorithms in this text that use sorting as a subroutine.
We can draw from among a wide variety of sorting algorithms, and they employ a rich set of techniques.
In fact, many important techniques used throughout algorithm design appear in the body of sorting algorithms that have been developed over the years.
In this way, sorting is also a problem of historical interest.
We can prove a nontrivial lower bound for sorting (as we shall do in Chapter 8)
Our best upper bounds match the lower bound asymptotically, and so we know that our sorting algorithms are asymptotically optimal.
Moreover, we can use the lower bound for sorting to prove lower bounds for certain other problems.
Many engineering issues come to the fore when implementing sorting algorithms.
The fastest sorting program for a particular situation may depend on many factors, such as prior knowledge about the keys and satellite data, the memory hierarchy (caches and virtual memory) of the host computer, and the software environment.
Many of these issues are best dealt with at the algorithmic level, rather than by “tweaking” the code.
Because its inner loops are tight, however, it is a fast in-place sorting algorithm for small input sizes.
Recall that a sorting algorithm sorts in place if only a constant number of elements of the input array are ever stored outside the array.
Merge sort has a better asymptotic running time, ‚.n lg n/, but the MERGE procedure it uses does not operate in place.
In this part, we shall introduce two more algorithms that sort arbitrary real numbers.
Heapsort, presented in Chapter 6, sorts n numbers in place in O.n lg n/ time.
It uses an important data structure, called a heap, with which we can also implement a priority queue.
Its expected running time is ‚.n lg n/, however, and it generally outperforms heapsort in practice.
Like insertion sort, quicksort has tight code, and so the hidden constant factor in its running time is small.
It is a popular algorithm for sorting large input arrays.
In Chapter 9, we show that we can ﬁnd the i th smallest element in O.n/ time, even when the elements are arbitrary real numbers.
We present a randomized algorithm with tight pseudocode that runs in ‚.n2/ time in the worst case, but whose expected running time is O.n/
We also give a more complicated algorithm that runs in O.n/ worst-case time.
Although most of this part does not rely on difﬁcult mathematics, some sections do require mathematical sophistication.
The analysis of the worst-case linear-time algorithm for order statistics involves somewhat more sophisticated mathematics than the other worst-case analyses in this part.
Like merge sort, but unlike insertion sort, heapsort’s running time is O.n lg n/
Like insertion sort, but unlike merge sort, heapsort sorts in place: only a constant number of array elements are stored outside the input array at any time.
Thus, heapsort combines the better attributes of the two sorting algorithms we have already discussed.
Heapsort also introduces another algorithm design technique: using a data structure, in this case one we call a “heap,” to manage information.
Not only is the heap data structure useful for heapsort, but it also makes an efﬁcient priority queue.
The heap data structure will reappear in algorithms in later chapters.
The term “heap” was originally coined in the context of heapsort, but it has since come to refer to “garbage-collected storage,” such as the programming languages Java and Lisp provide.
Our heap data structure is not garbage-collected storage, and whenever we refer to heaps in this book, we shall mean a data structure rather than an aspect of garbage collection.
Figure 6.1 A max-heap viewed as (a) a binary tree and (b) an array.
The number within the circle at each node in the tree is the value stored at that node.
The number above a node is the corresponding index in the array.
Above and below the array are lines showing parent-child relationships; parents are always to the left of their children.
On most computers, the LEFT procedure can compute 2i in one instruction by simply shifting the binary representation of i left by one bit position.
The PARENT procedure can compute bi=2c by shifting i right one bit position.
Good implementations of heapsort often implement these procedures as “macros” or “inline” procedures.
There are two kinds of binary heaps: max-heaps and min-heaps.
In both kinds, the values in the nodes satisfy a heap property, the speciﬁcs of which depend on the kind of heap.
Min-heaps commonly implement priority queues, which we discuss in Section 6.5
We shall be precise in specifying whether we need a max-heap or a min-heap for any particular application, and when properties apply to either max-heaps or min-heaps, we just use the term “heap.”
Alternatively, we can characterize the running time of MAXHEAPIFY on a node of height h as O.h/
How does the running time of MIN-HEAPIFY compare to that of MAXHEAPIFY?
The procedure BUILD-MAX-HEAP goes through the remaining nodes of the tree and runs MAX-HEAPIFY on each one.
Figure 6.3 shows an example of the action of BUILD-MAX-HEAP.
To show why BUILD-MAX-HEAP works correctly, we use the following loop.
We need to show that this invariant is true prior to the ﬁrst loop iteration, that each iteration of the loop maintains the invariant, and that the invariant provides a useful property to show correctness when the loop terminates.
Maintenance: To see that each iteration maintains the loop invariant, observe that the children of node i are numbered higher than i.
By the loop invariant, therefore, they are both roots of max-heaps.
This is precisely the condition required for the call MAX-HEAPIFY.A; i/ to make node i a max-heap root.
Decrementing i in the for loop update reestablishes the loop invariant for the next iteration.
We can compute a simple upper bound on the running time of BUILD-MAXHEAP as follows.
Each call to MAX-HEAPIFY costs O.lg n/ time, and BUILDMAX-HEAP makes O.n/ such calls.
The time required by MAX-HEAPIFY when called on a node of height h is O.h/, and so we can express the total cost of BUILD-MAX-HEAP as being bounded from above by.
The ﬁgure shows that the loop index i refers to node 5 before the call MAX-HEAPIFY.A; i/
Observe that whenever MAX-HEAPIFY is called on a node, the two subtrees of that node are both max-heaps.
Thus, we can bound the running time of BUILD-MAX-HEAP as.
Hence, we can build a max-heap from an unordered array in linear time.
We can build a min-heap by the procedure BUILD-MIN-HEAP, which is the.
BUILD-MIN-HEAP produces a min-heap from an unordered linear array in linear time.
The ﬁgure shows the max-heap before the ﬁrst iteration of the for loop of lines 2–5 and after each iteration.
Heapsort is an excellent algorithm, but a good implementation of quicksort, presented in Chapter 7, usually beats it in practice.
In this section, we present one of the most popular applications of a heap: as an efﬁcient priority queue.
As with heaps, priority queues come in two forms: max-priority queues and min-priority queues.
We will focus here on how to implement max-priority queues, which are in turn based on maxheaps; Exercise 6.5-3 asks you to write the procedures for min-priority queues.
A priority queue is a data structure for maintaining a set S of elements, each with an associated value called a key.
MAXIMUM.S/ returns the element of S with the largest key.
EXTRACT-MAX.S/ removes and returns the element of S with the largest key.
Among their other applications, we can use max-priority queues to schedule jobs on a shared computer.
The max-priority queue keeps track of the jobs to be performed and their relative priorities.
When a job is ﬁnished or interrupted, the scheduler selects the highest-priority job from among those pending by calling EXTRACT-MAX.
The scheduler can add a new job to the queue at any time by calling INSERT.
A min-priority queue can be used in an event-driven simulator.
The items in the queue are events to be simulated, each with an associated time of occurrence that serves as its key.
The events must be simulated in order of their time of occurrence, because the simulation of an event can cause other events to be simulated in the future.
The simulation program calls EXTRACT-MIN at each step to choose the next event to simulate.
As new events are produced, the simulator inserts them into the min-priority queue by calling INSERT.
Not surprisingly, we can use a heap to implement a priority queue.
In a given application, such as job scheduling or event-driven simulation, elements of a priority queue correspond to objects in the application.
We often need to determine which application object corresponds to a given priority-queue element, and vice versa.
When we use a heap to implement a priority queue, therefore, we often need to store a handle to the corresponding application object in each heap element.
The exact makeup of the handle (such as a pointer or an integer) depends on the application.
Similarly, we need to store a handle to the corresponding heap element in each application object.
Because heap elements change locations within the array during heap operations, an actual implementation, upon relocating a heap element, would also have to update the array index in the corresponding application object.
Because the details of accessing application objects depend heavily on the application and its implementation, we shall not pursue them here, other than noting that in practice, these handles do need to be correctly maintained.
Now we discuss how to implement the operations of a max-priority queue.
The procedure HEAP-MAXIMUM implements the MAXIMUM operation in ‚.1/ time.
It is similar to the for loop body (lines 3–5) of the HEAPSORT procedure.
The running time of HEAP-EXTRACT-MAX is O.lg n/, since it performs only a constant amount of work on top of the O.lg n/ time for MAX-HEAPIFY.
As HEAP-INCREASEKEY traverses this path, it repeatedly compares an element to its parent, exchanging their keys and continuing if the element’s key is larger, and terminating if the element’s key is smaller, since the max-heap property now holds.
The running time of HEAP-INCREASE-KEY on an n-element heap is O.lg n/, since the path traced from the node updated in line 3 to the root has length O.lg n/
The running time of MAX-HEAP-INSERT on an n-element heap is O.lg n/
In summary, a heap can support any priority-queue operation on a set of size n.
Show how to use the idea of the inner loop of INSERTIONSORT to reduce the three assignments down to just one assignment.
Show how to implement a stack with a priority queue.
Give an implementation of HEAP-DELETE that runs in O.lg n/ time for an n-element max-heap.
We can build a heap by repeatedly calling MAX-HEAP-INSERT to insert the elements into the heap.
Do the procedures BUILD-MAX-HEAP and BUILD-MAX-HEAP 0 always create the same heap when run on the same input array? Prove that they do, or provide a counterexample.
A d -ary heap is like a binary heap, but (with one possible exception) non-leaf nodes have d children instead of 2 children.
How would you represent a d -ary heap in an array?
What is the height of a d -ary heap of n elements in terms of n and d?
Give an efﬁcient implementation of EXTRACT-MAX in a d -ary max-heap.
Analyze its running time in terms of d and n.
Give an efﬁcient implementation of INSERT in a d -ary max-heap.
Analyze its running time in terms of d and n.
The heapsort algorithm was invented by Williams [357], who also described how to implement a priority queue with a heap.
This bound uses an amount of space unbounded in n, but it can be implemented in linear space by using randomized hashing.
An important special case of priority queues occurs when the sequence of EXTRACT-MIN operations is monotone, that is, the values returned by successive EXTRACT-MIN operations are monotonically increasing over time.
This case arises in several important applications, such as Dijkstra’s single-source shortestpaths algorithm, which we discuss in Chapter 24, and in discrete-event simulation.
For Dijkstra’s algorithm it is particularly important that the DECREASE-KEY operation be implemented efﬁciently.
The quicksort algorithm has a worst-case running time of ‚.n2/ on an input array of n numbers.
It also has the advantage of sorting in place (see page 17), and it works well even in virtual-memory environments.
Section 7.1 describes the algorithm and an important subroutine used by quicksort for partitioning.
Because the behavior of quicksort is complex, we start with an intuitive discussion of its performance in Section 7.2 and postpone its precise analysis to the end of the chapter.
Section 7.3 presents a version of quicksort that uses random sampling.
This algorithm has a good expected running time, and no particular input elicits its worst-case behavior.
To sort an entire array A, the initial call is QUICKSORT.A; 1;A: length/
We need to show that this loop invariant is true prior to the ﬁrst iteration, that each iteration of the loop maintains the invariant, and that the invariant provides a useful property to show correctness when the loop terminates.
Therefore, every entry in the array is in one of the three sets described by the invariant, and we have partitioned the values in the array into three sets: those less than or equal to x, those greater than x, and a singleton set containing x.
The running time of quicksort depends on whether the partitioning is balanced or unbalanced, which in turn depends on which elements are used for partitioning.
If the partitioning is balanced, the algorithm runs asymptotically as fast as merge.
If the partitioning is unbalanced, however, it can run asymptotically as slowly as insertion sort.
In this section, we shall informally investigate how quicksort performs under the assumptions of balanced versus unbalanced partitioning.
Thus, if the partitioning is maximally unbalanced at every recursive level of the algorithm, the running time is ‚.n2/
Therefore the worst-case running time of quicksort is no better than that of insertion sort.
Moreover, the ‚.n2/ running time occurs when the input array is already completely sorted—a common situation in which insertion sort runs in O.n/ time.
By equally balancing the two sides of the partition at every level of the recursion, we get an asymptotically faster algorithm.
The average-case running time of quicksort is much closer to the best case than to the worst case, as the analyses in Section 7.4 will show.
Nodes show subproblem sizes, with per-level costs on the right.
The per-level costs include the constant c implicit in the ‚.n/ term.
Suppose, for example, that the partitioning algorithm always produces a 9-to-1 proportional split, which at ﬁrst blush seems quite unbalanced.
The total cost of quicksort is therefore O.n lg n/
Indeed, even a 99-to-1 split yields an O.n lg n/ running time.
In fact, any split of constant proportionality yields a recursion tree of depth ‚.lg n/, where the cost at each level is O.n/
The running time is therefore O.n lg n/ whenever the split has constant proportionality.
To develop a clear notion of the randomized behavior of quicksort, we must make an assumption about how frequently we expect to encounter the various inputs.
The behavior of quicksort depends on the relative ordering of the values in the array elements given as the input, and not by the particular values in the array.
As in our probabilistic analysis of the hiring problem in Section 5.2, we will assume for now that all permutations of the input numbers are equally likely.
When we run quicksort on a random input array, the partitioning is highly unlikely to happen in the same way at every level, as our informal analysis has assumed.
We expect that some of the splits will be reasonably well balanced and that some will be fairly unbalanced.
In exploring the average-case behavior of quicksort, we have made an assumption that all permutations of the input numbers are equally likely.
In an engineering situation, however, we cannot always expect this assumption to hold.
As we saw in Section 5.3, we can sometimes add randomization to an algorithm in order to obtain good expected performance over all inputs.
Many people regard the resulting randomized version of quicksort as the sorting algorithm of choice for large enough inputs.
In the new partition procedure, we simply implement the swap before actually partitioning:
Section 7.2 gave some intuition for the worst-case behavior of quicksort and for why we expect it to run quickly.
In this section, we analyze the behavior of quicksort more rigorously.
Let T .n/ be the worst-case time for the procedure QUICKSORT on an input of size n.
Even if we add a few new levels with the most unbalanced split possible between these levels, the total time remains O.n lg n/
We assume throughout that the values of the elements being sorted are distinct.
The running time of QUICKSORT is dominated by the time spent in the PARTITION procedure.
Each time the PARTITION procedure is called, it selects a pivot element, and this element is never included in any future recursive calls to QUICKSORT and PARTITION.
Thus, there can be at most n calls to PARTITION over the entire execution of the quicksort algorithm.
Each iteration of this for loop performs a comparison in line 4, comparing the pivot element to another element of the array A.
Proof By the discussion above, the algorithm makes at most n calls to PARTITION, each of which does a constant amount of work and then executes the for loop some number of times.
Taking expectations of both sides, and then using linearity of expectation and Lemma 5.1, we obtain.
Let us think about when two items are not compared.
The second line follows because the two events are mutually exclusive.
Upon calling quicksort on a subarray with fewer than k elements, let it simply return without sorting the subarray.
After the top-level call to quicksort returns, run insertion sort on the entire array to ﬁnish the sorting process.
Argue that this sorting algorithm runs in O.nk C n lg.n=k// expected time.
How should we pick k, both in theory and in practice?
The version of PARTITION given in this chapter is not the original partitioning algorithm.
Here is the original partition algorithm, which is due to C.
The analysis of the expected running time of randomized quicksort in Section 7.4.2 assumes that all element values are distinct.
In this problem, we examine what happens when they are not.
What would be randomized quicksort’s running time in this case?
Then modify the QUICKSORT procedure to produce a procedure QUICKSORT0.p; r/ that calls.
Argue that, given an array of size n, the probability that any particular element.
Let T .n/ be a random variable denoting the running time of quicksort on an array of size n.
The QUICKSORT algorithm of Section 7.1 contains two recursive calls to itself.
After QUICKSORT calls PARTITION, it recursively sorts the left subarray and then it recursively sorts the right subarray.
The second recursive call in QUICKSORT is not really necessary; we can avoid it by using an iterative control structure.
This technique, called tail recursion, is provided automatically by good compilers.
Consider the following version of quicksort, which simulates tail recursion:
Compilers usually execute recursive procedures by using a stack that contains pertinent information, including the parameter values, for each recursive call.
The information for the most recent call is at the top of the stack, and the information for the initial call is at the bottom.
Upon calling a procedure, its information is pushed onto the stack; when it terminates, its information is popped.
Since we assume that array parameters are represented by pointers, the information for each procedure call on the stack requires O.1/ stack space.
The stack depth is the maximum amount of stack space used at any time during a computation.
Maintain the O.n lg n/ expected running time of the algorithm.
As the intervals overlap more and more, the problem of fuzzy-sorting the intervals becomes progressively easier.
Your algorithm should take advantage of such overlapping, to the extent that it exists.
The PARTITION procedure given in Section 7.1 is due to N.
The analysis in Section 7.4 is due to Avrim Blum.
If the implementation is randomized, the adversary produces the array after seeing the random choices of the quicksort algorithm.
These algorithms share an interesting property: the sorted order they determine is based only on comparisons between the input elements.
All the sorting algorithms introduced thus far are comparison sorts.
We can view comparison sorts abstractly in terms of decision trees.
A decision tree is a full binary tree that represents the comparisons between elements that are performed by a particular sorting algorithm operating on an input of a given size.
Control, data movement, and all other aspects of the algorithm are ignored.
The length of the longest simple path from the root of a decision tree to any of its reachable leaves represents the worst-case number of comparisons that the corresponding sorting algorithm performs.
Consequently, the worst-case number of comparisons for a given comparison sort algorithm equals the height of its decision tree.
A lower bound on the heights of all decision trees in which each permutation appears as a reachable leaf is therefore a lower bound on the running time of any comparison sort algorithm.
Corollary 8.2 Heapsort and merge sort are asymptotically optimal comparison sorts.
Counting sort assumes that each of the n input elements is an integer in the range 0 to k, for some integer k.
When k D O.n/, the sort runs in ‚.n/ time.
Counting sort determines, for each input element x, the number of elements less than x.
It uses this information to place element x directly into its position in the output array.
We must modify this scheme slightly to handle the situation in which several elements have the same value, since we do not want to put them all in the same position.
In practice, we usually use counting sort when we have k D O.n/, in which case the running time is ‚.n/
An important property of counting sort is that it is stable: numbers with the same value appear in the output array in the same order as they do in the input array.
That is, it breaks ties between two numbers by the rule that whichever number appears ﬁrst in the input array appears ﬁrst in the output array.
Normally, the property of stability is important only when satellite data are carried around with the element being sorted.
Counting sort’s stability is important for another reason: counting sort is often used as a subroutine in radix sort.
As we shall see in the next section, in order for radix sort to work correctly, counting sort must be stable.
Radix sort is the algorithm used by the card-sorting machines you now ﬁnd only in computer museums.
The sorter can be mechanically “programmed” to examine a given column of each card in a deck and distribute the card into one of 12 bins depending on which place has been punched.
An operator can then gather the cards bin by bin, so that cards with the ﬁrst place punched are on top of cards with the second place punched, and so on.
The other two places are reserved for encoding nonnumeric characters.
A d -digit number would then occupy a ﬁeld of d columns.
Since the card sorter can look at only one column at a time, the problem of sorting n cards on a d -digit number requires a sorting algorithm.
Intuitively, you might sort numbers on their most signiﬁcant digit, sort each of the resulting bins recursively, and then combine the decks in order.
Then it sorts the entire deck again on the second-least signiﬁcant digit and recombines the deck in a like manner.
The process continues until the cards have been sorted on all d digits.
Remarkably, at that point the cards are fully sorted on the d -digit number.
Thus, only d passes through the deck are required to sort.
In order for radix sort to work correctly, the digit sorts must be stable.
The sort performed by a card sorter is stable, but the operator has to be wary about not changing the order of the cards as they come out of a bin, even though all the cards in a bin have the same digit in the chosen column.
The remaining columns show the list after successive sorts on increasingly signiﬁcant digit positions.
Shading indicates the digit position sorted on to produce each list from the previous one.
In a typical computer, which is a sequential random-access machine, we sometimes use radix sort to sort records of information that are keyed by multiple ﬁelds.
For example, we might wish to sort dates by three keys: year, month, and day.
We could run a sorting algorithm with a comparison function that, given two dates, compares years, and if there is a tie, compares months, and if another tie occurs, compares days.
Alternatively, we could sort the information three times with a stable sort: ﬁrst on day, next on month, and ﬁnally on year.
The following procedure assumes that each element in the n-element array A has d digits, where digit 1 is the lowest-order digit and digit d is the highest-order digit.
When d is constant and k D O.n/, we can make radix sort run in linear time.
More generally, we have some ﬂexibility in how to break each key into digits.
How much additional time and space does your scheme entail?
Where does your proof need the assumption that the intermediate sort is stable?
To analyze the running time, observe that all lines except line 8 take O.n/ time in the worst case.
We now analyze the average-case running time of bucket sort, by computing the expected value of the running time, where we take the expectation over the input distribution.
Taking expectations of both sides and using linearity of expectation, we have.
Substituting these two expected values in equation (8.3), we obtain.
Even if the input is not drawn from a uniform distribution, bucket sort may still run in linear time.
As long as the input has the property that the sum of the squares of the bucket sizes is linear in the total number of elements, equation (8.1) tells us that bucket sort will run in linear time.
What simple change to the algorithm preserves its linear average-case running time and makes its worst-case running time O.n lg n/?
Let D.T / denote the external path length of a decision tree T ; that is, D.T / is the sum of the depths of all the leaves of T.
We can extend the decisiontree model to handle randomization by incorporating two kinds of nodes: ordinary comparison nodes and “randomization” nodes.
A randomization node models a random choice of the form RANDOM.1; r/ made by algorithm B; the node has r children, each of which is equally likely to be chosen during an execution of the algorithm.
Show that for any randomized comparison sort B , there exists a deterministic comparison sort A whose expected number of comparisons is no more than those made by B.
An algorithm for sorting such a set of records might possess some subset of the following three desirable characteristics:
Can you use any of your sorting algorithms from parts (a)–(c) as the sorting method used in line 2 of RADIX-SORT, so that RADIX-SORT sorts n records with b-bit keys in O.bn/ time? Explain how or why not.
Suppose that the n records have keys in the range from 1 to k.
Show how to modify counting sort so that it sorts the records in place in O.nC k/ time.
Is your algorithm stable? (Hint: How would you do it for k D 3?)
You are given an array of integers, where different integers may have different.
You are given an array of strings, where different strings may have different numbers of characters, but the total number of characters over all the strings is n.
Suppose that you are given n red and n blue water jugs, all of different shapes and sizes.
All red jugs hold different amounts of water, as do the blue ones.
Moreover, for every red jug, there is a blue jug that holds the same amount of water, and vice versa.
Your task is to ﬁnd a grouping of the jugs into pairs of red and blue jugs that hold the same amount of water.
To do so, you may perform the following operation: pick a pair of jugs in which one is red and one is blue, ﬁll the red jug with water, and then pour the water into the blue jug.
This operation will tell you whether the red or the blue jug can hold more water, or that they have the same volume.
Your goal is to ﬁnd an algorithm that makes a minimum number of comparisons to determine the grouping.
Remember that you may not directly compare two red jugs or two blue jugs.
Describe a deterministic algorithm that uses ‚.n2/ comparisons to group the.
Give a randomized algorithm whose expected number of comparisons is O.n lg n/, and prove that this bound is correct.
What is the worst-case number of comparisons for your algorithm?
What does it mean for an array to be 1-sorted?
Give an algorithm that k-sorts an n-element array in O.n lg.n=k// time.
We can also show a lower bound on the time to produce a k-sorted array, when k is a constant.
Show that we can sort a k-sorted array of length n in O.n lg k/ time.
Hint: Use the solution to the previous part along with the lower bound on comparison sorts.
Given 2n numbers, compute the number of possible ways to divide them into two sorted lists, each with n numbers.
The indices of the positions compared in the sequence must be determined in advance, and although they can depend on the number of elements being sorted, they cannot depend on the values being sorted, nor can they depend on the result of any prior compare-exchange operation.
For example, here is insertion sort expressed as an oblivious compare-exchange algorithm:
The 0-1 sorting lemma provides a powerful way to prove that an oblivious compare-exchange algorithm produces a sorted result.
To complete the proof of the 0-1 sorting lemma, prove that algorithm X fails to sort array B correctly.
Columnsort operates in eight steps, regardless of the value of n.
The odd steps are all the same: sort each column individually.
Shift the bottom half of the last column into the top half of a new rightmost column, and leave the bottom half of this new column empty.
Although it might seem hard to believe that columnsort actually sorts, you will use the 0-1 sorting lemma to prove that it does.
The 0-1 sorting lemma applies because we can treat columnsort as an oblivious compare-exchange algorithm.
Conclude that columnsort correctly sorts all inputs containing arbitrary values.
The decision-tree model for studying comparison sorts was introduced by Ford and Johnson [110]
Ben-Or [39] studied lower bounds for sorting using generalizations of the decision-tree model.
Seward with inventing counting sort in 1954, as well as with the idea of combining counting sort with radix sort.
Radix sorting starting with the least signiﬁcant digit appears to be a folk algorithm widely used by operators of mechanical card-sorting machines.
According to Knuth, the ﬁrst published reference to the method is a 1929 document by L.
Bucket sorting has been in use since 1956, when the basic idea was proposed by E.
The case of sorting n b-bit integers in o.n lgn/ time has been considered by many researchers.
Several positive results have been obtained, each under slightly different assumptions about the model of computation and the restrictions placed on the algorithm.
All the results assume that the computer memory is divided into addressable b-bit words.
Fredman and Willard [115] introduced the fusion tree data structure and used it to sort n integers in O.n lg n= lg lgn/ time.
Andersson, Hagerup, Nilsson, and Raman [17] have shown how to sort n integers in O.n lg lg n/ time without using multiplication, but their method requires storage that can be unbounded in terms of n.
Using multiplicative hashing, we can reduce the storage needed to O.n/, but then the O.n lg lg n/ worst-case bound on the running time becomes an expected-time bound.
Combining these techniques with some new ideas, Han [158] improved the bound for sorting to O.n lg lg n lg lg lg n/ time.
Although these algorithms are important theoretical breakthroughs, they are all fairly complicated and at the present time seem unlikely to compete with existing sorting algorithms in practice.
The i th order statistic of a set of n elements is the i th smallest element.
For example, the minimum of a set of elements is the ﬁrst order statistic (i D 1), and the maximum is the nth order statistic (i D n)
A median, informally, is the “halfway point” of the set.
When n is odd, the median is unique, occurring at i D .nC 1/=2
For simplicity in this text, however, we consistently use the phrase “the median” to refer to the lower median.
This chapter addresses the problem of selecting the i th order statistic from a set of n distinct numbers.
We assume for convenience that the set contains distinct numbers, although virtually everything that we do extends to the situation in which a set contains repeated values.
In Section 9.1, we examine the problem of selecting the minimum and maximum of a set of elements.
More interesting is the general selection problem, which we investigate in the subsequent two sections.
Section 9.2 analyzes a practical randomized algorithm that achieves an O.n/ expected running time, assuming distinct elements.
Section 9.3 contains an algorithm of more theoretical interest that achieves the O.n/ running time in the worst case.
In some applications, we must ﬁnd both the minimum and the maximum of a set of n elements.
For example, a graphics program may need to scale a set of .x; y/ data to ﬁt onto a rectangular display screen or other graphical output device.
To do so, the program must ﬁrst determine the minimum and maximum value of each coordinate.
We do so by maintaining both the minimum and maximum elements seen thus far.
How we set up initial values for the current minimum and maximum depends on whether n is odd or even.
If n is odd, we set both the minimum and maximum to the value of the ﬁrst element, and then we process the rest of the elements in pairs.
The general selection problem appears more difﬁcult than the simple problem of ﬁnding a minimum.
Yet, surprisingly, the asymptotic running time for both problems is the same: ‚.n/
In this section, we present a divide-and-conquer algorithm for the selection problem.
But unlike quicksort, which recursively processes both sides of the partition, RANDOMIZED-SELECT works on only one side of the partition.
Describe a sequence of partitions that results in a worst-case performance of RANDOMIZED-SELECT.
We now examine a selection algorithm whose running time is O.n/ in the worst case.
Like RANDOMIZED-SELECT, the algorithm SELECT ﬁnds the desired element by recursively partitioning the input array.
Here, however, we guarantee a good split upon partitioning the array.
If n D 1, then SELECT merely returns its only input value as the i th smallest.
If there are an even number of medians, then by our convention, x is the lower median.
To analyze the running time of SELECT, we ﬁrst determine a lower bound on the number of elements that are greater than the partitioning element x.
The n elements are represented by small circles, and each group of 5 elements occupies a column.
The medians of the groups are whitened, and the median-of-medians x is labeled.
When ﬁnding the median of an even number of elements, we use the lower median.
The elements known to be greater than x appear on a shaded background.
Discounting these two groups, it follows that the number of elements greater than x is at least.
We can now develop a recurrence for the worst-case running time T .n/ of the algorithm SELECT.
Because of our assumption that the numbers are distinct, all medians except x are either greater than or less than x.
Figure 9.2 Professor Olay needs to determine the position of the east-west oil pipeline that minimizes the total length of the north-south spurs.
Given the x- and y-coordinates of the wells, how should the professor pick the optimal location of the main pipeline, which would be the one that minimizes the total length of the spurs? Show how to determine the optimal location in linear time.
Given a set of n numbers, we wish to ﬁnd the i largest in sorted order using a comparison-based algorithm.
Find the algorithm that implements each of the following methods with the best asymptotic worst-case running time, and analyze the running times of the algorithms in terms of n and i.
Build a max-priority queue from the numbers, and call EXTRACT-MAX i times.
Use an order-statistic algorithm to ﬁnd the i th largest number, partition around that number, and sort the i largest numbers.
Show how to compute the weighted median of n elements in O.n lg n/ worstcase time using sorting.
We wish to ﬁnd a point p (not necessarily one of the input points) that minimizes the sum PniD1 wi d.p; pi /, where d.a; b/ is the distance between points a and b.
When i is small relative to n, we can implement a different procedure that uses SELECT as a subroutine but makes fewer comparisons in the worst case.
Describe an algorithm that uses Ui.n/ comparisons to ﬁnd the i th smallest of n elements, where.
Hint: Begin with bn=2c disjoint pairwise comparisons, and recurse on the set containing the smaller element from each pair.
Show that if i is a constant less than n=2, then Ui .n/ D nCO.lg n/
Conclude that, assuming all elements of array A are distinct, RANDOMIZEDSELECT runs in expected time O.n/
The worst-case linear-time median-ﬁnding algorithm was devised by Blum, Floyd, Pratt, Rivest, and Tarjan [50]
Floyd and Rivest [108] have developed an improved randomized version that partitions around an element recursively selected from a small sample of the elements.
Sets are as fundamental to computer science as they are to mathematics.
Whereas mathematical sets are unchanging, the sets manipulated by algorithms can grow, shrink, or otherwise change over time.
The next ﬁve chapters present some basic techniques for representing ﬁnite dynamic sets and manipulating them on a computer.
Algorithms may require several different types of operations to be performed on sets.
For example, many algorithms need only the ability to insert elements into, delete elements from, and test membership in a set.
We call a dynamic set that supports these operations a dictionary.
For example, min-priority queues, which Chapter 6 introduced in the context of the heap data structure, support the operations of inserting an element into and extracting the smallest element from a set.
The best way to implement a dynamic set depends upon the operations that must be supported.
In a typical implementation of a dynamic set, each element is represented by an object whose attributes can be examined and manipulated if we have a pointer to the object.
Section 10.3 discusses the implementation of objects and pointers in programming environments that do not contain them as basic data types.
Some kinds of dynamic sets assume that one of the object’s attributes is an identifying key.
If the keys are all different, we can think of the dynamic set as being a set of key values.
The object may contain satellite data, which are carried around in other object attributes but are otherwise unused by the set implementation.
Some dynamic sets presuppose that the keys are drawn from a totally ordered set, such as the real numbers, or the set of all words under the usual alphabetic ordering.
A total ordering allows us to deﬁne the minimum element of the set, for example, or to speak of the next element larger than a given element in a set.
Operations on a dynamic set can be grouped into two categories: queries, which simply return information about the set, and modifying operations, which change the set.
Any speciﬁc application will usually require only a few of these to be implemented.
SEARCH.S; k/ A query that, given a set S and a key value k, returns a pointer x to an element in S such that x:key D k, or NIL if no such element belongs to S.
INSERT.S; x/ A modifying operation that augments the set S with the element pointed to by x.
We usually assume that any attributes in element x needed by the set implementation have already been initialized.
DELETE.S; x/ A modifying operation that, given a pointer x to an element in the set S , removes x from S.
Note that this operation takes a pointer to an element x, not a key value.
MINIMUM.S/ A query on a totally ordered set S that returns a pointer to the element of S with the smallest key.
MAXIMUM.S/ A query on a totally ordered set S that returns a pointer to the element of S with the largest key.
SUCCESSOR.S; x/ A query that, given an element x whose key is from a totally ordered set S , returns a pointer to the next larger element in S , or NIL if x is the maximum element.
PREDECESSOR.S; x/ A query that, given an element x whose key is from a totally ordered set S , returns a pointer to the next smaller element in S , or NIL if x is the minimum element.
We usually measure the time taken to execute a set operation in terms of the size of the set.
For example, Chapter 13 describes a data structure that can support any of the operations listed above on a set of size n in time O.lg n/
Chapters 10–14 describe several data structures that we can use to implement dynamic sets; we shall use many of these later to construct efﬁcient algorithms for a variety of problems.
Chapter 10 presents the essentials of working with simple data structures such as stacks, queues, linked lists, and rooted trees.
It also shows how to implement objects and pointers in programming environments that do not support them as primitives.
If you have taken an introductory programming course, then much of this material should be familiar to you.
Chapter 11 introduces hash tables, which support the dictionary operations INSERT, DELETE, and SEARCH.
The analysis of hashing relies on probability, but most of the chapter requires no background in the subject.
Binary search trees, which are covered in Chapter 12, support all the dynamicset operations listed above.
In the worst case, each operation takes ‚.n/ time on a tree with n elements, but on a randomly built binary search tree, the expected time for each operation is O.lg n/
Binary search trees serve as the basis for many other data structures.
Chapter 13 introduces red-black trees, which are a variant of binary search trees.
Unlike ordinary binary search trees, red-black trees are guaranteed to perform well: operations take O.lg n/ time in the worst case.
A red-black tree is a balanced search tree; Chapter 18 in Part V presents another kind of balanced search tree, called a B-tree.
Although the mechanics of red-black trees are somewhat intricate, you can glean most of their properties from the chapter without studying the mechanics in detail.
Nevertheless, you probably will ﬁnd walking through the code to be quite instructive.
In Chapter 14, we show how to augment red-black trees to support operations other than the basic ones listed above.
First, we augment them so that we can dynamically maintain order statistics for a set of keys.
Then, we augment them in a different way to maintain intervals of real numbers.
In this chapter, we examine the representation of dynamic sets by simple data structures that use pointers.
Although we can construct many complex data structures using pointers, we present only the rudimentary ones: stacks, queues, linked lists, and rooted trees.
We also show ways to synthesize objects and pointers from arrays.
Stacks and queues are dynamic sets in which the element removed from the set by the DELETE operation is prespeciﬁed.
In a stack, the element deleted from the set is the one most recently inserted: the stack implements a last-in, ﬁrst-out, or LIFO, policy.
Similarly, in a queue, the element deleted is always the one that has been in the set for the longest time: the queue implements a ﬁrst-in, ﬁrst-out, or FIFO, policy.
There are several efﬁcient ways to implement stacks and queues on a computer.
In this section we show how to use a simple array to implement each.
The INSERT operation on a stack is often called PUSH, and the DELETE operation, which does not take an element argument, is often called POP.
These names are allusions to physical stacks, such as the spring-loaded stacks of plates used in cafeterias.
The order in which plates are popped from the stack is the reverse of the order in which they were pushed onto the stack, since only the top plate is accessible.
When S: top D 0, the stack contains no elements and is empty.
We can test to see whether the stack is empty by query operation STACK-EMPTY.
If we attempt to pop an empty stack, we say the stack underﬂows, which is normally an error.
In our pseudocode implementation, we don’t worry about stack overﬂow.
We can implement each of the stack operations with just a few lines of code:
Figure 10.1 shows the effects of the modifying operations PUSH and POP.
Queues We call the INSERT operation on a queue ENQUEUE, and we call the DELETE operation DEQUEUE; like the stack operation POP, DEQUEUE takes no element argument.
The FIFO property of a queue causes it to operate like a line of customers waiting to pay a cashier.
When an element is enqueued, it takes its place at the tail of the queue, just as a newly arriving customer takes a place at the end of the line.
The element dequeued is always the one at the head of the queue, like the customer at the head of the line who has waited the longest.
When Q:head D Q: tail C 1, the queue is full, and if we attempt to enqueue an element, then the queue overﬂows.
In our procedures ENQUEUE and DEQUEUE, we have omitted the error checking for underﬂow and overﬂow.
Exercise 10.1-4 asks you to supply code that checks for these two error conditions.
Figure 10.2 shows the effects of the ENQUEUE and DEQUEUE operations.
Write four O.1/-time procedures to insert elements into and delete elements from both ends of a deque implemented by an array.
A linked list is a data structure in which the objects are arranged in a linear order.
Unlike an array, however, in which the linear order is determined by the array indices, the order in a linked list is determined by a pointer in each object.
In the remainder of this section, we assume that the lists with which we are working are unsorted and doubly linked.
The procedure LIST-SEARCH.L; k/ ﬁnds the ﬁrst element with key k in list L by a simple linear search, returning a pointer to this element.
If no object with key k appears in the list, then the procedure returns NIL.
To search a list of n objects, the LIST-SEARCH procedure takes ‚.n/ time in the worst case, since it may have to search the entire list.
Given an element x whose key attribute has already been set, the LIST-INSERT procedure “splices” x onto the front of the linked list, as shown in Figure 10.3(b)
The procedure LIST-DELETE removes an element x from a linked list L.
It must be given a pointer to x, and it then “splices” x out of the list by updating pointers.
If we wish to delete an element with a given key, we must ﬁrst call LIST-SEARCH to retrieve a pointer to the element.
Figure 10.3(c) shows how an element is deleted from a linked list.
The code for LIST-DELETE would be simpler if we could ignore the boundary conditions at the head and tail of the list:
A sentinel is a dummy object that allows us to simplify boundary conditions.
For example, suppose that we provide with list L an object L:nil that represents NIL.
Figure 10.4 A circular, doubly linked list with a sentinel.
The attribute L:head is no longer needed, since we can access the head of the list by L:nil:next.
The code for LIST-SEARCH remains the same as before, but with the references to NIL and L:head changed as speciﬁed above:
We use the two-line procedure LIST-DELETE 0 from before to delete an element from the list.
In other situations, however, the use of sentinels helps to tighten the code in a loop, thus reducing the coefﬁcient of, say, n or n2 in the running time.
When there are many small lists, the extra storage used by their sentinels can represent signiﬁcant wasted memory.
In this book, we use sentinels only when they truly simplify the code.
The operations PUSH and POP should still take O.1/ time.
The operations ENQUEUE and DEQUEUE should still take O.1/ time.
Show how to support UNION in O.1/ time using a suitable list data structure.
The procedure should use no more than constant storage beyond that needed for the list itself.
How do we implement pointers and objects in languages that do not provide them? In this section, we shall see two ways of implementing linked data structures without an explicit pointer data type.
We shall synthesize objects and pointers from arrays and array indices.
The single-array representation is ﬂexible in that it permits objects of different lengths to be stored in the same array.
The problem of managing such a heterogeneous collection of objects is more difﬁcult than the problem of managing a homogeneous collection, where all objects have the same attributes.
Since most of the data structures we shall consider are composed of homogeneous elements, it will be sufﬁcient for our purposes to use the multiple-array representation of objects.
Allocating and freeing objects To insert a key into a dynamic set represented by a doubly linked list, we must allocate a pointer to a currently unused object in the linked-list representation.
Thus, it is useful to manage the storage of objects not currently used in the linked-list representation so that one can be allocated.
In some systems, a garbage collector is responsible for determining which objects are unused.
Many applications, however, are simple enough that they can bear responsibility for returning an unused object to a storage manager.
We shall now explore the problem of allocating and freeing (or deallocating) homogeneous objects using the example of a doubly linked list represented by multiple arrays.
We keep the free objects in a singly linked list, which we call the free list.
The free list uses only the next array, which stores the next pointers within the list.
The head of the free list is held in the global variable free.
When the dynamic set represented by linked list L is nonempty, the free list may be intertwined with list L, as shown in Figure 10.7
Note that each object in the representation is either in list L or in the free list, but not in both.
The free list acts like a stack: the next object allocated is the last one freed.
We can use a list implementation of the stack operations PUSH and POP to implement the procedures for allocating and freeing objects, respectively.
We assume that the global variable free used in the following procedures points to the ﬁrst element of the free list.
The two procedures run in O.1/ time, which makes them quite practical.
We can modify them to work for any homogeneous collection of objects by letting any one of the attributes in the object act like a next attribute in the free list.
The methods for representing lists given in the previous section extend to any homogeneous data structure.
In this section, we look speciﬁcally at the problem of representing rooted trees by linked data structures.
We ﬁrst look at binary trees, and then we present a method for rooted trees in which nodes can have an arbitrary number of children.
We represent each node of a tree by an object.
As with linked lists, we assume that each node contains a key attribute.
The remaining attributes of interest are pointers to other nodes, and they vary according to the type of tree.
Figure 10.9 shows how we use the attributes p, left, and right to store pointers to the parent, left child, and right child of each node in a binary tree T.
If node x has no left child, then x: left D NIL, and similarly for the right child.
The root of the entire tree T is pointed to by the attribute T:root.
This scheme no longer works when the number of children of a node is unbounded, since we do not know how many attributes (arrays in the multiple-array representation) to allocate in advance.
Moreover, even if the number of children k is bounded by a large constant but most nodes have a small number of children, we may waste a lot of memory.
Fortunately, there is a clever scheme to represent trees with arbitrary numbers of children.
It has the advantage of using only O.n/ space for any n-node rooted tree.
As before, each node contains a parent pointer p, and T:root points to the root of tree T.
Instead of having a pointer to each of its children, however, each node x has only two pointers:
If node x has no children, then x: left-child D NIL, and if node x is the rightmost child of its parent, then x:right-sibling D NIL.
Each node x has the attributes x:p (top), x: left (lower left), and x:right (lower right)
Figure 10.10 The left-child, right-sibling representation of a tree T.
Each node x has attributes x:p (top), x: left-child (lower left), and x:right-sibling (lower right)
In Chapter 6, for example, we represented a heap, which is based on a complete binary tree, by a single array plus the index of the last node in the heap.
The trees that appear in Chapter 21 are traversed only toward the root, and so only the parent pointers are present; there are no pointers to children.
From any node, its parent can be reached and identiﬁed in constant time and all its children can be reached and identiﬁed in time linear in the number of children.
Show how to use only two pointers and one boolean value in each node so that the parent of a node or all of its children can be reached and identiﬁed in time linear in the number of children.
For each of the four types of lists in the following table, what is the asymptotic worst-case running time for each dynamic-set operation listed?
Amergeable heap supports the following operations: MAKE-HEAP (which creates an empty mergeable heap), INSERT, MINIMUM, EXTRACT-MIN, and UNION.1 Show how to implement mergeable heaps using linked lists in each of the following cases.
Analyze the running time of each operation in terms of the size of the dynamic set(s) being operated on.
Lists are unsorted, and dynamic sets to be merged are disjoint.
If we ignore lines 3–7 of the procedure, we have an ordinary algorithm for searching a sorted linked list, in which index i points to each position of the list in.
Because we have deﬁned a mergeable heap to support MINIMUM and EXTRACT-MIN, we can also refer to it as a mergeable min-heap.
Alternatively, if it supported MAXIMUM and EXTRACT-MAX, it would be a mergeable max-heap.
This algorithm takes an additional parameter t which determines an upper bound on the number of iterations of the ﬁrst loop.
Many other texts cover both basic data structures and their implementation in a particular programming language.
Gonnet [145] provides experimental data on the performance of many data-structure operations.
The origin of stacks and queues as data structures in computer science is unclear, since corresponding notions already existed in mathematics and paper-based business practices before the introduction of digital computers.
Pointer-based data structures also seem to be a folk invention.
According to Knuth, pointers were apparently used in early computers with drum memories.
Knuth credits the IPL-II language, developed in 1956 by A.
Simon, for recognizing the importance and promoting the use of pointers.
Their IPL-III language, developed in 1957, included explicit stack operations.
Many applications require a dynamic set that supports only the dictionary operations INSERT, SEARCH, and DELETE.
For example, a compiler that translates a programming language maintains a symbol table, in which the keys of elements are arbitrary character strings corresponding to identiﬁers in the language.
A hash table is an effective data structure for implementing dictionaries.
Although searching for an element in a hash table can take as long as searching for an element in a linked list—‚.n/ time in the worst case—in practice, hashing performs extremely well.
Under reasonable assumptions, the average time to search for an element in a hash table is O.1/
A hash table generalizes the simpler notion of an ordinary array.
Directly addressing into an ordinary array makes effective use of our ability to examine an arbitrary position in an array in O.1/ time.
We can take advantage of direct addressing when we can afford to allocate an array that has one position for every possible key.
When the number of keys actually stored is small relative to the total number of possible keys, hash tables become an effective alternative to directly addressing an array, since a hash table typically uses an array of size proportional to the number of keys actually stored.
Instead of using the key as an array index directly, the array index is computed from the key.
Section 11.2 presents the main ideas, focusing on “chaining” as a way to handle “collisions,” in which more than one key maps to the same array index.
Section 11.3 describes how we can compute array indices from keys using hash functions.
We present and analyze several variations on the basic theme.
Section 11.4 looks at “open addressing,” which is another way to deal with collisions.
The bottom line is that hashing is an extremely effective and practical technique: the basic dictionary operations require only O.1/ time on the average.
Figure 11.1 How to implement a dynamic set by a direct-address table T.
For some applications, the direct-address table itself can hold the elements in the dynamic set.
That is, rather than storing an element’s key and satellite data in an object external to the direct-address table, with a pointer from a slot in the table to the object, we can store the object in the slot itself, thus saving space.
We would use a special key within an object to indicate an empty slot.
Moreover, it is often unnecessary to store the key of the object, since if we have the index of an object in the table, we have its key.
If keys are not stored, however, we must have some way to tell whether the slot is empty.
Describe a procedure that ﬁnds the maximum element of S.
A bit vector of length m takes much less space than an array of m pointers.
Describe how to use a bit vector to represent a dynamic set of distinct elements with no satellite data.
All three dictionary operations (INSERT, DELETE, and SEARCH) should run in O.1/ time.
Don’t forget that DELETE takes as an argument a pointer to an object to be deleted, not a key.
At the start, the array entries may contain garbage, and initializing the entire array is impractical because of its size.
Describe a scheme for implementing a directaddress dictionary on a huge array.
Hint: Use an additional array, treated somewhat like a stack whose size is the number of keys actually stored in the dictionary, to help determine whether a given entry in the huge array is valid or not.
The downside of direct addressing is obvious: if the universe U is large, storing a table T of size jU j may be impractical, or even impossible, given the memory available on a typical computer.
Furthermore, the set K of keys actually stored may be so small relative to U that most of the space allocated for T would be wasted.
When the set K of keys stored in a dictionary is much smaller than the universe U of all possible keys, a hash table requires much less storage than a directaddress table.
The catch is that this bound is for the average-case time, whereas for direct addressing it holds for the worst-case time.
Figure 11.2 Using a hash function h to map keys to hash-table slots.
There is one hitch: two keys may hash to the same slot.
Fortunately, we have effective techniques for resolving the conﬂict created by collisions.
Of course, the ideal solution would be to avoid collisions altogether.
We might try to achieve this goal by choosing a suitable hash function h.
One idea is to make h appear to be “random,” thus avoiding collisions or at least minimizing their number.
The very term “to hash,” evoking images of random mixing and chopping, captures the spirit of this approach.
Of course, a hash function h must be deterministic in that a given input k should always produce the same output h.k/
Because jU j > m, however, there must be at least two keys that have the same hash value; avoiding collisions altogether is therefore impossible.
Thus, while a welldesigned, “random”-looking hash function can minimize the number of collisions, we still need a method for resolving the collisions that do occur.
The remainder of this section presents the simplest collision resolution technique, called chaining.
Section 11.4 introduces an alternative method for resolving collisions, called open addressing.
In chaining, we place all the elements that hash to the same slot into the same linked list, as Figure 11.3 shows.
Slot j contains a pointer to the head of the list of all stored elements that hash to j ; if there are no such elements, slot j contains NIL.
The dictionary operations on a hash table T are easy to implement when collisions are resolved by chaining:
How well does hashing with chaining perform? In particular, how long does it take to search for an element with a given key?
The worst-case behavior of hashing with chaining is terrible: all n keys hash to the same slot, creating a list of length n.
The worst-case time for searching is thus ‚.n/ plus the time to compute the hash function—no better than if we used one linked list for all the elements.
Clearly, we do not use hash tables for their worst-case performance.
Perfect hashing, described in Section 11.5, does provide good worst-case performance when the set of keys is static, however.
The average-case performance of hashing depends on how well the hash function h distributes the set of keys to be stored among the m slots, on the average.
Section 11.3 discusses these issues, but for now we shall assume that any given element is equally likely to hash into any of the m slots, independently of where any other element has hashed to.
Proof We assume that the element being searched for is equally likely to be any of the n elements stored in the table.
The number of elements examined during a successful search for an element x is one more than the number of elements that.
Assume that one slot can store a ﬂag and either one element plus a pointer or two pointers.
All dictionary and free-list operations should run in O.1/ expected time.
Does the free list need to be doubly linked, or does a singly linked free list sufﬁce?
In this section, we discuss some issues regarding the design of good hash functions and then present three schemes for their creation.
Two of the schemes, hashing by division and hashing by multiplication, are heuristic in nature, whereas the third scheme, universal hashing, uses randomization to provide provably good performance.
A good hash function satisﬁes (approximately) the assumption of simple uniform hashing: each key is equally likely to hash to any of the m slots, independently of where any other key has hashed to.
Unfortunately, we typically have no way to check this condition, since we rarely know the probability distribution from which the keys are drawn.
In practice, we can often employ heuristic techniques to create a hash function that performs well.
Qualitative information about the distribution of keys may be useful in this design process.
For example, consider a compiler’s symbol table, in which the keys are character strings representing identiﬁers in a program.
Closely related symbols, such as pt and pts, often occur in the same program.
A good hash function would minimize the chance that such variants hash to the same slot.
A good approach derives the hash value in a way that we expect to be independent of any patterns that might exist in the data.
For example, the “division method” (discussed in Section 11.3.1) computes the hash value as the remainder when the key is divided by a speciﬁed prime number.
This method frequently gives good results, assuming that we choose a prime number that is unrelated to any patterns in the distribution of keys.
Finally, we note that some applications of hash functions might require stronger properties than are provided by simple uniform hashing.
For example, we might want keys that are “close” in some sense to yield hash values that are far apart.
This property is especially desirable when we are using linear probing, deﬁned in Section 11.4
Universal hashing, described in Section 11.3.3, often provides the desired properties.
In the division method for creating hash functions, we map a key k into one of m slots by taking the remainder of k divided by m.
Since it requires only a single division operation, hashing by division is quite fast.
A prime not too close to an exact power of 2 is often a good choice for m.
Treating each key k as an integer, our hash function would be.
The multiplication method for creating hash functions operates in two steps.
Then, we multiply this value by m and take the ﬂoor of the result.
Adapting Knuth’s suggestion, we choose A to be the fraction of the form s=232 that is closest to.
If a malicious adversary chooses the keys to be hashed by some ﬁxed hash function, then the adversary can choose n keys that all hash to the same slot, yielding an average retrieval time of ‚.n/
Any ﬁxed hash function is vulnerable to such terrible worst-case behavior; the only effective way to improve the situation is to choose the hash function randomly in a way that is independent of the keys that are actually going to be stored.
This approach, called universal hashing, can yield provably good performance on average, no matter which keys the adversary chooses.
In universal hashing, at the beginning of execution we select the hash function at random from a carefully designed class of functions.
As in the case of quicksort, randomization guarantees that no single input will always evoke worst-case behavior.
Because we randomly select the hash function, the algorithm can behave differently on each execution, even for the same input, guaranteeing good average-case performance for any input.
Returning to the example of a compiler’s symbol table, we ﬁnd that the programmer’s choice of identiﬁers cannot now cause consistently poor hashing performance.
Poor performance occurs only when the compiler chooses a random hash function that causes the set of identiﬁers to hash poorly, but the probability of this situation occurring is small and is the same for any set of identiﬁers of the same size.
Proof We note that the expectations here are over the choice of the hash function and do not depend on any assumptions about the distribution of the keys.
For each pair k and l of distinct keys, deﬁne the indicator random variable.
Next we deﬁne, for each key k, the random variable Yk that equals the number of keys other than k that hash to the same slot as k, so that.
The following corollary says universal hashing provides the desired payoff: it has now become impossible for an adversary to pick a sequence of operations that forces the worst-case running time.
By cleverly randomizing the choice of hash function at run time, we guarantee that we can process every sequence of operations with a good average-case running time.
It is quite easy to design a universal class of hash functions, as a little number theory will help us prove.
You may wish to consult Chapter 31 ﬁrst if you are unfamiliar with number theory.
How might we take advantage of the hash values when searching the list for an element with a given key?
How can we apply the division method to compute the hash value of the character string without using more than a constant number of words of storage outside the string itself?
In open addressing, all elements occupy the hash table itself.
That is, each table entry contains either an element of the dynamic set or NIL.
When searching for an element, we systematically examine table slots until either we ﬁnd the desired element or we have ascertained that the element is not in the table.
Of course, we could store the linked lists for chaining inside the hash table, in the otherwise unused hash-table slots (see Exercise 11.2-4), but the advantage of open addressing is that it avoids pointers altogether.
Instead of following pointers, we compute the sequence of slots to be examined.
The extra memory freed by not storing pointers provides the hash table with a larger number of slots for the same amount of memory, potentially yielding fewer collisions and faster retrieval.
The algorithm for searching for key k probes the same sequence of slots that the insertion algorithm examined when key k was inserted.
This argument assumes that keys are not deleted from the hash table.
The procedure HASH-SEARCH takes as input a hash table T and a key k, returning j if it ﬁnds that slot j contains key k, or NIL if key k is not present in table T.
Linear probing is easy to implement, but it suffers from a problem known as primary clustering.
Long runs of occupied slots build up, increasing the average search time.
Clusters arise because an empty slot preceded by i full slots gets ﬁlled next with probability .i C 1/=m.
Long runs of occupied slots tend to get longer, and the average search time increases.
Thus, unlike the case of linear or quadratic probing, the probe sequence here depends in two ways upon the key k, since the initial probe position, the offset, or both, may vary.
Figure 11.5 gives an example of insertion by double hashing.
The value h2.k/ must be relatively prime to the hash-table size m for the entire hash table to be searched.
Another way is to let m be prime and to design h2 so that it always returns a positive integer less than m.
We now analyze the expected number of probes for hashing with open addressing under the assumption of uniform hashing, beginning with an analysis of the number of probes made in an unsuccessful search.
Now, we use equation (C.25) to bound the expected number of probes:
Theorem 11.6 gives us the performance of the HASH-INSERT procedure almost immediately.
We have to do a little more work to compute the expected number of probes for a successful search.
If the hash table is half full, the expected number of probes in a successful search is less than 1:387
Although hashing is often a good choice for its excellent average-case performance, hashing can also provide excellent worst-case performance when the set of keys is static: once the keys are stored in the table, the set of keys never changes.
Some applications naturally have static sets of keys: consider the set of reserved words in a programming language, or the set of ﬁle names on a CD-ROM.
A secondary hash table Sj stores all keys hashing to slot j.
No collisions occur in any of the secondary hash tables, and so searching takes constant time in the worst case.
To create a perfect hashing scheme, we use two levels of hashing, with universal hashing at each level.
The ﬁrst level is essentially the same as for hashing with chaining: we hash the n keys into m slots using a hash function h carefully selected from a family of universal hash functions.
Instead of making a linked list of the keys hashing to slot j , however, we use a small secondary hash table Sj with an associated hash function hj.
By choosing the hash functions hj carefully, we can guarantee that there are no collisions at the secondary level.
In order to guarantee that there are no collisions at the secondary level, however, we will need to let the size mj of hash table Sj be the square of the number nj of keys hashing to slot j.
Although you might think that the quadratic dependence of mj on nj may seem likely to cause the overall storage requirement to be excessive, we shall show that by choosing the ﬁrst-level hash function well, we can limit the expected total amount of space used to O.n/
We use hash functions chosen from the universal classes of hash functions of Section 11.3.3
The ﬁrst-level hash function comes from the class Hpm, where as in Section 11.3.3, p is a prime number greater than any key value.
First, we shall determine how to ensure that the secondary tables have no collisions.
Second, we shall show that the expected amount of memory used overall—for the primary hash table and all the secondary hash tables—is O.n/
Then, the probability is less than 1=2 that there are any collisions.
Let X be a random variable that counts the number of collisions.
When m D n2, the expected number of collisions is.
Given the set K of n keys to be hashed (remember that K is static), it is thus easy to ﬁnd a collision-free hash function h with a few random trials.
When n is large, however, a hash table of size m D n2 is excessive.
Therefore, we adopt the two-level hashing approach, and we use the approach of Theorem 11.9 only to hash the entries within each slot.
We use an outer, or ﬁrst-level, hash function h to hash the keys into m D n slots.
Then, if nj keys hash to slot j , we use a secondary hash table Sj of size mj D n2j to provide collision-free constanttime lookup.
We now turn to the issue of ensuring that the overall memory used is O.n/
Since the size mj of the j th secondary hash table grows quadratically with the number nj of keys stored, we run the risk that the overall amount of storage could be excessive.
The following theorem and a corollary provide a bound on the expected combined sizes of all the secondary hash tables.
A second corollary bounds the probability that the combined size of all the secondary hash tables is superlinear (actually, that it equals or exceeds 4n)
Theorem 11.10 Suppose that we store n keys in a hash table of size m D n using a hash function h randomly chosen from a universal class of hash functions.
Proof We start with the following identity, which holds for any nonnegative integer a:
By the properties of universal hashing, the expected value of this summation is at most n.
From Corollary 11.12, we see that if we test a few randomly chosen hash functions from the universal family, we will quickly ﬁnd one that uses a reasonable amount of storage.
If i now equals m, the table is full, so terminate the search.
Show that this scheme is an instance of the general “quadratic probing” scheme.
Prove that this algorithm examines every table position in the worst case.
Hint: Find a key for which all hash functions in H produce the same value.
Suppose that Alice and Bob secretly agree on a hash function h from a 2-universal family H of hash functions.
Each h 2 H maps from a universe of keys U to Zp , where p is prime.
Later, Alice sends a message m to Bob over the Internet, where m 2 U.
She authenticates this message to Bob by also sending an authentication tag t D h.m/, and Bob checks that the pair .m; t/ he receives indeed satisﬁes t D h.m/
Luhn (1953) for inventing hash tables, along with the chaining method for resolving collisions.
Thus, we can use a search tree both as a dictionary and as a priority queue.
Basic operations on a binary search tree take time proportional to the height of the tree.
For a complete binary tree with n nodes, such operations run in ‚.lgn/ worst-case time.
If the tree is a linear chain of n nodes, however, the same operations take ‚.n/ worst-case time.
In practice, we can’t always guarantee that binary search trees are built randomly, but we can design variations of binary search trees with good guaranteed worst-case performance on basic operations.
Chapter 13 presents one such variation, red-black trees, which have height O.lg n/
Chapter 18 introduces B-trees, which are particularly good for maintaining databases on secondary (disk) storage.
After presenting the basic properties of binary search trees, the following sections show how to walk a binary search tree to print its values in sorted order, how to search for a value in a binary search tree, how to ﬁnd the minimum or maximum element, how to ﬁnd the predecessor or successor of an element, and how to insert into or delete from a binary search tree.
The basic mathematical properties of trees appear in Appendix B.
A binary search tree is organized, as the name suggests, in a binary tree, as shown in Figure 12.1
We can represent such a tree by a linked data structure in which each node is an object.
For any node x, the keys in the left subtree of x are at most x:key, and the keys in the right subtree of x are at least x:key.
Different binary search trees can represent the same set of values.
The worst-case running time for most search-tree operations is proportional to the height of the tree.
If a child or the parent is missing, the appropriate attribute contains the value NIL.
The root node is the only node in the tree whose parent is NIL.
The keys in a binary search tree are always stored in such a way as to satisfy the binary-search-tree property:
The same property holds for every node in the tree.
The binary-search-tree property allows us to print out all the keys in a binary search tree in sorted order by a simple recursive algorithm, called an inorder tree walk.
This algorithm is so named because it prints the key of the root of a subtree between printing the values in its left subtree and printing those in its right subtree.
Similarly, a preorder tree walk prints the root before the values in either subtree, and a postorder tree walk prints the root after the values in its subtrees.
The correctness of the algorithm follows by induction directly from the binary-search-tree property.
It takes ‚.n/ time to walk an n-node binary search tree, since after the initial call, the procedure calls itself recursively exactly twice for each node in the tree—once for its left child and once for its right child.
The following theorem gives a formal proof that it takes linear time to perform an inorder tree walk.
Hint: An easy solution uses a stack as an auxiliary data structure.
A more complicated, but elegant, solution uses no stack but assumes that we can test two pointers for equality.
We often need to search for a key stored in a binary search tree.
Besides the SEARCH operation, binary search trees can support such queries as MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR.
In this section, we shall examine these operations and show how to support each one in time O.h/ on any binary search tree of height h.
We use the following procedure to search for a node with a given key in a binary search tree.
Given a pointer to the root of the tree and a key k, TREE-SEARCH returns a pointer to a node with key k if one exists; otherwise, it returns NIL.
The minimum key in the tree is 2, which is found by following left pointers from the root.
The maximum key 20 is found by following right pointers from the root.
The node with key 13 has no right subtree, and thus its successor is its lowest ancestor whose left child is also an ancestor.
In this case, the node with key 15 is its successor.
The procedure begins its search at the root and traces a simple path downward in the tree, as shown in Figure 12.2
For each node x it encounters, it compares the key k with x:key.
If k is smaller than x:key, the search continues in the left subtree of x, since the binary-searchtree property implies that k could not be stored in the right subtree.
Symmetrically, if k is larger than x:key, the search continues in the right subtree.
The nodes encountered during the recursion form a simple path downward from the root of the tree, and thus the running time of TREE-SEARCH is O.h/, where h is the height of the tree.
We can rewrite this procedure in an iterative fashion by “unrolling” the recursion into a while loop.
We can always ﬁnd an element in a binary search tree whose key is a minimum by following left child pointers from the root until we encounter a NIL, as shown in Figure 12.2
The following procedure returns a pointer to the minimum element in the subtree rooted at a given node x, which we assume to be non-NIL:
If a node x has no left subtree, then since every key in the right subtree of x is at least as large as x:key, the minimum key in the subtree rooted at x is x:key.
If node x has a left subtree, then since no key in the right subtree is smaller than x:key and every key in the left subtree is not larger than x:key, the minimum key in the subtree rooted at x resides in the subtree rooted at x: left.
Both of these procedures run in O.h/ time on a tree of height h since, as in TREESEARCH, the sequence of nodes encountered forms a simple path downward from the root.
Given a node in a binary search tree, sometimes we need to ﬁnd its successor in the sorted order determined by an inorder tree walk.
The structure of a binary search tree allows us to determine the successor of a node without ever comparing keys.
The following procedure returns the successor of a node x in a binary search tree if it exists, and NIL if x has the largest key in the tree:
On the other hand, as Exercise 12.2-6 asks you to show, if the right subtree of node x is empty and x has a successor y, then y is the lowest ancestor of x whose left child is also an ancestor of x.
To ﬁnd y, we simply go up the tree from x until we encounter a node that is the left child of its parent; lines 3–7 of TREE-SUCCESSOR handle this case.
The running time of TREE-SUCCESSOR on a tree of height h is O.h/, since we either follow a simple path up the tree or follow a simple path down the tree.
The procedure TREE-PREDECESSOR, which is symmetric to TREE-SUCCESSOR, also runs in time O.h/
Theorem 12.2 We can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR so that each one runs in O.h/ time on a binary search tree of height h.
Which of the following sequences could not be the sequence of nodes examined? a.
Show that y:key is either the smallest key in T larger than x:key or the largest key in T smaller than x:key.
The operations of insertion and deletion cause the dynamic set represented by a binary search tree to change.
The data structure must be modiﬁed to reﬂect this change, but in such a way that the binary-search-tree property continues to hold.
As we shall see, modifying the tree to insert a new element is relatively straightforward, but handling deletion is somewhat more intricate.
Lightly shaded nodes indicate the simple path from the root down to the position where the item is inserted.
The dashed line indicates the link in the tree that is added to insert the item.
Like the other primitive operations on search trees, the procedure TREE-INSERT runs in O.h/ time on a tree of height h.
Thus, TREE-DELETE runs in O.h/ time on a tree of height h.
Theorem 12.3 We can implement the dynamic-set operations INSERT and DELETE so that each one runs in O.h/ time on a binary search tree of height h.
Argue that the number of nodes examined in searching for a value in the tree is one plus the number of nodes examined when the value was ﬁrst inserted into the tree.
What are the worstcase and best-case running times for this sorting algorithm?
We have shown that each of the basic operations on a binary search tree runs in O.h/ time, where h is the height of the tree.
Theorem 12.4 The expected height of a randomly built binary search tree on n distinct keys is O.lg n/
Using the substitution method, we shall show that for all positive integers n, the recurrence (12.2) has the solution.
Give an asymptotic upper bound on the height of an n-node binary search tree in which the average depth of a node is ‚.lgn/
Equal keys pose a problem for the implementation of binary search trees.
What is the asymptotic performance of TREE-INSERT when used to insert n items with identical keys into an initially empty binary search tree?
Give the worst-case performance and informally derive the expected running time.
This ordering is similar to that used in English-language dictionaries.
Let S be a set of distinct bit strings whose lengths sum to n.
Show how to use a radix tree to sort S lexicographically in ‚.n/ time.
In this problem, we prove that the average depth of a node in a randomly built binary search tree with n nodes is O.lg n/
We deﬁne the total path length P.T / of a binary tree T as the sum, over all nodes x in T , of the depth of node x, which we denote by d.x; T /
We can determine each node’s key by traversing the simple path from the root to that node.
There is no need, therefore, to store the keys in the nodes; the keys appear here for illustrative purposes only.
Nodes are heavily shaded if the keys corresponding to them are not in the tree; such nodes are present only to establish a path to other nodes.
Argue that the average depth of a node in T is.
Thus, we wish to show that the expected value of P.T / is O.n lg n/
Let TL and TR denote the left and right subtrees of tree T , respectively.
Let P.n/ denote the average total path length of a randomly built binary search tree with n nodes.
Recalling the alternative analysis of the randomized version of quicksort given in Problem 7-3, conclude that P.n/ D O.n lg n/
At each recursive invocation of quicksort, we choose a random pivot element to partition the set of elements being sorted.
Each node of a binary search tree partitions the set of elements that fall into the subtree rooted at that node.
Describe an implementation of quicksort in which the comparisons to sort a set of elements are exactly the same as the comparisons to insert the elements into a binary search tree.
The order in which comparisons are made may differ, but the same comparisons must occur.
Let bn denote the number of different binary trees with n nodes.
In this problem, you will ﬁnd a formula for bn, as well as an asymptotic estimate.
Referring to Problem 4-4 for the deﬁnition of a generating function, let B.x/ be the generating function.
Knuth [211] contains a good discussion of simple binary search trees as well as many variations.
Binary search trees seem to have been independently discovered by a number of people in the late 1950s.
Radix trees are often called “tries,” which comes from the middle letters in the word retrieval.
Section 15.5 will show how to construct an optimal binary search tree when we know the search frequencies before constructing the tree.
That is, given the frequencies of searching for each key and the frequencies of searching for values that fall between keys in the tree, we construct a binary search tree for which a set of searches that follows these frequencies examines the minimum number of nodes.
Chapter 12 showed that a binary search tree of height h can support any of the basic dynamic-set operations—such as SEARCH, PREDECESSOR, SUCCESSOR, MINIMUM, MAXIMUM, INSERT, and DELETE—in O.h/ time.
Thus, the set operations are fast if the height of the search tree is small.
If its height is large, however, the set operations may run no faster than with a linked list.
Red-black trees are one of many search-tree schemes that are “balanced” in order to guarantee that basic dynamic-set operations take O.lg n/ time in the worst case.
A red-black tree is a binary search tree with one extra bit of storage per node: its color, which can be either RED or BLACK.
By constraining the node colors on any simple path from the root to a leaf, red-black trees ensure that no such path is more than twice as long as any other, so that the tree is approximately balanced.
Each node of the tree now contains the attributes color, key, left, right, and p.
If a child or the parent of a node does not exist, the corresponding pointer attribute of the node contains the value NIL.
We shall regard these NILs as being pointers to leaves (external nodes) of the binary search tree and the normal, key-bearing nodes as being internal nodes of the tree.
A red-black tree is a binary tree that satisﬁes the following red-black properties:
If a node is red, then both its children are black.
As a matter of convenience in dealing with boundary conditions in red-black.
For a red-black tree T , the sentinel T:nil is an object with the same attributes as an ordinary node in the tree.
Its color attribute is BLACK, and its other attributes—p, left, right, and key—can take on arbitrary values.
As Figure 13.1(b) shows, all pointers to NIL are replaced by pointers to the sentinel T:nil.
We use the sentinel so that we can treat a NIL child of a node x as an ordinary node whose parent is x.
Although we instead could add a distinct sentinel node for each NIL in the tree, so that the parent of each NIL is well deﬁned, that approach would waste space.
Instead, we use the one sentinel T:nil to represent all the NILs—all leaves and the root’s parent.
The values of the attributes p, left, right, and key of the sentinel are immaterial, although we may set them during the course of a procedure for our convenience.
We generally conﬁne our interest to the internal nodes of a red-black tree, since they hold the key values.
In the remainder of this chapter, we omit the leaves when we draw red-black trees, as shown in Figure 13.1(c)
We call the number of black nodes on any simple path from, but not including, a node x down to a leaf the black-height of the node, denoted bh.x/
By property 5, the notion of black-height is well deﬁned, since all descending simple paths from the node have the same number of black nodes.
We deﬁne the black-height of a red-black tree to be the black-height of its root.
The following lemma shows why red-black trees make good search trees.
To complete the proof of the lemma, let h be the height of the tree.
According to property 4, at least half the nodes on any simple path from the root to a leaf, not.
Figure 13.1 A red-black tree with black nodes darkened and red nodes shaded.
Every node in a red-black tree is either red or black, the children of a red node are both black, and every simple path from a node to a descendant leaf contains the same number of black nodes.
We shall use this drawing style in the remainder of this chapter.
As an immediate consequence of this lemma, we can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR in O.lg n/ time on red-black trees, since each can run in O.h/ time on a binary search tree of height h (as shown in Chapter 12) and any red-black tree on n nodes is a binary search tree with height O.lg n/
Of course, references to NIL in the algorithms of Chapter 12 would have to be replaced by T:nil.
Although the algorithms TREE-INSERT and TREE-DELETE from Chapter 12 run in O.lg n/ time when given a red-black tree as input, they do not directly support the dynamic-set operations INSERT and DELETE, since they do not guarantee that the modiﬁed binary search tree will be a red-black tree.
If the inserted node is colored red, is the resulting tree a red-black tree? What if it is colored black?
In other words, the root may be either red or black.
Consider a relaxed red-black tree T whose root is red.
If we color the root of T black but make no other changes to T , is the resulting tree a red-black tree?
What are the possible degrees of a black node after all.
What is this ratio? What tree has the smallest possible ratio, and what is the ratio?
The search-tree operations TREE-INSERT and TREE-DELETE, when run on a redblack tree with n keys, take O.lg n/ time.
Because they modify the tree, the result may violate the red-black properties enumerated in Section 13.1
To restore these properties, we must change the colors of some of the nodes in the tree and also change the pointer structure.
We change the pointer structure through rotation, which is a local operation in a search tree that preserves the binary-search-tree property.
Figure 13.2 shows the two kinds of rotations: left rotations and right rotations.
When we do a left rotation on a node x, we assume that its right child y is not T:nil; x may be any node in the tree whose right child is not T:nil.
The left rotation “pivots” around the link from x to y.
It makes y the new root of the subtree, with x as y’s left child and y’s left child as x’s right child.
Figure 13.3 shows an example of how LEFT-ROTATE modiﬁes a binary search tree.
Only pointers are changed by a rotation; all other attributes in a node remain the same.
Figure 13.3 An example of how the procedure LEFT-ROTATE.T; x/ modiﬁes a binary search tree.
Inorder tree walks of the input tree and the modiﬁed tree produce the same listing of key values.
The while loop in lines 1–15 maintains the following three-part invariant at the start of each iteration of the loop:
Recall that we need to show that a loop invariant is true prior to the ﬁrst iteration of the loop, that each iteration maintains the loop invariant, and that the loop invariant gives us a useful property at loop termination.
Having shown that each iteration of the loop maintains the invariant, we have shown that RB-INSERT-FIXUP correctly restores the red-black properties.
Like the other basic operations on an n-node red-black tree, deletion of a node takes time O.lg n/
Deleting a node from a red-black tree is a bit more complicated than inserting a node.
The procedure for deleting a node from a red-black tree is based on the TREEDELETE procedure (Section 12.3)
First, we need to customize the TRANSPLANT subroutine that TREE-DELETE calls so that it applies to a red-black tree:
Although RB-DELETE contains almost twice as many lines of pseudocode as TREE-DELETE, the two procedures have the same basic structure.
You can ﬁnd each line of TREE-DELETE within RB-DELETE (with the changes of replacing NIL by T:nil and replacing calls to TRANSPLANT by calls to RB-TRANSPLANT), executed under the same conditions.
As discussed, we keep track of the node x that moves into node y’s original position.
Recall from Section 12.3 that y has no left child.
Finally, if node y was black, we might have introduced one or more violations of the red-black properties, and so we call RB-DELETE-FIXUP in line 22 to restore the red-black properties.
If y was red, the red-black properties still hold when y is removed or moved, for the following reasons:
Since y could not have been the root if it was red, the root remains black.
If node y was black, three problems may arise, which the call of RB-DELETEFIXUP will remedy.
Third, moving y within the tree causes any simple path that previously contained y to have one fewer black node.
Thus, property 5 is now violated by any ancestor of y in the tree.
We can correct the violation of property 5 by saying that node x, now occupying y’s original position, has an “extra” black.
When we remove or move the black node y, we “push” its blackness onto node x.
The color attribute of x will still be either RED (if x is red-and-black) or BLACK (if x is doubly black)
In other words, the extra black on a node is reﬂected in x’s pointing to the node rather than in the color attribute.
We can now see the procedure RB-DELETE-FIXUP and examine how it restores the red-black properties to the search tree.
The goal of the while loop in lines 1–22 is to move the extra black up the tree until.
Within the while loop, x always points to a nonroot doubly black node.
We determine in line 2 whether x is a left child or a right child of its parent x:p.
We have given the code for the situation in which x is a left child; the situation in which x is a right child—line 22—is symmetric.
We maintain a pointer w to the sibling of x.
Since node x is doubly black, node w cannot be T:nil, because otherwise, the number of blacks on the simple path from x:p to the (singly black) leaf w would be smaller than the number on the simple path from x:p to x.
Since w must have black children, we can switch the colors of w and x:p and then perform a left-rotation on x:p without violating any of the red-black properties.
As in RB-INSERT-FIXUP, the cases in RB-DELETE-FIXUP are not mutually exclusive.
Since w is also black, we take one black off both x and w, leaving x with only one black and leaving w red.
To compensate for removing one black from x and w, we would like to add an extra black to x:p, which was originally either red or black.
We do so by repeating the while loop with x:p as the new node x.
Hence, the value c of the color attribute of the new node x is RED, and the loop terminates when it tests the loop condition.
We can switch the colors of w and its left child w: left and then perform a right rotation on w without violating any of the red-black properties.
By making some color changes and performing a left rotation on x:p, we can remove the extra black on x, making it singly black, without violating any of the red-black properties.
Setting x to be the root causes the while loop to terminate when it tests the loop condition.
What is the running time of RB-DELETE? Since the height of a red-black tree of n nodes is O.lg n/, the total cost of the procedure without the call to RB-DELETEFIXUP takes O.lg n/ time.
Case 2 is the only case in which the while loop can be repeated, and then the pointer x moves up the tree at most O.lg n/ times, performing no rotations.
Thus, the procedure RB-DELETE-FIXUP takes O.lg n/ time and performs at most three rotations, and the overall time for RB-DELETE is therefore also O.lg n/
If the professors are correct, then lines 5–6 are wrong.
Show that x:p must be black at the start of case 1, so that the professors have nothing to worry about.
Is the resulting red-black tree the same as the initial red-black tree? Justify your answer.
During the course of an algorithm, we sometimes ﬁnd that we need to maintain past versions of a dynamic set as it is updated.
One way to implement a persistent set is to copy the entire set whenever it is modiﬁed, but this approach can slow down a program and also consume much space.
Consider a persistent set S with the operations INSERT, DELETE, and SEARCH, which we implement using binary search trees as shown in Figure 13.8(a)
We maintain a separate root for every version of the set.
We thus copy only part of the tree and share some of the nodes with the original tree, as shown in Figure 13.8(b)
Assume that each tree node has the attributes key, left, and right but no parent.
The most recent version of the set consists of the nodes reachable from the root r 0, and the previous version consists of the nodes reachable from r.
Heavily shaded nodes are added when key 5 is inserted.
For a general persistent binary search tree, identify the nodes that we need to change to insert a key k or delete a node y.
Show how to use red-black trees to guarantee that the worst-case running time and space are O.lg n/ per insertion or deletion.
Argue that RB-INSERT and RB-DELETE can maintain the bh attribute without requiring extra storage in the nodes of the tree and without increasing the asymptotic running times.
Show that while descending through T , we can determine the black-height of each node we visit in O.1/ time per node visited.
Argue that the running time of RB-JOIN is O.lg n/
To implement an AVL tree, we maintain an extra attribute in each node: x:h is the height of node x.
As for any other binary search tree T , we assume that T:root points to the root node.
Prove that an AVL tree with n nodes has height O.lg n/
Hint: Prove that an AVL tree of height h has at least Fh nodes, where Fh is the hth Fibonacci number.
Show that AVL-INSERT, run on an n-node AVL tree, takes O.lg n/ time and performs O.1/ rotations.
If we insert a set of n items into a binary search tree, the resulting tree may be horribly unbalanced, leading to long search times.
As we saw in Section 12.4, however, randomly built binary search trees tend to be balanced.
Therefore, one strategy that, on average, builds a balanced tree for a ﬁxed set of items would be to randomly permute the items and then insert them in that order into the tree.
What if we do not have all the items at once? If we receive the items one at a time, can we still randomly build a binary search tree out of them?
This combination of properties is why the tree is called a “treap”: it has features of both a binary search tree and a heap.
It helps to think of treaps in the following way.
Then the resulting treap is the tree that would have been formed if the nodes had been inserted into a normal binary search tree in the order given by their (randomly chosen) priorities, i.e., xi :priority < xj :priority means that we had inserted xi before xj.
Let us see how to insert a new node into an existing treap.
The ﬁrst thing we do is assign to the new node a random priority.
Then we call the insertion algorithm, which we call TREAP-INSERT, whose operation is illustrated in Figure 13.10
The left spine is shaded in (a), and the right spine is shaded in (b)
Hint: Execute the usual binary-search-tree insertion procedure and then perform rotations to restore the min-heap order property.
Show that the expected running time of TREAP-INSERT is ‚.lg n/
TREAP-INSERT performs a search and then a sequence of rotations.
Although these two operations have the same expected running time, they have different costs in practice.
A search reads information from the treap without modifying it.
In contrast, a rotation changes parent and child pointers within the treap.
On most computers, read operations are much faster than write operations.
We will show that the expected number of rotations performed is bounded by a constant.
In order to do so, we will need some deﬁnitions, which Figure 13.11 depicts.
The left spine of a binary search tree T is the simple path from the root to the node with the smallest key.
In other words, the left spine is the simple path from the root that consists of only left edges.
Symmetrically, the right spine of T is the simple path from the root consisting of only right edges.
The length of a spine is the number of nodes it contains.
Consider the treap T immediately after TREAP-INSERT has inserted node x.
Let C be the length of the right spine of the left subtree of x.
Let D be the length of the left spine of the right subtree of x.
Prove that the total number of rotations that were performed during the insertion of x is equal to C CD.
We will now calculate the expected values of C and D.
Xik D I fy is in the right spine of the left subtree of xg : f.
An AA-tree is similar to a red-black tree except that left children may never be red.
They are the default implementation of a dictionary in LEDA [253], which is a well-implemented collection of data structures and algorithms.
Splay trees maintain balance without any explicit balance condition such as color.
Instead, “splay operations” (which involve rotations) are performed within the tree every time an access is made.
The amortized cost (see Chapter 17) of each operation on an n-node tree is O.lg n/
Skip lists [286] provide an alternative to balanced binary trees.
A skip list is a linked list that is augmented with a number of additional pointers.
Each dictionary operation runs in expected time O.lg n/ on a skip list of n items.
Some engineering situations require no more than a “textbook” data structure—such as a doubly linked list, a hash table, or a binary search tree—but many others require a dash of creativity.
Only in rare situations will you need to create an entirely new type of data structure, though.
More often, it will sufﬁce to augment a textbook data structure by storing additional information in it.
You can then program new operations for the data structure to support the desired application.
Augmenting a data structure is not always straightforward, however, since the added information must be updated and maintained by the ordinary operations on the data structure.
This chapter discusses two data structures that we construct by augmenting redblack trees.
Section 14.1 describes a data structure that supports general orderstatistic operations on a dynamic set.
We can then quickly ﬁnd the i th smallest number in a set or the rank of a given element in the total ordering of the set.
Section 14.2 abstracts the process of augmenting a data structure and provides a theorem that can simplify the process of augmenting red-black trees.
Section 14.3 uses this theorem to help design a data structure for maintaining a dynamic set of intervals, such as time intervals.
Given a query interval, we can then quickly ﬁnd an interval in the set that overlaps it.
We saw how to determine any order statistic in O.n/ time from an unordered set.
In this section, we shall see how to modify red-black trees so that we can determine any order statistic for a dynamic set in O.lg n/ time.
We shall also see how to compute the rank of an element—its position in the linear order of the set—in O.lg n/ time.
Figure 14.1 An order-statistic tree, which is an augmented red-black tree.
In addition to its usual attributes, each node x has an attribute x:size, which is the number of nodes, other than the sentinel, in the subtree rooted at x.
Figure 14.1 shows a data structure that can support fast order-statistic operations.
An order-statistic tree T is simply a red-black tree with additional information stored in each node.
Besides the usual red-black tree attributes x:key, x:color, x:p, x: left, and x:right in a node x, we have another attribute, x:size.
This attribute contains the number of (internal) nodes in the subtree rooted at x (including x itself), that is, the size of the subtree.
In the presence of equal keys, the above notion of rank is not well deﬁned.
We remove this ambiguity for an order-statistic tree by deﬁning the rank of an element as the position at which it would be printed in an inorder walk of the tree.
Before we show how to maintain this size information during insertion and deletion, let us examine the implementation of two order-statistic queries that use this additional information.
We begin with an operation that retrieves an element with a given rank.
The procedure OS-SELECT.x; i/ returns a pointer to the node containing the i th smallest key in the subtree rooted at x.
Because each recursive call goes down one level in the order-statistic tree, the total time for OS-SELECT is at worst proportional to the height of the tree.
Since the tree is a red-black tree, its height is O.lg n/, where n is the number of nodes.
Thus, the running time of OS-SELECT is O.lg n/ for a dynamic set of n elements.
Given a pointer to a node x in an order-statistic tree T , the procedure OS-RANK returns the position of x in the linear order determined by an inorder tree walk of T.
We can think of node x’s rank as the number of nodes preceding x in an inorder tree walk, plus 1 for x itself.
At the start of each iteration of the while loop of lines 3–6, r is the rank of x:key in the subtree rooted at node y.
We use this loop invariant to show that OS-RANK works correctly as follows: Initialization: Prior to the ﬁrst iteration, line 1 sets r to be the rank of x:key within.
Maintenance: At the end of each iteration of the while loop, we set y D y:p.
Thus we must show that if r is the rank of x:key in the subtree rooted at y at the start of the loop body, then r is the rank of x:key in the subtree rooted at y:p at the end of the loop body.
In each iteration of the while loop, we consider the subtree rooted at y:p.
We have already counted the number of nodes in the subtree rooted at node y that precede x in an inorder walk, and so we must add the nodes in the subtree rooted at y’s sibling that precede x in an inorder walk, plus 1 for y:p if it, too, precedes x.
If y is a left child, then neither y:p nor any node in y:p’s right subtree precedes x, and so we leave r alone.
Otherwise, y is a right child and all the nodes in y:p’s left subtree precede x, as does y:p itself.
Termination: The loop terminates when y D T:root, so that the subtree rooted at y is the entire tree.
Thus, the value of r is the rank of x:key in the entire tree.
Since each iteration of the while loop takes O.1/ time, and y goes up one level in.
Given the size attribute in each node, OS-SELECT and OS-RANK can quickly compute order-statistic information.
But unless we can efﬁciently maintain these attributes within the basic modifying operations on red-black trees, our work will have been for naught.
We shall now show how to maintain subtree sizes for both insertion and deletion without affecting the asymptotic running time of either operation.
We noted in Section 13.3 that insertion into a red-black tree consists of two phases.
The ﬁrst phase goes down the tree from the root, inserting the new node as a child of an existing node.
The second phase goes up the tree, changing colors and performing rotations to maintain the red-black properties.
To maintain the subtree sizes in the ﬁrst phase, we simply increment x:size for each node x on the simple path traversed from the root down toward the leaves.
Since there are O.lg n/ nodes on the traversed path, the additional cost of maintaining the size attributes is O.lg n/
In the second phase, the only structural changes to the underlying red-black tree are caused by rotations, of which there are at most two.
Moreover, a rotation is a local operation: only two nodes have their size attributes invalidated.
The link around which the rotation is performed is incident on these two nodes.
Referring to the code for LEFT-ROTATE.T; x/ in Section 13.2, we add the following lines:
Since at most two rotations are performed during insertion into a red-black tree, we spend only O.1/ additional time updating size attributes in the second phase.
Thus, the total time for insertion into an n-node order-statistic tree is O.lg n/, which is asymptotically the same as for an ordinary red-black tree.
Deletion from a red-black tree also consists of two phases: the ﬁrst operates on the underlying search tree, and the second causes at most three rotations and otherwise performs no structural changes.
The ﬁrst phase either removes one node y from the tree or moves upward it within the tree.
To update the subtree sizes, we simply traverse a simple path from node y (starting from its original position within the tree) up to the root, decrementing the size.
The link around which we rotate is incident on the two nodes whose size attributes need to be updated.
The updates are local, requiring only the size information stored in x, y, and the roots of the subtrees shown as triangles.
Since this path has length O.lg n/ in an nnode red-black tree, the additional time spent maintaining size attributes in the ﬁrst phase is O.lg n/
We handle the O.1/ rotations in the second phase of deletion in the same manner as for insertion.
Thus, both insertion and deletion, including maintaining the size attributes, take O.lg n/ time for an n-node order-statistic tree.
Accordingly, suppose we store in each node its rank in the subtree of which it is the root.
Show how to maintain this information during insertion and deletion.
Describe an O.n lg n/time algorithm to determine the number of pairs of chords that intersect inside the circle.
For example, if the n chords are all diameters that meet at the center, then the correct answer is.
The process of augmenting a basic data structure to support additional functionality occurs quite frequently in algorithm design.
We shall use it again in the next section to design a data structure that supports operations on intervals.
In this section, we examine the steps involved in such augmentation.
We shall also prove a theorem that allows us to augment red-black trees easily in many cases.
Determine additional information to maintain in the underlying data structure.
As with any prescriptive design method, you should not blindly follow the steps in the order given.
Most design work contains an element of trial and error, and progress on all steps usually proceeds in parallel.
Nevertheless, this four-step method provides a good focus for your efforts in augmenting a data structure, and it is also a good way to organize the documentation of an augmented data structure.
We followed these steps in Section 14.1 to design our order-statistic trees.
For step 1, we chose red-black trees as the underlying data structure.
A clue to the suitability of red-black trees comes from their efﬁcient support of other dynamicset operations on a total order, such as MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR.
For step 2, we added the size attribute, in which each node x stores the size of the subtree rooted at x.
For example, we could have implemented OS-SELECT and OS-RANK using just the keys stored in the tree, but they would not have run in O.lg n/ time.
Sometimes, the additional information is pointer information rather than data, as in Exercise 14.2-1
For step 3, we ensured that insertion and deletion could maintain the size attributes while still running in O.lg n/ time.
Ideally, we should need to update only a few elements of the data structure in order to maintain the additional information.
For example, if we simply stored in each node its rank in the tree, the OS-SELECT and OS-RANK procedures would run quickly, but inserting a new minimum element would cause a change to this information in every node of the tree.
When we store subtree sizes instead, inserting a new element causes information to change in only O.lg n/ nodes.
For step 4, we developed the operations OS-SELECT and OS-RANK.
After all, the need for new operations is why we bother to augment a data structure in the ﬁrst place.
Occasionally, rather than developing new operations, we use the additional information to expedite existing ones, as in Exercise 14.2-1
When red-black trees underlie an augmented data structure, we can prove that insertion and deletion can always efﬁciently maintain certain kinds of additional information, thereby making step 3 very easy.
The proof of the following theorem is similar to the argument from Section 14.1 that we can maintain the size attribute for order-statistic trees.
Theorem 14.1 (Augmenting a red-black tree) Let f be an attribute that augments a red-black tree T of n nodes, and suppose that the value of f for each node x depends on only the information in nodes x, x: left, and x:right, possibly including x: left: f and x:right: f.
Then, we can maintain the values of f in all nodes of T during insertion and deletion without asymptotically affecting the O.lg n/ performance of these operations.
Proof The main idea of the proof is that a change to an f attribute in a node x propagates only to ancestors of x in the tree.
Once we have updated T:root: f , no other node will depend on the new value, and so the process terminates.
Since the height of a red-black tree is O.lg n/, changing an f attribute in a node costs O.lg n/ time in updating all nodes that depend on the change.
Insertion of a node x into T consists of two phases.
The ﬁrst phase inserts x as a child of an existing node x:p.
We can compute the value of x: f in O.1/ time since, by supposition, it depends only on information in the other attributes of x itself and the information in x’s children, but x’s children are both the sentinel T:nil.
Once we have computed x: f , the change propagates up the tree.
Thus, the total time for the ﬁrst phase of insertion is O.lg n/
During the second phase, the only structural changes to the tree come from rotations.
Since only two nodes change in a rotation, the total time for updating the f attributes is O.lg n/ per rotation.
Since the number of rotations during insertion is at most two, the total time for insertion is O.lg n/
In the ﬁrst phase, changes to the tree occur when the deleted node is removed from the tree.
If the deleted node had two children at the time, then its successor moves into the position of the deleted node.
Propagating the updates to f caused by these changes costs at most O.lg n/, since the changes modify the tree locally.
Fixing up the red-black tree during the second phase requires at most three rotations, and each rotation requires at most O.lg n/ time to propagate the updates to f.
Thus, like insertion, the total time for deletion is O.lg n/
The asymptotic performance of other operations on order-statistic trees should not be affected.
Intervals are convenient for representing events that each occupy a continuous period of time.
We might, for example, wish to query a database of time intervals to ﬁnd out what events occurred during a given interval.
The data structure in this section provides an efﬁcient means for maintaining such an interval database.
An interval tree is a red-black tree that maintains a dynamic set of elements, with each element x containing an interval x: int.
Figure 14.4 shows how an interval tree represents a set of intervals.
We shall track the four-step method from Section 14.2 as we review the design of an interval tree and the operations that run on it.
We choose a red-black tree in which each node x contains an interval x: int and the key of x is the low endpoint, x: int: low, of the interval.
Thus, an inorder tree walk of the data structure lists the intervals in sorted order by low endpoint.
In addition to the intervals themselves, each node x contains a value x:max, which is the maximum value of any interval endpoint stored in the subtree rooted at x.
We must verify that insertion and deletion take O.lg n/ time on an interval tree of n nodes.
We can determine x:max given interval x: int and the max values of node x’s children:
Each node x contains an interval, shown above the dashed line, and the maximum value of any interval endpoint in the subtree rooted at x, shown below the dashed line.
An inorder tree walk of the tree lists the nodes in sorted order by left endpoint.
If there is no interval that overlaps i in the tree, the procedure returns a pointer to the sentinel T:nil.
The search for an interval that overlaps i starts with x at the root of the tree and proceeds downward.
It terminates when either it ﬁnds an overlapping interval or x points to the sentinel T:nil.
Since each iteration of the basic loop takes O.1/ time, and since the height of an n-node red-black tree is O.lg n/, the INTERVAL-SEARCH procedure takes O.lg n/ time.
To see why INTERVAL-SEARCH is correct, we must understand why it sufﬁces to examine a single path from the root.
The basic idea is that at any node x, if x: int does not overlap i , the search always proceeds in a safe direction: the search will deﬁnitely ﬁnd an overlapping interval if the tree contains one.
Proof The while loop of lines 2–5 terminates either when x D T:nil or i overlaps x: int.
In the latter case, it is certainly correct to return x.
Therefore, we focus on the former case, in which the while loop terminates because x D T:nil.
We use the following invariant for the while loop of lines 2–5:
If tree T contains an interval that overlaps i , then the subtree rooted at x contains such an interval.
Initialization: Prior to the ﬁrst iteration, line 1 sets x to be the root of T , so that the invariant holds.
By the interval trichotomy, therefore, i 0 and i do not overlap.
Thus, the left subtree of x contains no intervals that overlap i , so that setting x to x:right maintains the invariant.
By the interval trichotomy, i and i 00 do not overlap.
We conclude that whether or not any interval in x’s left subtree overlaps i , setting x to x: left maintains the invariant.
Termination: If the loop terminates when x D T:nil, then the subtree rooted at x contains no interval overlapping i.
The contrapositive of the loop invariant implies that T contains no interval that overlaps i.
Hint: One simple method makes several queries, modifying the tree between queries.
A slightly more complicated method does not modify the tree.
The operation should return a pointer to a node x in T such that x: int: low D i: low and x: int:high D i:high, or T:nil if T contains no such node.
Assume that each rectangle is rectilinearly oriented (sides parallel to the x- and y-axes), so that we represent a rectangle by its minimum and maximum xand y-coordinates.
Give an O.n lg n/-time algorithm to decide whether or not a set of n rectangles so represented contains two rectangles that overlap.
Your algorithm need not report all intersecting pairs, but it must report that an overlap exists if one rectangle entirely covers another, even if the boundary lines do not intersect.
Hint: Move a “sweep” line across the set of rectangles.
Suppose that we wish to keep track of a point of maximum overlap in a set of intervals—a point with the largest number of intervals in the set that overlap it.
Show that there will always be a point of maximum overlap that is an endpoint of one of the segments.
Describe an O.n lg n/-time algorithm that, given integers n and m, outputs the .n;m/-Josephus permutation.
In their book, Preparata and Shamos [282] describe several of the interval trees that appear in the literature, citing work by H.
The book details an interval tree that, given a static database of n intervals, allows us to enumerate all k intervals that overlap a given query interval in O.k C lg n/ time.
The techniques in this part are somewhat more sophisticated, but they help us to attack many computational problems.
The themes introduced in this part will recur later in this book.
Dynamic programming typically applies to optimization problems in which we make a set of choices in order to arrive at an optimal solution.
As we make each choice, subproblems of the same form often arise.
Dynamic programming is effective when a given subproblem may arise from more than one partial set of choices; the key technique is to store the solution to each such subproblem in case it should reappear.
Chapter 15 shows how this simple idea can sometimes transform exponential-time algorithms into polynomial-time algorithms.
The idea of a greedy algorithm is to make each choice in a locally optimal manner.
A simple example is coin-changing: to minimize the number of U.S.
We cannot always easily tell whether a greedy approach will be effective, however.
We use amortized analysis to analyze certain algorithms that perform a sequence of similar operations.
Instead of bounding the cost of the sequence of operations by bounding the actual cost of each operation separately, an amortized analysis provides a bound on the actual cost of the entire sequence.
One advantage of this approach is that although some operations might be expensive, many others might be cheap.
In other words, many of the operations might run in well under the worstcase time.
Amortized analysis is not just an analysis tool, however; it is also a way of thinking about the design of algorithms, since the design of an algorithm and the analysis of its running time are often closely intertwined.
Chapter 17 introduces three ways to perform an amortized analysis of an algorithm.
Dynamic programming, like the divide-and-conquer method, solves problems by combining the solutions to subproblems.
In contrast, dynamic programming applies when the subproblems overlap—that is, when subproblems share subsubproblems.
In this context, a divide-and-conquer algorithm does more work than necessary, repeatedly solving the common subsubproblems.
Each solution has a value, and we wish to ﬁnd a solution with the optimal (minimum or maximum) value.
We call such a solution an optimal solution to the problem, as opposed to the optimal solution, since there may be several solutions that achieve the optimal value.
Compute the value of an optimal solution, typically in a bottom-up fashion.
Section 15.1 examines the problem of cutting a rod into.
Section 15.2 asks how we can multiply a chain of matrices while performing the fewest total scalar multiplications.
Given these examples of dynamic programming, Section 15.3 discusses two key characteristics that a problem must have for dynamic programming to be a viable solution technique.
Section 15.4 then shows how to ﬁnd the longest common subsequence of two sequences via dynamic programming.
Finally, Section 15.5 uses dynamic programming to construct binary search trees that are optimal, given a known distribution of keys to be looked up.
Our ﬁrst example uses dynamic programming to solve a simple problem in deciding where to cut steel rods.
Serling Enterprises buys long steel rods and cuts them into shorter rods, which it then sells.
The management of Serling Enterprises wants to know the best way to cut up the rods.
Note that if the price pn for a rod of length n is large enough, an optimal solution may require no cutting at all.
Each rod of length i inches earns the company pi dollars of revenue.
Above each piece is the value of that piece, according to the sample price chart of Figure 15.1
We shall not pursue this line of inquiry further, however.
Note that to solve the original problem of size n, we solve smaller problems of the same type, but of smaller sizes.
Once we make the ﬁrst cut, we may consider the two pieces as independent instances of the rod-cutting problem.
The overall optimal solution incorporates optimal solutions to the two related subproblems, maximizing revenue from each of those two pieces.
We say that the rod-cutting problem exhibits optimal substructure: optimal solutions to a problem incorporate optimal solutions to related subproblems, which we may solve independently.
In this formulation, an optimal solution embodies the solution to only one related subproblem—the remainder—rather than two.
The following procedure implements the computation implicit in equation (15.2) in a straightforward, top-down, recursive manner.
If you were to code up CUT-ROD in your favorite programming language and run it on your computer, you would ﬁnd that once the input size becomes moderately large, your program would take a long time to run.
For n D 40, you would ﬁnd that your program takes at least several minutes, and most likely more than an hour.
In fact, you would ﬁnd that each time you increase n by 1, your program’s running time would approximately double.
To analyze the running time of CUT-ROD, let T .n/ denote the total number of calls made to CUT-ROD when called with its second parameter equal to n.
This expression equals the number of nodes in a subtree whose root is labeled n in the recursion tree.
We now show how to convert CUT-ROD into an efﬁcient algorithm, using dynamic programming.
Having observed that a naive recursive solution is inefﬁcient because it solves the same subproblems repeatedly, we arrange for each subproblem to be solved only once, saving its solution.
If we need to refer to this subproblem’s solution again later, we can just look it.
Dynamic programming thus uses additional memory to save computation time; it serves an example of a time-memory trade-off.
The savings may be dramatic: an exponential-time solution may be transformed into a polynomial-time solution.
We shall illustrate both of them with our rod-cutting example.
The ﬁrst approach is top-down with memoization.2 In this approach, we write the procedure recursively in a natural manner, but modiﬁed to save the result of each subproblem (usually in an array or hash table)
The procedure now ﬁrst checks to see whether it has previously solved this subproblem.
If so, it returns the saved value, saving further computation at this level; if not, the procedure computes the value in the usual manner.
We say that the recursive procedure has beenmemoized; it “remembers” what results it has computed previously.
This approach typically depends on some natural notion of the “size” of a subproblem, such that solving any particular subproblem depends only on solving “smaller” subproblems.
We sort the subproblems by size and solve them in size order, smallest ﬁrst.
When solving a particular subproblem, we have already solved all of the smaller subproblems its solution depends upon, and we have saved their solutions.
We solve each subproblem only once, and when we ﬁrst see it, we have already solved all of its prerequisite subproblems.
These two approaches yield algorithms with the same asymptotic running time, except in unusual circumstances where the top-down approach does not actually recurse to examine all possible subproblems.
The bottom-up approach often has much better constant factors, since it has less overhead for procedure calls.
Here is the the pseudocode for the top-down CUT-ROD procedure, with memoization added:
Memoization comes from memo, since the technique consists of recording a value so that we can look it up later.
The vertex labels give the sizes of the corresponding subproblems.
A directed edge .x; y/ indicates that we need a solution to subproblem y when solving subproblem x.
This graph is a reduced version of the tree of Figure 15.3, in which all nodes with the same label are collapsed into a single vertex and all edges go from parent to child.
The bottom-up and top-down versions have the same asymptotic running time.
The running time of procedure BOTTOM-UP-CUT-ROD is ‚.n2/, due to its doubly-nested loop structure.
The number of iterations of its inner for loop, in lines 5–6, forms an arithmetic series.
The running time of its top-down counterpart, MEMOIZED-CUT-ROD, is also ‚.n2/, although this running time may be a little harder to see.
Because a recursive call to solve a previously solved subproblem returns immediately, MEMOIZED-CUT-ROD solves each subproblem just once.
To solve a subproblem of size n, the for loop of lines 6–7 iterates n times.
Thus, the total number of iterations of this for loop, over all recursive calls of MEMOIZED-CUT-ROD, forms an arithmetic series, giving a total of ‚.n2/ iterations, just like the inner for loop of BOTTOM-UPCUT-ROD.
We actually are using a form of aggregate analysis here.
We shall see aggregate analysis in detail in Section 17.1
The subproblem graph for the problem embodies exactly this information.
It is a directed graph, containing one vertex for each distinct subproblem.
For example, the subproblem graph contains an edge from x to y if a top-down recursive procedure for solving x directly calls itself to solve y.
We can think of the subproblem graph as a “reduced” or “collapsed” version of the recursion tree for the top-down recursive method, in which we coalesce all nodes for the same subproblem into a single vertex and direct all edges from parent to child.
The bottom-up method for dynamic programming considers the vertices of the subproblem graph in such an order that we solve the subproblems y adjacent to a given subproblem x before we solve subproblem x.
Recall from Section B.4 that the adjacency relation is not necessarily symmetric.
In other words, no subproblem is considered until all of the subproblems it depends upon have been solved.
Similarly, using notions from the same chapter, we can view the top-down method (with memoization) for dynamic programming as a “depth-ﬁrst search” of the subproblem graph (see Section 22.3)
The size of the subproblem graph G D .V;E/ can help us determine the running time of the dynamic programming algorithm.
Since we solve each subproblem just once, the running time is the sum of the times needed to solve each subproblem.
Typically, the time to compute the solution to a subproblem is proportional to the degree (number of outgoing edges) of the corresponding vertex in the subproblem graph, and the number of subproblems is equal to the number of vertices in the subproblem graph.
In this common case, the running time of dynamic programming is linear in the number of vertices and edges.
With this information, we can readily print an optimal solution.
Here is an extended version of BOTTOM-UP-CUT-ROD that computes, for each rod size j , not only the maximum revenue rj , but also sj , the optimal size of the ﬁrst piece to cut off:
Our next example of dynamic programming is an algorithm that solves the problem of matrix-chain multiplication.
How we parenthesize a chain of matrices can have a dramatic impact on the cost of evaluating the product.
The attributes rows and columns are the numbers of rows and columns in a matrix.
Note that in the matrix-chain multiplication problem, we are not actually multiplying matrices.
Our goal is only to determine an order for multiplying matrices that has the lowest cost.
In so doing, we shall follow the four-step sequence that we stated at the beginning of this chapter:
We shall go through these steps in order, demonstrating clearly how we apply each step to the problem.
A recursive algorithm may encounter each subproblem many times in different branches of its recursion tree.
This property of overlapping subproblems is the second hallmark of when dynamic programming applies (the ﬁrst hallmark being optimal substructure)
Instead of computing the solution to recurrence (15.7) recursively, we compute the optimal cost by using a tabular, bottom-up approach.
We present the corresponding top-down approach using memoization in Section 15.3
How many vertices does it have? How many edges does it have, and which edges are they?
The ﬁrst step in solving an optimization problem by dynamic programming is to characterize the structure of an optimal solution.
Recall that a problem exhibits optimal substructure if an optimal solution to the problem contains within it optimal solutions to subproblems.
Whenever a problem exhibits optimal substructure, we have a good clue that dynamic programming might apply.
As Chapter 16 discusses, it also might mean that a greedy strategy applies, however.
In dynamic programming, we build an optimal solution to the problem from optimal solutions to subproblems.
Consequently, we must take care to ensure that the range of subproblems we consider includes those used in an optimal solution.
You will ﬁnd yourself following a common pattern in discovering optimal substructure:
You show that a solution to the problem consists of making a choice, such as choosing an initial cut in a rod or choosing an index at which to split the matrix chain.
Making this choice leaves one or more subproblems to be solved.
You suppose that for a given problem, you are given the choice that leads to an optimal solution.
You do not concern yourself yet with how to determine this choice.
You just assume that it has been given to you.
Given this choice, you determine which subproblems ensue and how to best characterize the resulting space of subproblems.
You show that the solutions to the subproblems used within an optimal solution to the problem must themselves be optimal by using a “cut-and-paste” technique.
You do so by supposing that each of the subproblem solutions is not optimal and then deriving a contradiction.
In particular, by “cutting out” the nonoptimal solution to each subproblem and “pasting in” the optimal one, you show that you can get a better solution to the original problem, thus contradicting your supposition that you already had an optimal solution.
To characterize the space of subproblems, a good rule of thumb says to try to keep the space as simple as possible and then expand it as necessary.
For example, the space of subproblems that we considered for the rod-cutting problem contained the problems of optimally cutting up a rod of length i for each size i.
This subproblem space worked well, and we had no need to try a more general space of subproblems.
Usually, the subproblem graph gives an alternative way to perform the same analysis.
In Chapter 16, we shall examine “greedy algorithms,” which have many similarities to dynamic programming.
In particular, problems to which greedy algorithms apply have optimal substructure.
One major difference between greedy algorithms and dynamic programming is that instead of ﬁrst ﬁnding optimal solutions to subproblems and then making an informed choice, greedy algorithms ﬁrst make a “greedy” choice—the choice that looks best at the time—and then solve a resulting subproblem, without bothering to solve all possible related smaller subproblems.
Such a path must be simple, since removing a cycle from a path produces a path with fewer edges.
We can use the breadth-ﬁrst search technique of Chapter 22 to solve the unweighted problem.
Figure 15.6 A directed graph showing that the problem of ﬁnding a longest simple path in an unweighted directed graph does not have optimal substructure.
The path q ! r ! t is a longest simple path from q to t , but the subpath q ! r is not a longest simple path from q to r , nor is the subpath r ! t a longest simple path from r to t.
This example shows that for longest simple paths, not only does the problem lack optimal substructure, but we cannot necessarily assemble a “legal” solution to the problem from solutions to subproblems.
If we combine the longest simple paths q ! s ! t ! r and r ! q ! s ! t , we get the path q ! s ! t ! r ! q ! s ! t , which is not simple.
Indeed, the problem of ﬁnding an unweighted longest simple path does not appear to have any sort of optimal substructure.
In fact, this problem is NP-complete, which—as we shall see in Chapter 34—means that we are unlikely to ﬁnd a way to solve it in polynomial time.
Why is the substructure of a longest simple path so different from that of a shortest path? Although a solution to a problem for both longest and shortest paths uses two subproblems, the subproblems in ﬁnding the longest simple path are not independent, whereas for shortest paths they are.
What do we mean by subproblems being independent? We mean that the solution to one subproblem does not affect the solution to another subproblem of the same problem.
For the example of Figure 15.6, we have the problem of ﬁnding a longest simple path from q to t with two subproblems: ﬁnding longest simple paths from q to r and from r to t.
For the ﬁrst of these subproblems, we choose the path q ! s ! t ! r , and so we have also used the vertices s and t.
We can no longer use these vertices in the second subproblem, since the combination of the two solutions to subproblems would yield a path that is not simple.
If we cannot use vertex t in the second problem, then we cannot solve it at all, since t is required to be on the path that we ﬁnd, and it is not the vertex at which we are “splicing” together the subproblem solutions (that vertex being r)
Because we use vertices s and t in one subproblem solution, we cannot use them in the other subproblem solution.
We must use at least one of them to solve the other subproblem, however, and we must use both of them to solve it optimally.
Looked at another way, using resources in solving one subproblem (those resources being vertices) renders them unavailable for the other subproblem.
Thus, we are assured that the subproblems for the shortest-path problem are independent.
The second ingredient that an optimization problem must have for dynamic programming to apply is that the space of subproblems must be “small” in the sense that a recursive algorithm for the problem solves the same subproblems over and over, rather than always generating new subproblems.
Typically, the total number of distinct subproblems is a polynomial in the input size.
When a recursive algorithm revisits the same problem repeatedly, we say that the optimization problem has overlapping subproblems.4 In contrast, a problem for which a divide-andconquer approach is suitable usually generates brand-new problems at each step of the recursion.
In Section 15.1, we brieﬂy examined how a recursive solution to rod cutting makes exponentially many calls to ﬁnd solutions of smaller subproblems.
It may seem strange that dynamic programming relies on subproblems being both independent and overlapping.
Although these requirements may sound contradictory, they describe two different notions, rather than two points on the same axis.
Two subproblems of the same problem are independent if they do not share resources.
Two subproblems are overlapping if they are really the same subproblem that occurs as a subproblem of different problems.
Each node is labeled by the values of the parameters i and j.
The recursive algorithm, on the other hand, must again solve each subproblem every time it reappears in the recursion tree.
Whenever a recursion tree for the natural recursive solution to a problem contains the same subproblem repeatedly, and the total number of distinct subproblems is small, dynamic programming can improve efﬁciency, sometimes dramatically.
As a practical matter, we often store which choice we made in each subproblem in a table so that we do not have to reconstruct this information from the costs that we stored.
As we saw for the rod-cutting problem, there is an alternative approach to dynamic programming that often offers the efﬁciency of the bottom-up dynamicprogramming approach while maintaining a top-down strategy.
The idea is to memoize the natural, but inefﬁcient, recursive algorithm.
As in the bottom-up approach, we maintain a table with subproblem solutions, but the control structure for ﬁlling in the table is more like the recursive algorithm.
A memoized recursive algorithm maintains an entry in a table for the solution to each subproblem.
Each table entry initially contains a special value to indicate that the entry has yet to be ﬁlled in.
When the subproblem is ﬁrst encountered as the recursive algorithm unfolds, its solution is computed and then stored in the table.
Each subsequent time that we encounter this subproblem, we simply look up the value stored in the table and return it.5
Note where it resembles the memoized top-down method for the rod-cutting problem.
This approach presupposes that we know the set of all possible subproblem parameters and that we have established the relationship between table positions and subproblems.
Another, more general, approach is to memoize by using hashing with the subproblem parameters as keys.
Shaded subtrees represent values that it looks up rather than recomputes.
We can categorize the calls of LOOKUP-CHAIN into two types:
There are only ‚.n2/ distinct subproblems in total, and either of these methods computes the solution to each subproblem only once.
Without memoization, the natural recursive algorithm runs in exponential time, since solved subproblems are repeatedly solved.
Moreover, for some problems we can exploit the regular pattern of table accesses in the dynamicprogramming algorithm to reduce time or space requirements even further.
Alternatively, if some subproblems in the subproblem space need not be solved at all, the memoized solution has the advantage of solving only those subproblems that are deﬁnitely required.
Explain why memoization fails to speed up a good divideand-conquer algorithm such as MERGE-SORT.
You realize that instead of directly exchanging one currency for another, you might be better off making a series of trades through other currencies, winding up with the currency you want.
You are given, for each pair of currencies i and j , an exchange rate rij , meaning that if you start with d units of currency i , you can trade for drij units of currency j.
A sequence of trades may entail a commission, which depends on the number of trades you make.
Let ck be the commission that you are charged when you make k trades.
Then show that if commissions ck are arbitrary values, then the problem of ﬁnding the best sequence of exchanges from currency 1 to currency n does not necessarily exhibit optimal substructure.
Biological applications often need to compare the DNA of two (or more) different organisms.
A strand of DNA consists of a string of molecules called.
Representing each of these bases by its initial letter, we can express a strand of DNA as a string over the ﬁnite set fA;C;G;Tg.
One reason to compare two strands of DNA is to determine how “similar” the two strands are, as some measure of how closely related the two organisms are.
We can, and do, deﬁne similarity in many different ways.
For example, we can say that two DNA strands are similar if one is a substring of the other.
Alternatively, we could say that two strands are similar if the number of changes needed to turn one into the other is small.
Given two sequences X and Y , we say that a sequence Z is a common subsequence of X and Y if Z is a subsequence of both X and Y.
For example, if X D hA;B;C;B;D;A;Bi and Y D hB;D;C;A;B;Ai, the sequence hB;C;Ai is a common subsequence of both X and Y.
The sequence hB; C; B; Ai is an LCS of X and Y , as is the sequence hB; D; A; Bi, since X and Y have no common subsequence of length 5 or greater.
This section shows how to efﬁciently solve the LCS problem using dynamic programming.
In a brute-force approach to solving the LCS problem, we would enumerate all subsequences of X and check each subsequence to see whether it is also a subsequence of Y , keeping track of the longest subsequence we ﬁnd.
Because X has 2m subsequences, this approach requires exponential time, making it impractical for long sequences.
As we shall see, the natural classes of subproblems correspond to pairs of “preﬁxes” of the two input sequences.
The way that Theorem 15.1 characterizes longest common subsequences tells us that an LCS of two sequences contains within it an LCS of preﬁxes of the two sequences.
Based on equation (15.9), we could easily write an exponential-time recursive algorithm to compute the length of an LCS of two sequences.
With this method, we encounter the elements of this LCS in reverse order.
The following recursive procedure prints out an LCS of X and Y in the proper, forward order.
For the b table in Figure 15.8, this procedure prints BCBA.
The procedure takes time O.mC n/, since it decrements at least one of i and j in each recursive call.
Once you have developed an algorithm, you will often ﬁnd that you can improve on the time or space it uses.
Some changes can simplify the code and improve constant factors but otherwise yield no asymptotic improvement in performance.
Others can yield substantial asymptotic savings in time and space.
We can, however, reduce the asymptotic space requirements for LCS-LENGTH, since it needs only two rows of table c at a time: the row being computed and the previous row.
In fact, as Exercise 15.4-4 asks you to show, we can use only slightly more than the space for one row of c to compute the length of an LCS.
This improvement works if we need only the length of an LCS; if we need to reconstruct the elements of an LCS, the smaller table does not keep enough information to retrace our steps in O.mC n/ time.
Suppose that we are designing a program to translate text from English to French.
For each occurrence of each English word in the text, we need to look up its French equivalent.
We could perform these lookup operations by building a binary search tree with n English words as keys and their French equivalents as satellite data.
Because we will search the tree for each individual word in the text, we want the total time spent searching to be as low as possible.
We could ensure an O.lg n/ search time per occurrence by using a red-black tree or any other balanced binary search tree.
Words appear with different frequencies, however, and a frequently used word such as the may appear far from the root while a rarely used word such as machicolation appears near the root.
Such an organization would slow down the translation, since the number of nodes visited when searching for a key in a binary search tree equals one plus the depth of the node containing the key.
How do we organize a binary search tree so as to minimize the number of nodes visited in all searches, given that we know how often each word occurs?
Because we have probabilities of searches for each key and each dummy key, we can determine the expected cost of a search in a given binary search tree T.
Then the expected cost of a search in T is.
For a given set of probabilities, we wish to construct a binary search tree whose expected search cost is smallest.
We call such a tree an optimal binary search tree.
This example shows that an optimal binary search tree is not necessarily a tree whose overall height is smallest.
Nor can we necessarily construct an optimal binary search tree by always putting the key with the greatest probability at the root.
Step 1: The structure of an optimal binary search tree.
Thus, if kr is the root of an optimal subtree containing keys ki ; : : : ; kj , we have.
We choose the root that gives the lowest expected search cost, giving us our ﬁnal recursive formulation:
Step 3: Computing the expected search cost of an optimal binary search tree.
OPTIMAL-BST computes the rows from bottom to top and from left to right within each row.
For the example in Figure 15.10, your procedure should print out the structure.
Suppose that we are given a directed acyclic graph G D .V;E/ with realvalued edge weights and two distinguished vertices s and t.
Describe a dynamicprogramming approach for ﬁnding a longest weighted simple path from s to t.
What does the subproblem graph look like? What is the efﬁciency of your algorithm?
Figure 15.11 Seven points in the plane, shown on a unit grid.
A palindrome is a nonempty string over some alphabet that reads the same forward and backward.
Examples of palindromes are all strings of length 1, civic, racecar, and aibohphobia (fear of palindromes)
Give an efﬁcient algorithm to ﬁnd the longest palindrome that is a subsequence of a given input string.
For example, given the input character, your algorithm should return carac.
In the euclidean traveling-salesman problem, we are given a set of n points in the plane, and we wish to ﬁnd the shortest closed tour that connects all n points.
The general problem is NP-hard, and its solution is therefore believed to require more than polynomial time (see Chapter 34)
Bentley has suggested that we simplify the problem by restricting our attention to bitonic tours, that is, tours that start at the leftmost point, go strictly rightward to the rightmost point, and then go strictly leftward back to the starting point.
Describe an O.n2/-time algorithm for determining an optimal bitonic tour.
You may assume that no two points have the same x-coordinate and that all operations on real numbers take unit time.
Hint: Scan left to right, maintaining optimal possibilities for the two parts of the tour.
Consider the problem of neatly printing a paragraph with a monospaced font (all characters having the same width) on a printer.
This operation examines all characters in x that have not yet been examined.
The cost of an operation depends on the speciﬁc application, but we assume that each operation’s cost is a constant that is known to us.
We also assume that the individual costs of the copy and replace operations are less than the combined costs of the delete and insert operations; otherwise, the copy and replace operations would not be used.
The cost of a given sequence of transformation operations is the sum of the costs of the individual operations in the sequence.
For the sequence above, the cost of transforming algorithm to altruistic is.
There are several methods for measuring the similarity of two DNA sequences by aligning them.
One such method to align two sequences x and y consists of inserting spaces at.
Professor Stewart is consulting for the president of a corporation that is planning a company party.
The company has a hierarchical structure; that is, the supervisor relation forms a tree rooted at the president.
The personnel ofﬁce has ranked each employee with a conviviality rating, which is a real number.
In order to make the party fun for all attendees, the president does not want both an employee and his or her immediate supervisor to attend.
Professor Stewart is given the tree that describes the structure of the corporation, using the left-child, right-sibling representation described in Section 10.4
Each node of the tree holds, in addition to the pointers, the name of an employee and that employee’s conviviality ranking.
Describe an algorithm to make up a guest list that maximizes the sum of the conviviality ratings of the guests.
Give an algorithm to ﬁnd a seam with the lowest disruption measure.
A certain string-processing language allows a programmer to break a string into two pieces.
Because this operation copies the string, it costs n time units to break a string of n characters into two pieces.
Suppose a programmer wants to break a string into many pieces.
The order in which the breaks occur can affect the total amount of time used.
Your knowledge of algorithms helps you obtain an exciting job with the Acme Computer Company, along with a $10,000 signing bonus.
You decide to invest this money with the goal of maximizing your return at the end of 10 years.
You decide to use the Amalgamated Investment Company to manage your investments.
In each year j , investment i provides a return rate of rij.
In other words, if you invest d dollars in investment i in year j , then at the end of year j , you have drij dollars.
The return rates are guaranteed, that is, you are given all the return rates for the next 10 years for each investment.
At the end of each year, you can leave the money made in the previous year in the same investments, or you can shift money to other investments, by either shifting money between existing investments or moving money to a new investement.
The problem, as stated, allows you to invest your money in multiple investments in each year.
Prove that there exists an optimal investment strategy that, in each year, puts all the money into a single investment.
Recall that an optimal investment strategy maximizes the amount of money after 10 years and is not concerned with any other objectives, such as minimizing risk.
Prove that the problem of planning your optimal investment strategy exhibits optimal substructure.
Suppose that Amalgamated Investments imposed the additional restriction that, at any point, you can have no more than $15,000 in any one investment.
Show that the problem of maximizing your income at the end of 10 years no longer exhibits optimal substructure.
Give an algorithm that calculates a plan for the company that minimizes its costs while fulﬁlling all the demand.
The running time should be polyomial in n and D.
Suppose that you are the general manager for a major-league baseball team.
During the off-season, you need to sign some free-agent players for your team.
The team owner has given you a budget of $X to spend on free agents.
You are considering N different positions, and for each position, P free-agent players who play that position are available.8 Because you do not want to overload your roster with too many players at any position, for each position you may sign at most one free agent who plays that position.
If you do not sign any players at a particular position, then you plan to stick with the players you already have at that position.
To determine how valuable a player is going to be, you decide to use a sabermetric statistic9 known as “VORP,” or “value over replacement player.” A player with a higher VORP is more valuable than a player with a lower VORP.
A player with a higher VORP is not necessarily more expensive to sign than a player with a lower VORP, because factors other than a player’s value determine how much it costs to sign him.
Devise an algorithm that maximizes the total VORP of the players you sign while spending no more than $X altogether.
You may assume that each player signs for a multiple of $100,000
Your algorithm should output the total VORP of the players you sign, the total amount of money you spend, and a list of which players you sign.
Analyze the running time and space requirement of your algorithm.
The word “programming,” both here and in linear programming, refers to using a tabular solution method.
Although optimization techniques incorporating elements of dynamic programming were known earlier, Bellman provided the area with a solid mathematical basis [37]
Although there are nine positions on a baseball team, N is not necesarily equal to 9 because some general managers have particular ways of thinking about positions.
For example, a general manager might consider right-handed pitchers and left-handed pitchers to be separate “positions,” as well as starting pitchers, long relief pitchers (relief pitchers who can pitch several innings), and short relief pitchers (relief pitchers who normally pitch at most only one inning)
Sabermetrics is the application of statistical analysis to baseball records.
It provides several ways to compare the relative values of individual players.
Algorithms for optimization problems typically go through a sequence of steps, with a set of choices at each step.
For many optimization problems, using dynamic programming to determine the best choices is overkill; simpler, more efﬁcient algorithms will do.
A greedy algorithm always makes the choice that looks best at the moment.
That is, it makes a locally optimal choice in the hope that this choice will lead to a globally optimal solution.
This chapter explores optimization problems for which greedy algorithms provide optimal solutions.
Greedy algorithms do not always yield optimal solutions, but for many problems they do.
We shall ﬁrst examine, in Section 16.1, a simple but nontrivial problem, the activity-selection problem, for which a greedy algorithm efﬁciently computes an optimal solution.
Section 16.2 reviews the basic elements of the greedy approach, giving a direct approach for proving greedy algorithms correct.
Section 16.3 presents an important application of greedy techniques: designing data-compression (Huffman) codes.
In Section 16.4, we investigate some of the theory underlying combinatorial structures called “matroids,” for which a greedy algorithm always produces an optimal solution.
Finally, Section 16.5 applies matroids to solve a problem of scheduling unit-time tasks with deadlines and penalties.
We shall then observe that we need to consider only one choice—the greedy choice—and that when we make the greedy choice, only one subproblem remains.
We shall complete the process of developing a greedy solution by converting the recursive algorithm to an iterative one.
Although the steps we shall go through in this section are slightly more involved than is typical when developing a greedy algorithm, they illustrate the relationship between greedy algorithms and dynamic programming.
We can easily verify that the activity-selection problem exhibits optimal substructure.
Let us denote by Sij the set of activities that start after activity ai ﬁnishes and that ﬁnish before activity aj starts.
Suppose that we wish to ﬁnd a maximum set of mutually compatible activities in Sij , and suppose further that such a maximum set is Aij , which includes some activity ak.
By including ak in an optimal solution, we are left with two subproblems: ﬁnding mutually compatible activities in the set Sik (activities that start after activity ai ﬁnishes and that ﬁnish before activity ak starts) and ﬁnding mutually compatible activities in the set Skj (activities that start after activity ak ﬁnishes and that ﬁnish before activity aj starts)
The usual cut-and-paste argument shows that the optimal solution Aij must also include optimal solutions to the two subproblems for Sik and Skj.
We could then develop a recursive algorithm and memoize it, or we could work bottom-up and ﬁll in table entries as we go along.
But we would be overlooking another important characteristic of the activity-selection problem that we can use to great advantage.
What if we could choose an activity to add to our optimal solution without having to ﬁrst solve all the subproblems? That could save us from having to consider all the choices inherent in recurrence (16.2)
In fact, for the activity-selection problem, we need consider only one choice: the greedy choice.
What do we mean by the greedy choice for the activity-selection problem? Intuition suggests that we should choose an activity that leaves the resource available for as many other activities as possible.
Now, of the activities we end up choosing, one of them must be the ﬁrst one to ﬁnish.
Our intuition tells us, therefore, to choose the activity in S with the earliest ﬁnish time, since that would leave the resource available for as many of the activities that follow it as possible.
If more than one activity in S has the earliest ﬁnish time, then we can choose any such activity.
In other words, since the activities are sorted in monotonically increasing order by ﬁnish time, the greedy choice is activity a1
Choosing the ﬁrst activity to ﬁnish is not the only way to think of making a greedy choice for this problem; Exercise 16.1-3 asks you to explore other possibilities.
If we make the greedy choice, we have only one remaining subproblem to solve: ﬁnding activities that start after a1 ﬁnishes.
One big question remains: is our intuition correct? Is the greedy choice—in which we choose the ﬁrst activity to ﬁnish—always part of some optimal solution? The following theorem shows that it is.
We sometimes refer to the sets Sk as subproblems rather than as just sets of activities.
It will always be clear from the context whether we are referring to Sk as a set of activities or as a subproblem whose input is that set.
Theorem 16.1 Consider any nonempty subproblem Sk, and let am be an activity in Sk with the earliest ﬁnish time.
Then am is included in some maximum-size subset of mutually compatible activities of Sk.
Thus, we see that although we might be able to solve the activity-selection problem with dynamic programming, we don’t need to.
Besides, we have not yet examined whether the activity-selection problem even has overlapping subproblems.
Instead, we can repeatedly choose the activity that ﬁnishes ﬁrst, keep only the activities compatible with this activity, and repeat until no activities remain.
Moreover, because we always choose the activity with the earliest ﬁnish time, the ﬁnish times of the activities we choose must strictly increase.
We can consider each activity just once overall, in monotonically increasing order of ﬁnish times.
Instead, it can work top-down, choosing an activity to put into the optimal solution and then solving the subproblem of choosing activities from those that are compatible with those already chosen.
Greedy algorithms typically have this top-down design: make a choice and then solve a subproblem, rather than the bottom-up technique of solving subproblems before making a choice.
Because the pseudocode takes s and f as arrays, it indexes into them with square brackets rather than subscripts.
It returns a maximum-size set of mutually compatible activities in Sk.
We assume that the n input activities are already ordered by monotonically increasing ﬁnish time, according to equation (16.1)
If not, we can sort them into this order in O.n lg n/ time, breaking ties arbitrarily.
In particular, activity ai is examined in the last call made in which k < i.
We easily can convert our recursive procedure to an iterative one.
It is usually a straightforward task to transform a tail-recursive procedure to an iterative form; in fact, some compilers for certain programming languages perform this task automatically.
Activities considered in each recursive call appear between horizontal lines.
In each recursive call, the activities that have already been selected are shaded, and the activity shown in white is being considered.
If the starting time of an activity occurs before the ﬁnish time of the most recently added activity (the arrow between them points left), it is rejected.
Otherwise (the arrow points directly up or to the right), it is selected.
It also assumes that the input activities are ordered by monotonically increasing ﬁnish time.
It collects selected activities into a set A and returns this set when it is done.
The variable k indexes the most recent addition to A, corresponding to the activity ak in the recursive version.
Since we consider the activities in order of monotonically increasing ﬁnish time, fk is always the maximum ﬁnish time of any activity in A.
The for loop of lines 4–7 ﬁnds the earliest activity in Sk to ﬁnish.
The loop considers each activity am in turn and adds am to A if it is compatible with all previously selected activities; such an activity is the earliest in Sk to ﬁnish.
If activity am is compatible, then lines 6–7 add activity am to A and set k to m.
Assume that the inputs have been sorted as in equation (16.1)
Describe how this approach is a greedy algorithm, and prove that it yields an optimal solution.
Give an example to show that the approach of selecting the activity of least duration from among those that are compatible with previously selected activities does not work.
Do the same for the approaches of always selecting the compatible activity that overlaps the fewest other remaining activities and always selecting the compatible remaining activity with the earliest start time.
We wish to schedule all the activities using as few lecture halls as possible.
Give an efﬁcient greedy algorithm to determine which activity should use which lecture hall.
A greedy algorithm obtains an optimal solution to a problem by making a sequence of choices.
At each decision point, the algorithm makes choice that seems best at the moment.
This heuristic strategy does not always produce an optimal solution, but as we saw in the activity-selection problem, sometimes it does.
This section discusses some of the general properties of greedy methods.
The process that we followed in Section 16.1 to develop a greedy algorithm was a bit more involved than is typical.
For the activity-selection problem, we formulated recurrence (16.2), but we bypassed developing a recursive algorithm based on this recurrence.
Show that if we make the greedy choice, then only one subproblem remains.
For example, in the activity-selection problem, we ﬁrst deﬁned the subproblems Sij , where both i and j varied.
We then found that if we always made the greedy choice, we could restrict the subproblems to be of the form Sk.
Alternatively, we could have fashioned our optimal substructure with a greedy choice in mind, so that the choice leaves just one subproblem to solve.
In the activity-selection problem, we could have started by dropping the second subscript and deﬁning subproblems of the form Sk.
Then, we could have proven that a greedy choice (the ﬁrst activity am to ﬁnish in Sk), combined with an optimal solution to the remaining set Sm of compatible activities, yields an optimal solution to Sk.
More generally, we design greedy algorithms according to the following sequence of steps:
Cast the optimization problem as one in which we make a choice and are left with one subproblem to solve.
Prove that there is always an optimal solution to the original problem that makes the greedy choice, so that the greedy choice is always safe.
Demonstrate optimal substructure by showing that, having made the greedy choice, what remains is a subproblem with the property that if we combine an optimal solution to the subproblem with the greedy choice we have made, we arrive at an optimal solution to the original problem.
We shall use this more direct process in later sections of this chapter.
How can we tell whether a greedy algorithm will solve a particular optimization problem? No way works all the time, but the greedy-choice property and optimal substructure are the two key ingredients.
If we can demonstrate that the problem has these properties, then we are well on the way to developing a greedy algorithm for it.
The ﬁrst key ingredient is the greedy-choice property: we can assemble a globally optimal solution by making locally optimal (greedy) choices.
In other words, when we are considering which choice to make, we make the choice that looks best in the current problem, without considering results from subproblems.
In dynamic programming, we make a choice at each step, but the choice usually depends on the solutions to subproblems.
Of course, even though the code works top down, we still must solve the subproblems before making a choice.
In a greedy algorithm, we make whatever choice seems best at the moment and then solve the subproblem that remains.
The choice made by a greedy algorithm may depend on choices so far, but it cannot depend on any future choices or on the solutions to subproblems.
Thus, unlike dynamic programming, which solves the subproblems before making the ﬁrst choice, a greedy algorithm makes its ﬁrst choice before solving any subproblems.
A dynamicprogramming algorithm proceeds bottom up, whereas a greedy strategy usually progresses in a top-down fashion, making one greedy choice after another, reducing each given problem instance to a smaller one.
Of course, we must prove that a greedy choice at each step yields a globally optimal solution.
Typically, as in the case of Theorem 16.1, the proof examines a globally optimal solution to some subproblem.
It then shows how to modify the solution to substitute the greedy choice for some other choice, resulting in one similar, but smaller, subproblem.
We can usually make the greedy choice more efﬁciently than when we have to consider a wider set of choices.
By preprocessing the input or by using an appropriate data structure (often a priority queue), we often can make greedy choices quickly, thus yielding an efﬁcient algorithm.
A problem exhibits optimal substructure if an optimal solution to the problem contains within it optimal solutions to subproblems.
This property is a key ingredient of assessing the applicability of dynamic programming as well as greedy algorithms.
As an example of optimal substructure, recall how we demonstrated in Section 16.1 that if an optimal solution to subproblem Sij includes an activity ak, then it must also contain optimal solutions to the subproblems Sik and Skj.
Given this optimal substructure, we argued that if we knew which activity to use as ak, we could construct an optimal solution to Sij by selecting ak along with all activities in optimal solutions to the subproblems Sik and Skj.
Based on this observation of optimal substructure, we were able to devise the recurrence (16.2) that described the value of an optimal solution.
We usually use a more direct approach regarding optimal substructure when applying it to greedy algorithms.
As mentioned above, we have the luxury of assuming that we arrived at a subproblem by having made the greedy choice in the original problem.
All we really need to do is argue that an optimal solution to the subproblem, combined with the greedy choice already made, yields an optimal solution to the original problem.
This scheme implicitly uses induction on the subproblems to prove that making the greedy choice at every step produces an optimal solution.
To illustrate the subtleties between the two techniques, let us investigate two variants of a classical optimization problem.
In the fractional knapsack problem, the setup is the same, but the thief can take fractions of items, rather than having to make a binary (0-1) choice for each item.
You can think of an item in the 0-1 knapsack problem as being like a gold ingot and an item in the fractional knapsack problem as more like gold dust.
The two possible solutions that take item 1 are both suboptimal.
In the 0-1 problem, when we consider whether to include an item in the knapsack, we must compare the solution to the subproblem that includes the item with the solution to the subproblem that excludes the item before we can make the.
Give an efﬁcient algorithm to ﬁnd an optimal solution to this variant of the knapsack problem, and argue that your algorithm is correct.
The professor can carry two liters of water, and he can skate m miles before running out of water.
Because North Dakota is relatively ﬂat, the professor does not have to worry about drinking water at a greater rate on uphill sections than on ﬂat or downhill sections.
The professor will start in Grand Forks with two full liters of water.
His ofﬁcial North Dakota state map shows all the places along U.S.
The professor’s goal is to minimize the number of water stops along his route across the state.
Give an efﬁcient method by which he can determine which water stops he should make.
Prove that your strategy yields an optimal solution, and give its running time.
You can choose to reorder each set however you like.
After reordering, let ai be the i th element of set A, and let bi be the i th element of set B.
Prove that your algorithm maximizes the payoff, and state its running time.
We consider the data to be a sequence of characters.
Huffman’s greedy algorithm uses a table giving how often each character occurs (i.e., its frequency) to build up an optimal way of representing each character as a binary string.
Suppose we have a 100,000-character data ﬁle that we wish to store compactly.
We observe that the characters in the ﬁle occur with the frequencies given by Figure 16.3
We have many options for how to represent such a ﬁle of information.
Here, we consider the problem of designing a binary character code (or code for short)
A data ﬁle of 100,000 characters contains only the characters a–f, with the frequencies indicated.
Using the variable-length code shown, we can encode the ﬁle in only 224,000 bits.
This method requires 300,000 bits to code the entire ﬁle.
A variable-length code can do considerably better than a ﬁxed-length code, by giving frequent characters short codewords and infrequent characters long codewords.
We consider here only codes in which no codeword is also a preﬁx of some other codeword.
Such codes are called preﬁx codes.3 Although we won’t prove it here, a preﬁx code can always achieve the optimal data compression among any character code, and so we suffer no loss of generality by restricting our attention to preﬁx codes.
Since no codeword is a preﬁx of any other, the codeword that begins an encoded ﬁle is unambiguous.
We can simply identify the initial codeword, translate it back to the original char3Perhaps “preﬁx-free codes” would be a better name, but the term “preﬁx codes” is standard in the literature.
Each leaf is labeled with a character and its frequency of occurrence.
Each internal node is labeled with the sum of the frequencies of the leaves in its subtree.
The decoding process needs a convenient representation for the preﬁx code so that we can easily pick off the initial codeword.
A binary tree whose leaves are the given characters provides one such representation.
Note that these are not binary search trees, since the leaves need not appear in sorted order and internal nodes do not contain character keys.
Given a tree T corresponding to a preﬁx code, we can easily compute the number of bits required to encode a ﬁle.
For each character c in the alphabet C , let the attribute c: freq denote the frequency of c in the ﬁle and let dT .c/ denote the depth.
Note that dT .c/ is also the length of the codeword for character c.
The number of bits required to encode a ﬁle is thus.
Huffman invented a greedy algorithm that constructs an optimal preﬁx code called a Huffman code.
In line with our observations in Section 16.2, its proof of correctness relies on the greedy-choice property and optimal substructure.
Rather than demonstrating that these properties hold and then developing pseudocode, we present the pseudocode ﬁrst.
Doing so will help clarify how the algorithm makes greedy choices.
For our example, Huffman’s algorithm proceeds as shown in Figure 16.5
The codeword for a letter is the sequence of edge labels on the simple path from the root to the letter.
Line 2 initializes the min-priority queue Q with the characters in C.
The for loop in lines 3–8 repeatedly extracts the two nodes x and y of lowest frequency.
Each part shows the contents of the queue sorted into increasing order by frequency.
At each step, the two trees with lowest frequencies are merged.
Leaves are shown as rectangles containing a character and its frequency.
Internal nodes are shown as circles containing the sum of the frequencies of their children.
The codeword for a letter is the sequence of labels on the edges connecting the root to the leaf for that letter.
Let x and y be two characters in C having the lowest frequencies.
Then there exists an optimal preﬁx code for C in which the codewords for x and y have the same length and differ only in the last bit.
Proof The idea of the proof is to take the tree T representing an arbitrary optimal preﬁx code and modify it to make a tree representing another optimal preﬁx code such that the characters x and y appear as sibling leaves of maximum depth in the new tree.
If we can construct such a tree, then the codewords for x and y will have the same length and differ only in the last bit.
Lemma 16.2 implies that the process of building up an optimal tree by mergers can, without loss of generality, begin with the greedy choice of merging together those two characters of lowest frequency.
Why is this a greedy choice? We can view the cost of a single merger as being the sum of the frequencies of the two items being merged.
Exercise 16.3-4 shows that the total cost of the tree constructed equals the sum of the costs of its mergers.
Of all possible mergers at each step, HUFFMAN chooses the one that incurs the least cost.
Thus, T must represent an optimal preﬁx code for the alphabet C.
Can you generalize your answer to ﬁnd the optimal code when the frequencies are the ﬁrst n Fibonacci numbers?
Hint: Compare the number of possible ﬁles with the number of possible encoded ﬁles.
In this section, we sketch a beautiful theory about greedy algorithms.
This theory describes many situations in which the greedy method yields optimal solutions.
Furthermore, this theory has been extended to cover many applications; see the notes at the end of this chapter for references.
He was studying matric matroids, in which the elements of S are the rows of a given matrix and a set of rows is independent if they are linearly independent in the usual sense.
As Exercise 16.4-2 asks you to show, this structure deﬁnes a matroid.
Thus, it remains to show that MG satisﬁes the exchange property.
Suppose that GA D .V;A/ and GB D .V;B/ are forests of G and that jBj > jAj.
That is, A and B are acyclic sets of edges, and B contains more edges than A does.
If A is an independent subset in a matroid M , we say that A is maximal if it has no extensions.
That is, A is maximal if it is not contained in any larger independent subset of M.
Theorem 16.6 All maximal independent subsets in a matroid have the same size.
Line 4 checks whether adding each element x to A would maintain A as an independent set.
If A would remain independent, then line 5 adds x to A.
Since the empty set is independent, and since each iteration of the for loop maintains A’s independence, the subset A is always independent, by induction.
We shall see in a moment that A is a subset of maximum possible weight, so that A is an optimal subset.
The sorting phase of GREEDY takes time O.n lg n/
Line 4 executes exactly n times, once for each element of S.
If each such check takes time O.f .n//, the entire algorithm runs in time O.n lg nC nf .n//
Proof If no such x exists, then the only independent subset is the empty set and the lemma is vacuously true.
Assume that x … B; otherwise, letting A D B gives an optimal subset of S that contains x.
We next show that if an element is not an option initially, then it cannot be an option later.
Proof This corollary is simply the contrapositive of Lemma 16.8
Corollary 16.9 says that any element that cannot be used immediately can never be used.
Therefore, GREEDY cannot make an error by passing over any initial elements in S that are not an extension of ;, since they can never be used.
An interesting problem that we can solve using matroids is the problem of optimally scheduling unit-time tasks on a single processor, where each task has a deadline, along with a penalty paid if the task misses its deadline.
The problem looks complicated, but we can solve it in a surprisingly simple manner by casting it as a matroid and using a greedy algorithm.
A unit-time task is a job, such as a program to be run on a computer, that requires exactly one unit of time to complete.
We wish to ﬁnd a schedule for S that minimizes the total penalty incurred for missed deadlines.
We say that a task is late in this schedule if it ﬁnishes after its deadline.
We can always transform an arbitrary schedule into early-ﬁrst form, in which the early tasks precede the late tasks.
To see why, note that if some early task ai follows some late task aj , then we can switch the positions of ai and aj , and ai will still be early and aj will still be late.
Consider the problem of determining whether a given set A of tasks is independent.
Lemma 16.12 For any set of tasks A, the following statements are equivalent.
The problem of minimizing the sum of the penalties of the late tasks is the same as the problem of maximizing the sum of the penalties of the early tasks.
The following theorem thus ensures that we can use the greedy algorithm to ﬁnd an independent set A of tasks with the maximum total penalty.
By Theorem 16.11, we can use a greedy algorithm to ﬁnd a maximum-weight independent set of tasks A.
We can then create an optimal schedule having the tasks in A as its early tasks.
Figure 16.7 An instance of the problem of scheduling unit-time tasks with deadlines and penalties for a single processor.
Figure 16.7 demonstrates an example of the problem of scheduling unit-time tasks with deadlines and penalties for a single processor.
Consider the problem of making change for n cents using the fewest number of coins.
Describe a greedy algorithm to make change consisting of quarters, dimes, nickels, and pennies.
Give a set of coin denominations for which the greedy algorithm does not yield an optimal solution.
Your set should include a penny so that there is a solution for every value of n.
Give an O.nk/-time algorithm that makes change for any set of k different coin denominations, assuming that one of the coins is a penny.
You have one computer on which to run these tasks, and the computer can run only one task at a time.
Let ci be the completion time of task ai , that is, the time at which task ai completes processing.
Your goal is to minimize the average completion time, that is, to minimize .1=n/
Give an algorithm that schedules the tasks so as to minimize the average completion time.
Each task must run non-preemptively, that is, once task ai starts, it must run continuously for pi units of time.
Prove that your algorithm minimizes the average completion time, and state the running time of your algorithm.
Suppose now that the tasks are not all available at once.
That is, each task cannot start until its release time ri.
Suppose also that we allow preemption, so that a task can be suspended and restarted at a later time.
Task ai has run for a total of 6 time units, but its running time has been divided into three pieces.
Give an algorithm that schedules the tasks so as to minimize the average completion time in this new scenario.
Prove that your algorithm minimizes the average completion time, and state the running time of your algorithm.
Suppose that we associate a nonnegative weight w.e/ with each edge in an undirected graph G D .V;E/
Give an efﬁcient algorithm to ﬁnd an acyclic subset of E of maximum total weight.
Exercise 16.4-2 tells us that the set of linearly independent sets of columns of any matrix M forms a matroid.
Explain carefully why the results of parts (d) and (e) are not contradictory.
How can there fail to be a perfect correspondence between the notion of a set of edges being acyclic and the notion of the associated set of columns of the incidence matrix being linearly independent?
Consider the following algorithm for the problem from Section 16.5 of scheduling unit-time tasks with deadlines and penalties.
Let all n time slots be initially empty, where time slot i is the unit-length slot of time that ﬁnishes at time i.
We consider the tasks in order of monotonically decreasing penalty.
When considering task aj , if there exists a time slot at or before aj ’s deadline dj that is still empty, assign aj to the latest such slot, ﬁlling it.
If there is no such slot, assign task aj to the latest of the as yet unﬁlled slots.
Use the fast disjoint-set forest presented in Section 21.3 to implement the algorithm efﬁciently.
Assume that the set of input tasks has already been sorted into.
Modern computers use a cache to store a small amount of data in a fast memory.
Even though a program may access large amounts of data, by storing a small subset of the main memory in the cache—a small but faster memory—overall access time can greatly decrease.
For example, a program that accesses 4 distinct elements fa; b; c; dg might make the sequence of requests hd; b; d; b; d; a; c; d; b; a; c; bi.
When the cache contains k elements and the program requests the .k C 1/st element, the system must decide, for this and each subsequent request, which k elements to keep in the cache.
More precisely, for each request ri , the cache-management algorithm checks whether element ri is already in the cache.
If it is, then we have a cache hit; otherwise, we have a cache miss.
Upon a cache miss, the system retrieves ri from the main memory, and the cache-management algorithm must decide whether to keep ri in the cache.
If it decides to keep ri and the cache already holds k elements, then it must evict one element to make room for ri.
The cache-management algorithm evicts data with the goal of minimizing the number of cache misses over the entire sequence of requests.
That is, we have to make decisions about which data to keep in the cache without knowing the future requests.
Here, however, we consider the off-line version of this problem, in which we are given in advance the entire sequence of n requests and the cache size k, and we wish to minimize the total number of cache misses.
Write pseudocode for a cache manager that uses the furthest-in-future strategy.
Prove that furthest-in-future produces the minimum possible number of cache misses.
Our proof of the correctness of the greedy algorithm for the activity-selection problem is based on that of Gavril [131]
In an amortized analysis, we average the time required to perform a sequence of data-structure operations over all the operations performed.
With amortized analysis, we can show that the average cost of an operation is small, if we average over a sequence of operations, even though a single operation within the sequence might be expensive.
Amortized analysis differs from average-case analysis in that probability is not involved; an amortized analysis guarantees the average performance of each operation in the worst case.
The ﬁrst three sections of this chapter cover the three most common techniques used in amortized analysis.
Section 17.1 starts with aggregate analysis, in which we determine an upper bound T .n/ on the total cost of a sequence of n operations.
We take the average cost as the amortized cost of each operation, so that all operations have the same amortized cost.
Section 17.2 covers the accounting method, in which we determine an amortized cost of each operation.
When there is more than one type of operation, each type of operation may have a different amortized cost.
The accounting method overcharges some operations early in the sequence, storing the overcharge as “prepaid credit” on speciﬁc objects in the data structure.
Later in the sequence, the credit pays for operations that are charged less than they actually cost.
Section 17.3 discusses the potential method, which is like the accounting method in that we determine the amortized cost of each operation and may overcharge operations early on to compensate for undercharges later.
The potential method maintains the credit as the “potential energy” of the data structure as a whole instead of associating the credit with individual objects within the data structure.
We shall use two examples to examine these three methods.
One is a stack with the additional operation MULTIPOP, which pops several objects at once.
The other is a binary counter that counts up from 0 by means of the single operation INCREMENT.
While reading this chapter, bear in mind that the charges assigned during an amortized analysis are for analysis purposes only.
If, for example, we assign a credit to an object x when using the accounting method, we have no need to assign an appropriate amount to some attribute, such as x:credit, in the code.
When we perform an amortized analysis, we often gain insight into a particular data structure, and this insight can help us optimize the design.
In Section 17.4, for example, we shall use the potential method to analyze a dynamically expanding and contracting table.
In aggregate analysis, we show that for all n, a sequence of n operations takes worst-case time T .n/ in total.
In the worst case, the average cost, or amortized cost, per operation is therefore T .n/=n.
Note that this amortized cost applies to each operation, even when there are several types of operations in the sequence.
The other two methods we shall study in this chapter, the accounting method and the potential method, may assign different amortized costs to different types of operations.
In our ﬁrst example of aggregate analysis, we analyze stacks that have been augmented with a new operation.
POP.S/ pops the top of stack S and returns the popped object.
The total cost of a sequence of n PUSH and POP operations is therefore n, and the actual running time for n operations is therefore ‚.n/
Now we add the stack operation MULTIPOP.S; k/, which removes the k top objects of stack S , popping the entire stack if the stack contains fewer than k objects.
Of course, we assume that k is positive; otherwise the MULTIPOP operation leaves the stack unchanged.
In the following pseudocode, the operation STACK-EMPTY returns TRUE if there are no objects currently on the stack, and FALSE otherwise.
Figure 17.1 The action of MULTIPOP on a stack S , shown initially in (a)
What is the running time of MULTIPOP.S; k/ on a stack of s objects? The.
The number of iterations of the while loop is the number min.s; k/ of objects popped off the stack.
Thus, the total cost of MULTIPOP is min.s; k/, and the actual running time is a linear function of this cost.
Let us analyze a sequence of n PUSH, POP, and MULTIPOP operations on an initially empty stack.
The worst-case cost of a MULTIPOP operation in the sequence is O.n/, since the stack size is at most n.
The worst-case time of any stack operation is therefore O.n/, and hence a sequence of n operations costs O.n2/, since we may have O.n/ MULTIPOP operations costing O.n/ each.
Although this analysis is correct, the O.n2/ result, which we obtained by considering the worst-case cost of each operation individually, is not tight.
Using aggregate analysis, we can obtain a better upper bound that considers the entire sequence of n operations.
In fact, although a single MULTIPOP operation can be expensive, any sequence of n PUSH, POP, and MULTIPOP operations on an initially empty stack can cost at most O.n/
Why? We can pop each object from the stack at most once for each time we have pushed it onto the stack.
Therefore, the number of times that POP can be called on a nonempty stack, including calls within MULTIPOP, is at most the number of PUSH operations, which is at most n.
For any value of n, any sequence of n PUSH, POP, and MULTIPOP operations takes a total of O.n/ time.
The average cost of an operation is O.n/=n D O.1/
In this example, therefore, all three stack operations have an amortized cost of O.1/
We emphasize again that although we have just shown that the average cost, and hence the running time, of a stack operation is O.1/, we did not use probabilistic reasoning.
We actually showed a worst-case bound of O.n/ on a sequence of n operations.
Dividing this total cost by n yielded the average cost per operation, or the amortized cost.
As with the stack example, a cursory analysis yields a bound that is correct but not tight.
Thus, a sequence of n INCREMENT operations on an initially zero counter takes time O.nk/ in the worst case.
Bits that ﬂip to achieve the next value are shaded.
The running cost for ﬂipping bits is shown at the right.
Notice that the total cost is always less than twice the total number of INCREMENT operations.
The worst-case time for a sequence of n INCREMENT operations on an initially zero counter is therefore O.n/
The average cost of each operation, and therefore the amortized cost per operation, is O.n/=n D O.1/
Use aggregate analysis to determine the amortized cost per operation.
In the accounting method of amortized analysis, we assign differing charges to different operations, with some operations charged more or less than they actually cost.
We call the amount we charge an operation its amortized cost.
When an operation’s amortized cost exceeds its actual cost, we assign the difference to speciﬁc objects in the data structure as credit.
Credit can help pay for later operations whose amortized cost is less than their actual cost.
Thus, we can view the amortized cost of an operation as being split between its actual cost and credit that is either deposited or used up.
This method differs from aggregate analysis, in which all operations have the same amortized cost.
If we want to show that in the worst case the average cost per operation is small by analyzing with amortized costs, we must ensure that the total amortized cost of a sequence of operations provides an upper bound on the total actual cost of the sequence.
Moreover, as in aggregate analysis, this relationship must hold for all sequences of operations.
If we denote the actual cost of the i th operation by ci and the amortized cost of the i th operation by yci , we require nX.
The total credit stored in the data structure is the difference between the total amortized cost and the total actual cost, or.
By inequality (17.1), the total credit associated with the data.
If we ever were to allow the total credit to become negative (the result of undercharging early operations with the promise of repaying the account later on), then the total amortized costs incurred at that time would be below the total actual costs incurred; for the sequence of operations up to that time, the total amortized cost would not be an upper bound on the total actual cost.
Thus, we must take care that the total credit in the data structure never becomes negative.
To illustrate the accounting method of amortized analysis, let us return to the stack example.
Note that the amortized cost of MULTIPOP is a constant (0), whereas the actual cost is variable.
In general, the amortized costs of the operations under consideration may differ from each other, and they may even differ asymptotically.
We shall now show that we can pay for any sequence of stack operations by charging the amortized costs.
Suppose we use a dollar bill to represent each unit of cost.
Recall the analogy of Section 10.1 between the stack data structure and a stack of plates in a cafeteria.
At any point in time, every plate on the stack has a dollar of credit on it.
The dollar stored on the plate serves as prepayment for the cost of popping it from the stack.
When we execute a POP operation, we charge the operation nothing and pay its actual cost using the credit stored in the stack.
To pop a plate, we take the dollar of credit off the plate and use it to pay the actual cost of the operation.
Thus, by charging the PUSH operation a little bit more, we can charge the POP operation nothing.
To pop the ﬁrst plate, we take the dollar of credit off the plate and use it to pay the actual cost of a POP operation.
To pop a second plate, we again have a dollar of credit on the plate to pay for the POP operation, and so on.
Thus, we have always charged enough up front to pay for MULTIPOP operations.
In other words, since each plate on the stack has 1 dollar of credit on it, and the stack always has a nonnegative number of plates, we have ensured that the amount of credit is always nonnegative.
Thus, for any sequence of n PUSH, POP, and MULTIPOP operations, the total amortized cost is an upper bound on the total actual cost.
Since the total amortized cost is O.n/, so is the total actual cost.
As another illustration of the accounting method, we analyze the INCREMENT operation on a binary counter that starts at zero.
As we observed earlier, the running time of this operation is proportional to the number of bits ﬂipped, which we shall use as our cost for this example.
Let us once again use a dollar bill to represent each unit of cost (the ﬂipping of a bit in this example)
The cost of resetting the bits within thewhile loop is paid for by the dollars on the bits that are reset.
The number of 1s in the counter never becomes negative, and thus the amount of credit stays nonnegative at all times.
Thus, for n INCREMENT operations, the total amortized cost is O.n/, which bounds the total actual cost.
After every k operations, we make a copy of the entire stack for backup purposes.
Show that the cost of n stack operations, including copying the stack, is O.n/ by assigning suitable amortized costs to the various stack operations.
Counting the time to examine or modify a bit as ‚.1/, show how to implement a counter as an array of bits so that any sequence of n INCREMENT and RESET operations takes time O.n/ on an initially zero counter.
Instead of representing prepaid work as credit stored with speciﬁc objects in the data structure, the potential method of amortized analysis represents the prepaid work as “potential energy,” or just “potential,” which can be released to pay for future operations.
We associate the potential with the data structure as a whole rather than with speciﬁc objects within the data structure.
Pn iD1 yci gives an upper bound on the total actual cost.
Let us now compute the amortized costs of the various stack operations.
If the i th operation on a stack containing s objects is a PUSH operation, then the potential difference is.
Suppose that the i th operation on the stack is MULTIPOP.S; k/, which causes k0 D min.k; s/ objects to be popped off the stack.
The actual cost of the operation is k0, and the potential difference is.
The amortized cost of each of the three operations is O.1/, and thus the total.
As another example of the potential method, we again look at incrementing a binary counter.
This time, we deﬁne the potential of the counter after the i th INCREMENT operation to be bi , the number of 1s in the counter after the i th operation.
The potential method gives us an easy way to analyze the counter even when it does not start at zero.
Explain how to implement this data structure so that any sequence of m INSERT and DELETE-LARGER-HALF operations runs in O.m/ time.
Your implementation should also include a way to output the elements of S in O.jS j/ time.
We do not always know in advance how many objects some applications will store in a table.
We might allocate space for a table, only to ﬁnd out later that it is not enough.
We must then reallocate the table with a larger size and copy all objects stored in the original table over into the new, larger table.
Similarly, if many objects have been deleted from the table, it may be worthwhile to reallocate the table with a smaller size.
In this section, we study this problem of dynamically expanding and contracting a table.
Using amortized analysis, we shall show that the amortized cost of insertion and deletion is only O.1/, even though the actual cost of an operation is large when it triggers an expansion or a contraction.
Moreover, we shall see how to guarantee that the unused space in a dynamic table never exceeds a constant fraction of the total space.
We assume that the dynamic table supports the operations TABLE-INSERT and TABLE-DELETE.
TABLE-INSERT inserts into the table an item that occupies a single slot, that is, a space for one item.
Likewise, TABLE-DELETE removes an item from the table, thereby freeing a slot.
We might also use an array or collection of arrays to implement object storage, as we did in Section 10.3
We start by analyzing a dynamic table in which we only insert items.
We then consider the more general case in which we both insert and delete items.
Let us assume that storage for a table is allocated as an array of slots.
A table ﬁlls up when all slots have been used or, equivalently, when its load factor is 1.1 In some software environments, upon attempting to insert an item into a full table, the only alternative is to abort with an error.
We shall assume, however, that our software environment, like many modern ones, provides a memory-management system that can allocate and free blocks of storage on request.
Thus, upon inserting an item into a full table, we can expand the table by allocating a new table with more slots than the old table had.
Because we always need the table to reside in contiguous memory, we must allocate a new array for the larger table and then copy items from the old table into the new table.
A common heuristic allocates a new table with twice as many slots as the old one.
If the only table operations are insertions, then the load factor of the table is always at least 1=2, and thus the amount of wasted space never exceeds half the total space in the table.
In the following pseudocode, we assume that T is an object representing the table.
The attribute T: table contains a pointer to the block of storage representing the table, T:num contains the number of items in the table, and T:size gives the total number of slots in the table.
We can analyze the running time of TABLE-INSERT in terms of the number of elementary insertions by assigning a cost of 1 to each elementary insertion.
We call the event in which lines 5–9 are executed an expansion.
The total cost of n TABLE-INSERT operations is therefore nX.
Intuitively, each item pays for 3 elementary insertions: inserting itself into the current table, moving itself when the table expands, and moving another item that has already been moved once when the table expands.
For example, suppose that the size of the table is m immediately after an expansion.
We assume that we measure the cost in terms of elementary insertions and deletions.
You might think that we should double the table size upon inserting an item into a full table and halve the size when a deleting an item would cause the table to become less than half full.
This strategy would guarantee that the load factor of the table never drops below 1=2, but unfortunately, it can cause the amortized cost of an operation to be quite large.
At the end of this sequence of insertions, T:num D T:size D n=2
For the second n=2 operations, we perform the following sequence:
The ﬁrst insertion causes the table to expand to size n.
The two following deletions cause the table to contract back to size n=2
The downside of this strategy is obvious: after expanding the table, we do not delete enough items to pay for a contraction.
Likewise, after contracting the table, we do not insert enough items to pay for an expansion.
We can improve upon this strategy by allowing the load factor of the table to drop below 1=2
The load factor of the table is therefore bounded below by the constant 1=4
As the load factor deviates from 1=2, the potential increases so that by the time we expand or contract the table, the table has garnered sufﬁcient potential to pay for copying all the items into the newly allocated table.
We omit the code for TABLE-DELETE, since it is analogous to TABLE-INSERT.
For our analysis, we shall assume that whenever the number of items in the table drops to 0, we free the storage for the table.
Figure 17.4 The effect of a sequence of n TABLE-INSERT and TABLE-DELETE operations on the number numi of items in the table, the number sizei of slots in the table, and the potential.
In summary, since the amortized cost of each operation is bounded above by a constant, the actual time for any sequence of n operations on a dynamic table is O.n/
We can use an algorithm based on an amortized analysis to improve the running time of the bit-reversal permutation.
Suppose that you can shift a word left or right by only one bit in unit time.
Is it still possible to implement an O.n/-time bit-reversal permutation?
Binary search of a sorted array takes logarithmic search time, but the time to insert a new element is linear in the size of the array.
We can improve the time for insertion by keeping several sorted arrays.
Although each individual array is sorted, elements in different arrays bear no particular relationship to each other.
Describe how to perform the SEARCH operation for this data structure.
A 1=2-balanced tree is, in a sense, as balanced as it can be.
Given a node x in an arbitrary binary search tree, show how to rebuild the subtree rooted at x so that it becomes 1=2-balanced.
Your algorithm should run in time ‚.x:size/, and it can use O.x:size/ auxiliary storage.
We shall analyze this rebuilding scheme using the potential method.
For a node x in a binary search tree T , we deﬁne.
There are four basic operations on red-black trees that perform structural modiﬁcations: node insertions, node deletions, rotations, and color changes.
We have seen that RB-INSERT and RB-DELETE use only O.1/ rotations, node insertions, and node deletions to maintain the red-black properties, but they may make many more color changes.
Although the worst-case number of color changes per operation can be logarithmic, we shall prove that any sequence of m RB-INSERT and RB-DELETE operations on an initially empty red-black tree causes O.m/ structural modiﬁcations in the worst case.
Note that we count each color change as a structural modiﬁcation.
Some of the cases handled by the main loop of the code of both RB-INSERTFIXUP and RB-DELETE-FIXUP are terminating: once encountered, they cause the loop to terminate after a constant number of additional operations.
For each of the cases of RB-INSERT-FIXUP and RB-DELETE-FIXUP, specify which are terminating and which are not.
When we insert a node into a red-black tree using RB-INSERT, we can break the operation into three parts.
List the structural modiﬁcations and potential changes resulting from lines 1–16 of RB-INSERT, from nonterminating cases of RB-INSERT-FIXUP, and from terminating cases of RB-INSERT-FIXUP.
Using part (d), argue that the amortized number of structural modiﬁcations performed by any call of RB-INSERT is O.1/
We now wish to prove that there are O.m/ structural modiﬁcations when there are both insertions and deletions.
Now we redeﬁne the potential of a red-black tree T as.
Complete the proof that in the worst case, any sequence of m RB-INSERT and RB-DELETE operations performs O.m/ structural modiﬁcations.
A self-organizing list is a linked list of n elements, in which each element has a unique key.
When we search for an element in the list, we are given a key, and we want to ﬁnd an element with that key.
To ﬁnd an element in the list, given its key, we must traverse the list from the beginning until we encounter the element with the given key.
If that element is the kth element from the start of the list, then the cost to ﬁnd the element is k.
We may reorder the list elements after any operation, according to a given rule with a given cost.
We may choose any heuristic we like to decide how to reorder the list.
Out of the various possible ways to reorder the list after an operation, this problem focuses on transposing adjacent list elements—switching their positions in the list—with a unit cost for each transpose operation.
You will show, by means of a potential function, that a particular heuristic for reordering the list, move-to-front, entails a total cost no worse than 4 times that of any other heuristic for maintaining the list order—even if the other heuristic knows the access sequence in advance! We call this type of analysis a competitive analysis.
With the move-to-front heuristic, immediately after searching for an element x, we move x to the ﬁrst position on the list (i.e., the front of the list)
Tarjan [331] surveys the accounting and potential methods of amortized analysis and presents several applications.
He attributes the accounting method to several authors, including M.
The move-to-front heuristic from Problem 17-5 works quite well in practice.
Moreover, if we recognize that when we ﬁnd an element, we can splice it out of its position in the list and relocate it to the front of the list in constant time, we can show that the cost of move-to-front is at most twice the cost of any other heuristic including, again, one that knows the entire access sequence in advance.
This part returns to studying data structures that support operations on dynamic sets, but at a more advanced level than Part III.
Chapter 18 presents B-trees, which are balanced search trees speciﬁcally designed to be stored on disks.
Because disks operate much more slowly than random-access memory, we measure the performance of B-trees not only by how much computing time the dynamic-set operations consume but also by how many disk accesses they perform.
For each B-tree operation, the number of disk accesses increases with the height of the B-tree, but B-tree operations keep the height low.
Fibonacci heaps—the data structure in Chapter 19—also support the operations DELETE and DECREASE-KEY.
We use amortized time bounds to measure the performance of Fibonacci heaps.
The operations INSERT, MINIMUM, and UNION take only O.1/ actual and amortized time on Fibonacci heaps, and the operations EXTRACT-MIN and DELETE take O.lg n/ amortized time.
The most signiﬁcant advantage of Fibonacci heaps, however, is that DECREASE-KEY takes only O.1/ amortized time.
Alternatively, if it supported MAXIMUM and EXTRACT-MAX, it would be a mergeable max-heap.
Unless we specify otherwise, mergeable heaps will be by default mergeable min-heaps.
Dynamic trees support queries to ﬁnd parents, roots, edge costs, and the minimum edge cost on a simple path from a node up to a root.
Trees may be manipulated by cutting edges, updating all edge costs on a simple path from a node up to a root, linking a root into another tree, and making a node the root of the tree it appears in.
One implementation of dynamic trees gives an O.lg n/ amortized time bound for each operation; a more complicated implementation yields O.lg n/ worst-case time bounds.
Dynamic trees are used in some of the asymptotically fastest network-ﬂow algorithms.
Persistent data structures allow queries, and sometimes updates as well, on past versions of a data structure.
Driscoll, Sarnak, Sleator, and Tarjan [97] present techniques for making linked data structures persistent with only a small time.
Problem 13-1 gives a simple example of a persistent dynamic set.
As in Chapter 20, several data structures allow a faster implementation of dictionary operations (INSERT, DELETE, and SEARCH) for a restricted universe of keys.
By taking advantage of these restrictions, they are able to achieve better worst-case asymptotic running times than comparison-based data structures.
Fredman and Willard introduced fusion trees [115], which were the ﬁrst data structure to allow faster dictionary operations when the universe is restricted to integers.
They showed how to implement these operations in O.lg n= lg lg n/ time.
Several subsequent data structures, including exponential search trees [16], have also given improved bounds on some or all of the dictionary operations and are mentioned in the chapter notes throughout this book.
Dynamic graph data structures support various queries while allowing the structure of a graph to change through operations that insert or delete vertices or edges.
B-trees are balanced search trees designed to work well on disks or other directaccess secondary storage devices.
B-trees are similar to red-black trees (Chapter 13), but they are better at minimizing disk I/O operations.
Many database systems use B-trees, or variants of B-trees, to store information.
B-trees differ from red-black trees in that B-tree nodes may have many children, from a few to thousands.
That is, the “branching factor” of a B-tree can be quite large, although it usually depends on characteristics of the disk unit used.
B-trees are similar to red-black trees in that every n-node B-tree has height O.lg n/
The exact height of a B-tree can be considerably less than that of a red-black tree, however, because its branching factor, and hence the base of the logarithm that expresses its height, can be much larger.
Therefore, we can also use B-trees to implement many dynamic-set operations in time O.lg n/
If an internal B-tree node x contains x:n keys, then x has x:nC 1 children.
The keys in node x serve as dividing points separating the range of keys handled by x into x:n C 1 subranges, each handled by one child of x.
When searching for a key in a B-tree, we make an .x:n C 1/-way decision based on comparisons with the x:n keys stored at node x.
The structure of leaf nodes differs from that of internal nodes; we will examine these differences in Section 18.1
Section 18.1 gives a precise deﬁnition of B-trees and proves that the height of a B-tree grows only logarithmically with the number of nodes it contains.
Before proceeding, however, we need to ask why we evaluate data structures designed to work on a disk differently from data structures designed to work in main random-access memory.
Computer systems take advantage of various technologies that provide memory capacity.
The primary memory (or main memory) of a computer system normally.
Figure 18.1 A B-tree whose keys are the consonants of English.
An internal node x containing x:n keys has x:nC 1 children.
All leaves are at the same depth in the tree.
The lightly shaded nodes are examined in a search for the letter R.
It comprises one or more platters (two platters are shown here) that rotate around a spindle.
Each platter is read and written with a head at the end of an arm.
A track is the surface that passes beneath the read/write head when the head is stationary.
This technology is typically more than an order of magnitude more expensive per bit stored than magnetic storage technology, such as tapes or disks.
Most computer systems also have secondary storage based on magnetic disks; the amount of such secondary storage often exceeds the amount of primary memory by at least two orders of magnitude.
The drive consists of one or more platters, which rotate at a constant speed around a common spindle.
The drive reads and writes each platter by a head at the end of an arm.
When a given head is stationary, the surface that passes underneath it is called a track.
Multiple platters increase only the disk drive’s capacity and not its performance.
Although disks are cheaper and have higher capacity than main memory, they are much, much slower because they have moving mechanical parts.1 The mechanical motion has two components: platter rotation and arm movement.
As of this writing, commodity disks rotate at speeds of 5400–15,000 revolutions per minute (RPM)
In other words, if we have to wait a full rotation for a particular item to come under the read/write head, we could access main memory more than 100,000 times during that span.
On average we have to wait for only half a rotation, but still, the difference in access times for silicon memory compared with disks is enormous.
In order to amortize the time spent waiting for mechanical movements, disks access not just one item but several at a time.
Information is divided into a number of equal-sized pages of bits that appear consecutively within tracks, and each disk read or write is of one or more entire pages.
Once the read/write head is positioned correctly and the disk has rotated to the beginning of the desired page, reading or writing a magnetic disk is entirely electronic (aside from the rotation of the disk), and the disk can quickly read or write large amounts of data.
As of this writing, solid-state drives have recently come onto the consumer market.
Although they are faster than mechanical disk drives, they cost more per gigabyte and have lower capacities than mechanical disk drives.
In a typical B-tree application, the amount of data handled is so large that all the data do not ﬁt into main memory at once.
The B-tree algorithms copy selected pages from disk into main memory as needed and write back onto disk the pages that have changed.
B-tree algorithms keep only a constant number of pages in main memory at any time; thus, the size of main memory does not limit the size of B-trees that can be handled.
If the object is currently in the computer’s main memory, then we can refer to the attributes of the object as usual: x:key, for example.
If the object referred to by x resides on disk, however, then we must perform the operation DISK-READ.x/ to read object x into main memory before we can refer to its attributes.
That is, the typical pattern for working with an object is as follows:
The system can keep only a limited number of pages in main memory at any one time.
We shall assume that the system ﬂushes from main memory pages no longer in use; our B-tree algorithms will ignore this issue.
Since in most systems the running time of a B-tree algorithm depends primarily on the number of DISK-READ and DISK-WRITE operations it performs, we typically want each of these operations to read or write as much information as possible.
Thus, a B-tree node is usually as large as a whole disk page, and this size limits the number of children a B-tree node can have.
A large branching factor dramatically reduces both the height of the tree and the number of disk accesses required to ﬁnd any key.
Shown inside each node x is x:n, the number of keys in x.
To keep things simple, we assume, as we have for binary search trees and red-black trees, that any “satellite information” associated with a key resides in the same node as the key.
In practice, one might actually store with each key just a pointer to another disk page containing the satellite information for that key.
The pseudocode in this chapter implicitly assumes that the satellite information associated with a key, or the pointer to such satellite information, travels with the key whenever the key is moved from node to node.
A common variant on a B-tree, known as a BC-tree, stores all the satellite information in the leaves and stores only keys and child pointers in the internal nodes, thus maximizing the branching factor of the internal nodes.
A B-tree T is a rooted tree (whose root is T:root) having the following properties:
Leaf nodes have no children, and so their ci attributes are undeﬁned.
The keys x:keyi separate the ranges of keys stored in each subtree: if ki is any key stored in the subtree with root x:ci , then.
All leaves have the same depth, which is the tree’s height h.
Nodes have lower and upper bounds on the number of keys they can contain.
In practice, however, much larger values of t yield B-trees with smaller height.
The number of disk accesses required for most operations on a B-tree is proportional to the height of the B-tree.
Here we see the power of B-trees, as compared with red-black trees.
Although the height of the tree grows as O.lg n/ in both cases (recall that t is a constant), for B-trees the base of the logarithm can be many times larger.
Thus, B-trees save a factor of about lg t over red-black trees in the number of nodes examined for most tree operations.
Because we usually have to access the disk to examine an arbitrary node in a tree, B-trees avoid a substantial number of disk accesses.
Any nodes that are passed as parameters must already have had a DISK-READ operation performed on them.
The procedures we present are all “one-pass” algorithms that proceed downward from the root of the tree, without having to back up.
Searching a B-tree is much like searching a binary search tree, except that instead of making a binary, or “two-way,” branching decision at each node, we make a multiway branching decision according to the number of the node’s children.
More precisely, at each internal node x, we make an .x:nC 1/-way branching decision.
B-TREE-SEARCH is a straightforward generalization of the TREE-SEARCH procedure deﬁned for binary search trees.
B-TREE-SEARCH takes as input a pointer to the root node x of a subtree and a key k to be searched for in that subtree.
If k is in the B-tree, B-TREE-SEARCH returns the ordered pair .y; i/ consisting of a node y and an index i such that y:keyi D k.
The procedure examines the lightly shaded nodes during a search for the key R.
As in the TREE-SEARCH procedure for binary search trees, the nodes encountered during the recursion form a simple path downward from the root of the tree.
The B-TREE-SEARCH procedure therefore accesses O.h/ D O.logt n/ disk pages, where h is the height of the B-tree and n is the number of keys in the B-tree.
To build a B-tree T , we ﬁrst use B-TREE-CREATE to create an empty root node and then call B-TREE-INSERT to add new keys.
Both of these procedures use an auxiliary procedure ALLOCATE-NODE, which allocates one disk page to be used as a new node in O.1/ time.
We can assume that a node created by ALLOCATENODE requires no DISK-READ, since there is as yet no useful information stored on the disk for that node.
As with a binary search tree, we can insert a key into a B-tree in a single pass down the tree from the root to a leaf.
To do so, we do not wait to ﬁnd out whether we will actually need to split a full node in order to do the insertion.
Instead, as we travel down the tree searching for the position where the new key belongs, we split each full node we come to along the way (including the leaf itself)
Thus whenever we want to split a full node y, we are assured that its parent is not full.
Splitting a node in a B-tree The procedure B-TREE-SPLIT-CHILD takes as input a nonfull internal node x (assumed to be in main memory) and an index i such that x:ci (also assumed to be in main memory) is a full child of x.
The procedure then splits this child in two and adjusts x so that it has an additional child.
To split a full root, we will ﬁrst make the root a child of a new empty root node, so that we can use B-TREE-SPLIT-CHILD.
The tree thus grows in height by one; splitting is the only means by which the tree grows.
Inserting a key into a B-tree in a single pass down the tree We insert a key k into a B-tree T of height h in a single pass down the tree, requiring O.h/ disk accesses.
The B-TREE-INSERT procedure uses B-TREE-SPLIT-CHILD to guarantee that the recursion never descends to a full node.
Lines 3–9 handle the case in which the root node r is full: the root splits and a new node s (having two children) becomes the root.
Splitting the root is the only way to increase the height of a B-tree.
Unlike a binary search tree, a B-tree increases in height at the top instead of at the bottom.
Root node r splits in two, and a new root node s is created.
The new root contains the median key of r and has the two halves of r as children.
The B-tree grows in height by one when the root is split.
Lines 3–8 handle the case in which x is a leaf node by inserting key k into x.
If x is not a leaf node, then we must insert k into the appropriate leaf node in the subtree rooted at internal node x.
In this case, lines 9–11 determine the child of x to which the recursion descends.
Note that there is no need for a DISK-READ.x:ci/ after line 16 increments i , since the recursion will descend in this case to a child that was just created by B-TREE-SPLIT-CHILD.
The net effect of lines 13–16 is thus to guarantee that the procedure never recurses to a full node.
Line 17 then recurses to insert k into the appropriate subtree.
Figure 18.7 illustrates the various cases of inserting into a B-tree.
Draw only the conﬁgurations of the tree just before some node must split, and also draw the ﬁnal conﬁguration.
A redundant DISK-READ is a DISK-READ for a page that is already in memory.
A redundant DISK-WRITE writes to disk a page of information that is identical to what is already stored there.
Show how to modify the procedures for creating and inserting into a B-tree to handle this variation.
Nodes that are modiﬁed by the insertion process are lightly shaded.
The node RST UV splits into two nodes containing RS and UV , the key T moves up to the root, and Q is inserted in the leftmost of the two halves (the RS node)
The root splits right away, since it is full, and the B-tree grows in height by one.
The node ABCDE splits before F is inserted into the rightmost of the two halves (the DE node)
Show that this change makes the CPU time required O.lg n/, independently of how t might be chosen as a function of n.
Describe how to choose t so as to minimize (approximately) the B-tree search time.
The procedure B-TREE-DELETE deletes the key k from the subtree rooted at x.
We design this procedure to guarantee that whenever it calls itself recursively on a node x, the number of keys in x is at least the minimum degree t.
Note that this condition requires one more key than the minimum required by the usual B-tree conditions, so that sometimes a key may have to be moved into a child node before recursion descends to that child.
This strengthened condition allows us to delete a key from the tree in one downward pass without having to “back up” (with one exception, which we’ll explain)
This is case 2a: the predecessor L of M moves up to take M ’s position.
We sketch how deletion works instead of presenting the pseudocode.
Figure 18.8 illustrates the various cases of deleting keys from a B-tree.
If the key k is in node x and x is a leaf, delete the key k from x.
If the key k is in node x and x is an internal node, do the following:
This is case 3a: C moves to ﬁll B’s position and E moves to ﬁll C ’s position.
If the child y that precedes k in node x has at least t keys, then ﬁnd the predecessor k0 of k in the subtree rooted at y.
We can ﬁnd k0 and delete it in a single downward pass.
Since most of the keys in a B-tree are in the leaves, we may expect that in practice, deletion operations are most often used to delete keys from leaves.
The B-TREE-DELETE procedure then acts in one downward pass through the tree, without having to back up.
Although this procedure seems complicated, it involves only O.h/ disk operations for a B-tree of height h, since only O.1/ calls to DISK-READ and DISKWRITE are made between recursive invocations of the procedure.
Consider implementing a stack in a computer that has a relatively small amount of fast primary memory and a relatively large amount of slower disk storage.
The stack we wish to support can grow to be much larger than can ﬁt in memory, and thus most of it must be stored on disk.
A simple, but inefﬁcient, stack implementation keeps the entire stack on disk.
We maintain in memory a stack pointer, which is the disk address of the top element on the stack.
If the pointer has value p, the top element is the .p mod m/th word on page bp=mc of the disk, where m is the number of words per page.
To implement the PUSH operation, we increment the stack pointer, read the appropriate page into memory from disk, copy the element to be pushed to the appropriate word on the page, and write the page back to disk.
We decrement the stack pointer, read in the appropriate page from disk, and return the top of the stack.
We need not write back the page, since it was not modiﬁed.
Because disk operations are relatively expensive, we count two costs for any implementation: the total number of disk accesses and the total CPU time.
Any disk access to a page of m words incurs charges of one disk access and ‚.m/ CPU time.
Asymptotically, what is the worst-case number of disk accesses for n stack.
Now consider a stack implementation in which we keep one page of the stack in memory.
We also maintain a small amount of memory to keep track of which page is currently in memory.
We can perform a stack operation only if the relevant disk page resides in memory.
If necessary, we can write the page currently in memory to the disk and read in the new page from the disk to memory.
If the relevant disk page is already in memory, then no disk accesses are required.
What is the worst-case number of disk accesses required for n PUSH operations? What is the CPU time?
What is the worst-case number of disk accesses required for n stack operations? What is the CPU time?
Suppose that we now implement the stack by keeping two pages in memory (in addition to a small number of words for bookkeeping)
Describe how to manage the stack pages so that the amortized number of disk.
We assume for convenience that elements consist only of keys and that all key values are distinct.
Show how to maintain, for every node x of a 2-3-4 tree, the height of the subtree rooted at x as an attribute x:height.
Make sure that your implementation does not affect the asymptotic running times of searching, insertion, and deletion.
The running time of the split operation should be O.lg n/, where n is the number of keys in T.
Bender, Demaine, and Farach-Colton [40] studied how to make B-trees perform well in the presence of memory-hierarchy effects.
Their cache-oblivious algorithms work efﬁciently without explicitly knowing the data transfer sizes within the memory hierarchy.
First, it supports a set of operations that constitutes what is known as a “mergeable heap.” Second, several Fibonacci-heap operations run in constant amortized time, which makes this data structure well suited for applications that invoke these operations frequently.
Amergeable heap is any data structure that supports the following ﬁve operations, in which each element has a key:
MAKE-HEAP./ creates and returns a new heap containing no elements.
INSERT.H; x/ inserts element x, whose key has already been ﬁlled in, into heap H.
MINIMUM.H/ returns a pointer to the element in heap H whose key is minimum.
EXTRACT-MIN.H/ deletes the element from heap H whose key is minimum, returning a pointer to the element.
UNION.H1;H2/ creates and returns a new heap that contains all the elements of.
In addition to the mergeable-heap operations above, Fibonacci heaps also support the following two operations:
DECREASE-KEY.H; x; k/ assigns to element x within heap H the new key value k, which we assume to be no greater than its current key value.1
As mentioned in the introduction to Part V, our default mergeable heaps are mergeable minheaps, and so the operations MINIMUM, EXTRACT-MIN, and DECREASE-KEY apply.
Alternatively, we could deﬁne a mergeable max-heap with the operations MAXIMUM, EXTRACT-MAX, and INCREASE-KEY.
Figure 19.1 Running times for operations on two implementations of mergeable heaps.
The number of items in the heap(s) at the time of an operation is denoted by n.
Operations other than UNION run in worst-case time O.lg n/ on a binary heap.
If we need to support the UNION operation, however, binary heaps perform poorly.
Fibonacci heaps, on the other hand, have better asymptotic time bounds than binary heaps for the INSERT, UNION, and DECREASE-KEY operations, and they have the same asymptotic running times for the remaining operations.
Note, however, that the running times for Fibonacci heaps in Figure 19.1 are amortized time bounds, not worst-case per-operation time bounds.
The UNION operation takes only constant amortized time in a Fibonacci heap, which is signiﬁcantly better than the linear worst-case time required in a binary heap (assuming, of course, that an amortized time bound sufﬁces)
From a theoretical standpoint, Fibonacci heaps are especially desirable when the number of EXTRACT-MIN and DELETE operations is small relative to the number of other operations performed.
For example, some algorithms for graph problems may call DECREASE-KEY once per edge.
From a practical point of view, however, the constant factors and programming complexity of Fibonacci heaps make them less desirable than ordinary binary (or k-ary) heaps for most applications, except for certain applications that manage large amounts of data.
If a much simpler data structure with the same amortized time bounds as Fibonacci heaps were developed, it would be of practical use as well.
Both binary heaps and Fibonacci heaps are inefﬁcient in how they support the operation SEARCH; it can take a while to ﬁnd an element with a given key.
For this reason, operations such as DECREASE-KEY and DELETE that refer to a given element require a pointer to that element as part of their input.
As in our discussion of priority queues in Section 6.5, when we use a mergeable heap in an application, we often store a handle to the corresponding application object in each mergeable-heap element, as well as a handle to the corresponding mergeable-heap element in each application object.
The exact nature of these handles depends on the application and its implementation.
Like several other data structures that we have seen, Fibonacci heaps are based on rooted trees.
We represent each element by a node within a tree, and each node has a key attribute.
For the remainder of this chapter, we shall use the term “node” instead of “element.” We shall also ignore issues of allocating nodes prior to insertion and freeing nodes following deletion, assuming instead that the code calling the heap procedures deals with these details.
Section 19.1 deﬁnes Fibonacci heaps, discusses how we represent them, and presents the potential function used for their amortized analysis.
The remaining two operations, DECREASEKEY and DELETE, form the focus of Section 19.3
Finally, Section 19.4 ﬁnishes a key part of the analysis and also explains the curious name of the data structure.
A Fibonacci heap is a collection of rooted trees that are min-heap ordered.
That is, each tree obeys themin-heap property: the key of a node is greater than or equal to the key of its parent.
As Figure 19.2(b) shows, each node x contains a pointer x:p to its parent and a pointer x:child to any one of its children.
The children of x are linked together in a circular, doubly linked list, which we call the child list of x.
Each child y in a child list has pointers y: left and y:right that point to y’s left and right siblings, respectively.
If node y is an only child, then y: left D y:right D y.
Siblings may appear in a child list in any order.
Circular, doubly linked lists (see Section 10.2) have two advantages for use in Fibonacci heaps.
First, we can insert a node into any location or remove a node from anywhere in a circular, doubly linked list in O.1/ time.
Second, given two such lists, we can concatenate them (or “splice” them together) into one circular, doubly linked list in O.1/ time.
In the descriptions of Fibonacci heap operations, we shall refer to these operations informally, letting you ﬁll in the details of their implementations if you wish.
We store the number of children in the child list of node x in x:degree.
The boolean-valued attribute x:mark indicates whether node x has lost a child since the last time x was made the child of another node.
Newly created nodes are unmarked, and a node x becomes unmarked whenever it is made the child of another node.
Until we look at the DECREASE-KEY operation in Section 19.3, we will just set all mark attributes to FALSE.
We access a given Fibonacci heap H by a pointer H:min to the root of a tree containing the minimum key; we call this node theminimum node of the Fibonacci.
If more than one root has a key with the minimum value, then any such root may serve as the minimum node.
The roots of all the trees in a Fibonacci heap are linked together using their left and right pointers into a circular, doubly linked list called the root list of the Fibonacci heap.
The pointer H:min thus points to the node in the root list whose key is minimum.
Trees may appear in any order within a root list.
We rely on one other attribute for a Fibonacci heap H : H:n, the number of nodes currently in H.
We assume that a Fibonacci heap application begins with no heaps.
From equation (17.3), an upper bound on the total amortized cost provides an upper bound on the total actual cost for the sequence of operations.
The following procedure inserts node x into Fibonacci heap H , assuming that the node has already been allocated and that x:key has already been ﬁlled in.
The node becomes its own min-heap-ordered tree and is then added to the root list, becoming the left sibling of the root.
Lines 1–4 initialize some of the structural attributes of node x.
Line 5 tests to see whether Fibonacci heap H is empty.
If it is, then lines 6–7 make x be the only node in H ’s root list and set H:min to point to x.
Otherwise, lines 8–10 insert x into H ’s root list and update H:min if necessary.
Finally, line 11 increments H:n to reﬂect the addition of the new node.
The minimum node of a Fibonacci heap H is given by the pointer H:min, so we can ﬁnd the minimum node in O.1/ actual time.
Because the potential of H does not change, the amortized cost of this operation is equal to its O.1/ actual cost.
The amortized cost of FIB-HEAP-UNION is therefore equal to its O.1/ actual cost.
The process of extracting the minimum node is the most complicated of the operations presented in this section.
It is also where the delayed work of consolidating trees in the root list ﬁnally occurs.
The code assumes for convenience that when a node is removed from a linked list, pointers remaining in the list are updated, but pointers in the extracted node are left unchanged.
It also calls the auxiliary procedure CONSOLIDATE, which we shall see shortly.
It then consolidates the root list by linking roots of equal degree until at most one root remains of each degree.
The next step, in which we reduce the number of trees in the Fibonacci heap, is consolidating the root list of H , which the call CONSOLIDATE.H/ accomplishes.
Consolidating the root list consists of repeatedly executing the following steps until every root in the root list has a distinct degree value:
This procedure increments the attribute x:degree and clears the mark on y.
Figure 19.4, continued (i)–(l) The situation after each of the next four iterations of the for loop.
Lines 1–3 allocate and initialize the array A by making each entry NIL.
The for loop of lines 4–14 processes each root w in the root list.
As we link roots together, w may be linked to some other node and no longer be a root.
Nevertheless, w is always in a tree rooted at some node x, which may or may not be w itself.
Because we want at most one root with each degree, we look in the array A to see whether it contains a root y with the same degree as x.
If it does, then we link the roots x and y but guaranteeing that x remains a root after linking.
That is, we link y to x after ﬁrst exchanging the pointers to the two roots if y’s key is smaller than x’s key.
After we link y to x, the degree of x has increased by 1, and so we continue this process, linking x and another root whose degree equals x’s new degree, until no other root.
We then set the appropriate entry of A to point to x, so that as we process roots later on, we have recorded that x is the unique root of its degree that we have already processed.
When this for loop terminates, at most one root of each degree will remain, and the array A will point to each remaining root.
The while loop of lines 7–13 repeatedly links the root x of the tree containing node w to another tree whose root has the same degree as x, until no other root has the same degree.
At the start of each iteration of the while loop, d D x:degree.
We use this loop invariant as follows: Initialization: Line 6 ensures that the loop invariant holds the ﬁrst time we enter.
Because d D x:degree D y:degree, we want to link x and y.
Whichever of x and y has the smaller key becomes the parent of the other as a result of the link operation, and so lines 9–10 exchange the pointers to x and y if necessary.
Node y is no longer a root, and so line 12 removes the pointer to it in array A.
Because the call of FIBHEAP-LINK increments the value of x:degree, line 13 restores the invariant that d D x:degree.
In the next iteration of the for loop, three links occur; their results are shown in Figures 19.4(f)–(h)
Figures 19.4(i)–(l) show the result of the next four iterations of the for loop.
We are now ready to show that the amortized cost of extracting the minimum node of an n-node Fibonacci heap is O.D.n//
We start by accounting for the actual cost of extracting the minimum node.
Intuitively, the cost of performing each link is paid for by the reduction in potential due to the link’s reducing the number of roots by one.
We shall see in Section 19.4 that D.n/ D O.lg n/, so that the amortized cost of extracting the minimum node is O.lg n/
In this section, we show how to decrease the key of a node in a Fibonacci heap in O.1/ amortized time and how to delete any node from an n-node Fibonacci heap in O.D.n// amortized time.
If min-heap order has been violated, many changes may occur.
The CUT procedure “cuts” the link between x and its parent y, making x a root.
We use the mark attributes to obtain the desired time bounds.
They record a little piece of the history of each node.
Suppose that the following events have happened to node x:
As soon as the second child has been lost, we cut x from its parent, making it a new root.
The next time a child of y is cut, y:mark will be set to TRUE.
The only node whose key changed was the node x whose key decreased.
Thus, the new minimum node is either the original minimum node or node x.
The ﬁrst call, shown in Figure 19.5(b), involves no cascading cuts.
The second call, shown in Figures 19.5(c)–(e), invokes two cascading cuts.
The node becomes a root, and its parent (with key 24), which had previously been unmarked, becomes marked.
In part (c), the node, now with key 5, becomes a root.
Its parent, with key 26, is marked, so a cascading cut occurs.
The node with key 26 is cut from its parent and made an unmarked root in (d)
Another cascading cut occurs, since the node with key 24 is marked as well.
This node is cut from its parent and made an unmarked root in part (e)
The cascading cuts stop at this point, since the node with key 7 is a root.
Even if this node were not a root, the cascading cuts would stop, since it is unmarked.
You can now see why we deﬁned the potential function to include a term that is twice the number of marked nodes.
One unit of potential pays for the cut and the clearing of the mark bit, and the other unit compensates for the unit increase in potential due to node y becoming a root.
Argue that it doesn’t matter to the analysis that x is marked, even though it is not a root that was ﬁrst linked to another node and then lost one child.
For each node x within a Fibonacci heap, deﬁne size.x/ to be the number of nodes, including x itself, in the subtree rooted at x.
Note that x need not be in the root list—it can be any node at all.
Bear in mind that x:degree is always maintained as an accurate count of the degree of x.
Corollary 19.5 The maximum degree D.n/ of any node in an n-node Fibonacci heap is O.lg n/
Show that the professor is mistaken by exhibiting, for any positive integer n, a sequence of Fibonacci-heap operations that creates a Fibonacci heap consisting of just one tree that is a linear chain of n nodes.
For what values of k is D.n/ D O.lg n/?
Professor Pisano has proposed the following variant of the FIB-HEAP-DELETE procedure, claiming that it runs faster when the node being deleted is not the node pointed to by H:min.
Give a good upper bound on the actual time of PISANO-DELETE when x is not H:min.
Your bound should be in terms of x:degree and the number c of calls to the CASCADING-CUT procedure.
Suppose that we call PISANO-DELETE.H; x/, and let H 0 be the Fibonacci heap that results.
Assuming that node x is not a root, bound the potential of H 0 in terms of x:degree, c, t.H/, and m.H/
A binomial heapH is a set of binomial trees that satisﬁes the following properties:
Suppose that a binomial heap H has a total of n nodes.
Discuss the relationship between the binomial trees that H contains and the binary representation of n.
Conclude that H consists of at most blg nc C 1 binomial trees.
Figure 19.6 (a) The recursive deﬁnition of the binomial tree Bk.
Complete the description of how to represent a binomial heap (i.e., name the attributes, describe when attributes have the value NIL, and deﬁne how the root list is organized), and show how to implement the same seven operations on binomial heaps as this chapter implemented on Fibonacci heaps.
Each operation should run in O.lg n/ worst-case time, where n is the number of nodes in.
Suppose that we were to implement only the mergeable-heap operations on a Fibonacci heap (i.e., we do not implement the DECREASE-KEY or DELETE operations)
How would the trees in a Fibonacci heap resemble those in a binomial heap? How would they differ? Show that the maximum degree in an n-node Fibonacci heap would be at most blg nc.
Professor McGee has devised a new data structure based on Fibonacci heaps.
A McGee heap has the same structure as a Fibonacci heap and supports just the mergeable-heap operations.
The implementations of the operations are the same as for Fibonacci heaps, except that insertion and union consolidate the root list as their last step.
What are the worst-case running times of operations on McGee heaps?
We wish to augment a Fibonacci heap H to support two new operations without changing the amortized running time of any other Fibonacci-heap operations.
Hint: You may need to modify the data structure and potential function.
In this problem, we shall implement 2-3-4 heaps, which support the mergeable-heap operations.
In 2-3-4 heaps, only leaves store keys, and each leaf x stores exactly one key in the attribute x:key.
The keys in the leaves may appear in any order.
Each internal node x contains a value x:small that is equal to the smallest key stored in any leaf in the subtree rooted at x.
The root r contains an attribute r:height that gives the height of the.
Finally, 2-3-4 heaps are designed to be kept in main memory, so that disk reads and writes are not needed.
In parts (a)–(e), each operation should run in O.lg n/ time on a 2-3-4 heap with n elements.
The UNION operation in part (f) should run in O.lg n/ time, where n is the number of elements in the two input heaps.
MINIMUM, which returns a pointer to the leaf with the smallest key.
Subsequently, Driscoll, Gabow, Shrairman, and Tarjan [96] developed “relaxed heaps” as an alternative to Fibonacci heaps.
One gives the same amortized time bounds as Fibonacci heaps.
The other allows DECREASE-KEY to run in O.1/ worst-case (not amortized) time and EXTRACT-MIN and DELETE to run in O.lg n/ worst-case time.
Relaxed heaps also have some advantages over Fibonacci heaps in parallel algorithms.
See also the chapter notes for Chapter 6 for other data structures that support fast DECREASE-KEY operations when the sequence of values returned by EXTRACTMIN calls are monotonically increasing over time and the data are integers in a speciﬁc range.
We saw in Chapter 8, however, that sometimes we can exploit additional information about the keys to sort in o.n lg n/ time.
Speciﬁcally, van Emde Boas trees support each of the dynamic set operations listed on page 230—SEARCH, INSERT, DELETE, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR—in O.lg lg n/ time.
In this chapter, we will omit discussion of satellite data and focus only on storing keys.
Because we concentrate on keys and disallow duplicate keys to be stored, instead of describing the SEARCH.
Chapter 13 does not explicitly discuss how to implement EXTRACT-MIN and DECREASE-KEY, but we can easily build these operations for any data structure that supports MINIMUM, DELETE, and INSERT.
Section 20.1 starts us out by examining some simple approaches that will get us going in the right direction.
We enhance these approaches in Section 20.2, introducing proto van Emde Boas structures, which are recursive but do not achieve our goal of O.lg lgu/-time operations.
Section 20.3 modiﬁes proto van Emde Boas structures to develop van Emde Boas trees, and it shows how to implement each operation in O.lg lgu/ time.
In this section, we shall examine various approaches for storing a dynamic set.
Although none will achieve the O.lg lgu/ time bounds that we desire, we will gain insights that will help us understand van Emde Boas trees when we see them later in this chapter.
The arrows show the path followed to determine the predecessor of 14 in the set.
We can short-cut long scans in the bit vector by superimposing a binary tree of bits on top of it.
In other words, the bit stored in an internal node is the logical-or of its two children.
We assume throughout this chapter that MINIMUM and MAXIMUM return NIL if the dynamic set is empty and that SUCCESSOR and PREDECESSOR return NIL if the element they are given has no successor or predecessor, respectively.
When inserting a value, we store a 1 in each node on the simple path from the appropriate leaf up to the root.
When deleting a value, we go from the appropriate leaf up to the root, recomputing the bit in each internal node on the path as the logical-or of its two children.
Since the height of the tree is lgu and each of the above operations makes at most one pass up the tree and at most one pass down, each operation takes O.lgu/ time in the worst case.
This approach is only marginally better than just using a red-black tree.
We can still perform the MEMBER operation in O.1/ time, whereas searching a red-black tree takes O.lg n/ time.
Then again, if the number n of elements stored is much smaller than the size u of the universe, a red-black tree would be faster for all the other operations.
What happens if we superimpose a tree with greater degree? Let us assume that the size of the universe is u D 22k for some integer k, so that pu is an integer.
Instead of superimposing a binary tree on top of the bit vector, we superimpose a tree of degree.
Figure 20.2(a) shows such a tree for the same bit vector as in.
As before, each internal node stores the logical-or of the bits within its subtree, so that the p.
To ﬁnd the successor (predecessor) of x, ﬁrst search to the right (left) within its cluster.
If we ﬁnd a 1, that position gives the result.
Otherwise, let i D bx=puc and search to the right (left) within the summary array from index i.
The ﬁrst position that holds a 1 gives the index of a cluster.
In each of the above operations, we search through at most two clusters of p.
At ﬁrst glance, it seems as though we have made negative progress.
Superimposing a binary tree gave us O.lgu/-time operations, which are asymptotically faster than O.
Show how to ﬁnd the successor of x in a binary search tree when x is not stored in the tree.
What would be the height of such a tree, and how long would each of the operations take?
In this section, we modify the idea of superimposing a tree of degree p.
In the previous section, we used a summary structure of size.
Now, we make the structure recursive, shrinking the universe size by the square root at each level of recursion.
Starting with a universe of size u, we make structures holding.
We shall see in the next section how to relax this assumption and assume only that u D 2k for some integer k.
Since the structure we examine in this section is only a precursor to the true van Emde Boas tree structure, we tolerate this restriction in favor of aiding our understanding.
Recalling that our goal is to achieve running times of O.lg lgu/ for the operations, let’s think about how we might obtain such running times.
At the end of Section 4.3, we saw that by changing variables, we could show that the recurrence.
If we use the same technique, changing variables, we can show that recurrence (20.2) has the solution T .u/ D O.lg lgu/
Let m D lgu, so that u D 2m and we have.
Recurrence (20.2) will guide our search for a data structure.
We will design a recursive data structure that shrinks by a factor of.
When an operation traverses this data structure, it will spend a constant amount of time at each level before recursing to the level below.
Recurrence (20.2) will then characterize the running time of the operation.
Here is another way to think of how the term lg lgu ends up in the solution to recurrence (20.2)
If we consider how many bits we need to store the universe size at each level, we need lgu at the top level, and each level needs half the bits of the previous level.
In general, if we start with b bits and halve the number of bits at each level, then after lg b levels, we get down to just one bit.
Looking back at the data structure in Figure 20.2, a given value x resides in cluster number bx=puc.
If we view x as a lgu-bit binary integer, that cluster number, bx=puc, is given by the most signiﬁcant .lgu/=2 bits of x.
We will need to index in this way, and so let us deﬁne some functions that will help us do so:
The function low.x/ gives the least signiﬁcant .lgu/=2 bits of x and provides x’s position within its cluster.
The value of u used by each of these functions will.
Taking our cue from recurrence (20.2), let us design a recursive data structure to support the operations.
Although this data structure will fail to achieve our goal of O.lg lgu/ time for some operations, it serves as a basis for the van Emde Boas tree structure that we will see in Section 20.3
In the two-level structure of the previous section, each node stores a summary array of size.
In the proto-vEB structure, we use explicit pointers rather than index.
The array summary contains the summary bits stored recursively in a proto-vEB structure, and the array cluster contains.
We shall now describe how to perform operations on a proto-vEB structure.
We ﬁrst examine the query operations—MEMBER, MINIMUM, MAXIMUM, and SUCCESSOR—which do not change the proto-vEB structure.
We leave MAXIMUM and PREDECESSOR, which are symmetric to MINIMUM and SUCCESSOR, respectively, as Exercise 20.2-1
Its solution is T .u/ D O.lg lgu/, and so we conclude that PROTO-VEB-MEMBER runs in time O.lg lgu/
Line 7 assigns this cluster number to the variable min-cluster.
If the set is empty, then the recursive call returned NIL, and line 9 returns NIL.
Otherwise, the minimum element of the set is somewhere in cluster number min-cluster.
The recursive call in line 10 ﬁnds the offset within the cluster of the minimum element in this cluster.
Finally, line 11 constructs the value of the minimum element from the cluster number and offset, and it returns this value.
Thus, we see that because of the second recursive call, PROTO-VEBMINIMUM runs in ‚.lgu/ time rather than the desired O.lg lgu/ time.
Because PROTO-VEB-INSERT makes two recursive calls in the worst case, recurrence (20.3) characterizes its running time.
As we have deﬁned proto-vEB structures, we would have to examine all p.
Alternatively, we could add an attribute n to the proto-vEB structure, counting how many elements it has.
Clearly, we need to modify the proto-vEB structure to get each operation down to making at most one recursive call.
We will see in the next section how to do so.
It should update the appropriate summary bit by scanning the related bits within the cluster.
What is the worst-case running time of your procedure? What other procedures need to change because of the new attribute? Do these changes affect their running times?
The proto-vEB structure of the previous section is close to what we need to achieve O.lg lgu/ running times.
It falls short because we have to recurse too many times in most of the operations.
In this section, we shall design a data structure that is similar to the proto-vEB structure but stores a little more information, thereby removing the need for some of the recursion.
From this point on, therefore, we will allow the universe size u to be any exact power of 2, and when.
The min and max attributes will turn out to be key to reducing the number of recursive calls within the operations on vEB trees.
The MINIMUM and MAXIMUM operations do not even need to recurse, for they can just return the values of min or max.
The SUCCESSOR operation can avoid making a recursive call to determine whether the successor of a value x lies within high.x/
That is because x’s successor lies within its cluster if and only if x is strictly less than the max attribute of its cluster.
We can tell whether a vEB tree has no elements, exactly one element, or at least two elements in constant time from its min and max values.
This ability will help in the INSERT and DELETE operations.
If min and max are both NIL, then the vEB tree has no elements.
If min and max are non-NIL but are equal to each other, then the vEB tree has exactly one element.
Otherwise, both min and max are non-NIL but are unequal, and the vEB tree has two or more elements.
If we know that a vEB tree is empty, we can insert an element into it by updating only its min and max attributes.
Hence, we can insert into an empty vEB tree in constant time.
Similarly, if we know that a vEB tree has only one element, we can delete that element in constant time by updating only min and max.
These properties will allow us to cut short the chain of recursive calls.
Even if the universe size u is an odd power of 2, the difference in the sizes of the summary vEB tree and the clusters will not turn out to affect the asymptotic running times of the vEB-tree operations.
The recursive procedures that implement the vEB-tree operations will all have running times characterized by the recurrence.
Before using a van Emde Boas tree, we must know the universe size u, so that we can create a van Emde Boas tree of the appropriate size that initially represents an empty set.
As Problem 20-1 asks you to show, the total space requirement of a van Emde Boas tree is O.u/, and it is straightforward to create an empty tree in O.u/ time.
In contrast, we can create an empty red-black tree in constant time.
Therefore, we might not want to use a van Emde Boas tree when we perform only a small number of operations, since the time to create the data structure would exceed the time saved in the individual operations.
This drawback is usually not signiﬁcant, since we typically use a simple data structure, such as an array or linked list, to represent a set with only a few elements.
Because we store the minimum and maximum in the attributes min and max, two of the operations are one-liners, taking constant time:
We also check directly whether x equals the minimum or maximum element.
Recurrence (20.4) characterizes the running time of the VEB-TREE-MEMBER procedure, and so this procedure takes O.lg lgu/ time.
Because we can access the maximum value in a vEB tree quickly, we can avoid making two recursive calls, and instead make one recursive call on either a cluster or on the summary, but not on both.
If we are not in the base case, we next check in line 5 whether x is strictly less than the minimum element.
If we get to line 7, then we know that we are not in a base case and that x is greater than or equal to the minimum value in the vEB tree V.
Line 7 assigns to max-low the maximum element in x’s cluster.
If x’s cluster contains some element that is greater than x, then we know that x’s successor lies somewhere within x’s cluster.
We get to line 11 if x is greater than or equal to the greatest element in its cluster.
It is easy to see how recurrence (20.4) characterizes the running time of VEBTREE-SUCCESSOR.
The remainder of the procedure, including the calls to VEB-TREE-MINIMUM and VEB-TREE-MAXIMUM, takes O.1/ time.
This case occurs when x’s predecessor, if it exists, does not reside in x’s cluster.
But if x’s predecessor is the minimum value in vEB tree V , then the successor resides in no cluster at all.
Now we examine how to insert an element into a vEB tree.
Recall that PROTOVEB-INSERT made two recursive calls: one to insert the element and one to insert the element’s cluster number into the summary.
How can we get away with just one? When we insert an element, either the cluster that it goes into already has another element or it does not.
If the cluster already has another element, then the cluster number is already in the summary, and so we do not need to make that recursive call.
Lines 3–11 assume that V is not empty, and therefore some element will be inserted into one of V ’s clusters.
But that element might not necessarily be the element x passed to VEB-TREE-INSERT.
We don’t want to lose the original min, however, and so we need to insert it into one of V ’s clusters.
In this case, line 4 exchanges x with min, so that we insert the original min into one of V ’s clusters.
We execute lines 6–9 only if V is not a base-case vEB tree.
Line 6 determines whether the cluster that x will go into is currently empty.
If x’s cluster is not currently empty, then line 9 inserts x into its cluster.
In this case, we do not need to update the summary, since x’s cluster number is already a member of the summary.
Once again, we can easily see how recurrence (20.4) characterizes the running time.
Finally, we look at how to delete an element from a vEB tree.
If the vEB tree V contains only one element, then it’s just as easy to delete it as it was to insert an element into an empty vEB tree: just set min and max to NIL.
When we reach line 13, we know that we need to delete element x from its cluster, whether x was the value originally passed to VEB-TREE-DELETE or x is the element becoming the new minimum.
After updating the summary, we might need to update max.
Otherwise, line 20 sets max to the maximum element in the highest-numbered cluster.
If this cluster is where the element has been deleted, we again rely on the recursive call in line 13 having already corrected that cluster’s max attribute.
Finally, we have to handle the case in which x’s cluster did not become empty due to x being deleted.
Although we do not have to update the summary in this case, we might have to update max.
Now we show that VEB-TREE-DELETE runs in O.lg lgu/ time in the worst case.
Although the procedure can make both recursive calls, let’s think about what happens when it does.
In either case, recurrence (20.4) characterizes the running time of VEB-TREEDELETE, and hence its worst-case running time is O.lg lgu/
Show how to modify vEB trees and their operations so that we can check in constant time whether an element is present.
What is the smallest number of operations n for which the amortized time of each operation in a vEB tree is O.lg lgu/?
This problem explores the space requirements for van Emde Boas trees and suggests a way to modify the data structure to make its space requirement depend on the number n of elements actually stored in the tree, rather than on the universe size u.
Explain why the following recurrence characterizes the space requirement P.u/ of a van Emde Boas tree with universe size u:
Corresponding to the array version of V:cluster, the hash table stores pointers to RS-vEB trees with universe size.
A search in the hash table for an empty cluster returns NIL, indicating that the cluster is empty.
The attribute V:summary is NIL if all clusters are empty.
Otherwise, V:summary points to an RS-vEB tree with universe size.
Because the hash table is implemented with a dynamic table, the space it requires is proportional to the number of nonempty clusters.
When we need to insert an element into an empty RS-vEB tree, we create the RSvEB tree by calling the following procedure, where the parameter u is the universe size of the RS-vEB tree:
Assuming that elements are never deleted from a vEB tree, prove that the space requirement for the RS-vEB tree structure is O.n/, where n is the number of elements actually stored in the RS-vEB tree.
RS-vEB trees have another advantage over vEB trees: they require less time to create.
How long does it take to create an empty RS-vEB tree?
Willard’s “y-fast tries” which, like van Emde Boas trees, perform each of the operations MEMBER, MINIMUM, MAXIMUM, PREDECESSOR, and SUCCESSOR on elements drawn from a universe with size u in O.lg lgu/ worst-case time.
The INSERT and DELETE operations take O.lg lgu/ amortized time.
Like reduced-space van Emde Boas trees (see Problem 20-1), yfast tries use only O.n/ space to store n elements.
The design of y-fast tries relies on perfect hashing (see Section 11.5)
As a preliminary structure, suppose that we create a perfect hash table containing not only every element in the dynamic set, but every preﬁx of the binary representation of every element in the set.
In addition to the hash table, we create a doubly linked list of the elements currently in the set, in increasing order.
Show how to perform the MINIMUM and MAXIMUM operations in O.1/ time; the MEMBER, PREDECESSOR, and SUCCESSOR operations in O.lg lgu/ time; and the INSERT and DELETE operations in O.lgu/ time.
To reduce the space requirement to O.n/, we make the following changes to the data structure:
We cluster the n elements into n= lgu groups of size lgu.
The ﬁrst group consists of the lgu smallest elements in the set, the second group consists of the next lg u smallest elements, and so on.
We store the lgu elements of each group in a balanced binary search tree, such as a red-black tree.
Each representative points to the balanced binary search tree for its group, and each balanced binary search tree points to its group’s representative.
The perfect hash table stores only the representatives, which are also stored in a doubly linked list in increasing order.
Show that a y-fast trie requires only O.n/ space to store n elements.
Show how to perform the MINIMUM and MAXIMUM operations in O.lg lgu/ time with a y-fast trie.
Show how to perform the MEMBER operation in O.lg lgu/ time.
Show how to perform the PREDECESSOR and SUCCESSOR operations in O.lg lgu/ time.
Show how to relax the requirement that each group in a y-fast trie has exactly lgu elements to allow INSERT and DELETE to run in O.lg lgu/ amortized time without affecting the asymptotic running times of the other operations.
Mehlhorn’s book [249] contains a slightly different treatment of van Emde Boas trees than the one in this chapter.
Using the ideas behind van Emde Boas trees, Dementiev et al.
Wang and Lin [347] designed a hardware-pipelined version of van Emde Boas trees, which achieves constant amortized time per operation and uses O.lg lgu/ stages in the pipeline.
Some applications involve grouping n distinct elements into a collection of disjoint sets.
These applications often need to perform two operations in particular: ﬁnding the unique set that contains a given element and uniting two sets.
This chapter explores methods for maintaining a data structure that supports these operations.
Section 21.1 describes the operations supported by a disjoint-set data structure and presents a simple application.
In Section 21.2, we look at a simple linked-list implementation for disjoint sets.
Section 21.3 presents a more efﬁcient representation using rooted trees.
The running time using the tree representation is theoretically superlinear, but for all practical purposes it is linear.
Section 21.4 deﬁnes and discusses a very quickly growing function and its very slowly growing inverse, which appears in the running time of operations on the tree-based implementation, and then, by a complex amortized analysis, proves an upper bound on the running time that is just barely superlinear.
We identify each set by a representative, which is some member of the set.
In some applications, it doesn’t matter which member is used as the representative; we care only that if we ask for the representative of a dynamic set twice without modifying the set between the requests, we get the same answer both times.
Other applications may require a prespeciﬁed rule for choosing the representative, such as choosing the smallest member in the set (assuming, of course, that the elements can be ordered)
As in the other dynamic-set implementations we have studied, we represent each element of a set by an object.
Letting x denote an object, we wish to support the following operations:
MAKE-SET.x/ creates a new set whose only member (and thus representative) is x.
Since the sets are disjoint, we require that x not already be in some other set.
UNION.x; y/ unites the dynamic sets that contain x and y, say Sx and Sy , into a new set that is the union of these two sets.
We assume that the two sets are disjoint prior to the operation.
Since we require the sets in the collection to be disjoint, conceptually we destroy sets Sx and Sy , removing them from the collection S.
In practice, we often absorb the elements of one of the sets into the other set.
FIND-SET.x/ returns a pointer to the representative of the (unique) set containing x.
An application of disjoint-set data structures One of the many applications of disjoint-set data structures arises in determining the connected components of an undirected graph (see Section B.4)
Figure 21.1(a), for example, shows a graph with four connected components.
When the edges of the graph are static—not changing over time—we can compute the connected components faster by using depth-ﬁrst search (Exercise 22.3-12)
Sometimes, however, the edges are added dynamically and we need to maintain the connected components as each edge is added.
In this case, the implementation given here can be more efﬁcient than running a new depth-ﬁrst search for each new edge.
That is, an object representing a vertex would contain a pointer to the corresponding disjoint-set object, and vice versa.
These programming details depend on the implementation language, and we do not address them further here.
List the vertices in each connected component after each iteration of lines 3–5
Figure 21.2(a) shows a simple way to implement a disjoint-set data structure: each set is represented by its own linked list.
The object for each set has attributes head, pointing to the ﬁrst object in the list, and tail, pointing to the last object.
Each object in the list contains a set member, a pointer to the next object in the list, and a pointer back to the set object.
Within each linked list, the objects may appear in any order.
The representative is the set member in the ﬁrst object in the list.
With this linked-list representation, both MAKE-SET and FIND-SET are easy, requiring O.1/ time.
To carry out MAKE-SET.x/, we create a new linked list whose only object is x.
For FIND-SET.x/, we just follow the pointer from x back to its set object and then return the member in the object that head points to.
For example, in Figure 21.2(a), the call FIND-SET.g/ would return f.
Each object in the list contains a set member, a pointer to the next object in the list, and a pointer back to the set object.
Each set object has pointers head and tail to the ﬁrst and last objects, respectively.
The simplest implementation of the UNION operation using the linked-list set representation takes signiﬁcantly more time than MAKE-SET or FIND-SET.
As Figure 21.2(b) shows, we perform UNION.x; y/ by appending y’s list onto the end of x’s list.
The representative of x’s list becomes the representative of the resulting set.
We use the tail pointer for x’s list to quickly ﬁnd where to append y’s list.
Because all members of y’s list join x’s list, we can destroy the set object for y’s list.
Unfortunately, we must update the pointer to the set object for each object originally on y’s list, which takes time linear in the length of y’s list.
In Figure 21.2, for example, the operation UNION.g; e/ causes pointers to be updated in the objects for b, c, e, and h.
Theorem 21.1 Using the linked-list representation of disjoint sets and the weighted-union heuristic, a sequence of m MAKE-SET, UNION, and FIND-SET operations, n of which are MAKE-SET operations, takes O.mC n lg n/ time.
The time for the entire sequence of m operations follows easily.
Each MAKESET and FIND-SET operation takes O.1/ time, and there are O.m/ of them.
The total time for the entire sequence is thus O.mC n lg n/
Make sure to specify the attributes that you assume for set objects and list objects.
Assume that if the sets containing xi and xj have the same size, then the operation UNION.xi ; xj / appends xj ’s list onto xi ’s list.
Show that the professor’s suspicion is well founded by describing how to represent each set by a linked list such that each operation has the same running time as the operations described in this section.
Your scheme should allow for the weighted-union heuristic, with the same effect as described in this section.
Hint: Use the tail of a linked list as its set’s representative.
Whether or not the weighted-union heuristic is used, your change should not change the asymptotic running time of the UNION procedure.
Hint: Rather than appending one list to another, splice them together.
In a faster implementation of disjoint sets, we represent sets by rooted trees, with each node containing one member and each tree representing one set.
In a disjointset forest, illustrated in Figure 21.4(a), each member points only to its parent.
The root of each tree contains the representative and is its own parent.
As we shall see, although the straightforward algorithms that use this representation are no faster than ones that use the linked-list representation, by introducing two heuristics—“union by rank” and “path compression”—we can achieve an asymptotically optimal disjoint-set data structure.
The tree on the left represents the set fb; c; e; hg, with c as the representative, and the tree on the right represents the set fd; f; gg, with f as the representative.
A MAKE-SET operation simply creates a tree with just one node.
We perform a FIND-SET operation by following parent pointers until we ﬁnd the root of the tree.
The nodes visited on this simple path toward the root constitute the ﬁnd path.
A UNION operation, shown in Figure 21.4(b), causes the root of one tree to point to the root of the other.
The ﬁrst heuristic, union by rank, is similar to the weighted-union heuristic we used with the linked-list representation.
The obvious approach would be to make the root of the tree with fewer nodes point to the root of the tree with more nodes.
Rather than explicitly keeping track of the size of the subtree rooted at each node, we shall use an approach that eases the analysis.
For each node, we maintain a rank, which is an upper bound on the height of the node.
In union by rank, we make the root with smaller rank point to the root with larger rank during a UNION operation.
The second heuristic, path compression, is also quite simple and highly effective.
As shown in Figure 21.5, we use it during FIND-SET operations to make each node on the ﬁnd path point directly to the root.
Each node on the ﬁnd path now points directly to the root.
Pseudocode for disjoint-set forests To implement a disjoint-set forest with the union-by-rank heuristic, we must keep track of ranks.
With each node x, we maintain the integer value x:rank, which is an upper bound on the height of x (the number of edges in the longest simple path between x and a descendant leaf)
The UNION operation has two cases, depending on whether the roots of the trees have equal rank.
If the roots have unequal rank, we make the root with higher rank the parent of the root with lower rank, but the ranks themselves remain unchanged.
If, instead, the roots have equal ranks, we arbitrarily choose one of the roots as the parent and increment its rank.
The LINK procedure, a subroutine called by UNION, takes pointers to two roots as inputs.
The FIND-SET procedure is a two-pass method: as it recurses, it makes one pass up the ﬁnd path to ﬁnd the root, and as the recursion unwinds, it makes a second pass back down the ﬁnd path to update each node to point directly to the root.
If x is the root, then FIND-SET skips line 2 and instead returns x:p, which is x; this is the case in which the recursion bottoms out.
Otherwise, line 2 executes, and the recursive call with parameter x:p returns a pointer to the root.
Show how we can add just a single attribute to each node in a disjoint-set forest so that PRINT-SET.x/ takes time linear in the number of members of x’s set and the asymptotic running times of the other operations are unchanged.
Assume that we can print each member of the set in O.1/ time.
What happens in the same situation if we use only the path-compression heuristic?
A very quickly growing function and its very slowly growing inverse.
We will refer to the parameter k as the level of the function A.
The function Ak.j / strictly increases with both j and k.
Proof The proof is a straightforward induction on the number of operations, using the implementations of MAKE-SET, UNION, and FIND-SET that appear in Section 21.3
Corollary 21.5 As we follow the simple path from any node toward a root, the node ranks strictly increase.
In fact, every node has rank at most blg nc (see Exercise 21.4-2)
The looser bound of Lemma 21.6 will sufﬁce for our purposes, however.
With these auxiliary functions in place, we are ready to deﬁne the potential of node x after q operations:
Lemma 21.8 For every node x, and for all operation counts q, we have.
We are now ready to examine how the disjoint-set operations affect node potentials.
With an understanding of the change in potential due to each operation, we can determine each operation’s amortized cost.
Without loss of generality, suppose that the LINK makes y the parent of x.
Just prior to the path compression caused by the FIND-SET, we have.
Putting these inequalities together and letting i be the value of iter.x/ before path compression, we have.
In the following instance of the off-line minimum problem, each operation INSERT.i/ is represented by the value of i and each EXTRACT-MIN is represented by the letter E:
To develop an algorithm for this problem, we break the sequence S into homogeneous subsequences.
For each subsequence Ij , we initially place the keys inserted by these operations into a set Kj , which is empty if Ij is empty.
Argue that the array extracted returned by OFF-LINE-MINIMUM is correct.
Describe how to implement OFF-LINE-MINIMUM efﬁciently with a disjointset data structure.
Give a tight bound on the worst-case running time of your implementation.
By using the union-by-rank and path-compression heuristics, we can reduce the worst-case running time.
We use the disjoint-set forest S D fSig, where each set Si (which is itself a tree) corresponds to a tree Ti in the forest F.
The tree structure within a set Si , however, does not necessarily correspond to that of Ti.
In fact, the implementation of Si does not record the exact parent-child relationships but nevertheless allows us to determine any node’s depth in Ti.
Your implementation should perform path compression, and its running time should be linear in the length of the ﬁnd path.
Give a tight bound on the worst-case running time of a sequence of m MAKETREE, FIND-DEPTH, and GRAFT operations, n of which are MAKE-TREE operations.
We assume that each node is colored WHITE prior to the walk.
Argue that at the time of the call LCA.u/, the number of sets in the disjoint-set data structure equals the depth of u in T.
Analyze the running time of LCA, assuming that we use the implementation of the disjoint-set data structure in Section 21.3
Tarjan and van Leeuwen [333] discuss variants on the path-compression heuristic, including “one-pass methods,” which sometimes offer better constant factors in their performance than do two-pass methods.
As with Tarjan’s earlier analyses of the basic path-compression heuristic, the analyses by Tarjan and van Leeuwen are aggregate.
Harfst and Reingold [161] later showed how to make a small change to the potential function to adapt their path-compression analysis to these one-pass variants.
Gabow and Tarjan [121] show that in certain applications, the disjoint-set operations can be made to run in O.m/ time.
Graph problems pervade computer science, and algorithms for working with them are fundamental to the ﬁeld.
Hundreds of interesting computational problems are couched in terms of graphs.
In this part, we touch on a few of the more signiﬁcant ones.
Chapter 22 shows how we can represent a graph in a computer and then discusses algorithms based on searching a graph using either breadth-ﬁrst search or depthﬁrst search.
The chapter gives two applications of depth-ﬁrst search: topologically sorting a directed acyclic graph and decomposing a directed graph into its strongly connected components.
Chapter 23 describes how to compute a minimum-weight spanning tree of a graph: the least-weight way of connecting all of the vertices together when each edge has an associated weight.
The algorithms for computing minimum spanning trees serve as good examples of greedy algorithms (see Chapter 16)
Finally, Chapter 26 shows how to compute a maximum ﬂow of material in a ﬂow network, which is a directed graph having a speciﬁed source vertex of material, a speciﬁed sink vertex, and speciﬁed capacities for the amount of material that can traverse each directed edge.
This general problem arises in many forms, and a good algorithm for computing maximum ﬂows can help solve a variety of related problems efﬁciently.
When we characterize the running time of a graph algorithm on a given graph G D .V;E/, we usually measure the size of the input in terms of the number of vertices jV j and the number of edges jEj of the graph.
That is, we describe the size of the input with two parameters, not just one.
Inside asymptotic notation (such as O-notation or ‚-notation), and only inside such notation, the symbol V denotes jV j and the symbol E denotes jEj.
For example, we might say, “the algorithm runs in time O.VE/,” meaning that the algorithm runs in time O.jV j jEj/
This convention makes the running-time formulas easier to read, without risk of ambiguity.
We denote the vertex set of a graph G by G:V and its edge set by G:E.
That is, the pseudocode views vertex and edge sets as attributes of a graph.
This chapter presents methods for representing a graph and for searching a graph.
Searching a graph means systematically following the edges of the graph so as to visit the vertices of the graph.
A graph-searching algorithm can discover much about the structure of a graph.
Many algorithms begin by searching their input graph to obtain this structural information.
Techniques for searching a graph lie at the heart of the ﬁeld of graph algorithms.
Section 22.1 discusses the two most common computational representations of graphs: as adjacency lists and as adjacency matrices.
Section 22.2 presents a simple graph-searching algorithm called breadth-ﬁrst search and shows how to create a breadth-ﬁrst tree.
Section 22.3 presents depth-ﬁrst search and proves some standard results about the order in which depth-ﬁrst search visits vertices.
Section 22.4 provides our ﬁrst real application of depth-ﬁrst search: topologically sorting a directed acyclic graph.
A second application of depth-ﬁrst search, ﬁnding the strongly connected components of a directed graph, is the topic of Section 22.5
We can choose between two standard ways to represent a graph G D .V;E/: as a collection of adjacency lists or as an adjacency matrix.
Because the adjacency-list representation provides a compact way to represent sparse graphs—those for which jEj is much less than jV j2—it is usually the method of choice.
Most of the graph algorithms presented in this book assume that an input graph is represented in adjacencylist form.
We may prefer an adjacency-matrix representation, however, when the graph is dense—jEj is close to jV j2—or when we need to be able to tell quickly if there is an edge connecting two given vertices.
Although the adjacency-list representation is asymptotically at least as spaceefﬁcient as the adjacency-matrix representation, adjacency matrices are simpler, and so we may prefer them when graphs are reasonably small.
Describe what the entries of the matrix product BBT represent, where BT is the transpose of B.
Breadth-ﬁrst search is one of the simplest algorithms for searching a graph and the archetype for many important graph algorithms.
Breadth-ﬁrst search is so named because it expands the frontier between discovered and undiscovered vertices uniformly across the breadth of the frontier.
We distinguish between gray and black vertices to help us understand how breadth-ﬁrst search operates.
In fact, as Exercise 22.2-3 shows, we would get the same result even if we did not distinguish between gray and black vertices.
Figure 22.3 illustrates the progress of BFS on a sample graph.
Line 5 paints s gray, since we consider it to be discovered as the procedure begins.
Lines 8–9 initialize Q to the queue containing just the vertex s.
The while loop of lines 10–18 iterates as long as there remain gray vertices, which are discovered vertices that have not yet had their adjacency lists fully examined.
At the test in line 10, the queue Q consists of the set of gray vertices.
Figure 22.3 The operation of BFS on an undirected graph.
Tree edges are shown shaded as they are produced by BFS.
The queue Q is shown at the beginning of each iteration of the while loop of lines 10–18
The results of breadth-ﬁrst search may depend upon the order in which the neighbors of a given vertex are visited in line 12: the breadth-ﬁrst tree may vary, but the distances d computed by the algorithm will not.
Before proving the various properties of breadth-ﬁrst search, we take on the somewhat easier job of analyzing its running time on an input graph G D .V;E/
We use aggregate analysis, as we saw in Section 17.1
After initialization, breadth-ﬁrst search never whitens a vertex, and thus the test in line 13 ensures that each vertex is enqueued at most once, and hence dequeued at most once.
The operations of enqueuing and dequeuing take O.1/ time, and so the total time devoted to queue operations is O.V /
Because the procedure scans the adjacency list of each vertex only when the vertex is dequeued, it scans each adjacency list at most once.
Since the sum of the lengths of all the adjacency lists is ‚.E/, the total time spent in scanning adjacency lists is O.E/
The overhead for initialization is O.V /, and thus the total running time of the BFS procedure is O.V CE/
Thus, breadth-ﬁrst search runs in time linear in the size of the adjacency-list representation of G.
The graphs considered in the present chapter are unweighted or, equivalently, all edges have unit weight.
Proof The proof is by induction on the number of queue operations.
Initially, when the queue contains only s, the lemma certainly holds.
The following corollary shows that the d values at the time that vertices are enqueued are monotonically increasing over time.
Proof Immediate from Lemma 22.3 and the property that each vertex receives a ﬁnite d value at most once during the course of BFS.
We can now prove that breadth-ﬁrst search correctly ﬁnds shortest-path distances.
The following lemma shows that the predecessor subgraph produced by the BFS procedure is a breadth-ﬁrst tree.
This procedure runs in time linear in the number of vertices in the path printed, since each recursive call is for a path one vertex shorter.
Give an O.V C E/-time algorithm to compute a path in G that traverses each edge in E exactly once in each direction.
Describe how you can ﬁnd your way out of a maze if you are given a large supply of pennies.
As in breadth-ﬁrst search, depth-ﬁrst search colors vertices during the search to indicate their state.
Each vertex is initially white, is grayed when it is discovered in the search, and is blackened when it is ﬁnished, that is, when its adjacency list has been examined completely.
This technique guarantees that each vertex ends up in exactly one depth-ﬁrst tree, so that these trees are disjoint.
It may seem arbitrary that breadth-ﬁrst search is limited to only one source whereas depth-ﬁrst search may search from multiple sources.
Although conceptually, breadth-ﬁrst search could proceed from multiple sources and depth-ﬁrst search could be limited to one source, our approach reﬂects how the results of these searches are typically used.
Breadth-ﬁrst search usually serves to ﬁnd shortestpath distances (and the associated predecessor subgraph) from a given source.
Depth-ﬁrst search is often a subroutine in another algorithm, as we shall see later in this chapter.
The procedure DFS below records when it discovers vertex u in the attribute u:d and when it ﬁnishes vertex u in the attribute u: f.
The variable time is a global variable that we use for timestamping.
Figure 22.4 The progress of the depth-ﬁrst-search algorithm DFS on a directed graph.
As edges are explored by the algorithm, they are shown as either shaded (if they are tree edges) or dashed (otherwise)
Nontree edges are labeled B, C, or F according to whether they are back, cross, or forward edges.
When DFS returns, every vertex u has been assigned a discovery time u:d and a ﬁnishing time u: f.
Another important property of depth-ﬁrst search is that discovery and ﬁnishing times have parenthesis structure.
If we represent the discovery of vertex u with a left parenthesis “.u” and represent its ﬁnishing by a right parenthesis “u/”, then the history of discoveries and ﬁnishings makes a well-formed expression in the sense that the parentheses are properly nested.
The following theorem provides another way to characterize the parenthesis structure.
Vertices are timestamped and edge types are indicated as in Figure 22.4
Each rectangle spans the interval given by the discovery and ﬁnishing times of the corresponding vertex.
If two intervals overlap, then one is nested within the other, and the vertex corresponding to the smaller interval is a descendant of the vertex corresponding to the larger.
The next theorem gives another important characterization of when one vertex.
Another interesting property of depth-ﬁrst search is that the search can be used to classify the edges of the input graph G D .V;E/
The type of each edge can provide important information about a graph.
For example, in the next section, we shall see that a directed graph is acyclic if and only if a depth-ﬁrst search yields no “back” edges (Lemma 22.11)
They can go between vertices in the same depth-ﬁrst tree, as long as one vertex is not an ancestor of the other, or they can go between vertices in different depth-ﬁrst trees.
The ﬁrst case is immediate from the speciﬁcation of the algorithm.
For the second case, observe that the gray vertices always form a linear chain of descendants corresponding to the stack of active DFS-VISIT invocations; the number of gray vertices is one more than the depth in the depth-ﬁrst forest of the vertex most recently discovered.
We now show that forward and cross edges never occur in a depth-ﬁrst search of an undirected graph.
Theorem 22.10 In a depth-ﬁrst search of an undirected graph G, every edge of G is either a tree edge or a back edge.
We shall see several applications of these theorems in the following sections.
In each cell .i; j /, indicate whether, at any point during a depth-ﬁrst search of a directed graph, there can be an edge from a vertex of color i to a vertex of color j.
For each possible edge, indicate what edge types it can be.
Make a second such chart for depth-ﬁrst search of an undirected graph.
Assume that the for loop of lines 5–7 of the DFS procedure considers the vertices in alphabetical order, and assume that each adjacency list is ordered alphabetically.
Show the discovery and ﬁnishing times for each vertex, and show the classiﬁcation of each edge.
Many applications use directed acyclic graphs to indicate precedences among events.
Figure 22.7 gives an example that arises when Professor Bumstead gets dressed in the morning.
The professor must don certain garments before others (e.g., socks before shoes)
Figure 22.7(b) shows how the topologically sorted vertices appear in reverse order of their ﬁnishing times.
We prove the correctness of this algorithm using the following key lemma characterizing directed acyclic graphs.
Lemma 22.11 A directed graph G is acyclic if and only if a depth-ﬁrst search of G yields no back edges.
Theorem 22.12 TOPOLOGICAL-SORT produces a topological sort of the directed acyclic graph provided as its input.
Your algorithm should run in O.V / time, independent of jEj.
Explain how to implement this idea so that it runs in time O.V CE/
We now consider a classic application of depth-ﬁrst search: decomposing a directed graph into its strongly connected components.
This section shows how to do so using two depth-ﬁrst searches.
Many algorithms that work with directed graphs begin with such a decomposition.
After decomposing the graph into strongly connected components, such algorithms run separately on each one and then combine the solutions according to the structure of connections among components.
Each shaded region is a strongly connected component of G.
Each vertex is labeled with its discovery and ﬁnishing times in a depth-ﬁrst search, and tree edges are shaded.
Vertices b, c, g, and h, which are heavily shaded, are the roots of the depth-ﬁrst trees produced by the depth-ﬁrst search of GT.
The following linear-time (i.e., ‚.VCE/-time) algorithm computes the strongly connected components of a directed graph G D .V;E/ using two depth-ﬁrst searches, one on G and one on GT.
The key property is that the component graph is a dag, which the following lemma implies.
We shall see that by considering vertices in the second depth-ﬁrst search in decreasing order of the ﬁnishing times that were computed in the ﬁrst depth-ﬁrst search, we are, in essence, visiting the vertices of the component graph (each of which corresponds to a strongly connected component of G) in topologically sorted order.
The following lemma and its corollary give a key property relating strongly connected components and ﬁnishing times in the ﬁrst depth-ﬁrst search.
Proof We consider two cases, depending on which strongly connected component, C or C 0, had the ﬁrst discovered vertex during the depth-ﬁrst search.
The following corollary tells us that each edge in GT that goes between different strongly connected components goes from a component with an earlier ﬁnishing time (in the ﬁrst depth-ﬁrst search) to a component with a later ﬁnishing time.
Corollary 22.15 provides the key to understanding why the strongly connected components algorithm works.
Let us examine what happens when we perform the second depth-ﬁrst search, which is on GT.
We start with the strongly connected component C whose ﬁnishing time f .C / is maximum.
The search starts from some vertex x 2 C , and it visits all vertices in C.
By Corollary 22.15, GT contains no edges from C to any other strongly connected component, and so the search from x will not visit vertices in any other component.
Thus, the tree rooted at x contains exactly the vertices of C.
In general, when the depth-ﬁrst search of GT in line 3 visits any strongly connected component, any edges out of that component must be to components that the search already visited.
Each depth-ﬁrst tree, therefore, will be exactly one strongly connected component.
Proof We argue by induction on the number of depth-ﬁrst trees found in the depth-ﬁrst search of GT in line 3 that the vertices of each tree form a strongly connected component.
The inductive hypothesis is that the ﬁrst k trees produced in line 3 are strongly connected components.
The basis for the induction, when k D 0, is trivial.
Let the root of this tree be vertex u, and let u be in strongly connected component C.
By the inductive hypothesis, at the time that the search visits u, all other vertices of C are white.
By the white-path theorem, therefore, all other vertices of C are descendants of u in its depth-ﬁrst tree.
Moreover, by the inductive hypothesis and by Corollary 22.15, any edges in GT that leave C must be to strongly connected components that have already been visited.
Thus, the vertices of the depth-ﬁrst tree in GT that is rooted at u form exactly one strongly connected component, which completes the inductive step and the proof.
Here is another way to look at how the second depth-ﬁrst search operates.
If we map each strongly connected component visited in the second depth-ﬁrst search to a vertex of .GT/SCC, the second depth-ﬁrst search visits vertices of .GT/SCC in the reverse of a topologically sorted order.
If we reverse the edges of .GT/SCC, we get the graph ..GT/SCC/T.
Because ..GT/SCC/T D GSCC (see Exercise 22.5-4), the second depth-ﬁrst search visits the vertices of GSCC in topologically sorted order.
Assume that the loop of lines 5–7 of DFS considers vertices in alphabetical order and that the adjacency lists are in alphabetical order.
That is, the transpose of the component graph of GT is the same as the component graph of G.
Make sure that there is at most one edge between two vertices in the component graph your algorithm produces.
A depth-ﬁrst forest classiﬁes the edges of a graph into tree, back, forward, and cross edges.
A breadth-ﬁrst tree can also be used to classify the edges reachable from the source of the search into the same four categories.
Prove that in a breadth-ﬁrst search of an undirected graph, the following properties hold:
Prove that in a breadth-ﬁrst search of a directed graph, the following properties hold:
An articulation point of G is a vertex whose removal disconnects G.
A bridge of G is an edge whose removal disconnects G.
A biconnected component of G is a maximal set of edges such that any two edges in the set lie on a common simple cycle.
The articulation points are the heavily shaded vertices, the bridges are the heavily shaded edges, and the biconnected components are the edges in the shaded regions, with a bcc numbering shown.
Show how to compute all articulation points in O.E/ time.
Prove that an edge of G is a bridge if and only if it does not lie on any simple cycle of G.
Show how to compute all the bridges of G in O.E/ time.
Prove that the biconnected components of G partition the nonbridge edges of G.
An Euler tour of a strongly connected, directed graph G D .V;E/ is a cycle that traverses each edge of G exactly once, although it may visit a vertex more than once.
Describe an O.E/-time algorithm to ﬁnd an Euler tour of G if one exists.
Breadth-ﬁrst search was discovered by Moore [260] in the context of ﬁnding.
Lee [226] independently discovered the same algorithm in the context of routing wires on circuit boards.
Hopcroft and Tarjan [178] advocated the use of the adjacency-list representation over the adjacency-matrix representation for sparse graphs and were the ﬁrst to recognize the algorithmic importance of depth-ﬁrst search.
Depth-ﬁrst search has been widely used since the late 1950s, especially in artiﬁcial intelligence programs.
Tarjan [327] gave a linear-time algorithm for ﬁnding strongly connected components.
Gabow [119] also developed an algorithm for strongly connected components that is based on contracting cycles and uses two stacks to make it run in linear time.
Knuth [209] was the ﬁrst to give a linear-time algorithm for topological sorting.
Since T is acyclic and connects all of the vertices, it must form a tree, which we call a spanning tree since it “spans” the graph G.
We can easily make each of them run in time O.E lgV / using ordinary binary heaps.
By using Fibonacci heaps, Prim’s algorithm runs in time O.E C V lgV /, which improves over the binary-heap implementation if jV j is much smaller than jEj.
Each step of a greedy algorithm must make one of several possible choices.
The greedy strategy advocates making the choice that is the best at the moment.
Such a strategy does not generally guarantee that it will always ﬁnd globally optimal solutions.
Figure 23.1 A minimum spanning tree for a connected graph.
The weights on edges are shown, and the edges in a minimum spanning tree are shaded.
Although you can read this chapter independently of Chapter 16, the greedy methods presented here are a classic application of the theoretical notions introduced there.
Section 23.2 gives two algorithms that implement the generic method.
The second, due to Prim, resembles Dijkstra’s shortest-paths algorithm (Section 24.3)
Because a tree is a type of graph, in order to be precise we must deﬁne a tree in terms of not just its edges, but its vertices as well.
Although this chapter focuses on trees in terms of their edges, we shall operate with the understanding that the vertices of a tree T are those that some edge of T is incident on.
Assume that we have a connected, undirected graph G D .V;E/ with a weight function w W E ! R, and we wish to ﬁnd a minimum spanning tree for G.
The two algorithms we consider in this chapter use a greedy approach to the problem, although they differ in how they apply this approach.
This greedy strategy is captured by the following generic method, which grows the minimum spanning tree one edge at a time.
The generic method manages a set of edges A, maintaining the following loop invariant:
Prior to each iteration, A is a subset of some minimum spanning tree.
We call such an edge a safe edge for A, since we can add it safely to A while maintaining the invariant.
Initialization: After line 1, the set A trivially satisﬁes the loop invariant.
Maintenance: The loop in lines 2–4 maintains the invariant by adding only safe.
Termination: All edges added to A are in a minimum spanning tree, and so the.
In the remainder of this section, we provide a rule (Theorem 23.1) for recognizing safe edges.
The next section describes two algorithms that use this rule to ﬁnd safe edges efﬁciently.
Our rule for recognizing safe edges is given by the following theorem.
Show that the converse is not true by giving a counterexample.
Give an example to show that the same conclusion does not follow if we allow some weights to be nonpositive.
Show that T is still a minimum spanning tree for G.
More formally, let T be a minimum spanning tree for G with edge weights given by weight function w.
Show that T is a minimum spanning tree for G with edge weights given by w0
Give an algorithm for ﬁnding the minimum spanning tree in the modiﬁed graph.
They each use a speciﬁc rule to determine a safe edge in line 3 of GENERIC-MST.
In Kruskal’s algorithm, the set A is a forest whose vertices are all those of the given graph.
The safe edge added to A is always a least-weight edge in the graph that connects two distinct components.
In Prim’s algorithm, the set A forms a single tree.
The safe edge added to A is always a least-weight edge connecting the tree to a vertex not in the tree.
Lines 1–3 initialize the set A to the empty set and create jV j trees, one containing each vertex.
The for loop in lines 5–8 examines edges in order of weight, from lowest to highest.
The algorithm considers each edge in sorted order by weight.
An arrow points to the edge under consideration at each step of the algorithm.
If the edge joins two distinct trees in the forest, it is added to the forest, thereby merging the two trees.
Figure 23.4, continued Further steps in the execution of Kruskal’s algorithm.
Prim’s algorithm operates much like Dijkstra’s algorithm for ﬁnding shortest paths in a graph, which we shall see in Section 24.3
Prim’s algorithm has the property that the edges in the set A always form a single tree.
As Figure 23.5 shows, the tree starts from an arbitrary root vertex r and grows until the tree spans all the vertices in V.
Each step adds to the tree A a light edge that connects A to an isolated vertex—one on which no edge of A is incident.
By Corollary 23.2, this rule adds only edges that are safe for A; therefore, when the algorithm terminates, the edges in A form a minimum spanning tree.
This strategy qualiﬁes as greedy since at each step it adds to the tree an edge that contributes the minimum amount possible to the tree’s weight.
Shaded edges are in the tree being grown, and black vertices are in the tree.
At each step of the algorithm, the vertices in the tree determine a cut of the graph, and a light edge crossing the cut is added to the tree.
In the second step, for example, the algorithm has a choice of adding either edge .b; c/ or edge .a; h/ to the tree since both are light edges crossing the cut.
The running time of Prim’s algorithm depends on how we implement the minpriority queue Q.
The body of the while loop executes jV j times, and since each EXTRACT-MIN operation takes O.lgV / time, the total time for all calls to EXTRACT-MIN is O.V lgV /
Within the for loop, we can implement the test for membership in Q in line 9 in constant time by keeping a bit for each vertex that tells whether or not it is in Q, and updating the bit when the vertex is removed from Q.
The assignment in line 11 involves an implicit DECREASE-KEY operation on the min-heap, which a binary min-heap supports in O.lg V / time.
Thus, the total time for Prim’s algorithm is O.V lgV C E lgV / D O.E lgV /, which is asymptotically the same as for our implementation of Kruskal’s algorithm.
We can improve the asymptotic running time of Prim’s algorithm by using Fibonacci heaps.
Therefore, if we use a Fibonacci heap to implement the min-priority queue Q, the running time of Prim’s algorithm improves to O.E C V lgV /
Show that for each minimum spanning tree T of G, there is a way to sort the edges of G in Kruskal’s algorithm so that the algorithm returns T.
Give a simple implementation of Prim’s algorithm for this case that runs in O.V 2/ time.
How fast can you make Kruskal’s algorithm run? What if the edge weights are integers in the range from 1 to W for some constant W ?
How fast can you make Prim’s algorithm run? What if the edge weights are integers in the range from 1 to W for some constant W ?
How quickly can we update the minimum spanning tree if we add a new vertex and incident edges to G?
Either argue that the algorithm correctly computes a minimum spanning tree of G, or provide an example for which the algorithm fails.
Give an efﬁcient algorithm to compute the second-best minimum spanning tree of G.
Rather than contracting these edges one at a time, we ﬁrst identify sets of vertices that are united into the same new vertex.
Then we create the graph that would have resulted from contracting these edges one at a time, but we do so by “renaming” edges according to the sets into which their endpoints were placed.
Several edges from the original graph may be renamed the same as each other.
In such a case, only one edge results, and its weight is the minimum of the weights of the corresponding original edges.
Show how to implement MST-REDUCE so that it runs in O.E/ time.
Suppose that we run k phases of MST-REDUCE, using the output G0 produced by one phase as the input G to the next phase and accumulating edges in T.
Argue that the overall running time of the k phases is O.kE/
Show how to pick k so that the overall running time is O.E lg lgV /
Argue that your choice of k minimizes the overall asymptotic running time.
For what values of jEj (in terms of jV j) does Prim’s algorithm with preprocessing asymptotically beat Prim’s algorithm without preprocessing?
A bottleneck spanning tree T of an undirected graph G is a spanning tree of G whose largest edge weight is minimum over all spanning trees of G.
We say that the value of the bottleneck spanning tree is the weight of the maximum-weight edge in T.
Argue that a minimum spanning tree is a bottleneck spanning tree.
Part (a) shows that ﬁnding a bottleneck spanning tree is no harder than ﬁnding a minimum spanning tree.
In the remaining parts, we will show how to ﬁnd a bottleneck spanning tree in linear time.
Give a linear-time algorithm that given a graph G and an integer b, determines whether the value of the bottleneck spanning tree is at most b.
Hint: You may want to use a subroutine that contracts sets of edges, as in the MST-REDUCE procedure described in Problem 23-2
In this problem, we give pseudocode for three different algorithms.
Each one takes a connected graph and a weight function as input and returns a set of edges T.
For each algorithm, either prove that T is a minimum spanning tree or prove that T is not a minimum spanning tree.
Also describe the most efﬁcient implementation of each algorithm, whether or not it computes a minimum spanning tree.
The reason underlying why greedy algorithms are effective at ﬁnding minimum spanning trees is that the set of forests of a graph forms a graphic matroid.
Fredman and Willard [116] showed how to ﬁnd a minimum spanning tree in O.V CE/ time using a deterministic algorithm that is not comparison based.
Their algorithm assumes that the data are b-bit integers and that the computer memory consists of addressable b-bit words.
Professor Patrick wishes to ﬁnd the shortest possible route from Phoenix to Indianapolis.
Given a road map of the United States on which the distance between each pair of adjacent intersections is marked, how can she determine this shortest route?
One possible way would be to enumerate all the routes from Phoenix to Indianapolis, add up the distances on each route, and select the shortest.
It is easy to see, however, that even disallowing routes that contain cycles, Professor Patrick would have to examine an enormous number of possibilities, most of which are simply not worth considering.
For example, a route from Phoenix to Indianapolis that passes through Seattle is obviously a poor choice, because Seattle is several hundred miles out of the way.
Our goal is to ﬁnd a shortest path from a given intersection in Phoenix to a given intersection in Indianapolis.
Edge weights can represent metrics other than distances, such as time, cost, penalties, loss, or any other quantity that accumulates linearly along a path and that we would want to minimize.
Because many of the concepts from breadth-ﬁrst search arise in the study of shortest paths in weighted graphs, you might want to review Section 22.2 before proceeding.
Shortest-paths algorithms typically rely on the property that a shortest path between two vertices contains other shortest paths within it.
The Edmonds-Karp maximum-ﬂow algorithm in Chapter 26 also relies on this property.
Some shortest-paths algorithms, such as Dijkstra’s algorithm, assume that all edge weights in the input graph are nonnegative, as in the road-map example.
Others, such as the Bellman-Ford algorithm, allow negative-weight edges in the input graph and produce a correct answer as long as no negative-weight cycles are reachable from the source.
Typically, if there is such a negative-weight cycle, the algorithm can detect and report its existence.
Figure 24.2 (a) A weighted, directed graph with shortest-path weights from source s.
Shortest paths are not necessarily unique, and neither are shortest-paths trees.
For example, Figure 24.2 shows a weighted, directed graph and two shortest-paths trees with the same root.
It may seem strange that the term “relaxation” is used for an operation that tightens an upper bound.
To prove the algorithms in this chapter correct, we shall appeal to several properties of shortest paths and relaxation.
We state these properties here, and Section 24.5 proves them formally.
For your reference, each property stated here includes the appropriate lemma or corollary number from Section 24.5
Section 24.1 presents the Bellman-Ford algorithm, which solves the single-source shortest-paths problem in the general case in which edges can have negative weight.
The Bellman-Ford algorithm is remarkably simple, and it has the further beneﬁt of detecting whether a negative-weight cycle is reachable from the source.
Section 24.2 gives a linear-time algorithm for computing shortest paths from a single source in a directed acyclic graph.
Section 24.3 covers Dijkstra’s algorithm, which has a lower running time than the Bellman-Ford algorithm but requires the edge weights to be nonnegative.
Section 24.4 shows how we can use the Bellman-Ford algorithm to solve a special case of linear programming.
Finally, Section 24.5 proves the properties of shortest paths and relaxation stated above.
All algorithms in this chapter assume that the directed graph G is stored in the adjacency-list representation.
Additionally, stored with each edge is its weight, so that as we traverse each adjacency list, we can determine the edge weights in O.1/ time per edge.
The Bellman-Ford algorithm solves the single-source shortest-paths problem in the general case in which edge weights may be negative.
Given a weighted, directed graph G D .V;E/ with source s and weight function w W E ! R, the Bellman-Ford algorithm returns a boolean value indicating whether or not there is a negative-weight cycle that is reachable from the source.
If there is such a cycle, the algorithm indicates that no solution exists.
If there is no such cycle, the algorithm produces the shortest paths and their weights.
To prove the correctness of the Bellman-Ford algorithm, we start by showing that if there are no negative-weight cycles, the algorithm computes correct shortest-path weights for all vertices reachable from the source.
We conclude that the Bellman-Ford algorithm returns TRUE if graph G contains no negative-weight cycles reachable from the source, and FALSE otherwise.
By relaxing the edges of a weighted dag (directed acyclic graph) G D .V;E/ according to a topological sort of its vertices, we can compute shortest paths from a single source in ‚.V CE/ time.
Shortest paths are always well deﬁned in a dag, since even if there are negative-weight edges, no negative-weight cycles can exist.
The running time of this algorithm is easy to analyze.
The for loop of lines 3–5 makes one iteration per vertex.
Altogether, the for loop of lines 4–5 relaxes each edge exactly once.
The following theorem shows that the DAG-SHORTEST-PATHS procedure correctly computes the shortest paths.
The running time of Dijkstra’s algorithm depends on how we implement the min-priority queue.
Consider ﬁrst the case in which we maintain the min-priority.
If the graph is sufﬁciently sparse—in particular, E D o.V 2= lgV /—we can improve the algorithm by implementing the min-priority queue with a binary minheap.
As discussed in Section 6.5, the implementation should make sure that vertices and corresponding heap elements maintain handles to each other.
The time to build the binary min-heap is O.V /
Each DECREASE-KEY operation takes time O.lgV /, and there are still at most jEj such operations.
The total running time is therefore O..V CE/ lgV /, which is O.E lgV / if all vertices are reachable from the source.
We can in fact achieve a running time of O.V lgV C E/ by implementing the min-priority queue with a Fibonacci heap (see Chapter 19)
The amortized cost of each of the jV j EXTRACT-MIN operations is O.lgV /, and each DECREASEKEY call, of which there are at most jEj, takes only O.1/ amortized time.
Historically, the development of Fibonacci heaps was motivated by the observation that Dijkstra’s algorithm typically makes many more DECREASE-KEY calls than EXTRACT-MIN calls, so that any method of reducing the amortized time of each DECREASE-KEY operation to o.lgV / without increasing the amortized time of EXTRACT-MIN would yield an asymptotically faster implementation than with binary heaps.
It is like breadth-ﬁrst search in that set S corresponds to the set of black vertices in a breadth-ﬁrst search; just as vertices in S have their ﬁnal shortest-path weights, so do black vertices in a breadth-ﬁrst search have their correct breadth-ﬁrst distances.
Dijkstra’s algorithm is like Prim’s algorithm in that both algorithms use a minpriority queue to ﬁnd the “lightest” vertex outside a given set (the set S in Dijkstra’s algorithm and the tree being grown in Prim’s algorithm), add this vertex into the set, and adjust the weights of the remaining vertices outside the set accordingly.
Why doesn’t the proof of Theorem 24.6 go through when negative-weight edges are allowed?
Modify Dijkstra’s algorithm to compute the shortest paths from a given source vertex s in O.W V C E/ time.
Chapter 29 studies the general linear-programming problem, in which we wish to optimize a linear function subject to a set of linear inequalities.
In this section, we investigate a special case of linear programming that we reduce to ﬁnding shortest paths from a single source.
We can then solve the single-source shortest-paths problem that results by running the Bellman-Ford algorithm, thereby also solving the linear-programming problem.
Although the simplex algorithm, which is the focus of Chapter 29, does not always run in time polynomial in the size of its input, there are other linearprogramming algorithms that do run in polynomial time.
We offer here two reasons to understand the setup of linear-programming problems.
Second, faster algorithms exist for many special cases of linear programming.
The following theorem shows that we can ﬁnd a solution to a system of difference constraints by ﬁnding shortest-path weights in the corresponding constraint graph.
A system of difference constraints with m constraints on n unknowns produces a graph with n C 1 vertices and n C m edges.
Exercise 24.4-5 asks you to modify the algorithm to run in O.nm/ time, even if m is much less than n.
Show how to adapt the BellmanFord algorithm to solve this variety of constraint system.
We stated these properties without proof at the beginning of this chapter.
Thus, the sum of weights around the cycle c is negative, which provides the desired contradiction.
It remains, therefore, to prove the last property of shortest-paths trees: for each.
Does this scheme improve the asymptotic running time of the Bellman-Ford algorithm?
Describe an efﬁcient method to determine whether or not one d -dimensional box nests inside another.
Give an efﬁcient algorithm to print out such a sequence if one exists.
A scaling algorithm solves a problem by initially considering only the highestorder bit of each relevant input value (such as an edge weight)
It then reﬁnes the initial solution by looking at the two highest-order bits.
It progressively looks at more and more high-order bits, reﬁning the solution each time, until it has examined all bits and computed the correct solution.
Let G D .V;E/ be a directed graph with weight function w W E ! R, and let n D jV j.
Hint: Show how to extend a shortest path to any vertex on a minimum meanweight cycle along the cycle to make a shortest path to the next vertex on the cycle.
Give the most efﬁcient algorithm you can to solve this problem, and analyze its running time.
Bellman describes the relation of shortest paths to difference constraints.
Lawler [224] describes the linear-time algorithm for shortest paths in a dag, which he considers part of the folklore.
When edge weights are relatively small nonnegative integers, we have more efﬁcient algorithms to solve the single-source shortest-paths problem.
The sequence of values returned by the EXTRACT-MIN calls in Dijkstra’s algorithm monotonically increases over time.
As discussed in the chapter notes for Chapter 6, in this case several data structures can implement the various priority-queue operations more efﬁciently than a binary heap or a Fibonacci heap.
Ahuja, Mehlhorn, Orlin, and Tarjan [8] give an algorithm that runs in O.E C VplgW / time on graphs with nonnegative edge weights, where W is the largest weight of any edge in the graph.
Although the amount of space used can be unbounded in the size of the input, it can be reduced to be linear in the size of the input using randomized hashing.
For undirected graphs with integer weights, Thorup [336] gives an O.V C E/time algorithm for single-source shortest paths.
We can solve an all-pairs shortest-paths problem by running a single-source shortest-paths algorithm jV j times, once for each vertex as the source.
If all edge weights are nonnegative, we can use Dijkstra’s algorithm.
The binary min-heap implementation of the min-priority queue yields a running time of O.VE lgV /, which is an improvement if the graph is sparse.
Alternatively, we can implement the min-priority queue with a Fibonacci heap, yielding a running time of O.V 2 lgV C VE/
If the graph has negative-weight edges, we cannot use Dijkstra’s algorithm.
Instead, we must run the slower Bellman-Ford algorithm once from each vertex.
In this chapter we shall see how to do better.
We also investigate the relation of the all-pairs shortest-paths problem to matrix multiplication and study its algebraic structure.
We allow negative-weight edges, but we assume for the time being that the input graph contains no negative-weight cycles.
Section 25.2 also covers the problem of ﬁnding the transitive closure of a directed graph, which is related to the all-pairs shortest-paths problem.
Each major loop of the dynamic program will invoke an operation that is very similar to matrix multiplication, so that the algorithm will look like repeated matrix multiplication.
Compute the value of an optimal solution in a bottom-up fashion.
We reserve the fourth step—constructing an optimal solution from computed information—for the exercises.
We start by characterizing the structure of an optimal solution.
For the all-pairs shortest-paths problem on a graph G D .V;E/, we have proven (Lemma 24.1) that all subpaths of a shortest path are shortest paths.
Suppose that we represent the graph by an adjacency matrix W D .wij /
Consider a shortest path p from vertex i to vertex j , and suppose that p contains at most m edges.
Assuming that there are no negative-weight cycles, m is ﬁnite.
If i D j , then p has weight 0 and no edges.
If vertices i and j are distinct, then we decompose path p into i.
Now, let l .m/ij be the minimum weight of any path from vertex i to vertex j that contains at most m edges.
When m D 0, there is a shortest path from i to j with no edges if and only if i D j.
Describe how evaluating this product corresponds to a BellmanFord-like algorithm (see Section 24.1)
As before, negative-weight edges may be present, but we assume that there are no negative-weight cycles.
After studying the resulting algorithm, we present a similar method for ﬁnding the transitive closure of a directed graph.
Based on the above observations, we deﬁne a recursive formulation of shortestpath estimates that differs from the one in Section 25.1
Such a path has at most one edge, and hence d .0/ij D wij.
Following the above discussion, we deﬁne d .k/ij recursively by.
The running time of the Floyd-Warshall algorithm is determined by the triply nested for loops of lines 3–7
Thus, the Floyd-Warshall algorithm is quite practical for even moderate-sized input graphs.
There are a variety of different methods for constructing shortest paths in the FloydWarshall algorithm.
One way is to compute the matrix D of shortest-path weights and then construct the predecessor matrix … from the D matrix.
If there is a path from vertex i to vertex j , we get dij < n.
Figure 25.5 A directed graph and the matrices T .k/ computed by the transitive-closure algorithm.
Figure 25.5 shows the matrices T .k/ computed by the TRANSITIVE-CLOSURE procedure on a sample graph.
The TRANSITIVE-CLOSURE procedure, like the Floyd-Warshall algorithm, runs in ‚.n3/ time.
On some computers, though, logical operations on single-bit values execute faster than arithmetic operations on integer words of data.
Moreover, because the direct transitive-closure algorithm uses only boolean values rather than integer values, its space requirement is less.
Show the matrix D.k/ that results for each iteration of the outer loop.
Johnson’s algorithm ﬁnds shortest paths between all pairs in O.V 2 lgV C VE/ time.
For sparse graphs, it is asymptotically faster than either repeated squaring of matrices or the Floyd-Warshall algorithm.
The algorithm either returns a matrix of shortest-path weights for all pairs of vertices or reports that the input graph contains a negative-weight cycle.
Johnson’s algorithm uses as subroutines both Dijkstra’s algorithm and the Bellman-Ford algorithm, which Chapter 24 describes.
Johnson’s algorithm uses the technique of reweighting, which works as follows.
If all edge weights w in a graph G D .V;E/ are nonnegative, we can ﬁnd shortest paths between all pairs of vertices by running Dijkstra’s algorithm once from each vertex; with the Fibonacci-heap min-priority queue, the running time of this all-pairs algorithm is O.V 2 lgV C VE/
If G has negative-weight edges but no negative-weight cycles, we simply compute a new set of nonnegative edge weights.
The new set of edge weights yw must satisfy two important properties:
Dijkstra’s algorithm on each vertex of G using weight function wy.
If we implement the min-priority queue in Dijkstra’s algorithm by a Fibonacci heap, Johnson’s algorithm runs in O.V 2 lgV CVE/ time.
The simpler binary minheap implementation yields a running time of O.VE lgV /, which is still asymptotically faster than the Floyd-Warshall algorithm if the graph is sparse.
Show the values of h and yw computed by the algorithm.
He claims that instead we can just use G0 D G and let s be any vertex.
Give an example of a weighted, directed graph G for which incorporating the professor’s idea into JOHNSON causes incorrect answers.
Then show that if G is strongly connected (every vertex is reachable from every other vertex), the results returned by JOHNSON with the professor’s modiﬁcation are correct.
Describe an efﬁcient algorithm for updating the transitive closure as edges are inserted into the graph.
For any sequence of n insertions, your algorithm should run in total time.
Lawler [224] has a good discussion of the all-pairs shortest-paths problem, although he does not analyze solutions for sparse graphs.
Several researchers have given improved algorithms for computing shortest paths via matrix multiplication.
Baswana, Hariharan, and Sen [33] examined decremental algorithms for maintaining all-pairs shortest paths and transitive-closure information.
Decremental algorithms allow a sequence of intermixed edge deletions and queries; by comparison, Problem 25-1, in which edges are inserted, asks for an incremental algorithm.
For all-pairs shortest paths, the update times depend on the queries.
To report the actual shortest path, the amortized update time is min.O.V 3=2
Aho, Hopcroft, and Ullman [5] deﬁned an algebraic structure known as a “closed semiring,” which serves as a general framework for solving path problems in directed graphs.
Both the Floyd-Warshall algorithm and the transitive-closure algorithm from Section 25.2 are instantiations of an all-pairs algorithm based on closed semirings.
Maggs and Plotkin [240] showed how to ﬁnd minimum spanning trees using a closed semiring.
Just as we can model a road map as a directed graph in order to ﬁnd the shortest path from one point to another, we can also interpret a directed graph as a “ﬂow network” and use it to answer questions about material ﬂows.
Imagine a material coursing through a system from a source, where the material is produced, to a sink, where it is consumed.
The source produces the material at some steady rate, and the sink consumes the material at the same rate.
The “ﬂow” of the material at any point in the system is intuitively the rate at which the material moves.
Flow networks can model many problems, including liquids ﬂowing through pipes, parts through assembly lines, current through electrical networks, and information through communication networks.
We can think of each directed edge in a ﬂow network as a conduit for the material.
Vertices are conduit junctions, and other than the source and sink, material ﬂows through the vertices without collecting in them.
In other words, the rate at which material enters a vertex must equal the rate at which it leaves the vertex.
We call this property “ﬂow conservation,” and it is equivalent to Kirchhoff’s current law when the material is electrical current.
In the maximum-ﬂow problem, we wish to compute the greatest rate at which we can ship material from the source to the sink without violating any capacity constraints.
It is one of the simplest problems concerning ﬂow networks and, as we shall see in this chapter, this problem can be solved by efﬁcient algorithms.
Moreover, we can adapt the basic techniques used in maximum-ﬂow algorithms to solve other network-ﬂow problems.
This chapter presents two general methods for solving the maximum-ﬂow problem.
Section 26.1 formalizes the notions of ﬂow networks and ﬂows, formally deﬁning the maximum-ﬂow problem.
Section 26.2 describes the classical method of Ford and Fulkerson for ﬁnding maximum ﬂows.
Section 26.4 presents the push-relabel method, which underlies many of the fastest algorithms for network-ﬂow problems.
Although this algorithm is not the fastest algorithm known, it illustrates some of the techniques used in the asymptotically fastest algorithms, and it is reasonably efﬁcient in practice.
In this section, we give a graph-theoretic deﬁnition of ﬂow networks, discuss their properties, and deﬁne the maximum-ﬂow problem precisely.
In themaximum-ﬂow problem, we are given a ﬂow network G with source s and sink t , and we wish to ﬁnd a ﬂow of maximum value.
Before seeing an example of a network-ﬂow problem, let us brieﬂy explore the deﬁnition of ﬂow and the two ﬂow properties.
The capacity constraint simply says that the ﬂow from one vertex to another must be nonnegative and must not exceed the given capacity.
The ﬂow-conservation property says that the total ﬂow into a vertex other than the source or sink must equal the total ﬂow out of that vertex—informally, “ﬂow in equals ﬂow out.”
A ﬂow network can model the trucking problem shown in Figure 26.1(a)
The Lucky Puck Company has a factory (source s) in Vancouver that manufactures hockey pucks, and it has a warehouse (sink t) in Winnipeg that stocks them.
We can model the “ﬂow” of shipments with a ﬂow in this network because the number of crates shipped per day from one city to another is subject to a capacity constraint.
Additionally, the model must obey ﬂow conservation, for in a steady state, the rate at which pucks enter an intermediate city must equal the rate at which they leave.
Thus, we see that a real-world ﬂow problem might be most naturally modeled by a network with antiparallel edges.
It will be convenient to disallow antiparallel edges, however, and so we have a straightforward way to convert a network containing antiparallel edges into an equivalent one with no antiparallel edges.
A maximum-ﬂow problem may have several sources and sinks, rather than just one of each.
Fortunately, this problem is no harder than ordinary maximum ﬂow.
We can reduce the problem of determining a maximum ﬂow in a network with multiple sources and multiple sinks to an ordinary maximum-ﬂow problem.
Figure 26.3(b) shows how to convert the network from (a) to an ordinary ﬂow network with only a single source and a single sink.
Intuitively, any ﬂow in the network in (a) corresponds to a ﬂow in the network in (b), and vice versa.
The single source s simply provides as much ﬂow as desired for the multiple sources si , and the single sink t likewise consumes as much ﬂow as desired for the multiple sinks ti.
Exercise 26.1-2 asks you to prove formally that the two problems are equivalent.
Figure 26.3 Converting a multiple-source, multiple-sink maximum-ﬂow problem into a problem with a single source and a single sink.
We add a supersource s and an edge with inﬁnite capacity from s to each of the multiple sources.
We also add a supersink t and an edge with inﬁnite capacity from each of the multiple sinks to t.
Show that any ﬂow in a multiple-source, multiple-sink ﬂow network corresponds to a ﬂow of identical value in the single-source, single-sink network obtained by adding a supersource and a supersink, and vice versa.
The problem is so severe that not only do they refuse to walk to school together, but in fact each one refuses to walk on any block that the other child has stepped on that day.
The children have no problem with their paths crossing at a corner.
Fortunately both the professor’s house and the school are on corners, but beyond that he is not sure if it is going to be possible to send both of his children to the same school.
Show how to formulate the problem of determining whether both his children can go to the same school as a maximum-ﬂow problem.
This section presents the Ford-Fulkerson method for solving the maximum-ﬂow problem.
We call it a “method” rather than an “algorithm” because it encompasses several implementations with differing running times.
The Ford-Fulkerson method depends on three important ideas that transcend the method and are relevant to many ﬂow algorithms and problems: residual networks, augmenting paths, and cuts.
These ideas are essential to the important max-ﬂow min-cut theorem (Theorem 26.6), which characterizes the value of a maximum ﬂow in terms of cuts of.
We end this section by presenting one speciﬁc implementation of the Ford-Fulkerson method and analyzing its running time.
In order to implement and analyze the Ford-Fulkerson method, we need to introduce several additional concepts.
Sending ﬂow back along an edge is equivalent to decreasing the ﬂow on the edge, which is a necessary operation in many algorithms.
Lemma 26.1 Let G D .V;E/ be a ﬂow network with source s and sink t , and let f be a ﬂow in G.
Let Gf be the residual network of G induced by f , and let f 0 be a ﬂow in Gf.
The following lemma, whose proof we leave as Exercise 26.2-7, makes the above argument more precise.
The following corollary shows that if we augment f by fp, we get another ﬂow in G whose value is closer to the maximum.
Corollary 26.3 Let G D .V;E/ be a ﬂow network, let f be a ﬂow in G, and let p be an augmenting path in Gf.
Let fp be deﬁned as in equation (26.8), and suppose that we augment f by fp.
The Ford-Fulkerson method repeatedly augments the ﬂow along augmenting paths until it has found a maximum ﬂow.
How do we know that when the algorithm terminates, we have actually found a maximum ﬂow? The max-ﬂow min-cut theorem, which we shall prove shortly, tells us that a ﬂow is maximum if and only if its residual network contains no augmenting path.
To prove this theorem, though, we must ﬁrst explore the notion of a cut of a ﬂow network.
A minimum cut of a network is a cut whose capacity is minimum over all cuts of the network.
The asymmetry between the deﬁnitions of ﬂow and capacity of a cut is intentional and important.
For capacity, we count only the capacities of edges going from S to T , ignoring edges in the reverse direction.
For ﬂow, we consider the ﬂow going from S to T minus the ﬂow going in the reverse direction from T to S.
The reason for this difference will become clear later in this section.
The following lemma shows that, for a given ﬂow f , the net ﬂow across any cut is the same, and it equals jf j, the value of the ﬂow.
Lemma 26.4 Let f be a ﬂow in a ﬂow network G with source s and sink t , and let .S; T / be any cut of G.
Then the net ﬂow across .S; T / is f .S; T / D jf j.
The two summations within the parentheses are actually the same, since for all vertices x; y 2 V , the term f .x; y/ appears once in each summation.
A corollary to Lemma 26.4 shows how we can use cut capacities to bound the value of a ﬂow.
Corollary 26.5 The value of any ﬂow f in a ﬂow network G is bounded from above by the capacity of any cut of G.
Proof Let .S; T / be any cut of G and let f be any ﬂow.
By Lemma 26.4 and the capacity constraint, jf j D f .S; T /
Corollary 26.5 yields the immediate consequence that the value of a maximum ﬂow in a network is bounded from above by the capacity of a minimum cut of the network.
The important max-ﬂow min-cut theorem, which we now state and prove, says that the value of a maximum ﬂow is in fact equal to the capacity of a minimum cut.
Figure 26.6 shows the result of each iteration in a sample run.
The while loop of lines 3–8 repeatedly ﬁnds an augmenting path p in Gf and augments ﬂow f along p by the residual capacity cf .p/
Each residual edge in path p is either an edge in the original network or the reversal of an edge in the original network.
Lines 6–8 update the ﬂow in each case appropriately, adding ﬂow when the residual edge is an original edge and subtracting it otherwise.
When no augmenting paths exist, the ﬂow f is a maximum ﬂow.
If we choose it poorly, the algorithm might not even terminate: the value of the ﬂow will increase with successive augmentations, but it need not even converge to the maximum ﬂow value.2 If we ﬁnd the augmenting path by using a breadth-ﬁrst search (which we saw in Section 22.2), however, the algorithm runs in polynomial time.
Before proving this result, we obtain a simple bound for the case in which we choose the augmenting path arbitrarily and all capacities are integers.
The Ford-Fulkerson method might fail to terminate only if edge capacities are irrational numbers.
The left side of each part shows the residual network Gf from line 3 with a shaded augmenting path p.
The right side of each part shows the new ﬂow f that results from augmenting f by fp.
The residual network in (a) is the input network G.
Figure 26.6, continued (f) The residual network at the last while loop test.
It has no augmenting paths, and the ﬂow f shown in (e) is therefore a maximum ﬂow.
We can improve the bound on FORD-FULKERSON by ﬁnding the augmenting path p in line 3 with a breadth-ﬁrst search.
That is, we choose the augmenting path as a shortest path from s to t in the residual network, where each edge has unit distance (weight)
We call the Ford-Fulkerson method so implemented the Edmonds-Karp algorithm.
We now prove that the Edmonds-Karp algorithm runs in O.VE2/ time.
The next theorem bounds the number of iterations of the Edmonds-Karp algorithm.
Theorem 26.8 If the Edmonds-Karp algorithm is run on a ﬂow network G D .V;E/ with source s and sink t , then the total number of ﬂow augmentations performed by the algorithm is O.VE/
Each augmenting path has at least one critical edge, and hence the theorem follows.
Because we can implement each iteration of FORD-FULKERSON in O.E/ time when we ﬁnd the augmenting path by breadth-ﬁrst search, the total running time of the Edmonds-Karp algorithm is O.VE2/
We shall see that push-relabel algorithms can yield even better bounds.
Prove that any ﬂow in the resulting network has a ﬁnite value if the edges of the original network with multiple sources and sinks have ﬁnite capacity.
Show how to convert the problem of ﬁnding a ﬂow f that obeys.
Argue that the procedure FORD-FULKERSON still correctly computes a maximum ﬂow.
Does the augmented ﬂow satisfy the ﬂow conservation property? Does it satisfy the capacity constraint?
Show how to determine the edge connectivity of an undirected graph G D .V;E/ by running a maximum-ﬂow algorithm on at most jV j ﬂow networks, each having O.V / vertices and O.E/ edges.
Some combinatorial problems can easily be cast as maximum-ﬂow problems.
The multiple-source, multiple-sink maximum-ﬂow problem from Section 26.1 gave us one example.
Some other combinatorial problems seem on the surface to have little to do with ﬂow networks, but can in fact be reduced to maximum-ﬂow problems.
This section presents one such problem: ﬁnding a maximum matching in a bipartite graph.
In order to solve this problem, we shall take advantage of an integrality property provided by the Ford-Fulkerson method.
We can use the Ford-Fulkerson method to ﬁnd a maximum matching in an undirected bipartite graph G D .V;E/ in time polynomial in jV j and jEj.
The trick is to construct a ﬂow network in which ﬂows correspond to matchings, as shown in Figure 26.8(c)
Shaded edges have a ﬂow of 1, and all other edges carry no ﬂow.
The shaded edges from L to R correspond to those in the maximum matching from (b)
If M is a matching in G, then there is an integer-valued ﬂow f in G0 with value jf j D jM j.
Conversely, if f is an integer-valued ﬂow in G0, then there is a matching M in G with cardinality jM j D jf j.
To prove the converse, let f be an integer-valued ﬂow in G0, and let.
Proof The proof is by induction on the number of iterations.
We can now prove the following corollary to Lemma 26.9
Suppose that M is a maximum matching in G and that the corresponding ﬂow f in G0 is not maximum.
In a similar manner, we can show that if f is a maximum ﬂow in G0, its corresponding matching is a maximum matching on G.
Thus, given a bipartite undirected graph G, we can ﬁnd a maximum matching by creating the ﬂow network G0, running the Ford-Fulkerson method, and directly obtaining a maximum matching M from the integer-valued maximum ﬂow f found.
Since any matching in a bipartite graph has cardinality at most min.L;R/ D O.V /, the value of the maximum ﬂow in G0 is O.V /
For each iteration, pick the augmenting path that is lexicographically smallest.
Give a good upper bound on the length of any augmenting path found in G0 during the execution of FORD-FULKERSON.
In this section, we present the “push-relabel” approach to computing maximum ﬂows.
To date, many of the asymptotically fastest maximum-ﬂow algorithms are push-relabel algorithms, and the fastest actual implementations of maximum-ﬂow algorithms are based on the push-relabel method.
Push-relabel methods also efﬁciently solve other ﬂow problems, such as the minimum-cost ﬂow problem.
We shall begin this section by describing the intuition behind the push-relabel method.
We shall then investigate the two operations employed by the method: “pushing” preﬂow and “relabeling” a vertex.
Finally, we shall present a generic push-relabel algorithm and analyze its correctness and running time.
You can understand the intuition behind the push-relabel method in terms of ﬂuid ﬂows: we consider a ﬂow network G D .V;E/ to be a system of interconnected pipes of given capacities.
Applying this analogy to the Ford-Fulkerson method, we might say that each augmenting path in the network gives rise to an additional stream of ﬂuid, with no branch points, ﬂowing from the source to the sink.
The Ford-Fulkerson method iteratively adds more streams of ﬂow until no more can be added.
First, to accommodate excess ﬂow, each vertex has an outﬂow pipe leading to an arbitrarily large reservoir that can accumulate ﬂuid.
Second, each vertex, its reservoir, and all its pipe connections sit on a platform whose height increases as the algorithm progresses.
We may eventually ﬁnd that the only pipes that leave a vertex u and are not already saturated with ﬂow connect to vertices that are on the same level as u or are uphill from u.
In this case, to rid an overﬂowing vertex u of its excess ﬂow, we must increase its height—an operation called “relabeling” vertex u.
We increase its height to one unit more than the height of the lowest of its neighbors to which it has an unsaturated pipe.
After a vertex is relabeled, therefore, it has at least one outgoing pipe through which we can push more ﬂow.
Eventually, all the ﬂow that can possibly get through to the sink has arrived there.
No more can arrive, because the pipes obey the capacity constraints; the amount of ﬂow across any cut is still limited by the capacity of the cut.
To make the preﬂow a “legal” ﬂow, the algorithm then sends the excess collected in the reservoirs of overﬂowing vertices back to the source by continuing to relabel vertices to above.
As we shall see, once we have emptied all the reservoirs, the preﬂow is not only a “legal” ﬂow, it is also a maximum ﬂow.
From the preceding discussion, we see that a push-relabel algorithm performs two basic operations: pushing ﬂow excess from a vertex to one of its neighbors and relabeling a vertex.
The situations in which these operations apply depend on the heights of vertices, which we now deﬁne precisely.
In the literature, a height function is typically called a “distance function,” and the height of a vertex is called a “distance label.” We use the term “height” because it is more suggestive of the intuition behind the algorithm.
We retain the use of the term “relabel” to refer to the operation that increases the height of a vertex.
The height of a vertex is related to its distance from the sink t , as would be found in a breadth-ﬁrst search of the transpose GT.
The generic push-relabel algorithm uses the following subroutine to create an initial preﬂow in the ﬂow network.
The following lemma tells us that as long as an overﬂowing vertex exists, at least one of the two basic operations applies.
Lemma 26.14 (An overﬂowing vertex can be either pushed or relabeled) Let G D .V;E/ be a ﬂow network with source s and sink t , let f be a preﬂow, and let h be any height function for f.
If u is any overﬂowing vertex, then either a push or relabel operation applies to it.
To show that the generic push-relabel algorithm solves the maximum-ﬂow problem, we shall ﬁrst prove that if it terminates, the preﬂow f is a maximum ﬂow.
We start with some observations about the height function h.
Lemma 26.16 Let G D .V;E/ be a ﬂow network with source s and sink t.
Proof The proof is by induction on the number of basic operations performed.
Initially, h is a height function, as we have already observed.
The following lemma gives an important property of height functions.
Lemma 26.17 Let G D .V;E/ be a ﬂow network with source s and sink t , let f be a preﬂow in G, and let h be a height function on V.
Then there is no path from the source s to the sink t in the residual network Gf.
We are now ready to show that if the generic push-relabel algorithm terminates, the preﬂow it computes is a maximum ﬂow.
Maintenance: The only operations within thewhile loop of lines 2–3 are push and.
Relabel operations affect only height attributes and not the ﬂow values; hence they do not affect whether f is a preﬂow.
As argued on page 739, if f is a preﬂow prior to a push operation, it remains a preﬂow afterward.
To show that the generic push-relabel algorithm indeed terminates, we shall bound the number of operations it performs.
We bound separately each of the three types of operations: relabels, saturating pushes, and nonsaturating pushes.
With knowledge of these bounds, it is a straightforward problem to construct an algorithm that runs in O.V 2E/ time.
Before beginning the analysis, however, we prove an important lemma.
Recall that we allow edges into the source in the residual network.
Lemma 26.19 Let G D .V;E/ be a ﬂow network with source s and sink t , and let f be a preﬂow in G.
Then, for any overﬂowing vertex x, there is a simple path from x to s in the residual network Gf.
The next lemma bounds the heights of vertices, and its corollary bounds the number of relabel operations that are performed in total.
Lemma 26.20 also helps us to bound the number of saturating pushes.
The following lemma bounds the number of nonsaturating pushes in the generic push-relabel algorithm.
All that remains is to give an efﬁcient method for implementing each operation and for choosing an appropriate operation to execute.
It also asks you to design a data structure that allows you to pick an applicable operation in O.1/ time.
Give a fast algorithm to ﬁnd a minimum cut in G.
Analyze the running time of the generic push-relabel algorithm in terms of jV j, jEj, and k.
The push-relabel method allows us to apply the basic operations in any order at all.
The relabel-to-front algorithm maintains a list of the vertices in the network.
Beginning at the front, the algorithm scans the list, repeatedly selecting an overﬂowing vertex u and then “discharging” it, that is, performing push and relabel operations until u no longer has a positive excess.
The correctness and analysis of the relabel-to-front algorithm depend on the notion of “admissible” edges: those edges in the residual network through which ﬂow can be pushed.
After proving some properties about the network of admissible edges, we shall investigate the discharge operation and then present and analyze the relabel-to-front algorithm itself.
The admissible network consists of those edges through which we can push ﬂow.
The following lemma shows that this network is a directed acyclic graph (dag)
Lemma 26.26 (The admissible network is acyclic) If G D .V;E/ is a ﬂow network, f is a preﬂow in G, and h is a height function on G, then the admissible network Gf;h D .V;Ef;h/ is acyclic.
Because each vertex in cycle p appears once in each of the summations, we derive the contradiction that 0 D k.
The next two lemmas show how push and relabel operations change the admissible network.
Lemma 26.28 Let G D .V;E/ be a ﬂow network, let f be a preﬂow in G, and suppose that the attribute h is a height function.
If a vertex u is overﬂowing and there are no admissible edges leaving u, then RELABEL.u/ applies.
After the relabel operation, there is at least one admissible edge leaving u, but there are no admissible edges entering u.
The relabel-to-front algorithm cycles through each neighbor list in an arbitrary order that is ﬁxed throughout the execution of the algorithm.
For each vertex u, the attribute u:current points to the vertex currently under consideration in u:N.
An overﬂowing vertex u is discharged by pushing all of its excess ﬂow through admissible edges to neighboring vertices, relabeling u as necessary to cause edges leaving u to become admissible.
Observe that if DISCHARGE is called on an overﬂowing vertex u, then the last action performed by DISCHARGE must be a push from u.
Why? The procedure terminates only when u:e becomes zero, and neither the relabel operation nor advancing the pointer u:current affects the value of u:e.
We must be sure that when PUSH or RELABEL is called by DISCHARGE, the operation applies.
The pseudocode for the relabel-to-front algorithm assumes that the neighbor lists u:N have already been created for each vertex u.
It also assumes that u:next points to the vertex that follows u in list L and that, as usual, u:next D NIL if u is the last vertex in the list.
Line 1 initializes the preﬂow and heights to the same values as in the generic push-relabel algorithm.
Line 2 initializes the list L to contain all potentially overﬂowing vertices, in any order.
Lines 3–4 initialize the current pointer of each vertex u to the ﬁrst vertex in u’s neighbor list.
Line 5 makes it start with the ﬁrst vertex in the list.
Each time through the loop, line 8 discharges a vertex u.
If u was relabeled by the DISCHARGE procedure, line 10 moves it to the front of list L.
Line 11 makes the next iteration of the while loop use the vertex following u in list L.
If line 10 moved u to the front of the list, the vertex used in the next iteration is the one following u in its new position in the list.
To show that RELABEL-TO-FRONT computes a maximum ﬂow, we shall show that it is an implementation of the generic push-relabel algorithm.
First, observe that it performs push and relabel operations only when they apply, since Lemma 26.29 guarantees that DISCHARGE performs them only when they apply.
It remains to show that when RELABEL-TO-FRONT terminates, no basic operations apply.
The remainder of the correctness argument relies on the following loop invariant:
At each test in line 6 of RELABEL-TO-FRONT, list L is a topological sort of the vertices in the admissible network Gf;h D .V;Ef;h/, and no vertex before u in the list has excess ﬂow.
Maintenance: To see that each iteration of the while loop maintains the topological sort, we start by observing that the admissible network is changed only by push and relabel operations.
By Lemma 26.27, push operations do not cause edges to become admissible.
After a vertex u is relabeled, however, Lemma 26.28 states that there are no admissible edges entering u but there may be admissible edges leaving u.
Thus, by moving u to the front of L, the algorithm ensures that any admissible edges leaving u satisfy the topological sort ordering.
To see that no vertex preceding u in L has excess ﬂow, we denote the vertex that will be u in the next iteration by u0
When u is discharged, it has no excess ﬂow afterward.
Thus, if u is relabeled during the discharge, no vertices preceding u0 have excess ﬂow.
If u is not relabeled during the discharge, no vertices before it on the list acquired excess ﬂow during this discharge, because L remained topologically sorted at all times during the discharge (as just pointed out, admissible edges are created only by relabeling, not pushing), and so each push operation causes excess ﬂow to move only to vertices further down the list (or to s or t)
We shall now show that RELABEL-TO-FRONT runs in O.V 3/ time on any ﬂow network G D .V;E/
Proof Let us consider a “phase” of the relabel-to-front algorithm to be the time between two consecutive relabel operations.
Each phase consists of at most jV j calls to DISCHARGE, which we can see as follows.
If DISCHARGE does not perform a relabel operation, then the next call to DISCHARGE is further down the list L, and the length of L is less than jV j.
If DISCHARGE does perform a relabel, the next call to DISCHARGE belongs to a different phase.
We must now bound the work performed within DISCHARGE during the execution of the algorithm.
Each iteration of the while loop within DISCHARGE performs one of three actions.
We shall analyze the total amount of work involved in performing each of these actions.
The third type of action performed by DISCHARGE is a push operation (line 7)
We already know that the total number of saturating push operations is O.VE/
Thus, there can be at most one nonsaturating push per call to DISCHARGE.
The algorithm repeatedly discharges the vertex at the head of the queue, and any vertices that were not overﬂowing before the discharge but are overﬂowing afterward are placed at the end of the queue.
After the vertex at the head of the queue is discharged, it is removed.
Show how to implement this algorithm to compute a maximum ﬂow in O.V 3/ time.
That is, the total positive ﬂow entering any given vertex is subject to a capacity constraint.
Show that determining the maximum ﬂow in a network with edge and vertex capacities can be reduced to an ordinary maximum-ﬂow problem on a ﬂow network of comparable size.
Starting points are black, and other grid vertices are white.
Describe an efﬁcient algorithm to solve the escape problem, and analyze its running time.
A path cover of a directed graph G D .V;E/ is a set P of vertex-disjoint paths such that every vertex in V is included in exactly one path in P.
A minimum path cover of G is a path cover containing the fewest possible paths.
Give an efﬁcient algorithm to ﬁnd a minimum path cover of a directed acyclic graph G D .V;E/
Does your algorithm work for directed graphs that contain cycles? Explain.
If the company chooses to accept job Ji , it must have hired experts in all subareas in Ri , and it will take in revenue of pi dollars.
Professor Gore’s job is to determine which subareas to hire experts in and which jobs to accept in order to maximize the net revenue, which is the total income from jobs accepted minus the total cost of employing the experts.
Show how to determine the maximum net revenue from the capacity of a minimum cut of G and the given pi values.
Give an efﬁcient algorithm to determine which jobs to accept and which experts to hire.
Analyze the running time of your algorithm in terms of m, n, and r DPmiD1 jRi j.
Let G D .V;E/ be a ﬂow network with source s, sink t , and integer capacities.
Suppose that we are given a maximum ﬂow in G.
For a given number K, show how to ﬁnd an augmenting path of capacity at least K in O.E/ time, if such a path exists.
Argue that the inner while loop of lines 5–6 executes O.E/ times for each value of K.
In this problem, we describe a faster algorithm, due to Hopcroft and Karp, for ﬁnding a maximum matching in a bipartite graph.
Prove that if a shortest augmenting path with respect to M has l edges, the size of the maximum matching is at most jM j C jV j =.l C 1/
Hint: By how much can M grow after iteration number.
Conclude that the total running time of HOPCROFT-KARP is O.
The Ford-Fulkerson method is due to Ford and Fulkerson [109], who originated the formal study of many of the problems in the area of network ﬂow, including the maximum-ﬂow and bipartite-matching problems.
A related idea, that of using “blocking ﬂows,” was also ﬁrst developed by Dinic [89]
Cheriyan and Maheshwari [62] proposed pushing ﬂow from the overﬂowing vertex of maximum height.
The algorithm of King, Rao, and Tarjan [204] is the fastest such algorithm and runs in O.VE logE=.V lg V / V / time.
Informally, with respect to these lengths, shortest paths from the source to the sink tend have high capacity, which means that fewer iterations need be performed.
In practice, push-relabel algorithms currently dominate augmenting-path or linear-programming based algorithms for the maximum-ﬂow problem.
A study by Cherkassky and Goldberg [63] underscores the importance of using two heuristics when implementing a push-relabel algorithm.
The ﬁrst heuristic is to periodically perform a breadth-ﬁrst search of the residual network in order to obtain more accurate height values.
The second heuristic is the gap heuristic, described in Exercise 26.5-5
Cherkassky and Goldberg conclude that the best choice of pushrelabel variants is the one that chooses to discharge the overﬂowing vertex with the maximum height.
The best algorithm to date for maximum bipartite matching, discovered by Hopcroft and Karp [176], runs in O.
This part contains a selection of algorithmic topics that extend and complement earlier material in this book.
Some chapters introduce new models of computation such as circuits or parallel computers.
Others cover specialized domains such as computational geometry or number theory.
The last two chapters discuss some of the known limitations to the design of efﬁcient algorithms and introduce techniques for coping with those limitations.
Chapter 27 presents an algorithmic model for parallel computing based on dynamic multithreading.
The chapter introduces the basics of the model, showing how to quantify parallelism in terms of the measures of work and span.
It then investigates several interesting multithreaded algorithms, including algorithms for matrix multiplication and merge sorting.
It presents two general methods—LU decomposition and LUP decomposition—for solving linear equations by Gaussian elimination in O.n3/ time.
It also shows that matrix inversion and matrix multiplication can be performed equally fast.
The chapter concludes by showing how to compute a least-squares approximate solution when a set of linear equations has no exact solution.
Chapter 29 studies linear programming, in which we wish to maximize or minimize an objective, given limited resources and competing constraints.
Linear programming arises in a variety of practical application areas.
This chapter covers how to formulate and solve linear programs.
The solution method covered is the simplex algorithm, which is the oldest algorithm for linear programming.
In contrast to many algorithms in this book, the simplex algorithm does not run in polynomial time in the worst case, but it is fairly efﬁcient and widely used in practice.
Chapter 30 studies operations on polynomials and shows how to use a wellknown signal-processing technique—the fast Fourier transform (FFT)—to multiply two degree-n polynomials in O.n lg n/ time.
It also investigates efﬁcient implementations of the FFT, including a parallel circuit.
After reviewing elementary number theory, it presents Euclid’s algorithm for computing greatest common divisors.
Next, it studies algorithms for solving modular linear equations and for raising one number to a power modulo another number.
Then, it explores an important application of number-theoretic algorithms: the RSA public-key cryptosystem.
This cryptosystem can be used not only to encrypt messages so that an adversary cannot read them, but also to provide digital signatures.
The chapter then presents the Miller-Rabin randomized primality test, with which we can ﬁnd large primes efﬁciently—an essential requirement for the RSA system.
Finally, the chapter covers Pollard’s “rho” heuristic for factoring integers and discusses the state of the art of integer factorization.
Chapter 32 studies the problem of ﬁnding all occurrences of a given pattern string in a given text string, a problem that arises frequently in text-editing programs.
After examining the naive approach, the chapter presents an elegant approach due to Rabin and Karp.
Then, after showing an efﬁcient solution based on ﬁnite automata, the chapter presents the Knuth-Morris-Pratt algorithm, which modiﬁes the automaton-based algorithm to save space by cleverly preprocessing the pattern.
After discussing basic primitives of computational geometry, the chapter shows how to use a “sweeping” method to efﬁciently determine whether a set of line segments contains any intersections.
Two clever algorithms for ﬁnding the convex hull of a set of points—Graham’s scan and Jarvis’s march—also illustrate the power of sweeping methods.
The chapter closes with an efﬁcient algorithm for ﬁnding the closest pair from among a given set of points in the plane.
Many interesting computational problems are NP-complete, but no polynomial-time algorithm is known for solving any of them.
This chapter presents techniques for determining when a problem is NP-complete.
Several classic problems are proved to be NP-complete: determining whether a graph has a hamiltonian cycle, determining whether a boolean formula is satisﬁable, and determining whether a given set of numbers has a subset that adds up to a given target value.
The chapter also proves that the famous travelingsalesman problem is NP-complete.
Chapter 35 shows how to ﬁnd approximate solutions to NP-complete problems efﬁciently by using approximation algorithms.
For some NP-complete problems, approximate solutions that are near optimal are quite easy to produce, but for others even the best approximation algorithms known work progressively more poorly as.
Then, there are some problems for which we can invest increasing amounts of computation time in return for increasingly better approximate solutions.
This chapter illustrates these possibilities with the vertex-cover problem (unweighted and weighted versions), an optimization version of 3-CNF satisﬁability, the traveling-salesman problem, the set-covering problem, and the subset-sum problem.
The vast majority of algorithms in this book are serial algorithms suitable for running on a uniprocessor computer in which only one instruction executes at a time.
In this chapter, we shall extend our algorithmic model to encompass parallel algorithms, which can run on a multiprocessor computer that permits multiple instructions to execute concurrently.
In particular, we shall explore the elegant model of dynamic multithreaded algorithms, which are amenable to algorithmic design and analysis, as well as to efﬁcient implementation in practice.
Relatively inexpensive desktop and laptop chip multiprocessors contain a single multicore integrated-circuit chip that houses multiple processing “cores,” each of which is a full-ﬂedged processor that can access a common memory.
At an intermediate price/performance point are clusters built from individual computers—often simple PC-class machines—with a dedicated network interconnecting them.
The highest-priced machines are supercomputers, which often use a combination of custom architectures and custom networks to deliver the highest performance in terms of instructions executed per second.
Multiprocessor computers have been around, in one form or another, for decades.
Although the computing community settled on the random-access machine model for serial computing early on in the history of computer science, no single model for parallel computing has gained as wide acceptance.
A major reason is that vendors have not agreed on a single architectural model for parallel computers.
For example, some parallel computers feature shared memory, where each processor can directly access any location of memory.
Other parallel computers employ distributed memory, where each processor’s memory is private, and an explicit message must be sent between processors in order for one processor to access the memory of another.
Although time will tell, that is the approach we shall take in this chapter.
One common means of programming chip multiprocessors and other sharedmemory parallel computers is by using static threading, which provides a software abstraction of “virtual processors,” or threads, sharing a common memory.
Each thread maintains an associated program counter and can execute code independently of the other threads.
The operating system loads a thread onto a processor for execution and switches it out when another thread needs to run.
Although the operating system allows programmers to create and destroy threads, these operations are comparatively slow.
Thus, for most applications, threads persist for the duration of a computation, which is why we call them “static.”
Unfortunately, programming a shared-memory parallel computer directly using static threads is difﬁcult and error-prone.
One reason is that dynamically partitioning the work among the threads so that each thread receives approximately the same load turns out to be a complicated undertaking.
For any but the simplest of applications, the programmer must use complex communication protocols to implement a scheduler to load-balance the work.
This state of affairs has led toward the creation of concurrency platforms, which provide a layer of software that coordinates, schedules, and manages the parallel-computing resources.
Some concurrency platforms are built as runtime libraries, but others provide full-ﬂedged parallel languages with compiler and runtime support.
One important class of concurrency platform is dynamic multithreading, which is the model we shall adopt in this chapter.
Dynamic multithreading allows programmers to specify parallelism in applications without worrying about communication protocols, load balancing, and other vagaries of static-thread programming.
The concurrency platform contains a scheduler, which load-balances the computation automatically, thereby greatly simplifying the programmer’s chore.
Nested parallelism allows a subroutine to be “spawned,” allowing the caller to proceed while the spawned subroutine is computing its result.
A parallel loop is like an ordinary for loop, except that the iterations of the loop can execute concurrently.
These two features form the basis of the model for dynamic multithreading that we shall study in this chapter.
A key aspect of this model is that the programmer needs to specify only the logical parallelism within a computation, and the threads within the underlying concurrency platform schedule and load-balance the computation among themselves.
Moreover, if we delete these concurrency keywords from the multithreaded pseudocode, the resulting text is serial pseudocode for the same problem, which we call the “serialization” of the multithreaded algorithm.
It provides a theoretically clean way to quantify parallelism based on the notions of “work” and “span.”
Many multithreaded algorithms involving nested parallelism follow naturally from the divide-and-conquer paradigm.
Moreover, just as serial divide-andconquer algorithms lend themselves to analysis by solving recurrences, so do multithreaded algorithms.
The model is faithful to how parallel-computing practice is evolving.
Section 27.1 introduces the dynamic multithreading model and presents the metrics of work, span, and parallelism, which we shall use to analyze multithreaded algorithms.
Each instance of FIB with the same argument does the same work to produce the same result, providing an inefﬁcient but interesting way to compute Fibonacci numbers.
You would not really want to compute large Fibonacci numbers this way, because this computation does much repeated work.
Since the FIB procedure does not memoize, the second call to FIB.4/ replicates the work that the ﬁrst call performs.
Since FIB.n/ contains two recursive calls plus a constant amount of extra work, we obtain the recurrence.
We can then choose a large enough to satisfy the initial condition.
We augment our pseudocode to indicate parallelism by adding the concurrency keywords spawn and sync.
Here is how we can rewrite the FIB procedure to use dynamic multithreading:
Notice that if we delete the concurrency keywords spawn and sync from P-FIB, the resulting pseudocode text is identical to FIB (other than renaming the procedure in the header and in the two recursive calls)
We deﬁne the serialization of a multithreaded algorithm to be the serial algorithm that results from deleting the multithreaded keywords: spawn, sync, and when we examine parallel loops, parallel.
Indeed, our multithreaded pseudocode has the nice property that a serialization is always ordinary serial pseudocode to solve the same problem.
The semantics of a spawn differs from an ordinary procedure call in that the procedure instance that executes the spawn—the parent—may continue to execute in parallel with the spawned subroutine—its child—instead of waiting.
The keyword spawn does not say, however, that a procedure must execute concurrently with its spawned children, only that it may.
The concurrency keywords express the logical parallelism of the computation, indicating which parts of the computation may proceed in parallel.
At runtime, it is up to a scheduler to determine which subcomputations actually run concurrently by assigning them to available processors as the computation unfolds.
The keyword sync indicates that the procedure must wait as necessary for all its spawned children to complete before proceeding to the statement after the sync.
In the P-FIB procedure, a sync is required before the return statement in line 6 to avoid the anomaly that would occur if x and y were summed before x was computed.
In addition to explicit synchronization provided by the sync statement, every procedure executes a sync implicitly before it returns, thus ensuring that all its children terminate before it does.
We can picture a multithreaded computation as a dag of strands embedded in a tree of procedure instances.
Figure 27.2 zooms in on a section of that tree, showing the strands that constitute each procedure.
All directed edges connecting strands run either within a procedure or along undirected edges in the procedure tree.
We shall study the execution of multithreaded algorithms on an ideal parallel computer, which consists of a set of processors and a sequentially consistent shared memory.
Sequential consistency means that the shared memory, which may in reality be performing many loads and stores from the processors at the same time, produces the same results as if at each step, exactly one instruction from one of the processors is executed.
That is, the memory behaves as if the instructions were executed sequentially according to some global linear order that preserves the individual orders in which each processor issues its own instructions.
For dynamic multithreaded computations, which are scheduled onto processors automatically by the concurrency platform, the shared memory behaves as if the multithreaded computation’s instructions were interleaved to produce a linear order that preserves the partial order of the computation dag.
Depending on scheduling, the ordering could differ from one run of the program to another, but the behavior of any execution can be understood by assuming that the instructions are executed in some linear order consistent with the computation dag.
Speciﬁcally, it assumes that each processor in the machine has equal computing power, and it ignores the cost of scheduling.
Although this last assumption may sound optimistic, it turns out that for algorithms with sufﬁcient “parallelism” (a term we shall deﬁne precisely in a moment), the overhead of scheduling is generally minimal in practice.
We can gauge the theoretical efﬁciency of a multithreaded algorithm by using two metrics: “work” and “span.” The work of a multithreaded computation is the total time to execute the entire computation on one processor.
In other words, the work is the sum of the times taken by each of the strands.
For a computation dag in which each strand takes unit time, the work is just the number of vertices in the dag.
The span is the longest time to execute the strands along any path in the dag.
Again, for a dag in which each strand takes unit time, the span equals the number of vertices on a longest or critical path in the dag.
The actual running time of a multithreaded computation depends not only on its work and its span, but also on how many processors are available and how the scheduler allocates strands to processors.
To denote the running time of a multithreaded computation on P processors, we shall subscript by P.
For example, we might denote the running time of an algorithm on P processors by TP.
The work is the running time on a single processor, or T1
The span is the running time if we could run each strand on its own processor—in other words, if we had an unlimited number of processors—and so we denote the span by T1
Looked at another way, a machine with an unlimited number of processors can emulate a P -processor machine by using just P of its processors.
The ratio T1=T1 of the work to the span gives the parallelism of the multithreaded computation.
As a ratio, the parallelism denotes the average amount of work that can be performed in parallel for each step along the critical path.
As an upper bound, the parallelism gives the maximum possible speedup that can be achieved on any number of processors.
Finally, and perhaps most important, the parallelism provides a limit on the possibility of attaining perfect linear speedup.
Speciﬁcally, once the number of processors exceeds the parallelism, the computation cannot possibly achieve perfect linear speedup.
Consequently, achieving much more than double the speedup is impossible, no matter how many processors we employ to execute the computation.
For larger input sizes, however, we shall see that P-FIB.n/ exhibits substantial parallelism.
Good performance depends on more than just minimizing the work and span.
The strands must also be scheduled efﬁciently onto the processors of the parallel machine.
Our multithreaded programming model provides no way to specify which strands to execute on which processors.
Instead, we rely on the concurrency platform’s scheduler to map the dynamically unfolding computation to individual processors.
In practice, the scheduler maps the strands to static threads, and the operating system schedules the threads on the processors themselves, but this extra level of indirection is unnecessary for our understanding of scheduling.
We can just imagine that the concurrency platform’s scheduler maps strands to processors directly.
A multithreaded scheduler must schedule the computation with no advance knowledge of when strands will be spawned or when they will complete—it must operate on-line.
Moreover, a good scheduler operates in a distributed fashion, where the threads implementing the scheduler cooperate to load-balance the computation.
Provably good on-line, distributed schedulers exist, but analyzing them is complicated.
Instead, to keep our analysis simple, we shall investigate an on-line centralized scheduler, which knows the global state of the computation at any given time.
In particular, we shall analyze greedy schedulers, which assign as many strands to processors as possible in each time step.
If at least P strands are ready to execute during a time step, we say that the step is a complete step, and a greedy scheduler assigns any P of the ready strands to processors.
Otherwise, fewer than P strands are ready to execute, in which case we say that the step is an incomplete step, and the scheduler assigns each ready strand to its own processor.
The following theorem shows that greedy scheduling is provably good in that it achieves the sum of these two lower bounds as an upper bound.
In each complete step, the P processors together perform a total of P work.
Suppose for the purpose of contradiction that the number of complete steps is strictly greater than bT1=P c.
Then, the total work of the complete steps is at least.
Thus, we obtain the contradiction that the P processors would perform more work than the computation requires, which allows us to conclude that the number of complete steps is at most bT1=P c.
Let G be the dag representing the entire computation, and without loss of generality, assume that each strand takes unit time.
We can replace each longer strand by a chain of unit-time strands.
Hence, the number of incomplete steps is at most T1
Since each step is either complete or incomplete, the theorem follows.
The following corollary to Theorem 27.1 shows that a greedy scheduler always performs well.
The next corollary shows that, in fact, a greedy scheduler achieves near-perfect linear speedup on any multithreaded computation as the slackness grows.
We now have all the tools we need to analyze multithreaded algorithms and provide good bounds on their running times on various numbers of processors.
Analyzing the work is relatively straightforward, since it amounts to nothing more than analyzing the running time of an ordinary serial algorithm—namely, the serialization of the multithreaded algorithm—which you should already be familiar with, since that is what most of this textbook is about! Analyzing the span is more interesting, but generally no harder once you get the hang of it.
We shall investigate the basic ideas using the P-FIB program.
Many algorithms contain loops all of whose iterations can operate in parallel.
As we shall see, we can parallelize such loops using the spawn and sync keywords, but it is much more convenient to specify directly that the iterations of such loops can run concurrently.
Our pseudocode provides this functionality via the parallel concurrency keyword, which precedes the for keyword in a for loop statement.
We can perform matrix-vector multiplication by computing all the entries of y in parallel as follows:
A compiler can implement each parallel for loop as a divide-and-conquer subroutine using nested parallelism.
The two numbers within each rounded rectangle give the values of the last two parameters (i and i 0 in the procedure header) in the invocation (spawn or call) of the procedure.
This code recursively spawns the ﬁrst half of the iterations of the loop to execute in parallel with the second half of the iterations and then executes a sync, thereby creating a binary tree of execution where the leaves are individual loop iterations, as shown in Figure 27.4
In fact, the overhead of recursive spawning does increase the work of a parallel loop compared with that of its serialization, but not asymptotically.
Each internal node performs constant work to divide the iteration range, and each leaf corresponds to an iteration of the loop, which takes at least constant time (‚.n/ time in this case)
Thus, we can amortize the overhead of recursive spawning against the work of the iterations, contributing at most a constant factor to the overall work.
This reduced overhead comes at the expense of also reducing the parallelism, however, but if the computation has sufﬁcient parallel slackness, near-perfect linear speedup need not be sacriﬁced.
We must also account for the overhead of recursive spawning when analyzing the span of a parallel-loop construct.
Since the depth of recursive calling is logarithmic in the number of iterations, for a parallel loop with n iterations in which the i th iteration has span iter1.i/, the span is.
A multithreaded algorithm is deterministic if it always does the same thing on the same input, no matter how the instructions are scheduled on the multicore computer.
It is nondeterministic if its behavior might vary from run to run.
Often, a multithreaded algorithm that is intended to be deterministic fails to be, because it contains a “determinacy race.”
You can run tests in the lab for days without a failure only to discover that your software sporadically crashes in the ﬁeld.
A determinacy race occurs when two logically parallel instructions access the same memory location and at least one of the instructions performs a write.
When a processor increments x, the operation is not indivisible, but is composed of a sequence of instructions:
Read x from memory into one of the processor’s registers.
Write the value in the register back into x in memory.
Figure 27.5(a) illustrates a computation dag representing the execution of RACEEXAMPLE, with the strands broken down to individual instructions.
Recall that since an ideal parallel computer supports sequential consistency, we can view the parallel execution of a multithreaded algorithm as an interleaving of instructions that respects the dependencies in the dag.
Part (b) of the ﬁgure shows the values in an execution of the computation that elicits the anomaly.
Instructions unrelated to the race, such as the implementation of loop control, are omitted.
When the instructions of the two processors execute at the same time, however, it is possible, as in this example execution, that one of the updates to x is lost.
Generally, most orderings produce correct results—such as any in which the instructions on the left execute before the instructions on the right, or vice versa.
But some orderings generate improper results when the instructions interleave.
You can run tests for days and never see the bug, only to experience a catastrophic system crash in the field when the outcome is critical.
Although we can cope with races in a variety of ways, including using mutualexclusion locks and other methods of synchronization, for our purposes, we shall simply ensure that strands that operate in parallel are independent: they have no determinacy races among them.
Thus, in a parallel for construct, all the iterations should be independent.
Between a spawn and the corresponding sync, the code of the spawned child should be independent of the code of the parent, including code executed by additional spawned or called children.
Note that arguments to a spawned child are evaluated in the parent before the actual spawn occurs, and thus the evaluation of arguments to a spawned subroutine is in series with any accesses to those arguments after the spawn.
As an example of how easy it is to generate code with races, here is a faulty implementation of multithreaded matrix-vector multiplication that achieves a span of ‚.lgn/ by parallelizing the inner for loop:
This procedure is, unfortunately, incorrect due to races on updating yi in line 7, which executes concurrently for all n values of j.
As an example, two parallel threads might store the same value into a shared variable, and it wouldn’t matter which stored the value ﬁrst.
Generally, however, we shall consider code with races to be illegal.
We close this section with a true story that occurred during the development of the world-class multithreaded chess-playing program ?Socrates [80], although the timings below have been simpliﬁed for exposition.
The relative speeds of the two versions switch when we calculate the running times on 512 processors, however.
The moral of the story is that work and span can provide a better means of extrapolating performance than can measured running times.
Assuming that each strand in the computation takes unit time, what are the work, span, and parallelism of the computation? Show how to schedule the dag on 3 processors using greedy scheduling by labeling each strand with the time step in which it is executed.
Analyze the work, span, and parallelism of the resulting algorithm.
In this section, we examine how to multithread matrix multiplication, a problem whose serial running time we studied in Section 4.2
We’ll look at multithreaded algorithms based on the standard triply nested loop, as well as divide-and-conquer algorithms.
Because the eight parallel recursive calls all execute on matrices of the same size, the maximum span for any recursive call is just the span of any one.
To multithread Strassen’s algorithm, we follow the same general outline as on page 79, only using nested parallelism:
To analyze this algorithm, we ﬁrst observe that since the serialization is the same as the original serial algorithm, the work is just the running time of the serialization, namely, ‚.nlg7/
Because merge sort already uses the divide-and-conquer paradigm, it seems like a terriﬁc candidate for multithreading using nested parallelism.
We can easily modify the pseudocode so that the ﬁrst recursive call is spawned:
Recall that its serial running time to merge n elements is ‚.n/
Because MERGE is serial, both its work and its span are ‚.n/
Thus, the following recurrence characterizes the work MS01.n/ of MERGE-SORT.
To sort 10 million elements, for example, it might achieve linear speedup on a few processors, but it would not scale up effectively to hundreds of processors.
You probably have already ﬁgured out where the parallelism bottleneck is in this multithreaded merge sort: the serial MERGE procedure.
Although merging might initially seem to be inherently serial, we can, in fact, fashion a multithreaded version of it by using nested parallelism.
This recurrence does not fall under any of the cases of the master theorem, but it meets the condition of Exercise 4.6-2
We shall ﬁrst derive a recurrence for the worst-case work.
We start by analyzing the work PMS1.n/ of P-MERGE-SORT, which is considerably easier than analyzing the work of P-MERGE.
We now derive and analyze a recurrence for the worst-case span PMS1.n/
A good implementation in practice would sacriﬁce some parallelism by coarsening the base case in order to reduce the constants hidden by the asymptotic notation.
The straightforward way to coarsen the base case is to switch to an ordinary serial sort, perhaps quicksort, when the size of the array is sufﬁciently small.
Give pseudocode for an efﬁcient multithreaded merging procedure that uses this median-ﬁnding procedure.
Hint: You may need an auxiliary array and may need to make more than one pass over the input elements.
Rewrite the parallel loop in SUM-ARRAYS using nested parallelism (spawn and sync) in the manner of MAT-VEC-MAIN-LOOP.
Consider the following alternative implementation of the parallel loop, which contains a value grain-size to be speciﬁed:
Give a formula for the span of SUM-ARRAYS0 in terms of n and grain-size.
Describe a recursive multithreaded algorithm that eliminates the need for the temporary matrix T at the cost of increasing the span to ‚.n/
Give and solve recurrences for the work and span of your implementation.
Parallelize the LU-DECOMPOSITION procedure on page 821 by giving pseudocode for a multithreaded version of this algorithm.
Make your implementation as parallel as possible, and analyze its work, span, and parallelism.
Do the same for a multithreaded algorithm based on equation (28.13) for inverting a symmetric positive-deﬁnite matrix.
Argue that P-SCAN-2 is correct, and analyze its work, span, and parallelism.
Computational science is replete with algorithms that require the entries of an array to be ﬁlled in with values that depend on the values of certain already computed neighboring entries, along with other information that does not change over the course of the computation.
The pattern of neighboring entries does not change during the computation and is called a stencil.
Observe now that we can ﬁll in subarray A11 recursively, since it does not depend on the entries of the other three subarrays.
Give multithreaded pseudocode that performs this simple stencil calculation using a divide-and-conquer algorithm SIMPLE-STENCIL based on the decomposition (27.11) and the discussion above.
Don’t worry about the details of the base case, which depends on the speciﬁc stencil.
Give and solve recurrences for the work and span of this algorithm in terms of n.
Give pseudocode for a multithreaded algorithm for this simple stencil calculation that achieves ‚.n= lg n/ parallelism.
Argue using notions of work and span that the problem, in fact, has ‚.n/ inherent parallelism.
As it turns out, the divide-and-conquer nature of our multithreaded pseudocode does not let us achieve this maximal parallelism.
Just as with ordinary serial algorithms, we sometimes want to implement randomized multithreaded algorithms.
This problem explores how to adapt the various performance measures in order to handle the expected behavior of such algorithms.
It also asks you to design and analyze a multithreaded algorithm for randomized quicksort.
Parallel computers, models for parallel computers, and algorithmic models for parallel programming have been around in various forms for years.
Prior editions of this book included material on sorting networks and the PRAM (Parallel RandomAccess Machine) model.
Many of the multithreaded algorithms in this chapter appeared in unpublished lecture notes by C.
The multithreaded merge-sorting algorithm was inspired by an algorithm of Akl [12]
The notion of sequential consistency is due to Lamport [223]
Because operations on matrices lie at the heart of scientiﬁc computing, efﬁcient algorithms for working with matrices have many practical applications.
This chapter focuses on how to multiply matrices and solve sets of simultaneous linear equations.
Section 28.1 shows how to solve a set of linear equations using LUP decompositions.
Then, Section 28.2 explores the close relationship between multiplying and inverting matrices.
Finally, Section 28.3 discusses the important class of symmetric positive-deﬁnite matrices and shows how we can use them to ﬁnd a least-squares solution to an overdetermined set of linear equations.
One important issue that arises in practice is numerical stability.
Due to the limited precision of ﬂoating-point representations in actual computers, round-off errors in numerical computations may become ampliﬁed over the course of a computation, leading to incorrect results; we call such computations numerically unstable.
Although we shall brieﬂy consider numerical stability on occasion, we do not focus on it in this chapter.
We refer you to the excellent book by Golub and Van Loan [144] for a thorough discussion of stability issues.
Numerous applications need to solve sets of simultaneous linear equations.
We can formulate a linear system as a matrix equation in which each matrix or vector element belongs to a ﬁeld, typically the real numbers R.
This section discusses how to solve a system of linear equations using a method called LUP decomposition.
In this section, we treat only the case in which there are exactly n equations in n unknowns.
In this section, we shall be concerned predominantly with the case in which A is nonsingular or, equivalently (by Theorem D.1), the rank of A is equal to the number n of unknowns.
There are other possibilities, however, which merit a brief discussion.
If the number of equations is less than the number n of unknowns—or, more generally, if the rank of A is less than n—then the system is underdetermined.
An underdetermined system typically has inﬁnitely many solutions, although it may have no solutions at all if the equations are inconsistent.
If the number of equations exceeds the number n of unknowns, the system is overdetermined, and there may not exist any solutions.
We call matrices L, U , and P satisfying equation (28.4) an LUP decomposition of the matrix A.
We shall show that every nonsingular matrix A possesses such a decomposition.
Computing an LUP decomposition for the matrix A has the advantage that we can more easily solve linear systems when they are triangular, as is the case for both matrices L and U.
Once we have found an LUP decomposition for A, we can solve equation (28.2), Ax D b, by solving only triangular linear systems, as follows.
Using our decomposition (28.4), we obtain LUx D Pb : We can now solve this equation by solving two triangular linear systems.
Let us deﬁne y D Ux, where x is the desired solution vector.
Ly D Pb (28.5) for the unknown vector y by a method called “forward substitution.” Having solved for y, we then solve the upper-triangular system.
Our next step is to show how forward and back substitution work and then attack the problem of computing the LUP decomposition itself.
Since the summation within each of the for loops includes an implicit loop, the running time is ‚.n2/
Using back substitution, we solve Ux D y for x:
We use a process known as Gaussian elimination to create an LU decomposition.
We start by subtracting multiples of the ﬁrst equation from the other equations in order to remove the ﬁrst variable from those equations.
Then, we subtract multiples of the second equation from the third and subsequent equations so that now the ﬁrst and second variables are removed from them.
We continue this process until the system that remains has an upper-triangular form—in fact, it is the matrix U.
The matrix L is made up of the row multipliers that cause variables to be eliminated.
An important class of matrices for which LU decomposition always works correctly is the class of symmetric positive-deﬁnite matrices.
We shall prove this result, as well as several others, in Section 28.3
Our code for LU decomposition of a matrix A follows the recursive strategy, except that an iteration loop replaces the recursion.
This transformation is a standard optimization for a “tail-recursive” procedure—one whose last operation is a recursive call to itself.
It assumes that the attribute A:rows gives the dimension of A.
But we also want to avoid dividing by a small value—even if A is.
Because of its triply nested loop structure, LUP-DECOMPOSITION has a running time of ‚.n3/, which is the same as that of LU-DECOMPOSITION.
Thus, pivoting costs us at most a constant factor in time.
Although in practice we do not generally use matrix inverses to solve systems of linear equations, preferring instead to use more numerically stable techniques such as LUP decomposition, sometimes we need to compute a matrix inverse.
In this section, we show how to use LUP decomposition to compute a matrix inverse.
We also prove that matrix multiplication and computing the inverse of a matrix are equivalently hard problems, in that (subject to technical conditions) we can use an algorithm for one to solve the other in the same asymptotic running time.
Thus, we can use Strassen’s algorithm (see Section 4.2) for matrix multiplication to invert a matrix.
Indeed, Strassen’s original paper was motivated by the problem of showing that a set of a linear equations could be solved more quickly than by the usual method.
Suppose that we have an LUP decomposition of a matrix A in the form of three matrices L, U , and P such that PA D LU.
Using LUP-SOLVE, we can solve an equation of the form Ax D b in time ‚.n2/
In general, once we have the LUP decomposition of A, we can solve, in time ‚.kn2/, k versions of the equation Ax D b that differ only in b.
To be precise, let Xi denote the i th column of X , and recall that the unit vector ei is the i th column of In.
We can then solve equation (28.10) for X by using the LUP decomposition for A to solve each equation.
The proof that matrix inversion is no harder than matrix multiplication relies on some properties of symmetric positive-deﬁnite matrices that we will prove in Section 28.3
Exercise 28.2-6 asks you to generalize the proof for matrices whose entries are complex numbers.
It remains to prove that we can obtain the same asymptotic running time for matrix multiplication as for matrix inversion when A is invertible but not symmetric and positive-deﬁnite.
The trick, then, is to reduce the problem of inverting A to the problem of inverting ATA.
The proof of Theorem 28.2 suggests a means of solving the equation Ax D b by using LU decomposition without pivoting, so long as A is nonsingular.
We multiply both sides of the equation by AT, yielding .ATA/x D ATb.
This transformation doesn’t affect the solution x, since AT is invertible, and so we can factor the symmetric positive-deﬁnite matrix ATA by computing an LU decomposition.
We then use forward and back substitution to solve for x with the right-hand side ATb.
Although this method is theoretically correct, in practice the procedure LUP-DECOMPOSITION works much better.
The ﬁrst property we prove is perhaps the most basic.
The proof that we can perform LU decomposition on a symmetric positivedeﬁnite matrix A without dividing by 0 is more involved.
We begin by proving properties about certain submatrices of A.
Deﬁne the kth leading submatrix of A to be the matrix Ak consisting of the intersection of the ﬁrst k rows and ﬁrst k columns of A.
Lemma 28.4 If A is a symmetric positive-deﬁnite matrix, then every leading submatrix of A is symmetric and positive-deﬁnite.
The next lemma shows that the Schur-complement matrices of symmetric positive-deﬁnite matrices are themselves symmetric and positive-deﬁnite.
We used this result in Theorem 28.2, and we need its corollary to prove the correctness of LU decomposition for symmetric positive-deﬁnite matrices.
This last equation amounts to “completing the square” of the quadratic form.
We shall prove something stronger than the statement of the corollary: every pivot is strictly positive.
One important application of symmetric positive-deﬁnite matrices arises in ﬁtting curves to given sets of data points.
Suppose that we are given a set of m data points.
We would like to determine a function F.x/ such that the approximation errors.
By choosing n D m, we can calculate each yi exactly in equation (28.17)
Such a high-degree F “ﬁts the noise” as well as the data, however, and generally gives poor results when used to predict y for previously unseen values of x.
It is usually better to choose n signiﬁcantly smaller than m and hope that by choosing the coefﬁcients cj well, we can obtain a function F that ﬁnds the signiﬁcant patterns in the data points without paying undue attention to the noise.
In any case, once we choose a value of n that is less than m, we end up with an overdetermined set of equations whose solution we wish to approximate.
Let c D .ck/ denote the desired n-vector of coefﬁcients.
As an example of producing a least-squares ﬁt, suppose that we have ﬁve data points.
We wish to ﬁt these points with a quadratic polynomial.
As a practical matter, we solve the normal equation (28.19) by multiplying y.
If A has full rank, the matrix ATA is guaranteed to be nonsingular, because it is symmetric and positivedeﬁnite.
The question remains of how to choose the ﬁrst derivatives of f .x/ at the knots.
One method is to require the second derivatives to be continuous at the knots:
Many excellent texts describe numerical and scientiﬁc computation in much greater detail than we have room for here.
Strang [324] has an excellent presentation of symmetric positive-deﬁnite matrices and of linear algebra in general.
Many problems take the form of maximizing or minimizing an objective, given limited resources and competing constraints.
If we can specify the objective as a linear function of certain variables, and if we can specify the constraints on resources as equalities or inequalities on those variables, then we have a linearprogramming problem.
Suppose that you are a politician trying to win an election.
Your district has three different types of areas—urban, suburban, and rural.
Although not all the registered voters actually go to the polls, you decide that to govern effectively, you would like at least half the registered voters in each of the three regions to vote for you.
You are honorable and would never consider supporting policies in which you do not believe.
You realize, however, that certain issues may be more effective in winning votes in certain places.
Your primary issues are building more roads, gun control, farm subsidies, and a gasoline tax dedicated to improved public transit.
According to your campaign staff’s research, you can estimate how many votes you win or lose from each population segment by spending $1,000 on advertising on each issue.
In this table, each entry indicates the number of thousands of either urban, suburban, or rural voters who would be won over by spending $1,000 on advertising in support of a particular issue.
You could, by trial and error, devise a strategy that wins the required number of votes, but the strategy you come up with might not be the least expensive one.
Each entry describes the number of thousands of urban, suburban, or rural voters who could be won over by spending $1,000 on advertising support of a policy on a particular issue.
We can write the requirement that we win at least 50,000 urban votes as.
In the general linear-programming problem, we wish to optimize a linear function subject to a set of linear inequalities.
If b is a real number and f is a linear function, then the equation.
We use the general term linear constraints to denote either linear equalities or linear inequalities.
Formally, a linear-programming problem is the problem of either minimizing or maximizing a linear function subject to a ﬁnite set of linear constraints.
If we are to minimize, then we call the linear program a minimization linear program, and if we are to maximize, then we call the linear program a maximization linear program.
The remainder of this chapter covers how to formulate and solve linear programs.
Although several polynomial-time algorithms for linear programming have been developed, we will not study them in this chapter.
Instead, we shall study the simplex algorithm, which is the oldest linear-programming algorithm.
The simplex algorithm does not run in polynomial time in the worst case, but it is fairly efﬁcient and widely used in practice.
In order to describe properties of and algorithms for linear programs, we ﬁnd it convenient to express them in canonical forms.
We shall use two forms, standard and slack, in this chapter.
Informally, a linear program in standard form is the maximization of a linear function subject to linear inequalities, whereas a linear program in slack form is the maximization of a linear function subject to linear equalities.
We shall typically use standard form for expressing linear programs, but we ﬁnd it more convenient to use slack form when we describe the details of the simplex algorithm.
For now, we restrict our attention to maximizing a linear function on n variables subject to a set of m linear inequalities.
Let us ﬁrst consider the following linear program with two variables:
Each constraint is represented by a line and a direction.
The intersection of the constraints, which is the feasible region, is shaded.
We call this convex region the feasible region and the function we wish to maximize the objective function.
We could then identify a point that has the maximum objective value as an optimal solution.
For this example (and for most linear programs), the feasible region contains an inﬁnite number of points, and so we need to determine an efﬁcient way to ﬁnd a point that achieves the maximum objective value without explicitly evaluating the objective function at every point in the feasible region.
An intuitive deﬁnition of a convex region is that it fulﬁlls the requirement that for any two points in the region, all points on a line segment between them are also in the region.
The simplex algorithm takes as input a linear program and returns an optimal solution.
It starts at some vertex of the simplex and performs a sequence of iterations.
The simplex algorithm terminates when it reaches a local maximum, which is a vertex from which all neighboring vertices have a smaller objective value.
Because the feasible region is convex and the objective function is linear, this local optimum is actually a global optimum.
Although the geometric view gives a good intuitive view of the operations of the simplex algorithm, we shall not refer to it explicitly when developing the details of the simplex algorithm in Section 29.3
We ﬁrst write the given linear program in slack form, which is a set of linear equalities.
These linear equalities express some of the variables, called “basic variables,” in terms of other variables, called “nonbasic variables.” We move from one vertex to another by making a basic variable become nonbasic and making a nonbasic variable become basic.
We call this operation a “pivot” and, viewed algebraically, it is nothing more than rewriting the linear program in an equivalent slack form.
We shall need to address several more details in this chapter.
These issues include identifying linear programs that have no solutions, linear programs that have no ﬁnite optimal solution, and linear programs for which the origin is not a feasible solution.
An oil company wants to decide where to drill for oil.
Siting a drill at a particular location has an associated cost and, based on geological surveys, an expected payoff of some number of barrels of oil.
The company has a limited budget for locating new drills and wants to maximize the amount of oil it expects to ﬁnd, given this budget.
With linear programs, we also model and solve graph and combinatorial problems, such as those appearing in this textbook.
We have already seen a special case of linear programming used to solve systems of difference constraints in Section 24.4
In Section 29.2, we shall study how to formulate several graph and network-ﬂow problems as linear programs.
In Section 35.4, we shall use linear programming as a tool to ﬁnd an approximate solution to another graph problem.
This algorithm, when implemented carefully, often solves general linear programs quickly in practice.
With some carefully contrived inputs, however, the simplex algorithm can require exponential time.
The ﬁrst polynomial-time algorithm for linear programming was the ellipsoid algorithm, which runs slowly in practice.
A second class of polynomial-time algorithms are known as interior-point methods.
In contrast to the simplex algorithm, which moves along the exterior of the feasible region and maintains a feasible solution that is a vertex of the simplex at each iteration, these algorithms move through the interior of the feasible region.
The intermediate solutions, while feasible, are not necessarily vertices of the simplex, but the ﬁnal solution is a vertex.
For large inputs, interior-point algorithms can run as fast as, and sometimes faster than, the simplex algorithm.
The chapter notes point you to more information about these algorithms.
If we add to a linear program the additional requirement that all variables take on integer values, we have an integer linear program.
Exercise 34.5-3 asks you to show that just ﬁnding a feasible solution to this problem is NP-hard; since no polynomial-time algorithms are known for any NP-hard problems, there is no known polynomial-time algorithm for integer linear programming.
In contrast, we can solve a general linear-programming problem in polynomial time.
This section describes two formats, standard form and slack form, that are useful when we specify and work with linear programs.
In standard form, all the constraints are inequalities, whereas in slack form, all constraints are equalities (except for those that require the variables to be nonnegative)
We now introduce terminology to describe solutions to linear programs.
We used some of this terminology in the earlier example of a two-variable linear program.
We call a setting of the variables Nx that satisﬁes all the constraints a feasible solution, whereas a setting of the variables Nx that fails to satisfy at least one constraint is an infeasible solution.
We say that a solution Nx has objective value cT Nx.
A feasible solution Nx whose objective value is maximum over all feasible solutions is an optimal solution, and we call its objective value cT Nx the optimal objective value.
If a linear program has no feasible solutions, we say that the linear program is infeasible; otherwise it is feasible.
If a linear program has some feasible solutions but does not have a ﬁnite optimal objective value, we say that the linear program is unbounded.
Exercise 29.1-9 asks you to show that a linear program can have a ﬁnite optimal objective value even if the feasible region is not bounded.
It is always possible to convert a linear program, given as minimizing or maximizing a linear function subject to linear constraints, into standard form.
A linear program might not be in standard form for any of four possible reasons:
The objective function might be a minimization rather than a maximization.
We now show how to remove, one by one, each of the possible problems in the list above.
After removing each one, we shall argue that the new linear program is equivalent to the old one.
To convert a minimization linear program L into an equivalent maximization linear program L0, we simply negate the coefﬁcients in the objective function.
Continuing the example, we want to ensure that each variable has a corresponding nonnegativity constraint.
Finishing our example, we replace the equality in constraint (29.22) by two inequalities, obtaining.
To efﬁciently solve a linear program with the simplex algorithm, we prefer to express it in a form in which some of the constraints are equality constraints.
More precisely, we shall convert it into a form in which the nonnegativity constraints are the only inequality constraints, and the remaining constraints are equalities.
We introduce a new variable s and rewrite inequality (29.29) as the two constraints.
Give an upper bound on the number of variables and constraints in the resulting linear program.
Although we shall focus on the simplex algorithm in this chapter, it is also important to be able to recognize when we can formulate a problem as a linear program.
Once we cast a problem as a polynomial-sized linear program, we can solve it in polynomial time by the ellipsoid algorithm or interior-point methods.
Several linear-programming software packages can solve problems efﬁciently, so that once the problem is in the form of a linear program, such a package can solve it.
We shall look at several concrete examples of linear-programming problems.
Although the minimum-costﬂow problem has a polynomial-time algorithm that is not based on linear programming, we won’t describe the algorithm.
Finally, we describe the multicommodityﬂow problem, for which the only known polynomial-time algorithm is based on linear programming.
We can formulate the single-source shortest-paths problem as a linear program.
In this section, we shall focus on how to formulate the single-pair shortest-path problem, leaving the extension to the more general single-source shortest-paths problem as Exercise 29.2-3
The source vertex initially receives a value ds D 0, which never changes.
Thus we obtain the following linear program to compute the shortest-path weight from s to t :
In this section, we have used linear programming to solve problems for which we already knew efﬁcient algorithms.
In fact, an efﬁcient algorithm designed specifically for a problem, such as Dijkstra’s algorithm for the single-source shortestpaths problem, or the push-relabel method for maximum ﬂow, will often be more efﬁcient than linear programming, both in theory and in practice.
The real power of linear programming comes from the ability to solve new problems.
Recall the problem faced by the politician in the beginning of this chapter.
The problem of obtaining a sufﬁcient number of votes, while not spending too much money, is not solved by any of the algorithms that we have studied in this book, yet we can solve it by linear programming.
Books abound with such realworld problems that linear programming can solve.
Linear programming is also particularly useful for solving variants of problems for which we may not already know of an efﬁcient algorithm.
There are polynomial-time algorithms speciﬁcally designed for the minimumcost-ﬂow problem, but they are beyond the scope of this book.
We can, however, express the minimum-cost-ﬂow problem as a linear program.
We denote the capacities by c and the costs by a.
Vertex s is the source and vertex t is the sink, and we wish to send 4 units of ﬂow from s to t.
For each edge, the ﬂow and capacity are written as ﬂow/capacity.
Suppose that the Lucky Puck company from Section 26.1 decides to diversify its product line and ship not only hockey pucks, but also hockey sticks and hockey helmets.
Each piece of equipment is manufactured in its own factory, has its own warehouse, and must be shipped, each day, from factory to warehouse.
The sticks are manufactured in Vancouver and must be shipped to Saskatoon, and the helmets are manufactured in Edmonton and must be shipped to Regina.
The capacity of the shipping network does not change, however, and the different items, or commodities, must share the same network.
The only known polynomial-time algorithm for this problem expresses it as a linear program and then solves it with a polynomial-time linear-programming algorithm.
The simplex algorithm is the classical method for solving linear programs.
In contrast to most of the other algorithms in this book, its running time is not polynomial in the worst case.
It does yield insight into linear programs, however, and is often remarkably fast in practice.
In addition to having a geometric interpretation, described earlier in this chapter, the simplex algorithm bears some similarity to Gaussian elimination, discussed in Section 28.1
Gaussian elimination begins with a system of linear equalities whose solution is unknown.
In each iteration, we rewrite this system in an equivalent form that has some additional structure.
After some number of iterations, we have rewritten the system so that the solution is simple to obtain.
The simplex algorithm proceeds in a similar manner, and we can view it as Gaussian elimination for inequalities.
We now describe the main idea behind an iteration of the simplex algorithm.
Associated with each iteration will be a “basic solution” that we can easily obtain from the slack form of the linear program: set each nonbasic variable to 0 and compute the values of the basic variables from the equality constraints.
An iteration converts one slack form into an equivalent slack form.
The objective value of the associated basic feasible solution will be no less than that at the previous iteration, and usually greater.
To achieve this increase in the objective value, we choose a nonbasic variable such that if we were to increase that variable’s value from 0, then the objective value would increase, too.
The amount by which we can increase the variable is limited by the other constraints.
We then rewrite the slack form, exchanging the roles of that basic variable and the chosen nonbasic variable.
Although we have used a particular setting of the variables to guide the algorithm, and we shall use it in our proofs, the algorithm does not explicitly maintain this solution.
It simply rewrites the linear program until an optimal solution becomes “obvious.”
In addition to being an algebraic manipulation, slack is a useful algorithmic concept.
Similarly, a setting of the nonbasic variables that would make a basic variable become negative violates that constraint.
Thus, the slack variables explicitly maintain how far each constraint is from being tight, and so they help to determine how much we can increase values of nonbasic variables without violating any constraints.
If a basic solution is also feasible, we call it a basic feasible solution.
As we run the simplex algorithm, the basic solution is almost always a basic feasible solution.
We shall see in Section 29.5, however, that for the ﬁrst few iterations of the simplex algorithm, the basic solution might not be feasible.
Our goal, in each iteration, is to reformulate the linear program so that the basic solution has a greater objective value.
We select a nonbasic variable xe whose coefﬁcient in the objective function is positive, and we increase the value of xe as much as possible without violating any of the constraints.
The variable xe becomes basic, and some other variable xl becomes nonbasic.
The values of other basic variables and of the objective function may also change.
As demonstrated above, a pivot chooses a nonbasic variable xe, called the entering variable, and a basic variable xl , called the leaving variable, and exchanges their roles.
We perform two operations in the simplex algorithm: rewrite equations so that variables move between the lefthand side and the right-hand side, and substitute one equation into another.
The ﬁrst operation trivially creates an equivalent problem, and the second, by elementary linear algebra, also creates an equivalent problem.
Continuing the example, we wish to ﬁnd a new variable whose value we wish to increase.
We do not want to increase x6, since as its value increases, the objective value decreases.
Now the only way to increase the objective value is to increase x2
This constraint, therefore, places no restriction on how much we can increase x2
Furthermore, the ﬁnal solution to a linear program need not be integral; it is purely coincidental that this example has an integral solution.
Lines 3–6 compute the coefﬁcients in the new equation for xe by rewriting the equation that has xl on the left-hand side to instead have xe on the left-hand side.
Lines 8–12 update the remaining equations by substituting the right-hand side of this new equation for each occurrence of xe.
We now summarize the effect that PIVOT has on the values of the variables in the basic solution.
The procedure SIMPLEX takes as input a linear program in standard form, as just described.
The while loop of lines 3–12 forms the main part of the algorithm.
If all coefﬁcients in the objective function are negative, then the while loop terminates.
Otherwise, line 4 selects a variable xe, whose coefﬁcient in the objective function is positive, as the entering variable.
Although we may choose any such variable as the entering variable, we assume that we use some prespeciﬁed deterministic rule.
To show that SIMPLEX is correct, we ﬁrst show that if SIMPLEX has an initial feasible solution and eventually terminates, then it either returns a feasible solution or determines that the linear program is unbounded.
Then if SIMPLEX returns a solution in line 17, that solution is a feasible solution to the linear program.
If SIMPLEX returns “unbounded” in line 11, the linear program is unbounded.
Maintenance: We shall show that each iteration of the while loop maintains the loop invariant, assuming that the return statement in line 11 does not execute.
We shall handle the case in which line 11 executes when we discuss termination.
Using the second part of the loop invariant, we conclude that each basic variable Nxi is nonnegative.
It remains to show that SIMPLEX terminates, and when it does terminate, the solution it returns is optimal.
In the example given in the beginning of this section, each iteration of the simplex algorithm increased the objective value associated with the basic solution.
As Exercise 29.3-2 asks you to show, no iteration of SIMPLEX can decrease the objective value associated with the basic solution.
Unfortunately, it is possible that an iteration leaves the objective value unchanged.
This phenomenon is called degeneracy, and we shall now study it in greater detail.
Degeneracy can prevent the simplex algorithm from terminating, because it can lead to a phenomenon known as cycling: the slack forms at two different iterations of SIMPLEX are identical.
Because of degeneracy, SIMPLEX could choose a sequence of pivot operations that leave the objective value unchanged but repeat a slack form within the sequence.
Since SIMPLEX is a deterministic algorithm, if it cycles, then it will cycle through the same series of slack forms forever, never terminating.
Cycling is the only reason that SIMPLEX might not terminate.
To show this fact, we must ﬁrst develop some additional machinery.
A particular linear program has many different slack forms; recall that each slack form has the same set of feasible and optimal solutions as the original linear program.
We now show that the slack form of a linear program is uniquely determined by the set of basic variables.
That is, given the set of basic variables, a unique slack form (unique set of coefﬁcients and right-hand sides) is associated with those basic variables.
Lemma 29.4 Let .A; b; c/ be a linear program in standard form.
Given a set B of basic variables, the associated slack form is uniquely determined.
We can now show that cycling is the only possible reason that SIMPLEX might not terminate.
Lemma 29.5 If SIMPLEX fails to terminate in at most.
We can prevent it by choosing the entering and leaving variables somewhat more carefully.
One option is to perturb the input slightly so that it is impossible to have two solutions with the same objective value.
Another option is to break ties by always choosing the variable with the smallest index, a strategy known as Bland’s rule.
Lemma 29.7 Assuming that INITIALIZE-SIMPLEX returns a slack form for which the basic solution is feasible, SIMPLEX either reports that a linear program is unbounded, or it terminates with a feasible solution in at most.
By the contrapositive of Lemma 29.5, if SIMPLEX terminates with a feasible solution, then it terminates in at most.
Give an example of a linear program in which there are strictly fewer than.
We have not yet shown that it actually ﬁnds an optimal solution to a linear program, however.
In order to do so, we introduce a powerful concept called linear-programming duality.
Duality enables us to prove that a solution is indeed optimal.
Suppose that, given an instance of a maximum-ﬂow problem, we ﬁnd a ﬂow f with value jf j.
How do we know whether f is a maximum ﬂow? By the max-ﬂow min-cut theorem, if we can ﬁnd a cut whose value is also jf j, then we have veriﬁed that f is indeed a maximum ﬂow.
This relationship provides an example of duality: given a maximization problem, we deﬁne a related minimization problem such that the two problems have the same optimal objective values.
Given a linear program in which the objective is to maximize, we shall describe how to formulate a dual linear program in which the objective is to minimize and.
When referring to dual linear programs, we call the original linear program the primal.
Each of the m constraints in the primal has an associated variable yi in the dual, and each of the n constraints in the dual has an associated variable xj in the primal.
We shall show in Theorem 29.10 that the optimal value of the dual linear program is always equal to the optimal value of the primal linear program.
Furthermore, the simplex algorithm actually implicitly solves both the primal and the dual linear programs simultaneously, thereby providing a proof of optimality.
We begin by demonstrating weak duality, which states that any feasible solution to the primal linear program has a value no greater than that of any feasible solution to the dual linear program.
Corollary 29.9 Let Nx be a feasible solution to a primal linear program .A; b; c/, and let Ny be a feasible solution to the corresponding dual linear program.
Proof By Lemma 29.8, the objective value of a feasible solution to the primal cannot exceed that of a feasible solution to the dual.
The primal linear program is a maximization problem and the dual is a minimization problem.
Thus, if feasible solutions Nx and Ny have the same objective value, neither can be improved.
Let N and B denote the nonbasic and basic variables for the ﬁnal slack form, let c 0 denote the coefﬁcients in the ﬁnal slack form, and let Ny D.
Then Nx is an optimal solution to the primal linear program, Ny is an optimal solution to the dual linear program, and nX.
We shall now show that the solutions Nx and Ny described in the statement of the theorem satisfy equation (29.92)
Since SIMPLEX terminated with a solution, by the condition in line 3 we know that.
Equation (29.97) says that the ﬁrst and last slack forms, evaluated at Nx, are equal.
We have shown that, given a feasible linear program, if INITIALIZE-SIMPLEX returns a feasible solution, and if SIMPLEX terminates without returning “unbounded,” then the solution returned is indeed an optimal solution.
We have also shown how to construct an optimal solution to the dual linear program.
We could produce the dual by ﬁrst converting it to standard form, and then taking the dual.
It would be more convenient, however, to be able to produce the dual directly.
Explain how we can directly take the dual of an arbitrary linear program.
Explain how to interpret this formulation as a minimum-cut problem.
Explain how to interpret this problem in terms of graphs and ﬂows.
In this section, we ﬁrst describe how to test whether a linear program is feasible, and if it is, how to produce a slack form for which the basic solution is feasible.
We conclude by proving the fundamental theorem of linear programming, which says that the SIMPLEX procedure always produces the correct result.
In Section 29.3, we assumed that we had a procedure INITIALIZE-SIMPLEX that determines whether a linear program has any feasible solutions, and if it does, gives a slack form for which the basic solution is feasible.
A linear program can be feasible, yet the initial basic solution might not be feasible.
This solution violates constraint (29.104), and so it is not a feasible solution.
In order to determine whether a linear program has any feasible solutions, we will formulate an auxiliary linear program.
For this auxiliary linear program, we can ﬁnd (with a little work) a slack form for which the basic solution is feasible.
Furthermore, the solution of this auxiliary linear program determines whether the initial linear program is feasible and if so, it provides a feasible solution with which we can initialize SIMPLEX.
We now describe our strategy to ﬁnd an initial basic feasible solution for a linear program L in standard form:
This slack form is the ﬁnal solution to the auxiliary problem.
We then restore the original objective function, with appropriate substitutions made to include only nonbasic variables.
This slack form has a feasible basic solution, and we can return it to procedure SIMPLEX.
Lemma 29.12 If a linear program L has no feasible solution, then INITIALIZE-SIMPLEX returns “infeasible.” Otherwise, it returns a valid slack form for which the basic solution is feasible.
Letting Nx be the basic solution after the call to PIVOT, and letting yb and yB be values returned by PIVOT, Lemma 29.1 implies that.
Hence the basic solution after the call to PIVOT in line 8 is feasible.
We conclude this chapter by showing that the SIMPLEX procedure works.
In particular, any linear program either is infeasible, is unbounded, or has an optimal solution with a ﬁnite objective value.
Theorem 29.13 (Fundamental theorem of linear programming) Any linear program L, given in standard form, either.
If L is infeasible, SIMPLEX returns “infeasible.” If L is unbounded, SIMPLEX returns “unbounded.” Otherwise, SIMPLEX returns an optimal solution with a ﬁnite objective value.
Proof By Lemma 29.12, if linear program L is infeasible, then SIMPLEX returns “infeasible.” Now suppose that the linear program L is feasible.
By Lemma 29.12, INITIALIZE-SIMPLEX returns a slack form for which the basic solution is feasible.
By Lemma 29.7, therefore, SIMPLEX either returns “unbounded” or terminates with a feasible solution.
If it terminates with a ﬁnite solution, then Theorem 29.10 tells us that this solution is optimal.
On the other hand, if SIMPLEX returns “unbounded,” Lemma 29.2 tells us the linear program L is indeed unbounded.
Since SIMPLEX always terminates in one of these ways, the proof is complete.
Show that in this case, the fundamental theorem of linear programming does not hold.
Both P and D have optimal solutions with ﬁnite objective values.
Show that if we have an algorithm for linear programming, we can use it to solve a linear-inequality feasibility problem.
The number of variables and constraints that you use in the linear-programming problem should be polynomial in n and m.
Show that if we have an algorithm for the linear-inequality feasibility problem, we can use it to solve a linear-programming problem.
The number of variables and linear inequalities that you use in the linear-inequality feasibility problem should be polynomial in n and m, the number of variables and constraints in the linear program.
Complementary slackness describes a relationship between the values of primal variables and dual constraints and between the values of dual variables and primal constraints.
Complementary slackness states that the following conditions are necessary and sufﬁcient for Nx and Ny to be optimal: mX.
Prove that complementary slackness holds for any primal linear program and its corresponding dual.
An integer linear-programming problem is a linear-programming problem with the additional constraint that the variables x must take on integral values.
Exercise 34.5-3 shows that just determining whether an integer linear program has a feasible solution is NP-hard, which means that there is no known polynomial-time algorithm for this problem.
Show that weak duality (Lemma 29.8) holds for an integer linear program.
Show that duality (Theorem 29.10) does not always hold for an integer linear program.
Given a primal linear program in standard form, let us deﬁne P to be the optimal objective value for the primal linear program, D to be the optimal objective value for its dual, IP to be the optimal objective value for the integer version of the primal (that is, the primal with the added constraint that the variables take on integer values), and ID to be the optimal objective value for the integer version of the dual.
Assuming that both the primal integer program and the dual integer program are feasible and bounded, show that.
The simplex algorithm for linear programming was invented by G.
Shortly after, researchers discovered how to formulate a number of problems in a variety of ﬁelds as linear programs and solve them with the simplex algorithm.
As a result, applications of linear programming ﬂourished, along with several algorithms.
Variants of the simplex algorithm remain the most popular methods for solving linear-programming problems.
Karmarkar’s paper [198] includes a description of the ﬁrst interior-point algorithm.
The simplex algorithm is known to run efﬁciently in certain special cases.
Particularly noteworthy is the network-simplex algorithm, which is the simplex algorithm, specialized to network-ﬂow problems.
For certain network problems, including the shortest-paths, maximum-ﬂow, and minimum-cost-ﬂow problems, variants of the network-simplex algorithm run in polynomial time.
See, for example, the article by Orlin [268] and the citations therein.
In this chapter, we shall show how the fast Fourier transform, or FFT, can reduce the time to multiply polynomials to ‚.n lg n/
The most common use for Fourier transforms, and hence the FFT, is in signal processing.
A signal is given in the time domain: as a function mapping time to amplitude.
Fourier analysis allows us to express the signal as a weighted sum of phase-shifted sinusoids of varying frequencies.
The weights and phases associated with the frequencies characterize the signal in the frequency domain.
Among the many everyday applications of FFT’s are compression techniques used to encode digital video and audio information, including MP3 ﬁles.
Several ﬁne books delve into the rich area of signal processing; the chapter notes reference a few of them.
A polynomial in the variable x over an algebraic ﬁeld F represents a function A.x/ as a formal sum:
Section 30.1 presents two ways to represent polynomials: the coefﬁcient representation and the point-value representation.
We can, however, multiply polynomials using the coefﬁcient representation in only ‚.n lg n/ time by converting between the two representations.
To see why this approach works, we must ﬁrst study complex roots of unity, which we do in Section 30.2
Then, we use the FFT and its inverse, also described in Section 30.2, to perform the conversions.
Section 30.3 shows how to implement the FFT quickly in both serial and parallel models.
This chapter uses complex numbers extensively, and within this chapter we use the symbol i exclusively to denote.
The coefﬁcient and point-value representations of polynomials are in a sense equivalent; that is, a polynomial in point-value form has a unique counterpart in coefﬁcient form.
In this section, we introduce the two representations and show how to combine them so that we can multiply two degree-bound n polynomials in ‚.n lg n/ time.
The coefﬁcient representation is convenient for certain operations on polynomials.
We can evaluate a polynomial in ‚.n/ time using Horner’s rule:
The following theorem shows that interpolation is well deﬁned when the desired interpolating polynomial must have a degree-bound equal to the given number of point-value pairs.
A faster algorithm for n-point interpolation is based on Lagrange’s formula:
You may wish to verify that the right-hand side of equation (30.5) is a polynomial of degree-bound n that satisﬁes A.xk/ D yk for all k.
The point-value representation is quite convenient for many operations on polynomials.
Interpolation is a notoriously tricky problem from the point of view of numerical stability.
Although the approaches described here are mathematically correct, small differences in the inputs or round-off errors during computation can cause large differences in the result.
If C.x/ D A.x/B.x/, then C.xk/ D A.xk/B.xk/ for any point xk, and we can pointwise multiply a point-value representation for A by a point-value representation for B to obtain a point-value representation for C.
We must face the problem, however, that degree.C / D degree.A/ C degree.B/; if A and B are of degree-bound n, then C is of degree-bound 2n.
A standard point-value representation for A and B consists of n point-value pairs for each polynomial.
We must therefore begin with “extended” point-value representations for A and for B consisting of 2n point-value pairs each.
Finally, we consider how to evaluate a polynomial given in point-value form at a new point.
For this problem, we know of no simpler approach than converting the polynomial to coefﬁcient form ﬁrst, and then evaluating it at the new point.
Can we use the linear-time multiplication method for polynomials in point-value form to expedite polynomial multiplication in coefﬁcient form? The answer hinges.
Representations on the top are in coefﬁcient form, while those on the bottom are in point-value form.
The arrows from left to right correspond to the multiplication operation.
We can use any points we want as evaluation points, but by choosing the evaluation points carefully, we can convert between representations in only ‚.n lgn/ time.
As we shall see in Section 30.2, if we choose “complex roots of unity” as the evaluation points, we can produce a point-value representation by taking the discrete Fourier transform (or DFT) of a coefﬁcient vector.
We can perform the inverse operation, interpolation, by taking the “inverse DFT” of point-value pairs, yielding a coefﬁcient vector.
The product of two polynomials of degree-bound n is a polynomial of degree-bound 2n.
Given the FFT, we have the following ‚.n lg n/-time procedure for multiplying two polynomials A.x/ and B.x/ of degree-bound n, where the input and output representations are in coefﬁcient form.
We assume that n is a power of 2; we can always meet this requirement by adding high-order zero coefﬁcients.
Double degree-bound: Create coefﬁcient representations of A.x/ and B.x/ as degree-bound 2n polynomials by adding n high-order zero coefﬁcients to each.
These representations contain the values of the two polynomials at the .2n/th roots of unity.
This representation contains the value of C.x/ at each .2n/th root of unity.
Interpolate: Create the coefﬁcient representation of the polynomial C.x/ by applying the FFT on 2n point-value pairs to compute the inverse DFT.
Thus, once we show how to use the FFT, we will have proven the following.
We want to ﬁnd the elements of C and the number of times each element of C is realized as a sum of elements in A and B.
Show how to solve the problem in O.n lg n/ time.
Hint: Represent A and B as polynomials of degree at most 10n.
In this section, we deﬁne complex roots of unity and study their properties, deﬁne the DFT, and then show how the FFT computes the DFT and its inverse in ‚.n lg n/ time.
Proof The lemma follows directly from equation (30.6), since !dkdn D.
Note that if we square all of the complex nth roots of unity, then we obtain each .n=2/th root of unity exactly twice, since.
As we shall see, the halving lemma is essential to our divide-and-conquer approach for converting between coefﬁcient and point-value representations of polynomials, since it guarantees that the recursive subproblems are only half as large.
Proof Equation (A.5) applies to complex values as well as to reals, and so we have.
In the context of polynomial multiplication, therefore, we are actually working with complex .2n/th roots of unity.
Lines 2–3 represent the basis of the recursion; the DFT of one element is the element itself, since in this case.
Thus, the vector y returned by RECURSIVE-FFT is indeed the DFT of the input vector a.
To determine the running time of procedure RECURSIVE-FFT, we note that exclusive of the recursive calls, each invocation takes time ‚.n/, where n is the length of the input vector.
Thus, we can evaluate a polynomial of degree-bound n at the complex nth roots of unity in time ‚.n lgn/ using the fast Fourier transform.
We now complete the polynomial multiplication scheme by showing how to interpolate the complex roots of unity by a polynomial, which enables us to convert from point-value form back to coefﬁcient form.
We interpolate by writing the DFT as a matrix equation and then looking at the form of the matrix inverse.
From equation (30.4), we can write the DFT as the matrix product y D Vna, where Vn is a Vandermonde matrix containing the appropriate powers of !n:
We see that, by using the FFT and the inverse FFT, we can transform a polynomial of degree-bound n back and forth between its coefﬁcient representation and a point-value representation in time ‚.n lg n/
In the context of polynomial multiplication, we have shown the following.
Give a recurrence for the running time, and solve the recurrence.
Use ! D 2t instead of !n as a principal nth root of unity, modulo m.
Prove that the DFT and the inverse DFT are well deﬁned in this system.
Since the practical applications of the DFT, such as signal processing, demand the utmost speed, this section examines two efﬁcient FFT implementations.
Depending on the exact implementation, the recursive version may use the hardware cache more efﬁciently.
Then, we shall use the insights that led us to the iterative implementation to design an efﬁcient parallel FFT circuit.
We ﬁrst note that the for loop of lines 10–13 of RECURSIVE-FFT involves computing the value !kn y.
We can change the loop to compute it only once, storing it in a temporary variable t.
We now show how to make the FFT algorithm iterative rather than recursive.
The tree has one node for each call of the procedure, labeled.
We will use this representation in a parallel FFT circuit.
Figure 30.4 The tree of input vectors to the recursive calls of the RECURSIVE-FFT procedure.
Each RECURSIVE-FFT invocation makes two recursive calls, unless it has received a 1-element vector.
The ﬁrst call appears in the left child, and the second call appears in the right child.
Looking at the tree, we observe that if we could arrange the elements of the initial vector a into the order in which they appear in the leaves, we could trace the execution of the RECURSIVE-FFT procedure, but bottom up instead of top down.
First, we take the elements in pairs, compute the DFT of each pair using one butterﬂy operation, and replace the pair with its DFT.
We shall show later how to determine this order, which is known as a bit-reversal permutation.
How does BIT-REVERSE-COPY get the elements of the input vector a into the desired order in the array A? The order in which the leaves appear in Figure 30.4
Since we can easily compute the function rev.k/, the BIT-REVERSE-COPY procedure is simple:
We can exploit many of the properties that allowed us to implement an efﬁcient iterative FFT algorithm to produce an efﬁcient parallel algorithm for the FFT.
We will express the parallel FFT algorithm as a circuit.
The circuit begins with a bit-reverse permutation of the inputs, followed by lgn stages, each stage consisting of n=2 butterﬂies executed in parallel.
The depth of the circuit—the maximum number of computational elements between any output and any input that can reach it—is therefore ‚.lg n/
The leftmost part of the parallel FFT circuit performs the bit-reverse permutation, and the remainder mimics the iterative ITERATIVE-FFT procedure.
Because each iteration of the outermost for loop performs n=2 independent butterﬂy operations, the circuit performs them in parallel.
Suppose that exactly one adder has failed, but that you don’t know which one.
Describe how you can identify the failed adder by supplying inputs to the overall FFT circuit and observing the outputs.
Show how to multiply two linear polynomials ax C b and cx C d using only.
The ﬁrst algorithm should divide the input polynomial coefﬁcients into a high half and a low half, and the second algorithm should divide them according to whether their index is odd or even.
Show that the ordering of dimensions does not matter, so that we can compute a d -dimensional DFT by computing the 1-dimensional DFTs in any order of the d dimensions.
Show that if we compute each 1-dimensional DFT by computing the fast Fourier transform, the total time to compute a d -dimensional DFT is O.n lg n/, independent of d.
Given a polynomial A.x/ of degree-bound n, we deﬁne its t th derivative by.
We have seen how to evaluate a polynomial of degree-bound n at a single point in O.n/ time using Horner’s rule.
We have also discovered how to evaluate such a polynomial at all n complex roots of unity in O.n lg n/ time using the FFT.
We shall now show how to evaluate a polynomial of degree-bound n at n arbitrary points in O.n lg2 n/ time.
Suppose that we search for the smallest k such that p D knC 1 is prime.
Give a simple heuristic argument why we might expect k to be approximately ln n.
The value of k might be much larger or smaller, but we can reasonably expect to examine O.lg n/ candidate values of k on average.
How does the expected length of p compare to the length of n?
Show how to make the FFT and its inverse work modulo p in time O.n lg n/, where operations on words of O.lg n/ bits take unit time.
Van Loan’s book [343] provides an outstanding treatment of the fast Fourier transform.
It is widely used in image processing to analyze data in 2 or more dimensions.
Frigo and Johnson [117] developed a fast and ﬂexible implementation of the FFT, called FFTW (“fastest Fourier transform in the West”)
Before actually computing the DFTs, FFTW executes a “planner,” which, by a series of trial runs, determines how best to decompose the FFT computation for the given problem size on the host machine.
Furthermore, FFTW has the unusual advantage of taking ‚.n lg n/ time for any problem size n, even when n is a large prime.
Although the standard Fourier transform assumes that the input represents points that are uniformly spaced in the time domain, other techniques can approximate the FFT on “nonequispaced” data.
Number theory was once viewed as a beautiful but largely useless subject in pure mathematics.
Today number-theoretic algorithms are used widely, due in large part to the invention of cryptographic schemes based on large prime numbers.
These schemes are feasible because we can ﬁnd large primes easily, and they are secure because we do not know how to factor the product of large primes (or solve related problems, such as computing discrete logarithms) efﬁciently.
This chapter presents some of the number theory and related algorithms that underlie such applications.
Because we shall be working with large integers, we need to adjust how we think about the size of an input and about the cost of elementary arithmetic operations.
In this chapter, a “large input” typically means an input containing “large integers” rather than an input containing “many integers” (as for sorting)
We shall generally analyze algorithms in this chapter in terms of both the number of arithmetic operations and the number of bit operations they require.
Every positive integer a is divisible by the trivial divisors 1 and a.
The nontrivial divisors of a are the factors of a.
Primes have many special properties and play a critical role in number theory.
Exercise 31.1-2 asks you to prove that there are inﬁnitely many primes.
We call the integer 1 a unit, and it is neither prime nor composite.
Similarly, the integer 0 and all negative integers are neither prime nor composite.
Given an integer n, we can partition the integers into those that are multiples of n and those that are not multiples of n.
Much number theory is based upon reﬁning this partition by classifying the nonmultiples of n according to their remainders when divided by n.
We omit the proof (but see, for example, Niven and Zuckerman [265])
The value q D ba=nc is the quotient of the division.
The value r D a mod n is the remainder (or residue) of the division.
We can partition the integers into n equivalence classes according to their remainders modulo n.
The equivalence class modulo n containing an integer a is.
If d is a divisor of a and d is also a divisor of b, then d is a common divisor of a and b.
Note that 1 is a common divisor of any two integers.
The greatest common divisor of two integers a and b, not both zero, is the largest of the common divisors of a and b; we denote it by gcd.a; b/
If a and b are both nonzero, then gcd.a; b/ is an integer between 1 and min.jaj ; jbj/
The following theorem provides an alternative and useful characterization of gcd.a; b/
Corollary 31.3 For any integers a and b, if d j a and d j b, then d j gcd.a; b/
The following theorem states that if two integers are each relatively prime to an integer p, then their product is relatively prime to p.
An elementary but important fact about divisibility by primes is the following.
Theorem 31.7 For all primes p and all integers a and b, if p j ab, then p j a or p j b (or both)
A consequence of Theorem 31.7 is that we can uniquely factor any composite integer into a product of primes.
Theorem 31.8 (Unique factorization) There is exactly one way to write any composite integer a as a product of the form.
In this section, we describe Euclid’s algorithm for efﬁciently computing the greatest common divisor of two integers.
When we analyze the running time, we shall see a surprising connection with the Fibonacci numbers, which yield a worst-case input for Euclid’s algorithm.
This restriction is justiﬁed by equation (31.8), which states that gcd.a; b/ D gcd.jaj ; jbj/
In principle, we can compute gcd.a; b/ for positive integers a and b from the prime factorizations of a and b.
Euclid’s algorithm for computing greatest common divisors relies on the following theorem.
Proof We shall show that gcd.a; b/ and gcd.b; a mod b/ divide each other, so that by equation (31.5) they must be equal (since they are both nonnegative)
Showing that gcd.b; a mod b/ j gcd.a; b/ is almost the same.
If we now let d D gcd.b; a mod b/, then d j b and d j .a mod b/
Since a D qb C .a mod b/, where q D ba=bc, we have that a is a linear combination of b and .a mod b/
We express Euclid’s algorithm as a recursive program based directly on Theorem 31.9
The correctness of EUCLID follows from Theorem 31.9 and the property that if.
The algorithm cannot recurse indeﬁnitely, since the second argument strictly decreases in each recursive call and is always nonnegative.
The overall running time of EUCLID is proportional to the number of recursive calls it makes.
Our analysis makes use of the Fibonacci numbers Fk , deﬁned by the recurrence (3.22)
The following theorem is an immediate corollary of this lemma.
We now rewrite Euclid’s algorithm to compute additional useful information.
Speciﬁcally, we extend the algorithm to compute the integer coefﬁcients x and y such that.
We shall ﬁnd these coefﬁcients useful later for computing modular multiplicative inverses.
The procedure EXTENDEDEUCLID takes as input a pair of nonnegative integers and returns a triple of the form .d; x; y/ that satisﬁes equation (31.16)
The EXTENDED-EUCLID procedure is a variation of the EUCLID procedure.
Since the number of recursive calls made in EUCLID is equal to the number of recursive calls made in EXTENDED-EUCLID, the running times of EUCLID and EXTENDED-EUCLID are the same, to within a constant factor.
We can form two ﬁnite abelian groups by using addition and multiplication modulo n, where n is a positive integer.
These groups are based on the equivalence classes of the integers modulo n, deﬁned in Section 31.1
Using this deﬁnition of addition modulo n, we deﬁne the additive group modulo n as .Zn;Cn/
The size of the additive group modulo n is jZnj D n.
The lower bound (31.22) is essentially the best possible, since.
The following theorem provides an extremely useful constraint on the size of a.
The order of a (in the group S), denoted ord.a/, is deﬁned as the smallest positive integer t such that a.t/ D e.
Consistent with the above corollary, we deﬁne a.0/ as e and a.i/ as a.i mod t/, where t D ord.a/, for all integers i.
We now consider the problem of ﬁnding solutions to the equation.
The following corollaries of Theorem 31.24 give specializations of particular interest.
If b D 1, a common case of considerable interest, the x we are looking for is a multiplicative inverse of a, modulo n.
We shall use the following corollaries later in this chapter.
As an example of the application of the Chinese remainder theorem, suppose we are given the two equations.
Thus, we can work modulo n by working modulo n directly or by working in the.
We now turn our attention to the square roots of 1, modulo a prime power.
The following theorem will be useful in our development of a primality-testing algorithm in Section 31.8
A frequently occurring operation in number-theoretic computations is raising one number to a power modulo another number, also known as modular exponentiation.
More precisely, we would like an efﬁcient way to compute ab mod n, where a and b are nonnegative integers and n is a positive integer.
Modular exponentiation is an essential operation in many primality-testing routines and in the RSA public-key cryptosystem.
The method of repeated squaring solves this problem efﬁciently using the binary representation of b.
The values are shown after each execution of the for loop.
The following procedure computes ac mod n as c is increased by doublings and incrementations from 0 to b.
The variable c is not really needed by the algorithm but is included for the following two-part loop invariant:
In either case, d D ac mod n prior to the next iteration.
With a public-key cryptosystem, we can encrypt messages sent between two communicating parties so that an eavesdropper who overhears the encrypted messages will not be able to decode them.
A public-key cryptosystem also enables a party to append an unforgeable “digital signature” to the end of an electronic message.
Such a signature is the electronic version of a handwritten signature on a paper document.
It can be easily checked by anyone, forged by no one, yet loses its validity if any bit of the message is altered.
It therefore provides authentication of both the identity of the signer and the contents of the signed message.
The RSA public-key cryptosystem relies on the dramatic difference between the ease of ﬁnding large prime numbers and the difﬁculty of factoring the product of two large prime numbers.
In a public-key cryptosystem, each participant has both a public key and a secret key.
For example, in the RSA cryptosystem, each key consists of a pair of integers.
The participants “Alice” and “Bob” are traditionally used in cryptography examples; we denote their public and secret keys as PA, SA for Alice and PB , SB for Bob.
Each participant creates his or her own public and secret keys.
Secret keys are kept secret, but public keys can be revealed to anyone or even published.
In fact, it is often convenient to assume that everyone’s public key is available in a public directory, so that any participant can easily obtain the public key of any other participant.
The public and secret keys specify functions that can be applied to any message.
For example, D might be the set of all ﬁnite-length bit sequences.
In the simplest, and original, formulation of publickey cryptography, we require that the public and secret keys specify one-to-one functions from D to itself.
We denote the function corresponding to Alice’s public key PA by PA./ and the function corresponding to her secret key SA by SA./
The functions PA./ and SA./ are thus permutations of D.
We assume that the functions PA./ and SA./ are efﬁciently computable given the corresponding key PA or SA.
The public and secret keys for any participant are a “matched pair” in that they specify functions that are inverses of each other.
Transforming M with the two keys PA and SA successively, in either order, yields the message M back.
In a public-key cryptosystem, we require that no one but Alice be able to compute the function SA./ in any practical amount of time.
This assumption is crucial to keeping encrypted mail sent to Alice private and to knowing that Alice’s digital signatures are authentic.
Alice must keep SA secret; if she does not, she loses her uniqueness and the cryptosystem cannot provide her with unique capabilities.
The assumption that only Alice can compute SA./ must hold even though everyone.
Bob encrypts the message M using Alice’s public key PA and transmits the resulting ciphertext C D PA.M/ over a communication channel to Alice.
An eavesdropper who captures the transmitted ciphertext gains no information about M.
Alice receives C and decrypts it using her secret key to obtain the original message M D SA.C /
In order to design a workable public-key cryptosystem, we must ﬁgure out how to create a system in which we can reveal a transformation PA./ without thereby revealing how to compute the corresponding inverse transformation SA./
This task appears formidable, but we shall see how to accomplish it.
Because only Alice is able to compute SA./, Alice is the only one who can compute M from C.
Because Bob encrypts M using PA./, only Alice can understand the transmitted message.
Because a digital signature provides both authentication of the signer’s identity and authentication of the contents of the signed message, it is analogous to a handwritten signature at the end of a written document.
A digital signature must be veriﬁable by anyone who has access to the signer’s public key.
A signed message can be veriﬁed by one party and then passed on to other parties who can also verify the signature.
For example, the message might be an electronic check from Alice to Bob.
After Bob veriﬁes Alice’s signature on the check, he can give the check to his bank, who can then also verify the signature and effect the appropriate funds transfer.
A signed message is not necessarily encrypted; the message can be “in the clear” and not protected from disclosure.
By composing the above protocols for encryption and for signatures, we can create messages that are both signed and encrypted.
The signer ﬁrst appends his or her digital signature to the message and then encrypts the resulting message/signature pair with the public key of the intended recipient.
The recipient decrypts the received message with his or her secret key to obtain both the original message and its digital signature.
The recipient can then verify the signature using the public key of the signer.
The corresponding combined process using paper-based systems would be to sign the paper document and.
In the RSA public-key cryptosystem, a participant creates his or her public and secret keys with the following procedure:
Publish the pair P D .e; n/ as the participant’s RSA public key.
Keep secret the pair S D .d; n/ as the participant’s RSA secret key.
For this scheme, the domain D is the set Zn.
To create a signature, the signer applies his or her secret key to the message to be signed, rather than to a ciphertext.
To verify a signature, the public key of the signer is applied to it, rather than to a message to be encrypted.
The security of the RSA cryptosystem rests in large part on the difﬁculty of factoring large integers.
If an adversary can factor the modulus n in a public key, then the adversary can derive the secret key from the public key, using the knowledge of the factors p and q in the same way that the creator of the public key used them.
Therefore, if factoring large integers is easy, then breaking the RSA cryptosystem is easy.
The converse statement, that if factoring large integers is hard, then breaking RSA is hard, is unproven.
After two decades of research, however, no easier method has been found to break the RSA public-key cryptosystem than to factor the modulus n.
And as we shall see in Section 31.9, factoring large integers is surprisingly difﬁcult.
By randomly selecting and multiplying together two 1024-bit primes, we can create a public key that cannot be “broken” in any feasible amount of time with current technology.
In the absence of a fundamental breakthrough in the design of number-theoretic algorithms, and when implemented with care following recommended standards, the RSA cryptosystem is capable of providing a high degree of security in applications.
In order to achieve security with the RSA cryptosystem, however, we should use integers that are quite long—hundreds or even more than one thousand bits.
To create moduli of such sizes, we must be able to ﬁnd large primes efﬁciently.
For efﬁciency, RSA is often used in a “hybrid” or “key-management” mode with fast non-public-key cryptosystems.
With such a system, the encryption and decryption keys are identical.
If Alice wishes to send a long message M to Bob privately, she selects a random key K for the fast non-public-key cryptosystem and encrypts M using K, obtaining ciphertext C.
Here, C is as long as M , but K is quite short.
Since K is short, computing PB.K/ is fast (much faster than computing PB.M/)
She then transmits .C;PB.K// to Bob, who decrypts PB.K/ to obtain K and then uses K to decrypt C , obtaining M.
We can use a similar hybrid approach to make digital signatures efﬁciently.
The value h.M/ is a short (say, 256-bit) “ﬁngerprint” of the message M.
If Alice wishes to sign a message M , she ﬁrst applies h to M to obtain the ﬁngerprint h.M/, which she then encrypts with her secret key.
She sends .M;SA.h.M/// to Bob as her signed version of M.
Bob can verify the signature by computing h.M/ and verifying that PA applied to SA.h.M// as received equals h.M/
Because no one can create two messages with the same ﬁngerprint, it is computationally infeasible to alter a signed message and preserve the validity of the signature.
Finally, we note that the use of certiﬁcates makes distributing public keys much easier.
For example, assume there is a “trusted authority” T whose public key is known by everyone.
Alice can include her certiﬁcate with her signed messages, so that the recipient has Alice’s public key immediately available in order to verify her signature.
Because her key was signed by T , the recipient knows that Alice’s key is really Alice’s.
What value of d should be used in the secret key? What is the encryption of the message M D 100?
In this section, we consider the problem of ﬁnding large primes.
We begin with a discussion of the density of primes, proceed to examine a plausible, but incomplete, approach to primality testing, and then present an effective randomized primality test due to Miller and Rabin.
In the remainder of this section, we consider the problem of determining whether or not a large odd integer n is prime.
For notational convenience, we assume that n has the prime factorization.
One simple approach to the problem of testing for primality is trial division.
It is easy to see that n is prime if and only if none of the trial divisors divides n.
Assuming that each trial division takes constant time, the worst-case running time is ‚
In this section, we are interested only in ﬁnding out whether a given number n is prime; if n is composite, we are not concerned with ﬁnding its prime factorization.
As we shall see in Section 31.9, computing the prime factorization of a number is computationally expensive.
It is perhaps surprising that it is much easier to tell whether or not a given number is prime than it is to determine the prime factorization of the number if it is not prime.
We now consider a method for primality testing that “almost works” and in fact is good enough for many practical applications.
The following procedure pretends in this manner to be checking the primality of n.
This procedure can make errors, but only of one type.
That is, if it says that n is composite, then it is always correct.
If it says that n is prime, however, then it makes an error only if n is a base-2 pseudoprime.
As we shall see, a little more cleverness, and some randomization, will yield a primality-testing routine that works well on all inputs.
We next show how to improve our primality test so that it won’t be fooled by Carmichael numbers.
We now argue that if WITNESS.a; n/ returns TRUE, then we can construct a proof that n is composite using a as a witness.
We now examine the Miller-Rabin primality test based on the use of WITNESS.
The procedure MILLER-RABIN is a probabilistic search for a proof that n is composite.
Such a result is always correct, by the correctness of WITNESS.
If MILLER-RABIN ﬁnds no witness in s trials, then the procedure assumes that this is because no witnesses exist, and therefore it assumes that n is prime.
We shall see that this result is likely to be correct if s is large enough, but that there is still a tiny chance that the procedure may be unlucky in its choice of a’s and that witnesses do exist even though none has been found.
If MILLER-RABIN returns PRIME, then there is a very slim chance that it has made an error.
Unlike PSEUDOPRIME, however, the chance of error does not depend on n; there are no bad inputs for this procedure.
Rather, it depends on the size of s and the “luck of the draw” in choosing base values a.
Moreover, since each test is more stringent than a simple check of equation (31.40), we can expect on general principles that the error rate should be small for randomly chosen integers n.
Because, as we noted earlier, Carmichael numbers are extremely rare, case 1 is the main case that arises “in practice” (e.g., when n has been chosen randomly and is being tested for primality)
But what is Pr fA j Bg, the probability that n is prime, given that MILLERRABIN has returned PRIME? By the alternate form of Bayes’s theorem (equation (C.18)) we have.
In any case, choosing s D 50 should sufﬁce for almost any imaginable application.
If we are trying to ﬁnd large primes by applying MILLER-RABIN to large randomly chosen odd integers, then choosing a small value of s (say 3) is very unlikely to lead to erroneous results, though.
Suppose we have an integer n that we wish to factor, that is, to decompose into a product of primes.
The primality test of the preceding section may tell us that n is composite, but it does not tell us the prime factors of n.
Factoring a large integer n seems to be much more difﬁcult than simply determining whether n is prime or composite.
Even with today’s supercomputers and the best algorithms to date, we cannot feasibly factor an arbitrary 1024-bit number.
The while loop beginning on line 5 iterates forever, searching for factors of n.
During each iteration of the while loop, line 7 uses the recurrence.
The pseudocode is written using subscripted variables xi for clarity, but the program works the same if all of the subscripts are dropped, since only the most recent value of xi needs to be maintained.
With this modiﬁcation, the procedure uses only a constant number of memory locations.
Every so often, the program saves the most recently generated xi value in the variable y.
Speciﬁcally, the values that are saved are the ones whose subscripts are powers of 2:
This procedure for ﬁnding a factor may seem somewhat mysterious at ﬁrst.
Note, however, that POLLARD-RHO never prints an incorrect answer; any number it prints is a nontrivial divisor of n.
POLLARD-RHO might not print anything at all, though; it comes with no guarantee that it will print any divisors.
We shall see, however, that we have good reason to expect POLLARD-RHO to print a factor p of n after ‚.pp/ iterations of the while loop.
Thus, if n is composite, we can expect this procedure to discover enough divisors to factor n completely after approximately n1=4 updates, since every prime factor p of n except possibly the largest one is less than.
Let us consider the question of how long it takes for the sequence of xi to repeat.
This information is not exactly what we need, but we shall see later how to modify the argument.
For the purpose of this estimation, let us assume that the function.
Thus, although we are not explicitly computing the sequence hx 0ii, this sequence is well deﬁned and obeys the same recurrence as the sequence hxii.
If p is small compared to n, the sequence hx 0iimight.
Presumably, the factor found is the factor p, although it may occasionally happen that a multiple of p is discovered.
Since the expected values of both t and u are ‚
This algorithm might not perform quite as expected, for two reasons.
In this case, the algorithm performs correctly but much more slowly than desired.
Second, the divisors of n produced by this algorithm might always be one of the trivial factors 1 or n.
For example, suppose that n D pq, where p and q are prime.
It can happen that the values of t and u for p are identical with the values of t and u for q, and thus the factor p is always revealed in the same gcd operation that reveals the factor q.
Most computers can perform the operations of subtraction, testing the parity (odd or even) of a binary integer, and halving more quickly than computing remainders.
This problem investigates the binary gcd algorithm, which avoids the remainder computations used in Euclid’s algorithm.
Prove that if a is odd and b is even, then gcd.a; b/ D gcd.a; b=2/
Consider the ordinary “paper and pencil” algorithm for long division: dividing.
Show that this method requires O..1C lg q/ lg b/ bit operations.
This problem compares the efﬁciency of three methods for computing the nth Fibonacci number Fn, given n.
Assume that the cost of adding, subtracting, or multiplying two numbers is O.1/, independent of the size of the numbers.
Show that the running time of the straightforward recursive method for computing Fn based on recurrence (3.22) is exponential in n.
Show how to compute Fn in O.n/ time using memoization.
Give an efﬁcient algorithm that determines whether a given number a is a quadratic residue modulo p.
Niven and Zuckerman [265] provide an excellent introduction to elementary number theory.
Knuth [210] contains a good discussion of algorithms for ﬁnding the.
Dixon [91] gives an overview of factorization and primality testing.
The conference proceedings edited by Pomerance [280] contains several excellent survey articles.
More recently, Bach and Shallit [31] have provided an exceptional overview of the basics of computational number theory.
Euclid’s description may have been derived from an algorithm due to Eudoxus around 375 B.C.
Euclid’s algorithm may hold the honor of being the oldest nontrivial algorithm; it is rivaled only by an algorithm for multiplication known to the ancient Egyptians.
Shallit [312] chronicles the history of the analysis of Euclid’s algorithm.
For many years primality-testing was the classic example of a problem where randomization appeared to be necessary to obtain an efﬁcient (polynomial-time) algorithm.
Until then, the fastest deterministic primality testing algorithm known, due to Cohen and Lenstra [73], ran in time .lgn/O.lg lg lg n/ on input n, which is just slightly superpolynomial.
Nonetheless, for practical purposes randomized primality-testing algorithms remain more efﬁcient and are preferred.
The concept of a public-key cryptosystem is due to Difﬁe and Hellman [87]
Our understanding of the RSA cryptosystem has deepened, and modern implementations use significant reﬁnements of the basic techniques presented here.
In addition, many new techniques have been developed for proving cryptosystems to be secure.
For example, Goldwasser and Micali [142] show that randomization can be an effective tool in the design of secure public-key encryption schemes.
Goldwasser, Micali, and Rivest [143] present a digital-signature scheme for which every conceivable type of forgery is provably as difﬁcult as factoring.
Menezes, van Oorschot, and Vanstone [254] provide an overview of applied cryptography.
The rho heuristic for integer factorization was invented by Pollard [277]
The version presented here is a variant proposed by Brent [56]
The elliptic-curve method due to Lenstra [233] may be more effective for some inputs than the number-ﬁeld sieve method, since, like Pollard’s rho method, it can ﬁnd a small prime factor p quite quickly.
With this method, the time to ﬁnd p is estimated to be L.1=2; p/
Text-editing programs frequently need to ﬁnd all occurrences of a pattern in the text.
Typically, the text is a document being edited, and the pattern searched for is a particular word supplied by the user.
Efﬁcient algorithms for this problem—called “string matching”—can greatly aid the responsiveness of the text-editing program.
Among their many other applications, string-matching algorithms search for particular patterns in DNA sequences.
Internet search engines also use them to ﬁnd Web pages relevant to queries.
Figure 32.1 An example of the string-matching problem, where we want to ﬁnd all occurrences of the pattern P D abaa in the text T D abcabaabcabac.
The pattern occurs only once in the text, at shift s D 3, which we call a valid shift.
A vertical line connects each character of the pattern to its matching character in the text, and all matched characters are shaded.
Figure 32.2 The string-matching algorithms in this chapter and their preprocessing and matching times.
Figure 32.4 portrays the naive string-matching procedure as sliding a “template” containing the pattern over the text, noting for which shifts all of the characters on the template equal the corresponding characters in the text.
The for loop of lines 3–5 considers each possible shift explicitly.
The test in line 4 determines whether the current shift is valid; this test implicitly loops to check corresponding character positions until all positions match successfully or a mismatch is found.
Figure 32.4 The operation of the naive string matcher for the pattern P D aab and the text T D acaabc.
We can imagine the pattern P as a template that we slide next to the text.
In each part, vertical lines connect corresponding regions found to match (shown shaded), and a jagged line connects the ﬁrst mismatched character found, if any.
The algorithm ﬁnds one occurrence of the pattern, at shift s D 2, shown in part (c)
Assume that the naive algorithm stops comparing characters for a given shift once it ﬁnds a mismatch or matches the entire pattern.
Thus, for randomly chosen strings, the naive algorithm is quite efﬁcient.
Note that the gap character may occur an arbitrary number of times in the pattern but not at all in the text.
Give a polynomial-time algorithm to determine whether such a pattern P occurs in a given text T , and analyze the running time of your algorithm.
This algorithm makes use of elementary number-theoretic notions such as the equivalence of two numbers modulo a third number.
You might want to refer to Section 31.1 for the relevant deﬁnitions.
In the general case, we can assume that each character is a digit in radix-d notation, where d D j†j.
We can then view a string of k consecutive characters as representing a length-k decimal number.
Because we interpret the input characters as both graphical symbols and digits, we ﬁnd it convenient in this section to denote them as we would digits, in our standard text font.
The inputs to the procedure are the text T , the pattern P , the radix d to use (which is typically taken to be j†j), and the prime q to use.
Then generalize your solution to allow the patterns to have different lengths.
Many string-matching algorithms build a ﬁnite automaton—a simple machine for processing information—that scans the text string T for all occurrences of the pattern P.
This section presents a method for building such an automaton.
These string-matching automata are very efﬁcient: they examine each text character exactly once, taking constant time per text character.
The matching time used—after preprocessing the pattern to build the automaton—is therefore ‚.n/
The time to build the automaton, however, can be large if † is large.
We begin this section with the deﬁnition of a ﬁnite automaton.
We then examine a special string-matching automaton and show how to use it to ﬁnd occurrences of a pattern in a text.
Finally, we shall show how to construct the string-matching automaton for a given input pattern.
For a given pattern P , we construct a string-matching automaton in a preprocessing step before using it to search the text string.
Figure 32.7 illustrates how we construct the automaton for the pattern P D ababaca.
From now on, we shall assume that P is a given ﬁxed pattern string; for brevity, we shall not indicate the dependence upon P in our notation.
We are now ready to prove our main theorem characterizing the behavior of a string-matching automaton on a given input text.
As noted above, this theorem shows that the automaton is merely keeping track, at each step, of the longest preﬁx of the pattern that is a sufﬁx of what has been read so far.
Try to minimize the number of states in your automaton.
Figure 32.10(a) shows a particular shift s of a template containing the pattern P D ababaca against a text T.
The information that q characters have matched successfully determines the corresponding text characters.
Knowing these q text characters allows us to determine immediately that certain shifts are invalid.
In the example of the ﬁgure, the shift s C 1 is necessarily invalid, since the ﬁrst pattern character (a) would be aligned with a text character that we know does not match the ﬁrst pattern character, but does match the second pattern character (b)
In general, it is useful to know the answer to the following question:
We begin with an analysis of the running times of these procedures.
Explain why the modiﬁed algorithm is correct, and explain in what sense this change constitutes an improvement.
For example, arc and car are cyclic rotations of each other.
By extending these ideas greatly, they obtained a linear-time string-matching algorithm that uses only O.1/ storage beyond what is required for P and T.
The relation of string matching to the theory of ﬁnite automata is discussed by Aho, Hopcroft, and Ullman [5]
The Knuth-Morris-Pratt algorithm [214] was invented independently by Knuth and Pratt and by Morris; they published their work jointly.
Reingold, Urban, and Gries [294] give an alternative treatment of the Knuth-Morris-Pratt algorithm.
The Rabin-Karp algorithm was proposed by Karp and Rabin [201]
Computational geometry is the branch of computer science that studies algorithms for solving geometric problems.
In modern engineering and mathematics, computational geometry has applications in such diverse ﬁelds as computer graphics, robotics, VLSI design, computer-aided design, molecular modeling, metallurgy, manufacturing, textile layout, forestry, and statistics.
The output is often a response to a query about the objects, such as whether any of the lines intersect, or perhaps a new geometric object, such as the convex hull (smallest enclosing convex polygon) of the set of points.
Section 33.1 shows how to answer basic questions about line segments efﬁciently and accurately: whether one segment is clockwise or counterclockwise from another that shares an endpoint, which way we turn when traversing two adjoining line segments, and whether two line segments intersect.
Section 33.2 presents a technique called “sweeping” that we use to develop an O.n lg n/-time algorithm for determining whether a set of n line segments contains any intersections.
Section 33.3 gives two “rotational-sweep” algorithms that compute the convex hull (smallest enclosing convex polygon) of a set of n points: Graham’s scan, which runs in time O.n lg n/, and Jarvis’s march, which takes O.nh/ time, where h is the number of vertices of the convex hull.
We can answer each question in O.1/ time, which should come as no surprise.
Moreover, our methods use only additions, subtractions, multiplications, and comparisons.
We need neither division nor trigonometric functions, both of which can be computationally expensive and prone to problems with round-off error.
For example, the “straightforward” method of determining whether two segments intersect—compute the line equation of the form y D mx C b for each segment (m is the slope and b is the y-intercept), ﬁnd the point of intersection of the lines, and check whether this point is on both segments—uses division to ﬁnd the point of intersection.
When the segments are nearly parallel, this method is very sensitive to the precision of the division operation on real computers.
The method in this section, which avoids division, is much more accurate.
The darkly shaded region contains vectors that are counterclockwise from p.
To determine whether two line segments intersect, we check whether each segment straddles the line containing the other.
It calls the subroutines DIRECTION, which computes relative orientations using the crossproduct method above, and ON-SEGMENT, which determines whether a point known to be colinear with a segment lies on that segment.
If all the relative orientations are nonzero, no boundary case applies.
Here, we know that pk is colinear with the other segment.
It is directly on the other segment if and only if it is between the endpoints of the other segment.
The procedure ON-SEGMENT returns whether pk is between the endpoints of segment pipj , which will be the other segment when called in lines 7–13; the procedure assumes that pk is colinear with segment pipj.
Later sections of this chapter introduce additional uses for cross products.
In Section 33.3, we shall need to sort a set of points according to their polar angles with respect to a given origin.
As Exercise 33.1-3 asks you to show, we can use cross products to perform the comparisons in the sorting procedure.
In Section 33.2, we shall use red-black trees to maintain the vertical ordering of a set of line segments.
Rather than keeping explicit key values which we compare to each other in the red-black tree code, we shall compute a cross-product to determine which of two segments that intersect a given vertical line is above the other.
That is, it is a curve ending on itself that is formed by a sequence of straight-line segments, called the sides of the polygon.
A point joining two consecutive sides is a vertex of the polygon.
If the polygon is simple, as we shall generally assume, it does not cross itself.
The set of points in the plane enclosed by a simple polygon forms the interior of.
A simple polygon is convex if, given any two points on its boundary or in its interior, all points on the line segment drawn between them are contained in the polygon’s boundary or interior.
A vertex of a convex polygon cannot be expressed as a convex combination of any two distinct points on the boundary or in the interior of the polygon.
Make sure your algorithm is correct when the ray intersects the polygon boundary at a vertex and when the ray overlaps a side of the polygon.
This section presents an algorithm for determining whether any two line segments in a set of segments intersect.
In sweeping, an imaginary vertical sweep line passes through the given set of geometric objects, usually from left to right.
We treat the spatial dimension that the sweep line moves across, in this case the x-dimension, as a dimension of time.
Sweeping provides a method for ordering geometric objects, usually by placing them into a dynamic data structure, and for taking advantage of relationships among them.
To describe and prove correct our algorithm for determining whether any two of n line segments intersect, we shall make two simplifying assumptions.
Second, we assume that no three input segments intersect at a single point.
Because we assume that there are no vertical segments, we know that any input segment intersecting a given vertical sweep line intersects it at a single point.
Thus, we can order the segments that intersect a vertical sweep line according to the ycoordinates of the points of intersection.
We say that these segments are comparable at x if the vertical sweep line with x-coordinate x intersects both of them.
The total preorder may differ for differing values of x, however, as segments enter and leave the ordering.
A segment enters the ordering when its left endpoint is encountered by the sweep, and it leaves the ordering when its right endpoint is encountered.
The sweep-line status gives the relationships among the objects that the sweep line intersects.
The event-point schedule is a sequence of points, called event points, which we order from left to right according to their x-coordinates.
As the sweep progresses from left to right, whenever the sweep line reaches the x-coordinate of an event point, the sweep halts, processes the event point, and then resumes.
Changes to the sweep-line status occur only at event points.
For some algorithms (the algorithm asked for in Exercise 33.2-7, for example), the event-point schedule develops dynamically as the algorithm progresses.
The algorithm at hand, however, determines all the event points before the sweep, based.
We sort the segment endpoints by increasing x-coordinate and proceed from left to right.
If two or more endpoints are covertical, i.e., they have the same x-coordinate, we break the tie by putting all the covertical left endpoints before the covertical right endpoints.
Within a set of covertical left endpoints, we put those with lower y-coordinates ﬁrst, and we do the same within a set of covertical right endpoints.
When we encounter a segment’s left endpoint, we insert the segment into the sweep-line status, and we delete the segment from the sweep-line status upon encountering its right endpoint.
Whenever two segments ﬁrst become consecutive in the total preorder, we check whether they intersect.
In this case, the two segments may appear in either order in T.
If the input contains n segments, we can perform each of the operations INSERT, DELETE, ABOVE, and BELOW in O.lg n/ time using red-black trees.
Recall that the red-black-tree operations in Chapter 13 involve comparing keys.
We can replace the key comparisons by comparisons that use cross products to determine the relative ordering of two segments (see Exercise 33.2-2)
The following algorithm takes as input a set S of n line segments, returning the boolean value TRUE if any pair of segments in S intersects, and FALSE otherwise.
INSERT.T; s/ 6 if (ABOVE.T; s/ exists and intersects s)
Each iteration of the for loop of lines 3–11 processes one event point p.
A boundary condition occurs if p lies on another segment s0
In this case, we require only that s and s0 be placed consecutively into T.
If p is the right endpoint of a segment s, then we need to delete s from the total preorder.
But ﬁrst, lines 9–10 return TRUE if there is an intersection between the segments surrounding s in the total preorder deﬁned by the sweep line passing through p.
If these segments do not intersect, line 11 deletes segment s from the total preorder.
The correctness argument, which follows, will make it clear why it sufﬁces to check the segments surrounding s.
Each dashed line is the sweep line at an event point.
Except for the rightmost sweep line, the ordering of segment names below each sweep line corresponds to the total preorder T at the end of the for loop processing the corresponding event point.
The rightmost sweep line occurs when processing the right endpoint of segment c; because segments d and b surround c and intersect each other, the procedure returns TRUE.
If we allow three segments to intersect at the same point, there may be an intervening segment c that intersects both a and b at point p.
Either a or b is inserted into T , and the other segment is above or below it in the total preorder.
Segments a and b are already in T , and a segment between them in the total preorder is deleted, making a and b become consecutive.
Line 2 takes O.n lg n/ time, using merge sort or heapsort.
Hint: If a and b do not intersect, you can just use cross products.
If a and b intersect—which you can of course determine using only cross products—you can still use only addition, subtraction, and multiplication, avoiding division.
Of course, in the application of the <x relation used here, if a and b intersect, we can just stop and declare that we have found an intersection.
Professor Dixon disagrees, claiming that Professor Mason’s idea is incorrect.
Two disks intersect if they have any point in common.
Give an O.n lg n/time algorithm to determine whether any two disks in a set of n intersect.
How does your answer to Exercise 33.2-2 change if we allow vertical segments?
The convex hull of a set Q of points, denoted by CH.Q/, is the smallest convex polygon P for which each point in Q is either on the boundary of P or in its interior.
See Exercise 33.1-5 for a precise deﬁnition of a convex polygon.
We implicitly assume that all points in the set Q are unique and that Q contains at least three points which are not colinear.
Intuitively, we can think of each point in Q as being a nail sticking out from a board.
The convex hull is then the shape formed by a tight rubber band that surrounds all the nails.
Figure 33.6 shows a set of points and its convex hull.
In this section, we shall present two algorithms that compute the convex hull of a set of n points.
Both algorithms output the vertices of the convex hull in counterclockwise order.
The ﬁrst, known as Graham’s scan, runs in O.n lg n/ time.
The second, called Jarvis’s march, runs in O.nh/ time, where h is the number of vertices of the convex hull.
As Figure 33.6 illustrates, every vertex of CH.Q/ is a.
Both algorithms exploit this property, deciding which vertices in Q to keep as vertices of the convex hull and which vertices in Q to reject.
The prune-and-search method is similar to the worst-case linear-time median algorithm of Section 9.3
With this method, we ﬁnd the upper portion (or “upper chain”) of the convex hull by repeatedly throwing out a constant fraction of the remaining points until only the upper chain of the convex hull remains.
This method is asymptotically the fastest: if the convex hull contains h vertices, it runs in only O.n lg h/ time.
Computing the convex hull of a set of points is an interesting problem in its own right.
Consider, for example, the two-dimensional farthestpair problem: we are given a set of n points in the plane and wish to ﬁnd the two points whose distance from each other is maximum.
As Exercise 33.3-3 asks you to prove, these two points must be vertices of the convex hull.
Although we won’t prove it here, we can ﬁnd the farthest pair of vertices of an n-vertex convex polygon in O.n/ time.
Thus, by computing the convex hull of the n input points in O.n lg n/ time and then ﬁnding the farthest pair of the resulting convex-polygon vertices, we can ﬁnd the farthest pair of points in any set of n points in O.n lg n/ time.
Graham’s scan solves the convex-hull problem by maintaining a stack S of candidate points.
When the algorithm terminates, stack S contains exactly the vertices of CH.Q/, in counterclockwise order of their appearance on the boundary.
The current convex hull contained in stack S is shown in gray at each step.
Dashed lines show nonleft turns, which cause points to be popped from the stack.
The while loop of lines 8–9 removes points from the stack if we ﬁnd them not to be vertices of the convex hull.
When we traverse the convex hull counterclockwise, we should make a left turn at each vertex.
Thus, each time the while loop ﬁnds a vertex at which we make a nonleft turn, we pop the vertex from the stack.
By checking for a nonleft turn, rather than just a right turn, this test precludes the possibility of a straight angle at a vertex of the resulting convex hull.
We want no straight angles, since no vertex of a convex polygon may be a convex combination of other vertices of the polygon.
After we pop all vertices that have nonleft turns when heading toward point pi , we push pi onto the stack.
Figures 33.7(b)–(k) show the state of the stack S after each iteration of the for loop.
Moreover, they appear in counterclockwise order from bottom to top.
Clearly, since pt is within a triangle formed by three other points of Qi , it cannot be a vertex of CH.Qi/
Since pt is not a vertex of CH.Qi /, we have that.
Termination: When the loop terminates, we have i D m C 1, and so the loop invariant implies that stack S consists of exactly the vertices of CH.Qm/, which is CH.Q/, in counterclockwise order from bottom to top.
We choose the ﬁrst vertex as the lowest point p0
The right chain goes as high as the highest point p3
Then, we construct the left chain by ﬁnding smallest polar angles with respect to the negative x-axis.
Jarvis’s march Jarvis’s march computes the convex hull of a set Q of points by a technique known as package wrapping (or gift wrapping)
The algorithm runs in time O.nh/, where h is the number of vertices of CH.Q/
When h is o.lg n/, Jarvis’s march is asymptotically faster than Graham’s scan.
Intuitively, Jarvis’s march simulates wrapping a taut piece of paper around the set Q.
We start by taping the end of the paper to the lowest point in the set, that is, to the same point p0 with which we start Graham’s scan.
We know that this point must be a vertex of the convex hull.
We pull the paper to the right to make it taut, and then we pull it higher until it touches a point.
This point must also be a vertex of the convex hull.
Keeping the paper taut, we continue in this way around the set of vertices until we come back to our original point p0
When we reach the highest vertex, say pk (breaking ties by choosing the farthest such vertex), we have constructed, as Figure 33.9 shows, the right chain of CH.Q/
To construct the left chain, we start at pk and choose pkC1 as the point with the smallest polar angle with respect to pk, but from the negative x-axis.
We continue on, forming the left chain by taking polar angles from the negative x-axis, until we come back to our original vertex p0
If implemented properly, Jarvis’s march has a running time of O.nh/
For each of the h vertices of CH.Q/, we ﬁnd the vertex with the minimum polar angle.
As Figure 33.10 illustrates, a polygon P is star-shaped if there exists a point p in the interior of P that is in the shadow of every point on the boundary of P.
The set of all such points p is called the kernel of P.
The segment from point p to any point q on the boundary intersects the boundary only at q.
The shaded region on the left is the shadow of q, and the shaded region on the right is the shadow of q0
After receiving each point, we compute the convex hull of the points seen so far.
Obviously, we could run Graham’s scan once for each point, with a total running time of O.n2 lg n/
Show how to solve the on-line convex-hull problem in a total of O.n2/ time.
A system for controlling air or sea trafﬁc might need to identify the two closest vehicles in order to detect potential collisions.
In this section, we shall describe a divide-and-conquer algorithm for.
Divide: Find a vertical line l that bisects the point set P into two sets PL and PR such that jPLj D djP j =2e, jPRj D bjP j =2c, all points in PL are on or to the left of line l , and all points in PR are on or to the right of l.
Divide the array X into arrays XL and XR, which contain the points of PL and PR respectively, sorted by monotonically increasing x-coordinate.
Similarly, divide the array Y into arrays YL and YR, which contain the points of PL and PR respectively, sorted by monotonically increasing y-coordinate.
The above description omits some implementation details that are necessary to achieve the O.n lg n/ running time.
After proving the correctness of the algorithm, we shall show how to implement the algorithm to achieve the desired time bound.
Still assuming that the closest pair is pL and pR, let us assume without.
Thus, we have shown the correctness of the closest-pair algorithm.
The main difﬁculty comes from ensuring that the arrays XL, XR, YL, and YR, which are passed to recursive calls, are sorted by the proper coordinate and also that the array Y 0 is sorted by y-coordinate.
Note that if the array X that is received by a recursive call is already sorted, then we can easily divide set P into PL and PR in linear time.
The key observation is that in each call, we wish to form a sorted subset of a sorted array.
For example, a particular invocation receives the subset P and the array Y , sorted by y-coordinate.
Having partitioned P into PL and PR, it needs to form the arrays YL and YR, which are sorted by y-coordinate, in linear time.
We can view the method as the opposite of the MERGE procedure from merge sort in.
Section 2.3.1: we are splitting a sorted array into two sorted arrays.
The only remaining question is how to get the points sorted in the ﬁrst place.
We presort them; that is, we sort them once and for all before the ﬁrst recursive call.
We pass these sorted arrays into the ﬁrst recursive call, and from there we whittle them down through the recursive calls as necessary.
Presorting adds an additional O.n lg n/ term to the running time, but now each step of the recursion takes linear time exclusive of the recursive calls.
Hint: Merge sorted arrays YL and YR to form the sorted array Y.
Give an O.n2/-time algorithm to ﬁnd the convex layers of a set of n points.
Describe an O.n lg n/-time algorithm to compute the maximal layers of a set Q.
Do any difﬁculties arise if we now allow input points to have the same x- or.
Each Ghostbuster carries a proton pack, which shoots a stream at a ghost, eradicating it.
A stream goes in a straight line and terminates when it hits the ghost.
They will pair off with the ghosts, forming n Ghostbuster-ghost pairs, and then simultaneously each Ghostbuster will shoot a stream at his chosen ghost.
As we all know, it is very dangerous to let streams cross, and so the Ghostbusters must choose pairings for which no streams will cross.
Assume that the position of each Ghostbuster and each ghost is a ﬁxed point in the plane and that no three positions are colinear.
Argue that there exists a line passing through one Ghostbuster and one ghost.
Describe how to ﬁnd such a line in O.n lg n/ time.
Give an O.n2 lg n/-time algorithm to pair Ghostbusters with ghosts in such a way that no streams cross.
Give a procedure that takes two sticks a and b and reports whether a is above, below, or unrelated to b.
Describe an efﬁcient algorithm that determines whether it is possible to pick up all the sticks, and if so, provides a legal order in which to pick them up.
Show how to compute the convex hull of a set of n points drawn independently according to a sparse-hulled distribution in O.n/ average-case time.
Although geometry has been studied since antiquity, the development of algorithms for geometric problems is relatively new.
Preparata and Shamos note that the earliest notion of the complexity of a problem was given by E.
Lemoine was interested in the number of primitives needed to effect a given construction; he called this amount the “simplicity” of the construction.
The O.n lg n/-time divide-and-conquer algorithm for ﬁnding the closest pair of points is by Shamos and appears in Preparata and Shamos [282]
Preparata and Shamos also show that the algorithm is asymptotically optimal in a decision-tree model.
Almost all the algorithms we have studied thus far have been polynomial-time algorithms: on inputs of size n, their worst-case running time is O.nk/ for some constant k.
You might wonder whether all problems can be solved in polynomial time.
For example, there are problems, such as Turing’s famous “Halting Problem,” that cannot be solved by any computer, no matter how much time we allow.
There are also problems that can be solved, but not in time O.nk/ for any constant k.
Generally, we think of problems that are solvable by polynomial-time algorithms as being tractable, or easy, and problems that require superpolynomial time as being intractable, or hard.
Several NP-complete problems are particularly tantalizing because they seem on the surface to be similar to problems that we know how to solve in polynomial time.
In each of the following pairs of problems, one is solvable in polynomial time and the other is NP-complete, but the difference between problems appears to be slight:
Finding a longest simple path between two vertices is difﬁcult, however.
Merely determining whether a graph contains a simple path with at least a given number of edges is NP-complete.
A hamiltonian cycle of a directed graph G D .V;E/ is a simple cycle that contains each vertex in V.
Determining whether a directed graph has a hamiltonian cycle is NP-complete.
Later in this chapter, we shall prove that determining whether an undirected graph has a hamiltonian cycle is NP-complete.
Throughout this chapter, we shall refer to three classes of problems: P, NP, and NPC, the latter class being the NP-complete problems.
We describe them informally here, and we shall deﬁne them more formally later on.
The class P consists of those problems that are solvable in polynomial time.
More speciﬁcally, they are problems that can be solved in time O.nk/ for some constant k, where n is the size of the input to the problem.
Most of the problems examined in previous chapters are in P.
Informally, a problem is in the class NPC—and we refer to it as being NPcomplete—if it is in NP and is as “hard” as any problem in NP.
We shall formally deﬁne what it means to be as hard as any problem in NP later in this chapter.
In the meantime, we will state without proof that if any NP-complete problem can be solved in polynomial time, then every problem in NP has a polynomialtime algorithm.
Most theoretical computer scientists believe that the NP-complete problems are intractable, since given the wide range of NP-complete problems that have been studied to date—without anyone having discovered a polynomialtime solution to any of them—it would be truly astounding if all of them could be solved in polynomial time.
To become a good algorithm designer, you must understand the rudiments of the theory of NP-completeness.
If you can establish a problem as NP-complete, you provide good evidence for its intractability.
As an engineer, you would then do better to spend your time developing an approximation algorithm (see Chapter 35) or solving a tractable special case, rather than searching for a fast algorithm that solves the problem exactly.
Moreover, many natural and interesting problems that on the surface seem no harder than sorting, graph searching, or network ﬂow are in fact NP-complete.
Therefore, you should become familiar with this remarkable class of problems.
We rely on three key concepts in showing a problem to be NP-complete:
The relationship between an optimization problem and its related decision problem works in our favor when we try to show that the optimization problem is “hard.” That is because the decision problem is in a sense “easier,” or at least “no harder.” As a speciﬁc example, we can solve PATH by solving SHORTEST-PATH and then comparing the number of edges in the shortest path found to the value of the decision-problem parameter k.
In other words, if an optimization problem is easy, its related decision problem is easy as well.
Stated in a way that has more relevance to NP-completeness, if we can provide evidence that a decision problem is hard, we also provide evidence that its related optimization problem is hard.
Thus, even though it restricts attention to decision problems, the theory of NP-completeness often has implications for optimization problems as well.
We call such a procedure a polynomial-time reduction algorithm and, as Figure 34.1 shows, it provides us a way to solve problem A in polynomial time:
Recalling that NP-completeness is about showing how hard a problem is rather than how easy it is, we use polynomial-time reductions in the opposite way to show that a problem is NP-complete.
Let us take the idea a step further, and show how we could use polynomial-time reductions to show that no polynomial-time algorithm can exist for a particular problem B.
Suppose we have a decision problem A for which we already know that no polynomial-time algorithm can exist.
Let us not concern ourselves for now with how to ﬁnd such a problem A.
Suppose further that we have a polynomial-time reduction transforming instances of A to instances of B.
Now we can use a simple proof by contradiction to show that no polynomialtime algorithm can exist for B.
Suppose otherwise; i.e., suppose that B has a polynomial-time algorithm.
Then, using the method shown in Figure 34.1, we would have a way to solve problem A in polynomial time, which contradicts our assumption that there is no polynomial-time algorithm for A.
For NP-completeness, we cannot assume that there is absolutely no polynomialtime algorithm for problem A.
The proof methodology is similar, however, in that we prove that problem B is NP-complete on the assumption that problem A is also NP-complete.
A ﬁrst NP-complete problem Because the technique of reduction relies on having a problem already known to be NP-complete in order to prove a different problem NP-complete, we need a “ﬁrst” NP-complete problem.
We shall prove that this ﬁrst problem is NP-complete in Section 34.3
Section 34.3 shows we can relate problems via polynomial-time “reductions.” It deﬁnes NP-completeness and sketches a proof that one problem, called “circuit satisﬁability,” is NP-complete.
Having found one NP-complete problem, we show in Section 34.4 how to prove other problems to be NP-complete much more simply by the methodology of reductions.
With additional reductions, we show in Section 34.5 a variety of other problems to be NP-complete.
We begin our study of NP-completeness by formalizing our notion of polynomialtime solvable problems.
We generally regard these problems as tractable, but for philosophical, not mathematical, reasons.
First, although we may reasonably regard a problem that requires time ‚.n100/ to be intractable, very few practical problems require time on the order of such a high-degree polynomial.
The polynomial-time computable problems encountered in practice typically require much less time.
Experience has shown that once the ﬁrst polynomial-time algorithm for a problem has been discovered, more efﬁcient algorithms often follow.
Even if the current best algorithm for a problem has a running time of ‚.n100/, an algorithm with a much better running time will likely soon be discovered.
Second, for many reasonable models of computation, a problem that can be solved in polynomial time in one model can be solved in polynomial time in another.
For example, the class of problems solvable in polynomial time by the serial random-access machine used throughout most of this book is the same as the class of problems solvable in polynomial time on abstract Turing machines.1 It is also the same as the class of problems solvable in polynomial time on a parallel computer when the number of processors grows polynomially with the input size.
Third, the class of polynomial-time solvable problems has nice closure properties, since polynomials are closed under addition, multiplication, and composition.
For example, if the output of one polynomial-time algorithm is fed into the input of another, the composite algorithm is polynomial.
Exercise 34.1-5 asks you to show that if an algorithm makes a constant number of calls to polynomial-time subroutines and performs an additional amount of work that also takes polynomial time, then the running time of the composite algorithm is polynomial.
To understand the class of polynomial-time solvable problems, we must ﬁrst have a formal notion of what a “problem” is.
We deﬁne an abstract problem Q to be a binary relation on a set I of problem instances and a set S of problem solutions.
For example, an instance for SHORTEST-PATH is a triple consisting of a graph and two vertices.
A solution is a sequence of vertices in the graph, with perhaps the empty sequence denoting that no path exists.
The problem SHORTEST-PATH itself is the relation that associates each instance of a graph and two vertices with a shortest path in the graph that connects the two vertices.
Since shortest paths are not necessarily unique, a given problem instance may have more than one solution.
In order for a computer program to solve an abstract problem, we must represent problem instances in a way that the program understands.
We can encode a compound object as a binary string by combining the representations of its constituent parts.
Polygons, graphs, functions, ordered pairs, programs—all can be encoded as binary strings.
Thus, a computer algorithm that “solves” some abstract decision problem actually takes an encoding of a problem instance as input.
We call a problem whose instance set is the set of binary strings a concrete problem.
We say that an algorithm solves a concrete problem in time O.T .n// if, when it is provided a problem instance i of length n D ji j, the algorithm can produce the solution in O.T .n// time.3 A concrete problem is polynomial-time solvable, therefore, if there exists an algorithm to solve it in time O.nk/ for some constant k.
We can now formally deﬁne the complexity class P as the set of concrete decision problems that are polynomial-time solvable.
We would like to extend the deﬁnition of polynomial-time solvability from concrete problems to abstract problems by using encodings as the bridge, but we would.
That is, the efﬁciency of solving a problem should not depend on how the problem is encoded.
For example, suppose that an integer k is to be provided as the sole input to an algorithm, and suppose that the running time of the algorithm is ‚.k/
If the integer k is provided in unary—a string of k 1s—then the running time of the algorithm is O.n/ on length-n inputs, which is polynomial time.
Thus, depending on the encoding, the algorithm runs in either polynomial or superpolynomial time.
How we encode an abstract problem matters quite a bit to how we understand polynomial time.
We cannot really talk about solving an abstract problem without ﬁrst specifying an encoding.
Nevertheless, in practice, if we rule out “expensive” encodings such as unary ones, the actual encoding of a problem makes little difference to whether the problem can be solved in polynomial time.
Proof We need only prove the forward direction, since the backward direction is symmetric.
Suppose, therefore, that e1.Q/ can be solved in time O.nk/ for some constant k.
How long does this take? Converting encodings takes time O.nc/, and therefore je1.i/j D O.nc/, since the output of a serial computer cannot be longer than its running time.
Thus, whether an abstract problem has its instances encoded in binary or base 3 does not affect its “complexity,” that is, whether it is polynomial-time solvable or not; but if instances are encoded in unary, its complexity may change.
To be precise, we shall assume that the encoding of an integer is polynomially related to its binary representation, and that the encoding of a ﬁnite set is polynomially related to its encoding as a list of its elements, enclosed in braces and separated by commas.
With such a “standard” encoding in hand, we can derive reasonable encodings of other mathematical objects, such as tuples, graphs, and formulas.
To denote the standard encoding of an object, we shall enclose the object in angle braces.
Thus, hGi denotes the standard encoding of a graph G.
As long as we implicitly use an encoding that is polynomially related to this standard encoding, we can talk directly about abstract problems without reference to any particular encoding, knowing that the choice of encoding has no effect on whether the abstract problem is polynomial-time solvable.
Henceforth, we shall generally assume that all problem instances are binary strings encoded using the standard encoding, unless we explicitly specify the contrary.
We shall also typically neglect the distinction between abstract and concrete problems.
You should watch out for problems that arise in practice, however, in which a standard encoding is not obvious and the encoding does make a difference.
By focusing on decision problems, we can take advantage of the machinery of formal-language theory.
Where convenient, we shall sometimes use the same name—PATH in this caseto refer to both a decision problem and its corresponding language.
Even if language L is accepted by an algorithm A, the algorithm will not necessarily reject a string x 62 L provided as input to it.
A language L is decided by an algorithm A if every binary string in L is accepted by A and every binary string not in L is rejected by A.
We can informally deﬁne a complexity class as a set of languages, membership in which is determined by a complexity measure, such as running time, of an algorithm that determines whether a given string x belongs to language L.
The actual deﬁnition of a complexity class is somewhat more technical.6
Using this language-theoretic framework, we can provide an alternative deﬁnition of the complexity class P:
In fact, P is also the class of languages that can be accepted in polynomial time.
Theorem 34.2 P D fL W L is accepted by a polynomial-time algorithmg :
Proof Because the class of languages decided by polynomial-time algorithms is a subset of the class of languages accepted by polynomial-time algorithms, we need only show that if L is accepted by a polynomial-time algorithm, it is decided by a polynomial-time algorithm.
For more on complexity classes, see the seminal paper by Hartmanis and Stearns [162]
We shall use a classic “simulation” argument to construct another polynomial-time algorithm A0 that decides L.
Because A accepts L in time O.nk/ for some constant k, there also exists a constant c such that A accepts L in at most cnk steps.
For any input string x, the algorithm A0 simulates cnk steps of A.
After simulating cnk steps, algorithm A0 inspects the behavior of A.
For a given language L 2 P, we may not actually know a bound on the running time for the algorithm A that accepts L.
Also show that a polynomial number of calls to polynomial-time subroutines may result in an exponential-time algorithm.
The problem of ﬁnding a hamiltonian cycle in an undirected graph has been studied for over a hundred years.
Formally, a hamiltonian cycle of an undirected graph G D .V;E/ is a simple cycle that contains each vertex in V.
A graph that contains a hamiltonian cycle is said to be hamiltonian; otherwise, it is nonhamiltonian.
Hamilton, who described a mathematical game on the dodecahedron (Figure 34.2(a)) in which one player sticks ﬁve pins in any ﬁve consecutive vertices and the other player must complete the path to form a cycle.
Figure 34.2 (a) A graph representing the vertices, edges, and faces of a dodecahedron, with a hamiltonian cycle shown by shaded edges.
For example, Figure 34.2(b) shows a bipartite graph with an odd number of vertices.
Exercise 34.2-2 asks you to show that all such graphs are nonhamiltonian.
We can deﬁne the hamiltonian-cycle problem, “Does a graph G have a hamiltonian cycle?” as a formal language:
Thus, this naive algorithm does not run in polynomial time.
In fact, the hamiltonian-cycle problem is NP-complete, as we shall prove in Section 34.5
Suppose that a friend tells you that a given graph G is hamiltonian, and then offers to prove it by giving you the vertices in order along the hamiltonian cycle.
It would certainly be easy enough to verify the proof: simply verify that the provided cycle is hamiltonian by checking whether it is a permutation of the vertices of V and whether each of the consecutive edges along the cycle actually exists in the graph.
You could certainly implement this veriﬁcation algorithm to run in O.n2/ time, where n is the length of the encoding of G.
Thus, a proof that a hamiltonian cycle exists in a graph can be veriﬁed in polynomial time.
We deﬁne a veriﬁcation algorithm as being a two-argument algorithm A, where one argument is an ordinary input string x and the other is a binary string y called a certiﬁcate.
For example, in the hamiltonian-cycle problem, the certiﬁcate is the list of vertices in some hamiltonian cycle.
If a graph is hamiltonian, the hamiltonian cycle itself offers enough information to verify this fact.
Conversely, if a graph is not hamiltonian, there can be no list of vertices that fools the veriﬁcation algorithm into believing that the graph is hamiltonian, since the veriﬁcation algorithm carefully checks the proposed “cycle” to be sure.
The complexity class NP is the class of languages that can be veriﬁed by a polynomial-time algorithm.8 More precisely, a language L belongs to NP if and only if there exist a two-input polynomial-time algorithm A and a constant c such that.
We say that algorithm A veriﬁes language L in polynomial time.
From our earlier discussion on the hamiltonian-cycle problem, we now see that.
It is unknown whether P D NP, but most researchers believe that P and NP are not the same class.
Intuitively, the class P consists of problems that can be solved quickly.
The class NP consists of problems for which a solution can be veriﬁed quickly.
You may have learned from experience that it is often more difﬁcult to solve a problem from scratch than to verify a clearly presented solution, especially when working under time constraints.
Theoretical computer scientists generally believe that this analogy extends to the classes P and NP, and thus that NP includes languages that are not in P.
The name “NP” stands for “nondeterministic polynomial time.” The class NP was originally studied in the context of nondeterminism, but this book uses the somewhat simpler yet equivalent notion of veriﬁcation.
Hopcroft and Ullman [180] give a good presentation of NP-completeness in terms of nondeterministic models of computation.
Thus, our understanding of the precise relationship between P and NP is woefully incomplete.
Nevertheless, even though we might not be able to prove that a particular problem is intractable, if we can prove that it is NP-complete, then we have gained valuable information about it.
Prove that GRAPH-ISOMORPHISM 2 NP by describing a polynomial-time algorithm to verify the language.
The NP-complete languages are, in a sense, the “hardest” languages in NP.
In this section, we shall show how to compare the relative “hardness” of languages using a precise notion called “polynomial-time reducibility.” Then we formally deﬁne the NP-complete languages, and we ﬁnish by sketching a proof that one such language, called CIRCUIT-SAT, is NP-complete.
For example, the problem of solving linear equations in an indeterminate x reduces to the problem of solving quadratic equations.
Polynomial-time reductions give us a powerful tool for proving that various languages belong to P.
We can now deﬁne the set of NP-complete languages, which are the hardest problems in NP.
As the following theorem shows, NP-completeness is at the crux of deciding whether P is in fact equal to NP.
Equivalently, if any problem in NP is not polynomial-time solvable, then no NP-complete problem is polynomial-time solvable.
To prove the second statement, note that it is the contrapositive of the ﬁrst statement.
Figure 34.6 How most theoretical computer scientists view the relationships among P, NP, and NPC.
We have deﬁned the notion of an NP-complete problem, but up to this point, we have not actually proved that any problem is NP-complete.
Once we prove that at least one problem is NP-complete, we can use polynomial-time reducibility as a tool to prove other problems to be NP-complete.
Instead, we shall informally describe a proof that relies on a basic understanding of boolean combinational circuits.
Boolean combinational circuits are built from boolean combinational elements that are interconnected by wires.
A boolean combinational element is any circuit element that has a constant number of boolean inputs and outputs and that performs a well-deﬁned function.
We can describe the operation of each gate, and of any boolean combinational element, by a truth table, shown under each gate in Figure 34.7
A truth table gives the outputs of the combinational element for each possible setting of the inputs.
Figure 34.7 Three basic logic gates, with binary inputs and outputs.
Under each gate is the truth table that describes the gate’s operation.
We can generalize AND and OR gates to take more than two inputs.
A boolean combinational circuit consists of one or more boolean combinational elements interconnected by wires.
A wire can connect the output of one element to the input of another, thereby providing the output value of the ﬁrst element as an input value of the second.
Figure 34.8 shows two similar boolean combinational circuits, differing in only one gate.
The number of element inputs fed by a wire is called the fan-out of the wire.
If no element output is connected to a wire, the wire is a circuit input, accepting input values from an external source.
If no element input is connected to a wire, the wire is a circuit output, providing the results of the circuit’s computation to the outside world.
An internal wire can also fan out to a circuit output.
A truth assignment for a boolean combinational circuit is a set of boolean input values.
The size of a boolean combinational circuit is the number of boolean combinational elements plus the number of wires in the circuit.
We could devise a graphlike encoding that maps any given circuit C into a binary string hC i whose length is polynomial in the size of the circuit itself.
You can see why we would like to have a polynomial-time algorithm for this problem.
Given a circuit C , we might attempt to determine whether it is satisﬁable by simply checking all possible assignments to the inputs.
Unfortunately, if the circuit has k inputs, then we would have to check up to 2k possible assignments.
Proof We shall provide a two-input, polynomial-time algorithm A that can verify CIRCUIT-SAT.
One of the inputs to A is (a standard encoding of) a boolean combinational circuit C.
The other input is a certiﬁcate corresponding to an assignment of boolean values to the wires in C.
For each logic gate in the circuit, it checks that the value provided by the certiﬁcate on the output wire is correctly computed as a function of the values on the input wires.
Whenever an unsatisﬁable circuit is input, no certiﬁcate can fool A into believing that the circuit is satisﬁable.
Algorithm A runs in polynomial time: with a good implementation, linear time sufﬁces.
Thus, we can verify CIRCUIT-SAT in polynomial time, and CIRCUIT-SAT 2 NP.
The second part of proving that CIRCUIT-SAT is NP-complete is to show that the language is NP-hard.
That is, we must show that every language in NP is polynomial-time reducible to CIRCUIT-SAT.
The actual proof of this fact is full of technical intricacies, and so we shall settle for a sketch of the proof based on some understanding of the workings of computer hardware.
The program counter automatically increments upon fetching each instruction, thereby causing the computer to execute instructions sequentially.
The execution of an instruction can cause a value to be written to the program counter, however, which alters the normal sequential execution and allows the computer to loop and perform conditional branches.
At any point during the execution of a program, the computer’s memory holds the entire state of the computation.
We take the memory to include the program itself, the program counter, working storage, and any of the various bits of state that a computer maintains for bookkeeping.
We call any particular state of computer memory a conﬁguration.
We can view the execution of an instruction as mapping one conﬁguration to another.
The computer hardware that accomplishes this mapping can be implemented as a boolean combinational circuit, which we denote by M in the proof of the following lemma.
Since L 2 NP, there must exist an algorithm A that veriﬁes L in polynomial time.
The algorithm F that we shall construct uses the two-input algorithm A to compute the reduction function f.
The basic idea of the proof is to represent the computation of A as a sequence of conﬁgurations.
As Figure 34.9 illustrates, we can break each conﬁguration into parts consisting of the program for A, the program counter and auxiliary machine state, the input x, the certiﬁcate y, and working storage.
Thus, if the algorithm runs for at most T .n/ steps, the output appears as one of the bits in cT .n/
The reduction algorithm F constructs a single combinational circuit that computes all conﬁgurations produced by a given initial conﬁguration.
Figure 34.9 The sequence of conﬁgurations produced by an algorithm A running on an input x and certiﬁcate y.
Each conﬁguration represents the state of the computer for one step of the computation and, besides A, x, and y, includes the program counter (PC), auxiliary machine state, and working storage.
Except for the certiﬁcate y, the initial conﬁguration c0 is constant.
A boolean combinational circuit M maps each conﬁguration to the next conﬁguration.
The output is a distinguished bit in the working storage.
The output of the i th circuit, which produces conﬁguration ci , feeds directly into the input of the .iC1/st circuit.
Thus, the conﬁgurations, rather than being stored in the computer’s memory, simply reside as values on the wires connecting copies of M.
When F obtains an input x, it ﬁrst computes n D jxj and constructs a combinational circuit C 0 consisting of T .n/ copies of M.
The input to C 0 is an initial conﬁguration corresponding to a computation on A.x; y/, and the output is the conﬁguration cT .n/
Algorithm F modiﬁes circuit C 0 slightly to construct the circuit C D f .x/
First, it wires the inputs to C 0 corresponding to the program for A, the initial program counter, the input x, and the initial state of memory directly to these known values.
Thus, the only remaining inputs to the circuit correspond to the certiﬁcate y.
Second, it ignores all outputs from C 0, except for the one bit of cT .n/ corresponding to the output of A.
This circuit C , so constructed, computes C.y/ D A.x; y/ for any input y of length O.nk/
The reduction algorithm F , when provided an input string x, computes such a circuit C and outputs it.
First, we must show that F correctly computes a reduction function f.
Second, we must show that F runs in polynomial time.
To complete the proof sketch, we need only show that F runs in time polynomial in n D jxj.
The ﬁrst observation we make is that the number of bits required to represent a conﬁguration is polynomial in n.
The program for A itself has constant size, independent of the length of its input x.
The length of the input x is n, and the length of the certiﬁcate y is O.nk/
Since the algorithm runs for at most O.nk/ steps, the amount of working storage required by A is polynomial in n as well.
We assume that this memory is contiguous; Exercise 34.3-5 asks you to extend the argument to the situation in which the locations accessed by A are scattered across a much larger region of memory and the particular pattern of scattering can differ for each input x.
The combinational circuit M implementing the computer hardware has size polynomial in the length of a conﬁguration, which is O.nk/; hence, the size of M is polynomial in n.
Most of this circuitry implements the logic of the memory.
The circuit C consists of at most t D O.nk/ copies of M , and hence it has size polynomial in n.
The reduction algorithm F can construct C from x in polynomial time, since each step of the construction takes polynomial time.
The language CIRCUIT-SAT is therefore at least as hard as any language in NP, and since it belongs to NP, it is NP-complete.
Where in the proof do we exploit this assumption? Argue that this assumption does not involve any loss of generality.
Professor Sartre observes that the string x is input to F , but only the existence of A, k, and the constant factor implicit in the O.nk/ running time is known to F (since the language L belongs to NP), not their actual values.
Thus, the professor concludes that F can’t possibly construct the circuit C and that the language CIRCUIT-SAT is not necessarily NP-hard.
The following lemma is the basis of our method for showing that a language is NP-complete.
In other words, by reducing a known NP-complete language L0 to L, we implicitly reduce every language in NP to L.
Thus, Lemma 34.8 gives us a method for proving that a language L is NP-complete:
Prove that the algorithm computing f runs in polynomial time.
This methodology of reducing from a single known NP-complete language is far simpler than the more complicated process of showing directly how to reduce from every language in NP.
Moreover, as we develop a catalog of known NP-complete problems, we will have more and more choices for languages from which to reduce.
We illustrate the reduction methodology by giving an NP-completeness proof for the problem of determining whether a boolean formula, not a circuit, is satisﬁable.
This problem has the historical honor of being the ﬁrst problem ever shown to be NP-complete.
Without loss of generality, we assume that there are no redundant parentheses, i.e., a formula contains at most one pair of parentheses per boolean connective.
Unfortunately, this straightforward method does not amount to a polynomialtime reduction.
The formula produced by the reduction algorithm has a variable for each wire in the circuit.
We can now express how each gate operates as a small formula involving the variables of its incident wires.
We can prove many problems NP-complete by reducing from formula satisﬁability.
The reduction algorithm must handle any input formula, though, and this requirement can lead to a huge number of cases that we must consider.
We often prefer to reduce from a restricted language of boolean formulas, so that we need to consider fewer cases.
Of course, we must not restrict the language so much that it becomes polynomial-time solvable.
A literal in a boolean formula is an occurrence of a variable or its negation.
A boolean formula is in conjunctive normal form, or CNF, if it is expressed as an AND of clauses, each of which is the OR of one or more literals.
Describe a circuit of size n that, when converted to a formula by this method, yields a formula whose size is exponential in n.
Describe how to use this algorithm to ﬁnd satisfying assignments in polynomial time.
Hint: Observe that x _ y is equivalent to :x ! y.
Reduce 2-CNF-SAT to an efﬁciently solvable problem on a directed graph.
NP-complete problems arise in diverse domains: boolean logic, graphs, arithmetic, network design, sets and partitions, storage and retrieval, sequencing and scheduling, mathematical programming, algebra and number theory, games and puzzles, automata and language theory, program optimization, biology, chemistry, physics, and more.
In this section, we shall use the reduction methodology to provide NPcompleteness proofs for a variety of problems drawn from graph theory and set partitioning.
We prove each language in the ﬁgure to be NP-complete by reduction from the language that points to it.
At the root is CIRCUIT-SAT, which we proved NP-complete in Theorem 34.7
All proofs ultimately follow by reduction from the NP-completeness of CIRCUIT-SAT.
As a decision problem, we ask simply whether a clique of a given size k exists in the graph.
In general, however, k could be near jV j =2, in which case the algorithm runs in superpolynomial time.
Indeed, an efﬁcient algorithm for the clique problem is unlikely to exist.
You might think that we have shown only that CLIQUE is NP-hard in graphs in which the vertices are restricted to occur in triples and in which there are no edges between vertices in the same triple.
Indeed, we have shown that CLIQUE is NP-hard only in this restricted case, but this proof sufﬁces to show that CLIQUE is NP-hard in general graphs.
Why? If we had a polynomial-time algorithm that solved CLIQUE on general graphs, it would also solve CLIQUE on restricted graphs.
The opposite approach—reducing instances of 3-CNF-SAT with a special structure to general instances of CLIQUE—would not have sufﬁced, however.
Why not? Perhaps the instances of 3-CNF-SAT that we chose to reduce from were “easy,” and so we would not have reduced an NP-hard problem to CLIQUE.
The vertex-cover problem is to ﬁnd a vertex cover of minimum size in a given graph.
Restating this optimization problem as a decision problem, we wish to.
VERTEX-COVERD fhG; ki W graph G has a vertex cover of size kg : The following theorem shows that this problem is NP-complete.
Since VERTEX-COVER is NP-complete, we don’t expect to ﬁnd a polynomialtime algorithm for ﬁnding a minimum-size vertex cover.
Section 35.1 presents a polynomial-time “approximation algorithm,” however, which produces “approximate” solutions for the vertex-cover problem.
The size of a vertex cover produced by the algorithm is at most twice the minimum size of a vertex cover.
Thus, we shouldn’t give up hope just because a problem is NP-complete.
We may be able to design a polynomial-time approximation algorithm that obtains near-optimal solutions, even though ﬁnding an optimal solution is NP-complete.
We now return to the hamiltonian-cycle problem deﬁned in Section 34.2
Given a graph G D .V;E/, our certiﬁcate is the sequence of jV j vertices that makes up the hamiltonian cycle.
The veriﬁcation algorithm checks that this sequence contains each vertex in V exactly once and that with the ﬁrst vertex repeated at the end, it forms a cycle in G.
That is, it checks that there is an edge between each pair of consecutive vertices and between the ﬁrst and last vertices.
We use edges incident on selector vertices in G0 to select the k vertices of the cover in G.
Now we show that the transformation from graph G to G0 is a reduction.
That is, we must show that G has a vertex cover of size k if and only if G0 has a hamiltonian cycle.
Technically, we deﬁne a cycle in terms of vertices rather than edges (see Section B.4)
In the interest of clarity, we abuse notation here and deﬁne the hamiltonian cycle in terms of edges.
The following theorem shows that a fast algorithm for the traveling-salesman problem is unlikely to exist.
Given an instance of the problem, we use as a certiﬁcate the sequence of n vertices in the tour.
The veriﬁcation algorithm checks that this sequence contains each vertex exactly once, sums up the edge costs, and checks whether the sum is at most k.
We conclude that h0 is a hamiltonian cycle in graph G.
Proof To show that SUBSET-SUM is in NP, for an instance hS; ti of the problem, we let the subset S 0 be the certiﬁcate.
The reduction creates two numbers in set S for each variable xi and two numbers in S for each clause Cj.
We shall create numbers in base 10, where each number contains nCk digits and each digit corresponds to either one variable or one clause.
Base 10 (and other bases, as we shall see) has the property we need of preventing carries from lower digits to higher digits.
For each clause Cj , set S contains two integers sj and s0j.
The target t has nC k digits, and the reduction produces each in constant time.
Formulate a related decision problem, and show that the decision problem is NP-complete.
Formulate a related decision problem for the independent-set problem, and prove that it is NP-complete.
Suppose that you are given a “black-box” subroutine to solve the decision problem you deﬁned in part (a)
Give an algorithm to ﬁnd an independent set of maximum size.
The running time of your algorithm should be polynomial in jV j and jEj, counting queries to the black box as a single step.
Although the independent-set decision problem is NP-complete, certain special cases are polynomial-time solvable.
Analyze the running time, and prove that your algorithm works correctly.
Give an efﬁcient algorithm to solve the independent-set problem when G is bipartite.
Analyze the running time, and prove that your algorithm works correctly.
They have a bag of money and want to divide it up.
For each of the following scenarios, either give a polynomial-time algorithm, or prove that the problem is NP-complete.
The input in each case is a list of the n items in the bag, along with the value of each.
The bag contains n coins, but only 2 different denominations: some coins are worth x dollars, and some are worth y dollars.
Bonnie and Clyde wish to divide the money exactly evenly.
Bonnie and Clyde wish to divide the money exactly evenly.
The bag contains n checks, which are, in an amazing coincidence, made out to “Bonnie or Clyde.” They wish to divide the checks so that they each get the exact same amount of money.
The bag contains n checks as in part (c), but this time Bonnie and Clyde are willing to accept a split in which the difference is no larger than 100 dollars.
Give an efﬁcient algorithm to determine a 2-coloring of a graph, if one exists.
Show that your decision problem is solvable in polynomial time if and only if the graph-coloring problem is solvable in polynomial time.
Show that if 3-COLOR is NP-complete, then your decision problem from part (b) is NP-complete.
Each task aj requires tj time units on the machine (its processing time), yields a proﬁt of pj , and has a deadline dj.
The machine can process only one task at a time, and task aj must run without interruption for tj consecutive time units.
If we complete task aj by its deadline dj , we receive a proﬁt pj , but if we complete it after its deadline, we receive no proﬁt.
As an optimization problem, we are given the processing times, proﬁts, and deadlines for a set of n tasks, and we wish to ﬁnd a schedule that completes all the tasks and returns the greatest amount of proﬁt.
The processing times, proﬁts, and deadlines are all nonnegative numbers.
Give a polynomial-time algorithm for the decision problem, assuming that all processing times are integers from 1 to n.
Give a polynomial-time algorithm for the optimization problem, assuming that all processing times are integers from 1 to n.
Many problems of practical signiﬁcance are NP-complete, yet they are too important to abandon merely because we don’t know how to ﬁnd an optimal solution in polynomial time.
Even if a problem is NP-complete, there may be hope.
We have at least three ways to get around NP-completeness.
First, if the actual inputs are small, an algorithm with exponential running time may be perfectly satisfactory.
Second, we may be able to isolate important special cases that we can solve in polynomial time.
Third, we might come up with approaches to ﬁnd near-optimal solutions in polynomial time (either in the worst case or the expected case)
We call an algorithm that returns near-optimal solutions an approximation algorithm.
This chapter presents polynomial-time approximation algorithms for several NP-complete problems.
Suppose that we are working on an optimization problem in which each potential solution has a positive cost, and we wish to ﬁnd a near-optimal solution.
Depending on the problem, we may deﬁne an optimal solution as one with maximum possible cost or one with minimum possible cost; that is, the problem may be either a maximization or a minimization problem.
For many problems, we have polynomial-time approximation algorithms with small constant approximation ratios, although for other problems, the best known polynomial-time approximation algorithms have approximation ratios that grow as functions of the input size n.
An example of such a problem is the set-cover problem presented in Section 35.3
Some NP-complete problems allow polynomial-time approximation algorithms that can achieve increasingly better approximation ratios by using more and more computation time.
That is, we can trade computation time for the quality of the approximation.
An example is the subset-sum problem studied in Section 35.5
This situation is important enough to deserve a name of its own.
The vertex-cover problem is to ﬁnd a vertex cover of minimum size in a given undirected graph.
We call such a vertex cover an optimal vertex cover.
This problem is the optimization version of an NP-complete decision problem.
Even though we don’t know how to ﬁnd an optimal vertex cover in a graph G in polynomial time, we can efﬁciently ﬁnd a vertex cover that is near-optimal.
The following approximation algorithm takes as input an undirected graph G and returns a vertex cover whose size is guaranteed to be no more than twice the size of an optimal vertex cover.
Vertices b and c, shown lightly shaded, are added to the set C containing the vertex cover being created.
Edges .a; b/, .c; e/, and .c; d/, shown dashed, are removed since they are now covered by some vertex in C.
Instead of requiring that we know the exact size of an optimal vertex cover, we rely on a lower bound on the size.
A maximal matching is a matching that is not a proper subset of any other matching.
The algorithm returns a vertex cover whose size is at most twice the size of the maximal matching A.
By relating the size of the solution returned to the lower bound, we obtain our approximation ratio.
We will use this methodology in later sections as well.
Does this relationship imply that there is a polynomial-time approximation algorithm with a constant approximation ratio for the clique problem? Justify your answer.
The triangle inequality seems as though it should naturally hold, and it is automatically satisﬁed in several applications.
For example, if the vertices of the graph are points in the plane and the cost of traveling between two vertices is the ordinary euclidean distance between them, then the triangle inequality is satisﬁed.
Furthermore, many cost functions other than euclidean distance satisfy the triangle inequality.
As Exercise 35.2-2 shows, the traveling-salesman problem is NP-complete even if we require that the cost function satisfy the triangle inequality.
Thus, we should not expect to ﬁnd a polynomial-time algorithm for solving this problem exactly.
In Section 35.2.2, we show that without the triangle inequality, a polynomial-time approximation algorithm with a constant approximation ratio does not exist unless P D NP.
Applying the methodology of the previous section, we shall ﬁrst compute a structure—a minimum spanning tree—whose weight gives a lower bound on the length of an optimal traveling-salesman tour.
We shall then use the minimum spanning tree to create a tour whose cost is no more than twice that of the minimum spanning tree’s weight, as long as the cost function satisﬁes the triangle inequality.
The parameter G is a complete undirected graph, and the cost function c satisﬁes the triangle inequality.
Recall from Section 12.1 that a preorder tree walk recursively visits every vertex in the tree, listing a vertex when it is ﬁrst encountered, before visiting any of its children.
Part (a) of the ﬁgure shows a complete undirected graph, and part (b) shows the minimum spanning tree T grown from root vertex a by MST-PRIM.
Part (c) shows how a preorder walk of T visits the vertices, and part (d) displays the corresponding tour, which is the tour returned by APPROX-TSP-TOUR.
Part (e) displays an optimal tour, which is about 23% shorter.
We now show that if the cost function for an instance of the traveling-salesman problem satisﬁes the triangle inequality, then APPROX-TSP-TOUR returns a tour whose cost is not more than twice the cost of an optimal tour.
This ordering is the same as that obtained by a preorder walk of the tree T.
Let H be the cycle corresponding to this preorder walk.
In spite of the nice approximation ratio provided by Theorem 35.2, APPROXTSP-TOUR is usually not the best practical choice for this problem.
There are other approximation algorithms that typically perform much better in practice.
If we drop the assumption that the cost function c satisﬁes the triangle inequality, then we cannot ﬁnd good approximate tours in polynomial time unless P D NP.
We can create representations of G0 and c from a representation of G in time polynomial in jV j and jEj.
On the other hand, if G does not contain a hamiltonian cycle, then any tour of G0 must use some edge not in E.
But any tour that uses an edge not in E has a cost of at least.
The set-covering problem is an optimization problem that models many problems that require resources to be allocated.
Its corresponding decision problem generalizes the NP-complete vertex-cover problem and is therefore also NP-hard.
The approximation algorithm developed to handle the vertex-cover problem doesn’t apply here, however, and so we need to try other approaches.
We shall examine a simple greedy heuristic with a logarithmic approximation ratio.
That is, as the size of the instance gets larger, the size of the approximate solution may grow, relative to the size of an optimal solution.
Because the logarithm function grows rather slowly, however, this approximation algorithm may nonetheless give useful results.
An instance .X;F / of the set-covering problem consists of a ﬁnite set X and a family F of subsets of X , such that every element of X belongs to at least one subset in F :
We say that any C satisfying equation (35.8) covers X.
The size of C is the number of sets it contains, rather than the number of individual elements in these sets, since every subset C that covers X must contain all jX j individual elements.
As a simple example, suppose that X represents a set of skills that are needed to solve a problem and that we have a given set of people available to work on the problem.
We wish to form a committee, containing as few people as possible, such that for every requisite skill in X , at least one member of the committee has that skill.
In the decision version of the set-covering problem, we ask whether a covering exists with size at most k, where k is an additional parameter speciﬁed in the problem instance.
The decision version of the problem is NP-complete, as Exercise 35.3-2 asks you to show.
The greedy method works by picking, at each stage, the set S that covers the greatest number of remaining elements that are uncovered.
The set U contains, at each stage, the set of remaining uncovered elements.
Line 4 is the greedy decision-making step, choosing a subset S that covers as many uncovered elements as possible (breaking ties arbitrarily)
When the algorithm terminates, the set C contains a subfamily of F that covers X.
We can easily implement GREEDY-SET-COVER to run in time polynomial in jX j and jF j.
Since the number of iterations of the loop on lines 3–6 is bounded from above by min.jX j ; jF j/, and we can implement the loop body to run in time O.jX j jF j/, a simple implementation runs in time O.jX j jF jmin.jX j ; jF j//
We now show that the greedy algorithm returns a set cover that is not too much larger than an optimal set cover.
For convenience, in this chapter we denote the d th harmonic number Hd D.
Proof We have already shown that GREEDY-SET-COVER runs in polynomial time.
Each step of the algorithm assigns 1 unit of cost, and so.
The remainder of the proof rests on the following key inequality, which we shall prove shortly.
For any set S belonging to the family F ,X x2S.
In some applications, max fjS j W S 2 F g is a small constant, and so the solution.
Show which set cover GREEDY-SET-COVER produces when we break ties in favor of the word that appears ﬁrst in the dictionary.
In this section, we study two useful techniques for designing approximation algorithms: randomization and linear programming.
We shall give a simple randomized algorithm for an optimization version of 3-CNF satisﬁability, and then we shall use linear programming to help design an approximation algorithm for a weighted version of the vertex-cover problem.
This section only scratches the surface of these two powerful techniques.
The chapter notes give references for further study of these areas.
If an instance is not satisﬁable, we may want to compute how “close” to satisﬁable it is, that is, we may wish to ﬁnd an assignment of the variables that satisﬁes as many clauses as possible.
We further assume that no clause contains both a variable and its negation.
We shall, however, compute a lower bound on the weight of the minimum-weight.
We shall then “round” this solution and use it to obtain a vertex cover.
Therefore, the value of an optimal solution to the linear program gives a lower bound on the value of an optimal solution to the 0-1 integer program, and hence a lower bound on the optimal weight in the minimum-weight vertex-cover problem.
The following procedure uses the solution to the linear-programming relaxation to construct an approximate solution to the minimum-weight vertex-cover problem:
Give a randomized 2-approximation algorithm for the MAX-CNF satisﬁability problem.
This decision problem asks whether there exists a subset of S that adds up exactly to the target value t.
As we saw in Section 34.5.5, this problem is NP-complete.
The optimization problem associated with this decision problem arises in practical applications.
For example, we may have a truck that can carry no more than t pounds, and n different boxes to ship, the i th of which weighs xi pounds.
We wish to ﬁll the truck with as heavy a load as possible without exceeding the given weight limit.
If L is a list of positive integers and x is another positive integer, then we let LC x denote the list of integers derived from L by increasing each element of L by x.
We also use this notation for sets, so that S C x D fs C x W s 2 Sg :
We can derive a fully polynomial-time approximation scheme for the subset-sum problem by “trimming” each list Li after it is created.
The procedure scans the elements of L in monotonically increasing order.
Theorem 35.8 APPROX-SUBSET-SUM is a fully polynomial-time approximation scheme for the subset-sum problem.
Then show that after executing line 5 of EXACT-SUBSETSUM, Li is a sorted list containing every element of Pi whose value is not more than t.
We wish to pack all the objects into the minimum number of unit-size bins.
Prove that the problem of determining the minimum number of bins required is NP-hard.
The ﬁrst-ﬁt heuristic takes each object in turn and places it into the ﬁrst bin that can accommodate it.
Argue that the optimal number of bins required is at least dSe.
Argue that the ﬁrst-ﬁt heuristic leaves at most one bin less than half full.
Prove that the number of bins used by the ﬁrst-ﬁt heuristic is never more than d2Se.
Prove an approximation ratio of 2 for the ﬁrst-ﬁt heuristic.
Give an efﬁcient implementation of the ﬁrst-ﬁt heuristic, and analyze its running time.
Prove that the size of the maximum clique in G.k/ is equal to the kth power of the size of the maximum clique in G.
Argue that if there is an approximation algorithm that has a constant approximation ratio for ﬁnding a maximum-size clique, then there is a polynomial-time approximation scheme for the problem.
Suppose that we generalize the set-covering problem so that each set Si in the family F has an associated weight wi and the weight of a cover C is.
Show how to generalize the greedy set-covering heuristic in a natural manner to provide an approximate solution for any instance of the weighted set-covering problem.
Show that your heuristic has an approximation ratio of H.d/, where d is the maximum size of any set Si.
Recall that for an undirected graph G, a matching is a set of edges such that no two edges in the set are incident on the same vertex.
In Section 26.3, we saw how to ﬁnd a maximum matching in a bipartite graph.
In this problem, we will look at matchings in undirected graphs in general (i.e., the graphs are not required to be bipartite)
A maximal matching is a matching that is not a proper subset of any other.
Show that a maximal matching need not be a maximum matching by exhibiting an undirected graph G and a maximal matching M in G that is not a maximum matching.
Hint: You can ﬁnd such a graph with only four vertices.
Give an O.E/-time greedy algorithm to ﬁnd a maximal matching in G.
In this problem, we shall concentrate on a polynomial-time approximation algorithm for maximum matching.
Whereas the fastest known algorithm for maximum matching takes superlinear (but polynomial) time, the approximation algorithm here will run in linear time.
You will show that the linear-time greedy algorithm for maximal matching in part (b) is a 2-approximation algorithm for maximum matching.
Show that the size of a maximum matching in G is a lower bound on the size of any vertex cover for G.
Conclude from part (d) that 2 jM j is the size of a vertex cover for G.
Using parts (c) and (e), prove that the greedy algorithm in part (b) is a 2-approximation algorithm for maximum matching.
Suppose that we use the following greedy algorithm for parallel machine scheduling: whenever a machine is idle, schedule any job that has not yet been scheduled.
For the schedule returned by the greedy algorithm, show that.
Give an O.V CE/-time algorithm to compute a 2-approximation to the maximum spanning tree.
In the 0-1 knapsack problem, we wish to ﬁnd a subset of the items whose total weight is at most W and whose total value is maximum.
The fractional knapsack problem is like the 0-1 knapsack problem, except that we are allowed to take a fraction of each item, rather than being restricted to taking either all or none of.
Prove that we can always construct an optimal solution Qj to the fractional problem for instance Ij that includes at most one item fractionally.
That is, for all items except possibly one, we either include all of the item or none of the item in the knapsack.
Since this early work, thousands of approximation algorithms have been designed for a wide range of problems, and there is a wealth of literature on this ﬁeld.
Lawler, Lenstra, Rinnooy Kan, and Shmoys [225] provide an extensive treatment of approximation algorithms for the traveling-salesman problem.
The algorithm APPROX-TSP-TOUR appears in a paper by Rosenkrantz, Stearns, and Lewis [298]
Christoﬁdes improved on this algorithm and gave a 3=2-approximation algorithm for the traveling-salesman problem with the triangle inequality.
The algorithm APPROX-SUBSET-SUM and its analysis are loosely modeled after related approximation algorithms for the knapsack and subset-sum problems by Ibarra and Kim [187]
Section 35.4 only touches on the power of randomization and linear programming in the design of approximation algorithms.
A combination of these two ideas yields a technique called “randomized rounding,” which formulates a problem as an integer linear program, solves the linear-programming relaxation, and interprets the variables in the solution as probabilities.
These probabilities then help guide the solution of the original problem.
This technique was ﬁrst used by Raghavan and Thompson [290], and it has had many subsequent uses.
As mentioned in the chapter notes for Chapter 34, recent results in probabilistically checkable proofs have led to lower bounds on the approximability of many problems, including several in this chapter.
In addition to the references there, the chapter by Arora and Lund [23] contains a good description of the relationship between probabilistically checkable proofs and the hardness of approximating various problems.
When we analyze algorithms, we often need to draw upon a body of mathematical tools.
Some of these tools are as simple as high-school algebra, but others may be new to you.
In Part I, we saw how to manipulate asymptotic notations and solve recurrences.
This appendix comprises a compendium of several other concepts and methods we use to analyze algorithms.
As noted in the introduction to Part I, you may have seen much of the material in this appendix before having read this book (although the speciﬁc notational conventions we use might occasionally differ from those you have seen elsewhere)
As in the rest of this book, however, we have included exercises and problems, in order for you to improve your skills in these areas.
Appendix A offers methods for evaluating and bounding summations, which occur frequently in the analysis of algorithms.
Many of the formulas here appear in any calculus text, but you will ﬁnd it convenient to have these methods compiled in one place.
Appendix B contains basic deﬁnitions and notations for sets, relations, functions, graphs, and trees.
It also gives some basic properties of these mathematical objects.
Appendix C begins with elementary principles of counting: permutations, combinations, and the like.
Most of the algorithms in this book require no probability for their analysis, and thus you can easily omit the latter sections of the chapter on a ﬁrst reading, even without skimming them.
Later, when you encounter a probabilistic analysis that you want to understand better, you will ﬁnd Appendix C well organized for reference purposes.
Appendix D deﬁnes matrices, their operations, and some of their basic properties.
You have probably seen most of this material already if you have taken a course in linear algebra, but you might ﬁnd it helpful to have one place to look for our notation and deﬁnitions.
When an algorithm contains an iterative control construct such as a while or for loop, we can express its running time as the sum of the times spent on each execution of the body of the loop.
For example, we found in Section 2.2 that the j th iteration of insertion sort took time proportional to j in the worst case.
By adding up the time spent on each iteration, we obtained the summation (or series) nX.
When we evaluated this summation, we attained a bound of ‚.n2/ on the worstcase running time of the algorithm.
This example illustrates why you should know how to manipulate and bound summations.
You can ﬁnd most of the other proofs in any calculus text.
The value of a ﬁnite series is always well deﬁned, and we can add its terms in any order.
If the limit does not exist, the series diverges; otherwise, it converges.
The terms of a convergent series cannot always be added in any order.
We can, however, rearrange the terms of an absolutely convergent series, that is, a series.
We can exploit the linearity property to manipulate summations incorporating.
In this equation, the ‚-notation on the left-hand side applies to the variable k, but on the right-hand side, it applies to n.
We can also apply such manipulations to inﬁnite convergent series.
We have the following summations of squares and cubes: nX.
By integrating or differentiating the formulas above, additional formulas arise.
For example, by differentiating both sides of the inﬁnite geometric series (A.6) and multiplying by x, we get.
We can convert a formula with a product to a formula with a summation by using the identity.
We have many techniques at our disposal for bounding the summations that describe the running times of algorithms.
The most basic way to evaluate a series is to use mathematical induction.
As an example, let us prove that the arithmetic series.
You don’t always need to guess the exact value of a summation in order to use mathematical induction.
Instead, you can use induction to prove a bound on a summation.
As an example, let us prove that the geometric series.
We have to be careful when we use asymptotic notation to prove bounds by induction.
The bug in the argument is that the “constant” hidden by the “big-oh” grows with n and thus is not constant.
We have not shown that the same constant works for all n.
We can sometimes obtain a good upper bound on a series by bounding each term of the series, and it often sufﬁces to use the largest term to bound the others.
The technique of bounding each term in a series by the largest term is a weak method when the series can in fact be bounded by a geometric series.
We can apply this method to bound the summation P1
A common bug in applying this method is to show that the ratio of consecutive terms is less than 1 and then to assume that the summation is bounded by a geometric series.
An example is the inﬁnite harmonic series, which diverges since.
One way to obtain bounds on a difﬁcult summation is to express the series as the sum of two or more series by partitioning the range of the index and then to bound each of the resulting series.
For example, suppose we try to ﬁnd a lower bound on the arithmetic series.
Pn kD1 k, which we have already seen has an upper bound.
We can obtain a better lower bound by ﬁrst splitting the summation.
For a summation arising from the analysis of an algorithm, we can often split.
Generally, this technique applies when each term ak in a summation.
The technique of splitting summations can help us determine asymptotic bounds in much more difﬁcult situations.
For example, we can obtain a bound of O.lg n/ on the harmonic series (A.7):
The last piece might contain terms not in the original harmonic series, and thus we have nX.
The summation is represented as the area of the rectangles in the ﬁgure, and the integral is the shaded region under the curve.
When f .k/ is a monotonically decreasing function, we can use a similar method to provide the boundsZ nC1 m.
The integral approximation (A.12) gives a tight estimate for the nth harmonic number.
Pn kDm f .k/, and then by shifting the rectangles one unit to the right, we getPn.
Knuth [209] provides an excellent reference for the material presented here.
You can ﬁnd basic properties of series in any good calculus book, such as Apostol [18] or Thomas et al.
Many chapters of this book touch on the elements of discrete mathematics.
This appendix reviews more completely the notations, deﬁnitions, and elementary properties of sets, relations, functions, graphs, and trees.
If you are already well versed in this material, you can probably just skim this chapter.
A set is a collection of distinguishable objects, called its members or elements.
If an object x is a member of a set S , we write x 2 S (read “x is a member of S” or, more brieﬂy, “x is in S”)
If x is not a member of S , we write x 62 S.
We can describe a set by explicitly listing its members as a list inside braces.
A set cannot contain the same object more than once,1 and its elements are not ordered.
Two sets A and B are equal, written A D B , if they contain the same elements.
A variation of a set, which can contain the same object more than once, is called a multiset.
Each of the sets A, B , and C is represented as a circle.
Figure B.1 illustrates the ﬁrst of DeMorgan’s laws, using a Venn diagram: a graphical picture in which sets are represented as regions of the plane.
In other words, S forms a partition of S if each element of S appears in exactly one Si 2 S.
The number of elements in a set is the cardinality (or size) of the set, denoted jS j.
Two sets have the same cardinality if their elements can be put into a one-to-one correspondence.
If the cardinality of a set is a natural number, we say the set is ﬁnite; otherwise, it is inﬁnite.
An inﬁnite set that can be put into a one-to-one correspondence with the natural numbers N is countably inﬁnite; otherwise, it is uncountable.
For example, the integers Z are countable, but the reals R are uncountable.
For any two ﬁnite sets A and B , we have the identity.
A ﬁnite set of n elements is sometimes called an n-set.
A subset of k elements of a set is sometimes called a k-subset.
We sometimes care about setlike structures in which the elements are ordered.
An ordered pair of two elements a and b is denoted .a; b/ and is deﬁned formally as the set .a; b/ D fa; fa; bgg.
Thus, the ordered pair .a; b/ is not the same as the ordered pair .b; a/
B.1-2 Prove the generalization of DeMorgan’s laws to any ﬁnite collection of sets:
B.1-4 Show that the set of odd natural numbers is countable.
B.1-6 Give an inductive deﬁnition for an n-tuple by extending the set-theoretic deﬁnition for an ordered pair.
Theorem B.1 (An equivalence relation is the same as a partition) The equivalence classes of any equivalence relation R on a set A form a partition of A, and any partition of A determines an equivalence relation on A for which the sets in the partition are the equivalence classes.
A binary relation R on a set A is antisymmetric if.
To be precise, in order for the “ﬁt inside” relation to be a partial order, we need to view a box as ﬁtting inside itself.
B.2-5 Professor Narcissus claims that if a relation R is symmetric and transitive, then it is also reﬂexive.
The set A is called the domain of f , and the set B is called the codomain of f.
We sometimes write f W A ! B; and if .a; b/ 2 f , we write b D f .a/, since b is uniquely determined by the choice of a.
Intuitively, the function f assigns an element of B to each element of A.
No element of A is assigned two different elements of B , but the same element of B can be assigned to two different elements of A.
Given a function f W A! B , if b D f .a/, we say that a is the argument of f and that b is the value of f at a.
We can deﬁne a function by stating its value for every element of its domain.
Two functions f and g are equal if they have the same domain and codomain and if, for all a in the domain, f .a/ D g.a/
A function is a surjection if its range is its codomain.
For example, the function f .n/ D bn=2c is a surjective function from N to N, since every element in N appears as the value of f for some argument.
The function f .n/ D 2n is, however, a surjective function from the natural numbers to the even numbers.
When we say that f is onto, we mean that it is surjective.
The function is injective, since no element of Z is the image of more than one element of N.
It is surjective, since every element of Z appears as the image of some element of N.
A bijection is sometimes called a one-to-one correspondence, since it pairs elements in the domain and codomain.
A bijection from a set A to itself is sometimes called a permutation.
This section presents two kinds of graphs: directed and undirected.
Certain definitions in the literature differ from those given here, but for the most part, the differences are slight.
Section 22.1 shows how we can represent graphs in computer memory.
A directed graph (or digraph) G is a pair .V;E/, where V is a ﬁnite set and E is a binary relation on V.
The set V is called the vertex set of G, and its elements are called vertices (singular: vertex)
The set E is called the edge set of G, and its elements are called edges.
Vertices are represented by circles in the ﬁgure, and edges are represented by arrows.
The degree of a vertex in an undirected graph is the number of edges incident on it.
In a directed graph, the out-degree of a vertex is the number of edges leaving it, and the in-degree of a vertex is the number of edges entering it.
The degree of a vertex in a directed graph is its in1170 Appendix B Sets, Etc.
A directed graph is strongly connected if every two vertices are reachable from each other.
The strongly connected components of a directed graph are the equiv4Some authors refer to what we call a path as a “walk” and to what we call a simple path as just a “path.” We use the terms “path” and “simple path” throughout this book in a manner consistent with their deﬁnitions.
A directed graph is strongly connected if it has only one strongly connected component.
There are two variants of graphs that you may occasionally encounter.
A multigraph is like an undirected graph, but it can have both multiple edges between vertices and self-loops.
A hypergraph is like an undirected graph, but each hyperedge, rather than connecting two vertices, connects an arbitrary subset of vertices.
Many algorithms written for ordinary directed and undirected graphs can be adapted to run on these graphlike structures.
B.4-1 Attendees of a faculty party shake hands to greet each other, and each professor remembers how many times he or she shook hands.
At the end of the party, the department head adds up the number of times that each professor shook hands.
Hint: Let one set of vertices in the bipartite graph correspond to vertices of the hypergraph, and let the other set of vertices of the bipartite graph correspond to hyperedges.
As with graphs, there are many related, but slightly different, notions of trees.
This section presents deﬁnitions and mathematical properties of several kinds of trees.
As deﬁned in Section B.4, a free tree is a connected, acyclic, undirected graph.
We often omit the adjective “free” when we say that a graph is a tree.
If an undirected graph is acyclic but possibly disconnected, it is a forest.
The forest in Figure B.4(b) is not a tree because it is not connected.
The graph in Figure B.4(c) is connected but neither a tree nor a forest, because it contains a cycle.
The following theorem captures many important facts about free trees.
Thus, if G is a tree, there can be at most one simple path between two vertices.
A rooted tree is a free tree in which one of the vertices is distinguished from the others.
We call the distinguished vertex the root of the tree.
We often refer to a vertex of a rooted tree as a node5 of the tree.
If the last edge on the simple path from the root r of a tree T to a node x is .y; x/, then y is the parent of x, and x is a child of y.
The root is the only node in T with no parent.
If two nodes have the same parent, they are siblings.
A node with no children is a leaf or external node.
The term “node” is often used in the graph theory literature as a synonym for “vertex.” We reserve the term “node” to mean a vertex of a rooted tree.
If the tree is ordered, the relative leftto-right order of the children of a node matters; otherwise it doesn’t.
As a rooted tree, it is identical to the tree in (a), but as an ordered tree it is different, since the children of node 3 appear in a different order.
The number of children of a node x in a rooted tree T equals the degree of x.6 The length of the simple path from the root r to a node x is the depth of x in T.
A level of a tree consists of all nodes at the same depth.
The height of a node in a tree is the number of edges on the longest simple downward path from the node to a leaf, and the height of a tree is the height of its root.
The height of a tree is also equal to the largest depth of any node in the tree.
An ordered tree is a rooted tree in which the children of each node are ordered.
The two trees in Figure B.6 are different when considered to be ordered trees, but the same when considered to be just rooted trees.
Notice that the degree of a node depends on whether we consider T to be a rooted tree or a free tree.
The degree of a vertex in a free tree is, as in any undirected graph, the number of adjacent vertices.
In a rooted tree, however, the degree is the number of children—the parent of a node does not count toward its degree.
The left child of a node is drawn beneath the node and to the left.
The right child is drawn beneath and to the right.
As ordered trees, these trees are the same, but as binary trees, they are distinct.
The binary tree that contains no nodes is called the empty tree or null tree, sometimes denoted NIL.
If the left subtree is nonempty, its root is called the left child of the root of the entire tree.
Likewise, the root of a nonnull right subtree is the right child of the root of the entire tree.
If a subtree is the null tree NIL, we say that the child is absent or missing.
For example, in a binary tree, if a node has just one child, the position of the child—whether it is the left child or the right child—matters.
In an ordered tree, there is no distinguishing a sole child as being either left or right.
Considered as ordered trees, however, the two trees are identical.
We can represent the positioning information in a binary tree by the internal nodes of an ordered tree, as shown in Figure B.7(c)
The idea is to replace each missing child in the binary tree with a node having no children.
These leaf nodes are drawn as squares in the ﬁgure.
Consequently, the order of the children of a node preserves the position information.
We can extend the positioning information that distinguishes binary trees from ordered trees to trees with more than 2 children per node.
The i th child of a node is absent if no child is labeled with integer i.
A k-ary tree is a positional tree in which for every node, all children with labels greater than k are missing.
A complete k-ary tree is a k-ary tree in which all leaves have the same depth and all internal nodes have degree k.
Thus, the number of leaves at depth h is kh.
Consequently, the height of a complete k-ary tree with n leaves is logk n.
The number of internal nodes of a complete k-ary tree of height h is.
Conclude that the number of internal nodes in a full binary tree is 1 fewer than the number of leaves.
Let d be the maximum degree of any vertex in a graph G.
Prove that we can color G with d C 1 colors.
Show that if G has O.jV j/ edges, then we can color G with O.
B-2 Friendly graphs Reword each of the following statements as a theorem about undirected graphs, and then prove it.
Any group of at least two people contains at least two people with the same number of friends in the group.
Every group of six people contains either at least three mutual friends or at least three mutual strangers.
Any group of people can be partitioned into two subgroups such that at least half the friends of each person belong to the subgroup of which that person is not a member.
If everyone in a group is the friend of at least half the people in the group, then the group can be seated around a table in such a way that everyone is seated between two friends.
B-3 Bisecting trees Many divide-and-conquer algorithms that operate on graphs require that the graph be bisected into two nearly equal-sized subgraphs, which are induced by a partition of the vertices.
This problem investigates bisections of trees formed by removing a small number of edges.
We require that whenever two vertices end up in the same subtree after removing edges, then they must be in the same partition.
The book by Harary [160] provides a useful compendium of many deﬁnitions and results from graph theory.
If you have a good background in these areas, you may want to skim the beginning of this appendix lightly and concentrate on the later sections.
Most of this book’s chapters do not require probability, but for some chapters it is essential.
Section C.1 reviews elementary results in counting theory, including standard formulas for counting permutations and combinations.
The axioms of probability and basic facts concerning probability distributions form Section C.2
Random variables are introduced in Section C.3, along with the properties of expectation and variance.
Section C.4 investigates the geometric and binomial distributions that arise from studying Bernoulli trials.
The study of the binomial distribution continues in Section C.5, an advanced discussion of the “tails” of the distribution.
Counting theory tries to answer the question “How many?” without actually enumerating all the choices.
For example, we might ask, “How many different n-bit numbers are there?” or “How many orderings of n distinct elements are there?” In this section, we review the elements of counting theory.
Since some of the material assumes a basic understanding of sets, you might wish to start by reviewing the material in Section B.1
We can sometimes express a set of items that we wish to count as a union of disjoint sets or as a Cartesian product of sets.
The rule of sum says that the number of ways to choose one element from one of two disjoint sets is the sum of the cardinalities of the sets.
For example, each position on a car’s license plate is a letter or a digit.
A string over a ﬁnite set S is a sequence of elements of S.
We sometimes call a string of length k a k-string.
A substring s0 of a string s is an ordered sequence of consecutive elements of s.
A k-substring of a string is a substring of length k.
A permutation of a ﬁnite set S is an ordered sequence of all the elements of S , with each element appearing exactly once.
For example, if S D fa; b; cg, then S has 6 permutations:
A k-permutation of S is an ordered sequence of k elements of S , with no element appearing more than once in the sequence.
Thus, an ordinary permutation is an n-permutation of an n-set.
The twelve 2-permutations of the set fa; b; c; dg are.
A k-combination of an n-set S is simply a k-subset of S.
Here we use the shorthand of denoting the 2-subset fa; bg by ab, and so on.
We can construct a k-combination of an n-set by choosing k distinct (different) elements from the n-set.
The order in which we select the elements does not matter.
These numbers are also known as binomial coefﬁcients, due to their appearance in the binomial expansion:
A special case of the binomial expansion occurs when x D y D 1:
C.1-2 An n-input, m-output boolean function is a function from fTRUE; FALSEgn to fTRUE; FALSEgm.
How many n-input, 1-output boolean functions are there? How many n-input, m-output boolean functions are there?
C.1-3 In how many ways can n professors sit around a circular conference table? Consider two seatings to be the same if one can be rotated to form the other.
Such a table of binomial coefﬁcients is called Pascal’s triangle.
Probability is an essential tool for the design and analysis of probabilistic and randomized algorithms.
We deﬁne probability in terms of a sample space S , which is a set whose elements are called elementary events.
We can think of each elementary event as a possible outcome of an experiment.
For the experiment of ﬂipping two distinguishable coins, with each individual ﬂip resulting in a head (H) or a tail (T), we can view the sample space as consisting of the set of all possible 2-strings over fH; Tg: S D fHH; HT; TH; TTg :
An event is a subset1 of the sample space S.
For example, in the experiment of ﬂipping two coins, the event of obtaining one head and one tail is fHT; THg.
The event S is called the certain event, and the event ; is called the null event.
We say that two events A and B are mutually exclusive if A\B D ;
We sometimes treat an elementary event s 2 S as the event fsg.
A probability distribution Pr fg on a sample space S is a mapping from events of S to real numbers satisfying the following probability axioms:
We call Pr fAg the probability of the event A.
For a general probability distribution, there may be some subsets of the sample space S that are not considered to be events.
This situation usually arises when the sample space is uncountably inﬁnite.
The main requirement for what subsets are events is that the set of events of a sample space be closed under the operations of taking the complement of an event, forming the union of a ﬁnite or countable number of events, and taking the intersection of a ﬁnite or countable number of events.
Most of the probability distributions we shall see are over ﬁnite or countable sample spaces, and we shall generally consider all subsets of a sample space to be events.
A notable exception is the continuous uniform probability distribution, which we shall see shortly.
In our coin-ﬂipping example, suppose that each of the four elementary events has probability 1=4
Then the probability of getting at least one head is.
A probability distribution is discrete if it is deﬁned over a ﬁnite or countably inﬁnite sample space.
In such a case the experiment is often described as “picking an element of S at random.”
As an example, consider the process of ﬂipping a fair coin, one for which the probability of obtaining a head is the same as the probability of obtaining a tail, that is, 1=2
If we ﬂip the coin n times, we have the uniform probability distribution deﬁned on the sample space S D fH; Tgn, a set of size 2n.
We can represent each elementary event in S as a string of length n over fH; Tg, each string occurring with probability 1=2n.
Sometimes we have some prior partial knowledge about the outcome of an experiment.
For example, suppose that a friend has ﬂipped two fair coins and has told you that at least one of the coins showed a head.
What is the probability that both coins are heads? The information given eliminates the possibility of two tails.
The three remaining elementary events are equally likely, so we infer that each occurs with probability 1=3
Since only one of these elementary events shows two heads, the answer to our question is 1=3
Conditional probability formalizes the notion of having prior partial knowledge of the outcome of an experiment.
The conditional probability of an event A given that another event B occurs is deﬁned to be.
For example, suppose that we have a fair coin and a biased coin that always comes up heads.
We run an experiment consisting of three independent events: we choose one of the two coins at random, we ﬂip that coin once, and then we ﬂip it again.
Suppose that the coin we have chosen comes up heads both times.
What is the probability that Professor Rosencrantz obtains more heads Professor Rosencrantz ﬂips a fair coin once.
We then remove three cards, one at a time, from the deck.
What is the probability that we select the three cards in sorted (increasing) order?
C.2-9 ? You are a contestant in a game show in which a prize is hidden behind one of three curtains.
You will win the prize if you select the correct curtain.
C.2-10 ? A prison warden has randomly picked one prisoner among three to go free.
The guard knows which one will go free but is forbidden to give any prisoner information regarding his status.
Let us call the prisoners X , Y , and Z.
Prisoner X asks the guard privately which of Y or Z will be executed, arguing that since he already knows that at least one of them must die, the guard won’t be revealing any information about his own status.
The guard tells X that Y is to be executed.
Prisoner X feels happier now, since he ﬁgures that either he or prisoner Z will go free, which means that his probability of going free is now 1=2
Is he right, or are his chances still 1=3? Explain.
A (discrete) random variable X is a function from a ﬁnite or countably inﬁnite sample space S to the real numbers.
It associates a real number with each possible outcome of an experiment, which allows us to work with the probability distribution induced on the resulting set of numbers.
Random variables can also be deﬁned for uncountably inﬁnite sample spaces, but they raise technical issues that are unnecessary to address for our purposes.
For a random variable X and a real number x, we deﬁne the event X D x to be fs 2 S W X.s/ D xg; thus, Pr fX D xg D.
As an example, consider the experiment of rolling a pair of ordinary, 6-sided dice.
There are 36 possible elementary events in the sample space.
Deﬁne the random variable X to be the maximum of the two values showing on the dice.
We often deﬁne several random variables on the same sample space.
We deﬁne two random variables X and Y to be independent if for all x and y, the events X D x and Y D y are independent or, equivalently, if for all x and y, we have Pr fX D x and Y D yg D Pr fX D xgPr fY D yg.
Given a set of random variables deﬁned over the same sample space, we can deﬁne new random variables as sums, products, or other functions of the original variables.
Sometimes the expectation of X is denoted by X or, when the random variable is apparent from context, simply by.
Consider a game in which you ﬂip two fair coins.
If X is any random variable, any function g.x/ deﬁnes a new random variable g.X/
When we apply a convex function f .x/ to a random variable X , Jensen’s inequality gives us.
What is the expectation of the sum of the two values showing? What is the expectation of the maximum of the two values showing?
C.3-3 A carnival game consists of three dice in a cage.
The cage is shaken, and the payoff is as follows.
If the player’s number doesn’t appear on any of the dice, he loses his dollar.
What is his expected gain from playing the carnival game once?
C.3-4 Argue that if X and Y are nonnegative random variables, then.
C.3-5 ? Let X and Y be independent random variables.
Prove that f .X/ and g.Y / are independent for any choice of functions f and g.
C.3-8 Which is larger: the expectation of the square of a random variable, or the square of its expectation?
As an example, suppose we repeatedly roll two dice until we obtain either a seven or an eleven.
The name “binomial” comes from the right-hand side of equation (C.34) being the kth term of the expansion of .pCq/n.
We can prove that the distribution always behaves in this manner by looking at the ratio of successive terms:
The following lemma provides an upper bound on the binomial distribution.
Show that the probability of exactly one success is also approximately 1=e.
C.4-6 ? Professor Rosencrantz ﬂips a fair coin n times, and so does Professor Guildenstern.
Show that the probability that they get the same number of heads is.
For Professor Rosencrantz, call a head a success; for Professor Guildenstern, call a tail a success.
The probability of having at least, or at most, k successes in n Bernoulli trials, each with probability p of success, is often of more interest than the probability of having exactly k successes.
In this section, we investigate the tails of the binomial distribution: the two regions of the distribution b.kIn; p/ that are far from the mean np.
We shall prove several important bounds on (the sum of all terms in) a tail.
We ﬁrst provide a bound on the right tail of the distribution b.kIn; p/
We can determine bounds on the left tail by inverting the roles of successes and failures.
Theorem C.2 Consider a sequence of n Bernoulli trials, where success occurs with probability p.
Let X be the random variable denoting the total number of successes.
The following corollary restates the theorem for the left tail of the binomial distribution.
In general, we shall leave it to you to adapt the proofs from one tail to the other.
Corollary C.3 Consider a sequence of n Bernoulli trials, where success occurs with probability p.
If X is the random variable denoting the total number of successes, then for.
Our next bound concerns the left tail of the binomial distribution.
Its corollary shows that, far from the mean, the left tail diminishes exponentially.
Corollary C.6 Consider a sequence of n Bernoulli trials, where success occurs with probability p.
Let X be the random variable denoting the total number of successes.
When applied to Bernoulli trials in which each trial has the same probability of success, Theorem C.8 yields the following corollary bounding the right tail of a binomial distribution.
Similarly, show that the conditions of Corollary C.9 imply that.
C-1 Balls and bins In this problem, we investigate the effect of various assumptions on the number of ways of placing n balls into b distinct bins.
Suppose that the n balls are distinct and that their order within a bin does not matter.
Argue that the number of ways of placing the balls in the bins is bn.
Suppose that the balls are identical, and hence their order within a bin does not matter.
Show that the number of ways of placing the balls in the bins is.
The ﬁrst general methods for solving probability problems were discussed in a famous correspondence between B.
Matrices arise in numerous applications, including, but by no means limited to, scientiﬁc computing.
If you have seen matrices before, much of the material in this appendix will be familiar to you, but some of it might be new.
In this section, we review some basic concepts of matrix theory and some fundamental properties of matrices.
The transpose of a matrix A is the matrix AT obtained by exchanging the rows and columns of A.
If a matrix of 0s is intended, then the size of the matrix also needs to be derived from the context.
When I appears without a subscript, we derive its size from the context.
The i th column of an identity matrix is the unit vector ei.
An upper-triangular matrix is unit upper-triangular if it has all 1s along the diagonal.
A lower-triangular matrix is unit lower-triangular if it has all 1s along the diagonal.
Such a matrix is called a permutation matrix because multiplying a vector x by a permutation matrix has the effect of permuting (rearranging) the elements of x.
The elements of a matrix or vector are numbers from a number system, such as the real numbers, the complex numbers, or integers modulo a prime.
The number system deﬁnes how to add and multiply numbers.
We can extend these deﬁnitions to encompass addition and multiplication of matrices.
Matrices have many (but not all) of the algebraic properties typical of numbers.
In this section, we deﬁne some basic properties pertaining to matrices: inverses, linear dependence and independence, rank, and determinants.
Theorem D.1 A square matrix has full rank if and only if it is nonsingular.
The following theorem (whose proof is left as Exercise D.2-7) and its corollary relate the notions of column rank and singularity to null vectors.
Theorem D.2 A matrix A has full column rank if and only if it does not have a null vector.
Corollary D.3 A square matrix A is singular if and only if it has a null vector.
Also, for any square matrices A and B , we have det.AB/ D det.A/ det.B/
Matrices that arise in applications are often positive-deﬁnite due to the following theorem.
Theorem D.6 For any matrix A with full column rank, the matrix ATA is positive-deﬁnite.
D.2-1 Prove that matrix inverses are unique, that is, if B and C are inverses of A, then B D C.
D.2-2 Prove that the determinant of a lower-triangular or upper-triangular matrix is equal to the product of its diagonal elements.
Prove that the inverse of a lower-triangular matrix, if it exists, is lower-triangular.
D.2-3 Prove that if P is a permutation matrix, then P is invertible, its inverse is P T, and P T is a permutation matrix.
Hint: Express the linear dependence of one column on the others as a matrix-vector equation.
If r is the rank of matrix A, prove that jR.A/j D 2r.
Conclude that A deﬁnes a permutation on Sn only if A has full rank.
Use a counting argument to show that the number of linear permutations of Sn is much less than the number of permutations of Sn.
Give an example of a value of n and a permutation of Sn that cannot be achieved by any linear permutation.
Hint: For a given permutation, think about how multiplying a matrix by a unit vector relates to the columns of the matrix.
A fast and simple algorithm for the maximum ﬂow problem.
Probabilistic checking of proofs and the hardness of approximation problems.
Polynomial time approximation schemes for euclidean traveling salesman and other geometric problems.
A simple bound on the expected height of a randomly built binary search tree.
Using Strassen’s algorithm to accelerate the solution of linear systems.
Improved decremental algorithms for maintaining transitive closure and all-pairs shortest paths.
On implementing the push-relabel method for the maximum ﬂow problem.
A measure of asymptotic efﬁciency for tests of a hypothesis based on the sum of observations.
Engineering a sorted list data structure for 32 bit keys.
Fully dynamic all pairs shortest paths with real edge weights.
Algorithm for solution of a problem of maximum ﬂow in a network with power estimation.
Veriﬁcation and sensitivity analysis of minimum spanning trees in linear time.
An alternative to Fibonacci heaps with applications to parallel computation.
Theoretical improvements in the algorithmic efﬁciency for network ﬂow problems.
New bounds on the complexity of the shortest path problem.
Fibonacci heaps and their uses in improved network optimization algorithms.
Efﬁcient algorithms for ﬁnding minimum spanning trees in undirected and directed graphs.
A linear-time algorithm for a special case of disjoint set union.
All pairs shortest distances for graphs with small integer length edges.
All pairs shortest paths for graphs with small integer length edges.
Improved approximation algorithms for maximum cut and satisﬁability problems using semideﬁnite programming.
The primal-dual method for approximation algorithms and its application to network design problems.
An efﬁcient algorithm for determining the convex hull of a ﬁnite planar set.
Randomized fully dynamic graph algorithms with polylogarithmic time per operation.
Efﬁcient bounds for the stable set, vertex cover and set packing problems.
On the distribution of the number of successes in independent trials.
Fast approximation algorithms for the knapsack and sum of subset problems.
On the identiﬁcation of the convex hull of a ﬁnite set of points in the plane.
The NP-completeness column: An ongoing guide—The tale of the second prover.
Finding the hidden path: Time bounds for all-pairs shortest paths.
Determining the maximal ﬂow in a network by the method of preﬂows.
On the shortest spanning subtree of a graph and the traveling salesman.
How to make a multiprocessor computer that correctly executes multiprocess programs.
Multicommodity max-ﬂow min-cut theorems and their use in designing approximation algorithms.
Guillotine subdivisions approximate polygonal subdivisions: A simple polynomial-time approximation scheme for geometric TSP, k-MST, and related problems.
Evaluation and comparison of two efﬁcient probabilistic primality testing algorithms.
A polynomial time primal network simplex algorithm for minimum cost ﬂows.
Randomized rounding: A technique for provably good algorithms and algorithmic proofs.
An analysis of several heuristics for the traveling salesman problem.
All pairs shortest paths in undirected graphs with integer weights.
Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time.
Efﬁciency of a good but not linear set union algorithm.
A class of algorithms which require nonlinear time to maintain disjoint sets.
Undirected single-source shortest paths with positive integer weights in linear time.
Preserving order in a forest in less than logarithmic time.
Preserving order in a forest in less than logarithmic time and linear space.
Numbers are alphabetized as if spelled out; for example, “2-3-4 tree” is indexed as if it were “two-three-four tree.” When an entry refers to a place other than the main text, the page number is followed by a tag: ex.
A tagged page number often indicates the ﬁrst page of an exercise or problem, which is not necessarily the page on which the reference actually appears.
